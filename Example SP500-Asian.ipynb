{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P500 Example: Hedging of an Asian Put Option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines\n",
    "from matplotlib import rc\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from scipy.optimize import minimize\n",
    "from matplotlib import rcParams\n",
    "from Functions import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only execute next box if program should run on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Data of 20 of the largest constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks =[]\n",
    "stocks += [pd.read_csv(\"time_series/AAPL.OQ.csv\")] #Apple Inc.\n",
    "stocks += [pd.read_csv(\"time_series/MSFT.OQ.csv\")] # Microsoft Corporation \n",
    "stocks += [pd.read_csv(\"time_series/AMZN.OQ.csv\")] # Amazon.com Inc.\n",
    "stocks += [pd.read_csv(\"time_series/GOOGL.OQ.csv\")] #Alphabet Inc. Class C\n",
    "stocks += [pd.read_csv(\"time_series/BRKb.N.csv\")] # Berkshire Hathaway Inc. Class B\n",
    "stocks += [pd.read_csv(\"time_series/JPM.N.csv\")] #JPMorgan Chase & Co.\n",
    "stocks += [pd.read_csv(\"time_series/JNJ.N.csv\")] #Johnson & Johnson\n",
    "stocks += [pd.read_csv(\"time_series/V.N.csv\")] # Visa Inc. Class A\n",
    "stocks += [pd.read_csv(\"time_series/UNH.N.csv\")] #UnitedHealth Group Incorporated\n",
    "stocks += [pd.read_csv(\"time_series/NVDA.OQ.csv\")] #NVIDIA Corporation\n",
    "stocks += [pd.read_csv(\"time_series/PG.N.csv\")] #Procter & Gamble Company\n",
    "stocks += [pd.read_csv(\"time_series/HD.N.csv\")] #Home Depot Inc.\n",
    "stocks += [pd.read_csv(\"time_series/MA.N.csv\")] # Mastercard Incorporated Class A\n",
    "stocks += [pd.read_csv(\"time_series/BAC.N.csv\")] # Bank of America Corp\n",
    "stocks += [pd.read_csv(\"time_series/DIS.N.csv\")] # Walt Disney Company\n",
    "stocks += [pd.read_csv(\"time_series/CMCSA.OQ.csv\")] #Comcast Corporation Class A\n",
    "stocks += [pd.read_csv(\"time_series/XOM.N.csv\")] #Exxon Mobil Corporation\n",
    "stocks += [pd.read_csv(\"time_series/ADBE.OQ.csv\")] # Adobe Inc.\n",
    "stocks += [pd.read_csv(\"time_series/VZ.N.csv\")] #Verizon Communications Inc.\n",
    "stocks += [pd.read_csv(\"time_series/INTC.OQ.csv\")] # Intel Corporation\n",
    "\n",
    "\n",
    "for i in range(len(stocks)):\n",
    "    # Clean the NaNs\n",
    "    stocks[i] = stocks[i].dropna()\n",
    "    # Reset Indices\n",
    "    stocks[i] = stocks[i].reset_index()\n",
    "    # Only Dates and Close Values\n",
    "    stocks[i]  = stocks[i] [[\"Date\",\"CLOSE\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the normalized evolution of the 20 considered stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the size of xticks and yticks\n",
    "labelsize = 18\n",
    "rcParams['xtick.labelsize'] = labelsize\n",
    "rcParams['ytick.labelsize'] = labelsize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalized_stocks = []\n",
    "for i in range(len(stocks)):\n",
    "    normalized_stocks+=[(100*stocks[i][\"CLOSE\"]/stocks[i][\"CLOSE\"][0]).tolist()]\n",
    "for i in range(len(normalized_stocks)):\n",
    "    plt.plot(range(len(normalized_stocks[i])),normalized_stocks[i])\n",
    "plt.title(\"Normalized evolution of the considered stocks from 2008-2020\",fontsize='xx-large')\n",
    "xtick_numbers = [0,1000,2000,2999]\n",
    "plt.xticks(xtick_numbers, stocks[0][\"Date\"].iloc[xtick_numbers], fontsize=15) # Scale here down\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on the test period (Feb 2020 - Mar 2020)\n",
    "and plot the normalized evolution in this period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_index = 2880\n",
    "end_index = 2910\n",
    "period = np.arange(start_index,end_index) # Feb to March 2020\n",
    "normalized_stocks_period_2 = []\n",
    "for i in range(len(stocks)):\n",
    "    normalized_stocks_period_2+=[(100*stocks[i][\"CLOSE\"][start_index:end_index]/stocks[i][\"CLOSE\"][start_index]).tolist()]\n",
    "for i in range(len(normalized_stocks_period_2)):\n",
    "    plt.plot(range(len(normalized_stocks_period_2[i])),normalized_stocks_period_2[i])\n",
    "plt.figsize=(3, 2)\n",
    "plt.title(\"Normalized evolution of the considered stocks\",fontsize = 'xx-large')\n",
    "xtick_numbers = [start_index,start_index+15,end_index]\n",
    "plt.xticks([0,15,29], stocks[0][\"Date\"].iloc[xtick_numbers])\n",
    "plt.yticks(np.arange(70,140,10), np.arange(70,140,10))\n",
    "plt.savefig('eps/fig_evolution_normalized.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maxmimum Likelihood Estimation for all constituents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function for the estimation (Can choose between stochastic gradient descent, gradient descent, and ADAM Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_max_parameters(x, \n",
    "                           iterations = 10000,\n",
    "                           learning_rate= 0.001,\n",
    "                           initial_guess= [0.25,0.25,0.05,0,0.75],\n",
    "                           tolerance = 10e-8,\n",
    "                           method = 'Adam'):\n",
    "    x_0 = np.array(initial_guess) #Initial guess\n",
    "    eps = tolerance # Tolerance to avoid that fractions and log-expressions become inf or -inf\n",
    "    \n",
    "    #Definte the Log-Likelihood Function\n",
    "    def log_likelihood(param):\n",
    "        a_0 = param[0]\n",
    "        a_1 = param[1]\n",
    "        b_0 = param[2]\n",
    "        b_1 = param[3]\n",
    "        gamma = param[4]\n",
    "        constant = np.sqrt(2*np.pi)\n",
    "        l= [np.log(1/((a_0+a_1*np.maximum(x[i],0))**gamma*constant+eps)+eps)-0.5*((x[i+1]-b_0-(1+b_1)*x[i])/(a_0+a_1*np.maximum(x[i],0)+eps)**gamma)**2 for i in range(len(x)-1)]\n",
    "        return -np.mean(l) # Mean instead of sum to have smaller values\n",
    "    \n",
    "    #Provide the gradients of the log-likelihood\n",
    "    def derivative(param):\n",
    "        a_0 = param[0]\n",
    "        a_1 = param[1]\n",
    "        b_0 = param[2]\n",
    "        b_1 = param[3]\n",
    "        gamma = param[4]\n",
    "        d1 = [gamma*(a_0+a_1*np.maximum(x[i],0))**(-2*gamma-1)*((x[i+1]-b_0-(1+b_1)*x[i]))**2-(gamma)/(a_0+a_1*np.maximum(x[i],0)+eps) for i in range(len(x)-1)]\n",
    "        d1 = -np.mean(d1)\n",
    "        d2 = [gamma*np.maximum(x[i],0)*(a_0+a_1*np.maximum(x[i],0))**(-2*gamma-1)*((x[i+1]-b_0-(1+b_1)*x[i]))**2-(gamma*np.maximum(x[i],0))/(a_0+a_1*np.maximum(x[i],0)+eps) for i in range(len(x)-1)]\n",
    "        d2 = -np.mean(d2)\n",
    "        d3 = [(x[i+1]-b_0-(1+b_1)*x[i])/((a_0+a_1*np.maximum(x[i],0)+eps)**(2*gamma)) for i in range(len(x)-1)]\n",
    "        d3 = -np.mean(d3)\n",
    "        d4 = [x[i]*(x[i+1]-b_0-(1+b_1)*x[i])/((a_0+a_1*np.maximum(x[i],0)+eps)**(2*gamma)) for i in range(len(x)-1)]\n",
    "        d4 = -np.mean(d4)\n",
    "        d5 = [np.log(a_0+a_1*np.maximum(x[i],0)+eps)*((-x[i+1]+b_0+(1+b_1)*x[i])**2/((a_0+a_1*np.maximum(x[i],0)+eps)**(2*gamma))-1)for i in range(len(x)-1)]\n",
    "        d5 = -np.mean(d5)        \n",
    "        return np.array([d1,d2,d3,d4,d5])\n",
    "\n",
    "\n",
    "        return(param)\n",
    "    \n",
    "    def derivative_sgd(param,index):\n",
    "        a_0 = param[0]\n",
    "        a_1 = param[1]\n",
    "        b_0 = param[2]\n",
    "        b_1 = param[3]\n",
    "        gamma = param[4]\n",
    "        d1 = [gamma*(a_0+a_1*np.maximum(x[i],0))**(-2*gamma-1)*((x[i+1]-b_0-(1+b_1)*x[i]))**2-(gamma)/(a_0+a_1*np.maximum(x[i],0)+eps) for i in range(len(x)-1)]\n",
    "        d2 = [gamma*np.maximum(x[i],0)*(a_0+a_1*np.maximum(x[i],0))**(-2*gamma-1)*((x[i+1]-b_0-(1+b_1)*x[i]))**2-(gamma*np.maximum(x[i],0))/(a_0+a_1*np.maximum(x[i],0)+eps) for i in range(len(x)-1)]\n",
    "        d3 = [(x[i+1]-b_0-(1+b_1)*x[i])/((a_0+a_1*np.maximum(x[i],0)+eps)**(2*gamma)) for i in range(len(x)-1)]\n",
    "        d4 = [x[i]*(x[i+1]-b_0-(1+b_1)*x[i])/((a_0+a_1*np.maximum(x[i],0)+eps)**(2*gamma)) for i in range(len(x)-1)]\n",
    "        d5 = [np.log(a_0+a_1*np.maximum(x[i],0)+eps)*((-x[i+1]+b_0+(1+b_1)*x[i])**2/((a_0+a_1*np.maximum(x[i],0)+eps)**(2*gamma))-1)for i in range(len(x)-1)]    \n",
    "        return np.array([-d1[index],-d2[index],-d3[index],-d4[index],-d5[index]])\n",
    "    \n",
    "    def gradient_descent(x_0,alpha=0.001,max_iter=1000):\n",
    "        # Decay of the learning rate\n",
    "        def l_r(iteration):\n",
    "            return alpha*(10./(iteration+10))\n",
    "        history=[]\n",
    "        # Initial value for the parameters\n",
    "        param=x_0\n",
    "        for i in range(max_iter):\n",
    "            param = np.maximum(param - l_r(i)*derivative(param),[0,0,-np.inf,-np.inf,0.1])\n",
    "            history+=[log_likelihood(param)]\n",
    "        plt.plot(range(iterations),history)\n",
    "        return(param)\n",
    "        \n",
    "    def Adam(x_0,alpha=0.001,p1 = 0.9,p2=0.999,max_iter=1000):\n",
    "        s = 0\n",
    "        r = 0\n",
    "        history=[]\n",
    "        # Initial value for the parameters\n",
    "        param=x_0\n",
    "        for i in range(max_iter):\n",
    "            index = np.random.randint(0,len(x)-1) # Choose Random Index\n",
    "            gradient = derivative_sgd(param,index)\n",
    "            s = p1*s+(1-p1)*gradient\n",
    "            r = p2*r+(1-p2)*gradient**2\n",
    "            s_hat = s/(1-p1**(i+1))\n",
    "            r_hat = r/(1-p2**(i+1))\n",
    "            update = -alpha*(s_hat/(np.sqrt(r_hat)+eps))\n",
    "            param = np.maximum(param +update,[0,0,-np.inf,-np.inf,0.1])\n",
    "            history+=[log_likelihood(param)]\n",
    "        plt.plot(range(iterations),history)\n",
    "        return(param)\n",
    "    \n",
    "    def stochastic_gradient_descent(x_0,alpha=0.001,p1 = 0.9,p2=0.999,max_iter=1000):\n",
    "        history=[]\n",
    "        # Initial value for the parameters\n",
    "        param=x_0\n",
    "        def l_r(iteration):\n",
    "            return alpha*(10./(iteration+10))\n",
    "        history=[]\n",
    "        # Initial value for the parameters\n",
    "        param=x_0\n",
    "        for i in range(max_iter):\n",
    "            index = np.random.randint(0,len(x)-1) # Choose Random Index\n",
    "            param = np.maximum(param - l_r(i)*derivative_sgd(param,index),[0,0,-np.inf,-np.inf,0.1])\n",
    "            history+=[log_likelihood(param)]\n",
    "        plt.plot(range(iterations),history)\n",
    "        return(param)\n",
    "    \n",
    "    if method == 'sgd':\n",
    "        return stochastic_gradient_descent(x_0,alpha=learning_rate,max_iter=iterations)\n",
    "    if method == 'Adam':\n",
    "        return Adam(x_0,alpha=learning_rate,max_iter=iterations)\n",
    "    if method == 'gradient_descent':\n",
    "        return gradient_descent(x_0,alpha=learning_rate,max_iter=iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determination of MLE-Parameters (Takes very long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_index = 2880\n",
    "end_index = 2910\n",
    "list_parameters=[]\n",
    "\n",
    "for j in range(len(stocks)):\n",
    "    print(\"MLE for stock {}\".format((str(j))))\n",
    "    #Create lists for the parameters\n",
    "    list_a0 = []\n",
    "    list_a1 = []\n",
    "    list_b0 = []\n",
    "    list_b1 = []\n",
    "    list_gamma = []\n",
    "    list_a0_rescaled = []\n",
    "    list_a1_rescaled = []\n",
    "    list_b0_rescaled = []\n",
    "    list_b1_rescaled = []\n",
    "    \n",
    "    #Compute optimal parameters\n",
    "    for i in np.arange(279,start_index,100): # until 9 March 2020\n",
    "        x = np.array(stocks[j].iloc[(i-250):i][\"CLOSE\"])\n",
    "        a0,a1,b0,b1,gamma = compute_max_parameters(x)\n",
    "        \n",
    "        list_a0 += [a0]\n",
    "        list_a1 += [a1]\n",
    "        list_b0 += [b0]\n",
    "        list_b1 += [b1]\n",
    "        list_gamma += [gamma]\n",
    "        # Rescale the parameters\n",
    "    list_parameters+= [pd.DataFrame({'a0': list_a0,\n",
    "                   'a1': list_a1,\n",
    "                   'b0': list_b0,\n",
    "                   'b1': list_b1,\n",
    "                   'gamma': list_gamma})]\n",
    "    list_parameters[j].to_csv('csv/mle_parameters_stock'+str(j)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the estimated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_parameters=[]\n",
    "for j in range(len(stocks)):\n",
    "    list_parameters+= [pd.read_csv('csv/mle_parameters_stock'+str(j)+'.csv')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the estimated parameters for a single company (Apple Inc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the parameters\n",
    "list_a0 = list_parameters[0]['a0']\n",
    "list_a1 = list_parameters[0]['a1']\n",
    "list_b0 = list_parameters[0]['b0']\n",
    "list_b1 = list_parameters[0]['b1']\n",
    "list_gamma = list_parameters[0]['gamma']\n",
    "\n",
    "\n",
    "# Display the parameters\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot((list_a0, list_a1, list_b0,list_b1,list_gamma), vert=False, showmeans=True, meanline=True,\n",
    "           labels=('$a_0$', '$a_1$', '$b_0$','$b_1$','$\\gamma$'), patch_artist=True,\n",
    "           medianprops={'linewidth': 2, 'color': 'purple'},\n",
    "           meanprops={'linewidth': 2, 'color': 'red'})\n",
    "fig.suptitle(\"Estimated Parameters for Apple Inc.\",fontsize = 'xx-large')\n",
    "plt.savefig('eps/fig_parameter_estimation_sp500_single.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the estimated parameters for all companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the parameters\n",
    "list_a0 = []\n",
    "list_a1 = []\n",
    "list_b0 = []\n",
    "list_b1 = []\n",
    "list_gamma = []\n",
    "for j in range(20):\n",
    "    list_a0 += list_parameters[j]['a0'].dropna().tolist()\n",
    "    list_a1 += list_parameters[j]['a1'].dropna().tolist()\n",
    "    list_b0 += list_parameters[j]['b0'].dropna().tolist()\n",
    "    list_b1 += list_parameters[j]['b1'].dropna().tolist()\n",
    "    list_gamma += list_parameters[j]['gamma'].dropna().tolist()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot((list_a0, list_a1, list_b0,list_b1,list_gamma), vert=False, showmeans=True, meanline=True,\n",
    "           labels=('$a_0$', '$a_1$', '$b_0$','$b_1$','$\\gamma$'), patch_artist=True,\n",
    "           medianprops={'linewidth': 2, 'color': 'purple'},\n",
    "           meanprops={'linewidth': 2, 'color': 'red'})\n",
    "fig.suptitle(\"Estimated Parameters for all constituents\",fontsize = 'xx-large')\n",
    "plt.savefig('eps/fig_parameter_estimation_sp500_all.eps', format='eps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Hedges and Hedging Errors for all stocks.\n",
    "Also compute the (relative) hedging errors, when fixing one parameters and choosing the other parameters to be robust. (Sensitivity analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 1 \n",
      "\n",
      "tf.Tensor(0.289758, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.34066639921185243, Loss: 0.0029711597296306013\n",
      "Iteration:20, Price of Hedge: 0.1615267907540286, Loss: 0.002426328183362658\n",
      "Iteration:30, Price of Hedge: 0.2974343832027643, Loss: 0.0022619987094774975\n",
      "Iteration:40, Price of Hedge: 0.23127552851173336, Loss: 0.002357425956355641\n",
      "Iteration:50, Price of Hedge: 0.2616092998533276, Loss: 0.002372071228490613\n",
      "Iteration:60, Price of Hedge: 0.23638717197779613, Loss: 0.0029894396909754483\n",
      "Iteration:70, Price of Hedge: 0.26209699891907406, Loss: 0.0024531634532398705\n",
      "Iteration:80, Price of Hedge: 0.24864697558407728, Loss: 0.002446930565477157\n",
      "Iteration:90, Price of Hedge: 0.2663989092356701, Loss: 0.0023492122714254826\n",
      "Iteration:100, Price of Hedge: 0.22608282496917412, Loss: 0.002309903092127552\n",
      "Iteration:110, Price of Hedge: 0.2595691144050676, Loss: 0.0024732034345942735\n",
      "Iteration:120, Price of Hedge: 0.2391635167813206, Loss: 0.002786805961189098\n",
      "Iteration:130, Price of Hedge: 0.2437478483369148, Loss: 0.0030188106058774314\n",
      "Iteration:140, Price of Hedge: 0.25912898545760754, Loss: 0.002842258598668868\n",
      "Iteration:150, Price of Hedge: 0.2228159799412964, Loss: 0.0025407556286472176\n",
      "Iteration:160, Price of Hedge: 0.2633832760778887, Loss: 0.0019102921757369717\n",
      "Iteration:170, Price of Hedge: 0.2534386920326284, Loss: 0.0026950027519912823\n",
      "Iteration:180, Price of Hedge: 0.2324425457231399, Loss: 0.0021135866876835995\n",
      "Iteration:190, Price of Hedge: 0.23974343097996212, Loss: 0.0018416597229237608\n",
      "Iteration:200, Price of Hedge: 0.2725306702148771, Loss: 0.00220036586089023\n",
      "Iteration:210, Price of Hedge: 0.25096534334990395, Loss: 0.0021082278063362827\n",
      "Iteration:220, Price of Hedge: 0.2527044414314588, Loss: 0.0024538447638025487\n",
      "Iteration:230, Price of Hedge: 0.2151244693984097, Loss: 0.002598571162708918\n",
      "Iteration:240, Price of Hedge: 0.2619307142116924, Loss: 0.0023096308002994895\n",
      "Iteration:250, Price of Hedge: 0.26027939402948735, Loss: 0.002362489306174065\n",
      "Iteration:260, Price of Hedge: 0.25806318179125753, Loss: 0.0024155230781257365\n",
      "Iteration:270, Price of Hedge: 0.2452820404269346, Loss: 0.002036511638887051\n",
      "Iteration:280, Price of Hedge: 0.24809152814247, Loss: 0.0022571332844444794\n",
      "Iteration:290, Price of Hedge: 0.24166695932730706, Loss: 0.0026984898691008842\n",
      "Iteration:300, Price of Hedge: 0.24317428012591336, Loss: 0.002578023006563024\n",
      "Iteration:310, Price of Hedge: 0.26724552843829485, Loss: 0.0021933517318512676\n",
      "Iteration:320, Price of Hedge: 0.21936398576621627, Loss: 0.002155416406200761\n",
      "Iteration:330, Price of Hedge: 0.20899684818457728, Loss: 0.002257501633702641\n",
      "Iteration:340, Price of Hedge: 0.26065720339520054, Loss: 0.0027452233581574336\n",
      "Iteration:350, Price of Hedge: 0.2683864180287145, Loss: 0.0023147454711239137\n",
      "Iteration:360, Price of Hedge: 0.269998298889297, Loss: 0.0022665455569449654\n",
      "Iteration:370, Price of Hedge: 0.22995357996145743, Loss: 0.0024854641197598728\n",
      "Iteration:380, Price of Hedge: 0.21822443478256445, Loss: 0.002288248338893784\n",
      "Iteration:390, Price of Hedge: 0.24931213920261827, Loss: 0.0025120170272719955\n",
      "Iteration:400, Price of Hedge: 0.2521434908286949, Loss: 0.002465986539165566\n",
      "Iteration:410, Price of Hedge: 0.25874931691582786, Loss: 0.002268077246893863\n",
      "Iteration:420, Price of Hedge: 0.26431593794886793, Loss: 0.00239858385385463\n",
      "Iteration:430, Price of Hedge: 0.25260389718978615, Loss: 0.002648011883248036\n",
      "Iteration:440, Price of Hedge: 0.24625914900040868, Loss: 0.002314085076291983\n",
      "Iteration:450, Price of Hedge: 0.24717626815947255, Loss: 0.001978850842500046\n",
      "Iteration:460, Price of Hedge: 0.22972219930273638, Loss: 0.002387352493771644\n",
      "Iteration:470, Price of Hedge: 0.23149178787178074, Loss: 0.0021090563016708864\n",
      "Iteration:480, Price of Hedge: 0.25507781601983764, Loss: 0.002530727697738899\n",
      "Iteration:490, Price of Hedge: 0.2692791200087726, Loss: 0.002255912812822536\n",
      "Iteration:500, Price of Hedge: 0.2838240741018268, Loss: 0.0022785314326482452\n",
      "Iteration:510, Price of Hedge: 0.2488263984689951, Loss: 0.0019643947802626682\n",
      "Iteration:520, Price of Hedge: 0.2369550635045414, Loss: 0.0019158362000342378\n",
      "Iteration:530, Price of Hedge: 0.22200932062959283, Loss: 0.0023295615550599892\n",
      "Iteration:540, Price of Hedge: 0.24782291438439188, Loss: 0.0028585641537639986\n",
      "Iteration:550, Price of Hedge: 0.248920299254857, Loss: 0.002246667672503855\n",
      "Iteration:560, Price of Hedge: 0.2513781052256661, Loss: 0.0023101403307401957\n",
      "Iteration:570, Price of Hedge: 0.22723424989063687, Loss: 0.002738143770627799\n",
      "Iteration:580, Price of Hedge: 0.2212824323656463, Loss: 0.002565766001016723\n",
      "Iteration:590, Price of Hedge: 0.24254622566165837, Loss: 0.002025764245573858\n",
      "Iteration:600, Price of Hedge: 0.25877194928580993, Loss: 0.002517455504594657\n",
      "Iteration:610, Price of Hedge: 0.2537171470293515, Loss: 0.0020864917141496077\n",
      "Iteration:620, Price of Hedge: 0.2261362700838305, Loss: 0.00239653527422643\n",
      "Iteration:630, Price of Hedge: 0.22510065943679933, Loss: 0.0023990033304546188\n",
      "Iteration:640, Price of Hedge: 0.24408180593647444, Loss: 0.0026035307085302997\n",
      "Iteration:650, Price of Hedge: 0.2708747144870131, Loss: 0.002129796379012805\n",
      "Iteration:660, Price of Hedge: 0.24794941272395193, Loss: 0.0014942441094453085\n",
      "Iteration:670, Price of Hedge: 0.24086667079225776, Loss: 0.0014565441825977966\n",
      "Iteration:680, Price of Hedge: 0.24235396206737506, Loss: 0.002010193452353315\n",
      "Iteration:690, Price of Hedge: 0.2585889319938303, Loss: 0.0019001933637411207\n",
      "Iteration:700, Price of Hedge: 0.28690958749069184, Loss: 0.0022225609371683054\n",
      "Iteration:710, Price of Hedge: 0.2668570597964674, Loss: 0.0017461094992953896\n",
      "Iteration:720, Price of Hedge: 0.2255936633515887, Loss: 0.0014087766236863808\n",
      "Iteration:730, Price of Hedge: 0.2498061594669906, Loss: 0.0016092733661492887\n",
      "Iteration:740, Price of Hedge: 0.2661803940753288, Loss: 0.0012787826457930974\n",
      "Iteration:750, Price of Hedge: 0.25393149763530404, Loss: 0.001647370014056393\n",
      "Iteration:760, Price of Hedge: 0.2654496387251641, Loss: 0.0016828525829484242\n",
      "Iteration:770, Price of Hedge: 0.2577375533004755, Loss: 0.0020167894604415037\n",
      "Iteration:780, Price of Hedge: 0.259557736247541, Loss: 0.001302321848267951\n",
      "Iteration:790, Price of Hedge: 0.2655485468918983, Loss: 0.0014220080505220835\n",
      "Iteration:800, Price of Hedge: 0.2698556876904945, Loss: 0.0014642283896773689\n",
      "Iteration:810, Price of Hedge: 0.2650652106926543, Loss: 0.002148162520914898\n",
      "Iteration:820, Price of Hedge: 0.2656115109880148, Loss: 0.0016972908280818322\n",
      "Iteration:830, Price of Hedge: 0.2546391496242166, Loss: 0.0013972788785326263\n",
      "Iteration:840, Price of Hedge: 0.27009299292361394, Loss: 0.0018841862451374868\n",
      "Iteration:850, Price of Hedge: 0.24383607243852054, Loss: 0.0014609816098071881\n",
      "Iteration:860, Price of Hedge: 0.2360307803203682, Loss: 0.0014652001965004269\n",
      "Iteration:870, Price of Hedge: 0.22610196208815125, Loss: 0.001530480903461373\n",
      "Iteration:880, Price of Hedge: 0.2680430158147374, Loss: 0.0018949165960034044\n",
      "Iteration:890, Price of Hedge: 0.2853583901369177, Loss: 0.0020867552910898593\n",
      "Iteration:900, Price of Hedge: 0.26479994345149577, Loss: 0.0018528585474255844\n",
      "Iteration:910, Price of Hedge: 0.2605524945991391, Loss: 0.001630997063828854\n",
      "Iteration:920, Price of Hedge: 0.23806972631791723, Loss: 0.0016016490981314413\n",
      "Iteration:930, Price of Hedge: 0.2352462823873765, Loss: 0.00214478792269015\n",
      "Iteration:940, Price of Hedge: 0.24150322788838993, Loss: 0.0014400418647023017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:950, Price of Hedge: 0.2556174480703732, Loss: 0.0015713827769228805\n",
      "Iteration:960, Price of Hedge: 0.255936383527316, Loss: 0.0015350704538791172\n",
      "Iteration:970, Price of Hedge: 0.26263754816313567, Loss: 0.0017406429406675583\n",
      "Iteration:980, Price of Hedge: 0.25493356874609674, Loss: 0.001418428942930028\n",
      "Iteration:990, Price of Hedge: 0.2509637320639797, Loss: 0.0016191961374113495\n",
      "tf.Tensor(0.43594366, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.5136683840886065, Loss: 0.0067143779550550954\n",
      "Iteration:20, Price of Hedge: 0.4192270489826115, Loss: 0.01123772853567031\n",
      "Iteration:30, Price of Hedge: 0.4289375007885724, Loss: 0.008587627984310143\n",
      "Iteration:40, Price of Hedge: 0.45419701049754624, Loss: 0.006544398909898064\n",
      "Iteration:50, Price of Hedge: 0.5413408068636386, Loss: 0.00741346456489822\n",
      "Iteration:60, Price of Hedge: 0.4805303803024913, Loss: 0.008521916955555486\n",
      "Iteration:70, Price of Hedge: 0.3706281370280465, Loss: 0.006616118175974073\n",
      "Iteration:80, Price of Hedge: 0.4466995235689524, Loss: 0.007966960646292431\n",
      "Iteration:90, Price of Hedge: 0.4738310500537239, Loss: 0.00657681209530292\n",
      "Iteration:100, Price of Hedge: 0.47423471436126763, Loss: 0.006037838890285974\n",
      "Iteration:110, Price of Hedge: 0.46115325408968033, Loss: 0.007548471733588968\n",
      "Iteration:120, Price of Hedge: 0.4756908210564973, Loss: 0.006913892335997485\n",
      "Iteration:130, Price of Hedge: 0.4589514442687119, Loss: 0.007906587776818519\n",
      "Iteration:140, Price of Hedge: 0.4348582576787465, Loss: 0.009095526223361716\n",
      "Iteration:150, Price of Hedge: 0.41262779198424654, Loss: 0.008221118535797345\n",
      "Iteration:160, Price of Hedge: 0.49321134926035487, Loss: 0.007148491693283532\n",
      "Iteration:170, Price of Hedge: 0.4407392529901131, Loss: 0.007962149253563843\n",
      "Iteration:180, Price of Hedge: 0.4527399122417478, Loss: 0.00750973502558816\n",
      "Iteration:190, Price of Hedge: 0.4628500621129774, Loss: 0.007693396057280743\n",
      "Iteration:200, Price of Hedge: 0.4787211293106964, Loss: 0.008084606209149482\n",
      "Iteration:210, Price of Hedge: 0.48330451888375026, Loss: 0.007827744767781298\n",
      "Iteration:220, Price of Hedge: 0.46942990931320877, Loss: 0.008005456436061298\n",
      "Iteration:230, Price of Hedge: 0.4310685627629596, Loss: 0.00702292758969687\n",
      "Iteration:240, Price of Hedge: 0.4796592447648038, Loss: 0.007179284296883815\n",
      "Iteration:250, Price of Hedge: 0.5072917572269432, Loss: 0.00683153083625454\n",
      "Iteration:260, Price of Hedge: 0.54168740686045, Loss: 0.006913545289798417\n",
      "Iteration:270, Price of Hedge: 0.47632973310898025, Loss: 0.007830414234750017\n",
      "Iteration:280, Price of Hedge: 0.42091022304808806, Loss: 0.006059731850453254\n",
      "Iteration:290, Price of Hedge: 0.49316434928939545, Loss: 0.006441137947198339\n",
      "Iteration:300, Price of Hedge: 0.43688352014044657, Loss: 0.006455538427817898\n",
      "Iteration:310, Price of Hedge: 0.4465527726047753, Loss: 0.00758145971426103\n",
      "Iteration:320, Price of Hedge: 0.453020077680452, Loss: 0.006614111040479021\n",
      "Iteration:330, Price of Hedge: 0.4709913693188696, Loss: 0.005905850171404748\n",
      "Iteration:340, Price of Hedge: 0.47361657550270025, Loss: 0.006569811522756108\n",
      "Iteration:350, Price of Hedge: 0.4440433311173479, Loss: 0.005304737492322431\n",
      "Iteration:360, Price of Hedge: 0.459799129398948, Loss: 0.005132681592567856\n",
      "Iteration:370, Price of Hedge: 0.5133713125422048, Loss: 0.014237440174412797\n",
      "Iteration:380, Price of Hedge: 0.44557519304003107, Loss: 0.007650394864177556\n",
      "Iteration:390, Price of Hedge: 0.42460051401685633, Loss: 0.007793647478722932\n",
      "Iteration:400, Price of Hedge: 0.4076563056045785, Loss: 0.006218394710619269\n",
      "Iteration:410, Price of Hedge: 0.4298318388435689, Loss: 0.006820345568244868\n",
      "Iteration:420, Price of Hedge: 0.48286694320475476, Loss: 0.009059412502927966\n",
      "Iteration:430, Price of Hedge: 0.4565588086162848, Loss: 0.009120231574657823\n",
      "Iteration:440, Price of Hedge: 0.450689910343857, Loss: 0.006470995540168545\n",
      "Iteration:450, Price of Hedge: 0.41790510043233553, Loss: 0.006185464054542589\n",
      "Iteration:460, Price of Hedge: 0.4592169346109984, Loss: 0.0071028458222258456\n",
      "Iteration:470, Price of Hedge: 0.44549423211959155, Loss: 0.0062017349437506475\n",
      "Iteration:480, Price of Hedge: 0.4681481189659678, Loss: 0.005061710644858586\n",
      "Iteration:490, Price of Hedge: 0.48378512829143006, Loss: 0.00654126155028596\n",
      "Iteration:500, Price of Hedge: 0.4877959412140513, Loss: 0.0043574958076988855\n",
      "Iteration:510, Price of Hedge: 0.48382146898627526, Loss: 0.006349651766252684\n",
      "Iteration:520, Price of Hedge: 0.44716030176525695, Loss: 0.007570470434395027\n",
      "Iteration:530, Price of Hedge: 0.42414444573325344, Loss: 0.005456380800852623\n",
      "Iteration:540, Price of Hedge: 0.4483160151861796, Loss: 0.005331276068685708\n",
      "Iteration:550, Price of Hedge: 0.45650114936921116, Loss: 0.0056827037260162696\n",
      "Iteration:560, Price of Hedge: 0.4025756484062896, Loss: 0.005513968392182012\n",
      "Iteration:570, Price of Hedge: 0.40858867000738713, Loss: 0.0048917002261054335\n",
      "Iteration:580, Price of Hedge: 0.4475184534426944, Loss: 0.0051413631701414\n",
      "Iteration:590, Price of Hedge: 0.47525954178711344, Loss: 0.005634561523761051\n",
      "Iteration:600, Price of Hedge: 0.4955809311295582, Loss: 0.004411956884609891\n",
      "Iteration:610, Price of Hedge: 0.487161292872014, Loss: 0.004350763653696666\n",
      "Iteration:620, Price of Hedge: 0.49803846442121086, Loss: 0.004513792091663671\n",
      "Iteration:630, Price of Hedge: 0.46227366795435504, Loss: 0.0041844684884495996\n",
      "Iteration:640, Price of Hedge: 0.48442964266112654, Loss: 0.004895202449020575\n",
      "Iteration:650, Price of Hedge: 0.4823053728766354, Loss: 0.005162028299448141\n",
      "Iteration:660, Price of Hedge: 0.4484969254119506, Loss: 0.003904520728276495\n",
      "Iteration:670, Price of Hedge: 0.4858861955586122, Loss: 0.005471561748091736\n",
      "Iteration:680, Price of Hedge: 0.5032058831692666, Loss: 0.004949247535286716\n",
      "Iteration:690, Price of Hedge: 0.4860733030379379, Loss: 0.0056256510351343275\n",
      "Iteration:700, Price of Hedge: 0.46339765143707723, Loss: 0.005072989646328275\n",
      "Iteration:710, Price of Hedge: 0.4507547584050542, Loss: 0.005198250084490752\n",
      "Iteration:720, Price of Hedge: 0.45622777612040294, Loss: 0.005391701614814837\n",
      "Iteration:730, Price of Hedge: 0.43181763719463223, Loss: 0.00493624027473194\n",
      "Iteration:740, Price of Hedge: 0.4764038026834669, Loss: 0.004695937120205418\n",
      "Iteration:750, Price of Hedge: 0.4918489946169018, Loss: 0.004495080646540073\n",
      "Iteration:760, Price of Hedge: 0.4606224717172211, Loss: 0.005123016975649187\n",
      "Iteration:770, Price of Hedge: 0.46353384228119693, Loss: 0.004481191439338783\n",
      "Iteration:780, Price of Hedge: 0.4310312305075456, Loss: 0.00462859582643751\n",
      "Iteration:790, Price of Hedge: 0.4347145805523326, Loss: 0.005097422705796317\n",
      "Iteration:800, Price of Hedge: 0.44537742628459115, Loss: 0.004305190600368248\n",
      "Iteration:810, Price of Hedge: 0.4354301898148094, Loss: 0.00476066898289842\n",
      "Iteration:820, Price of Hedge: 0.4823965468709332, Loss: 0.0044656766150644065\n",
      "Iteration:830, Price of Hedge: 0.5126351779759546, Loss: 0.005133968297337166\n",
      "Iteration:840, Price of Hedge: 0.4839207241992085, Loss: 0.005910222721115988\n",
      "Iteration:850, Price of Hedge: 0.4640510898518926, Loss: 0.004684156141197793\n",
      "Iteration:860, Price of Hedge: 0.47979117189847786, Loss: 0.005293133522369465\n",
      "Iteration:870, Price of Hedge: 0.45760872252452034, Loss: 0.004732366125913767\n",
      "Iteration:880, Price of Hedge: 0.4986785167683479, Loss: 0.004975771393172801\n",
      "Iteration:890, Price of Hedge: 0.46626217076417903, Loss: 0.0051545017350058675\n",
      "Iteration:900, Price of Hedge: 0.4494407423393284, Loss: 0.004602834618067009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:910, Price of Hedge: 0.41188900499347486, Loss: 0.0038459574568405763\n",
      "Iteration:920, Price of Hedge: 0.41755631900227286, Loss: 0.004566927343642302\n",
      "Iteration:930, Price of Hedge: 0.43570519913855604, Loss: 0.005255649046915068\n",
      "Iteration:940, Price of Hedge: 0.4420870316932053, Loss: 0.003632817251972975\n",
      "Iteration:950, Price of Hedge: 0.4964163704867701, Loss: 0.00579562581967954\n",
      "Iteration:960, Price of Hedge: 0.46251669944975904, Loss: 0.003919311635870004\n",
      "Iteration:970, Price of Hedge: 0.4450358832466805, Loss: 0.004646720081786793\n",
      "Iteration:980, Price of Hedge: 0.44484634644396126, Loss: 0.004341908165695241\n",
      "Iteration:990, Price of Hedge: 0.47694494686386973, Loss: 0.004502441047121409\n",
      "tf.Tensor(0.23284706, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.2201586224060236, Loss: 0.0038381032126165947\n",
      "Iteration:20, Price of Hedge: 0.27455305715092776, Loss: 0.002721777985974683\n",
      "Iteration:30, Price of Hedge: 0.28239731759943254, Loss: 0.0019714296313682045\n",
      "Iteration:40, Price of Hedge: 0.2757135052735663, Loss: 0.0020402795690483535\n",
      "Iteration:50, Price of Hedge: 0.24858584587501298, Loss: 0.0020331664776166883\n",
      "Iteration:60, Price of Hedge: 0.24630022439696972, Loss: 0.0022774256102170653\n",
      "Iteration:70, Price of Hedge: 0.2513820962569554, Loss: 0.0024881680589514898\n",
      "Iteration:80, Price of Hedge: 0.27614590004858997, Loss: 0.0024021062178438248\n",
      "Iteration:90, Price of Hedge: 0.25744898438595104, Loss: 0.0021953224584816858\n",
      "Iteration:100, Price of Hedge: 0.25970079364859944, Loss: 0.0023631863035348034\n",
      "Iteration:110, Price of Hedge: 0.25420338354325905, Loss: 0.002148885662939071\n",
      "Iteration:120, Price of Hedge: 0.24268206945957901, Loss: 0.002654224048944176\n",
      "Iteration:130, Price of Hedge: 0.2341873700669794, Loss: 0.002274596176640964\n",
      "Iteration:140, Price of Hedge: 0.20423682449070527, Loss: 0.0023187736859345168\n",
      "Iteration:150, Price of Hedge: 0.22758008142800748, Loss: 0.0024101055165338227\n",
      "Iteration:160, Price of Hedge: 0.26046756743642446, Loss: 0.0019306728123727136\n",
      "Iteration:170, Price of Hedge: 0.2412714753944556, Loss: 0.0028956338005585724\n",
      "Iteration:180, Price of Hedge: 0.21681039504446462, Loss: 0.002787476813886403\n",
      "Iteration:190, Price of Hedge: 0.24935222303861054, Loss: 0.0022011306407117236\n",
      "Iteration:200, Price of Hedge: 0.22488115271588924, Loss: 0.0028819409688292997\n",
      "Iteration:210, Price of Hedge: 0.24896529131566467, Loss: 0.0027551687881278045\n",
      "Iteration:220, Price of Hedge: 0.2865239943745138, Loss: 0.0022763765313887465\n",
      "Iteration:230, Price of Hedge: 0.28818379239958175, Loss: 0.001774778187903947\n",
      "Iteration:240, Price of Hedge: 0.2809468132214164, Loss: 0.0030203078236034297\n",
      "Iteration:250, Price of Hedge: 0.25284782108970205, Loss: 0.002052370991726238\n",
      "Iteration:260, Price of Hedge: 0.25794672300245625, Loss: 0.002996372287397331\n",
      "Iteration:270, Price of Hedge: 0.24120910623468036, Loss: 0.0026415390455742484\n",
      "Iteration:280, Price of Hedge: 0.24448661053867227, Loss: 0.0018085257194648153\n",
      "Iteration:290, Price of Hedge: 0.2667044586249347, Loss: 0.0024474464868355916\n",
      "Iteration:300, Price of Hedge: 0.27633618052173575, Loss: 0.0023590246541085992\n",
      "Iteration:310, Price of Hedge: 0.25473909892954794, Loss: 0.0021232427833786315\n",
      "Iteration:320, Price of Hedge: 0.22496402239042368, Loss: 0.0021588547199386187\n",
      "Iteration:330, Price of Hedge: 0.23151930367756393, Loss: 0.00211869845354542\n",
      "Iteration:340, Price of Hedge: 0.2258542950470883, Loss: 0.0027885069136257103\n",
      "Iteration:350, Price of Hedge: 0.2573008948150061, Loss: 0.0020159086757800316\n",
      "Iteration:360, Price of Hedge: 0.2757645210648292, Loss: 0.001844962471740108\n",
      "Iteration:370, Price of Hedge: 0.28172850999580135, Loss: 0.0024481692415314173\n",
      "Iteration:380, Price of Hedge: 0.2381392595028018, Loss: 0.002032227206374793\n",
      "Iteration:390, Price of Hedge: 0.24085539179078808, Loss: 0.001933407156839584\n",
      "Iteration:400, Price of Hedge: 0.23068383953133775, Loss: 0.0024022444940637656\n",
      "Iteration:410, Price of Hedge: 0.2317732919172528, Loss: 0.002033520302061831\n",
      "Iteration:420, Price of Hedge: 0.2091563902800914, Loss: 0.0027688871835279904\n",
      "Iteration:430, Price of Hedge: 0.22714736439579894, Loss: 0.0022553721024498818\n",
      "Iteration:440, Price of Hedge: 0.1949312268649706, Loss: 0.0017986988119686798\n",
      "Iteration:450, Price of Hedge: 0.2049527064323385, Loss: 0.0023868102340856012\n",
      "Iteration:460, Price of Hedge: 0.2237131191548997, Loss: 0.002606072744472798\n",
      "Iteration:470, Price of Hedge: 0.2344951752565379, Loss: 0.0018365878518816993\n",
      "Iteration:480, Price of Hedge: 0.2549067470327117, Loss: 0.0021006175789710204\n",
      "Iteration:490, Price of Hedge: 0.25571380296864277, Loss: 0.001978468162093039\n",
      "Iteration:500, Price of Hedge: 0.26572211956946035, Loss: 0.0019393435447525365\n",
      "Iteration:510, Price of Hedge: 0.2384023948887375, Loss: 0.0023286767034508718\n",
      "Iteration:520, Price of Hedge: 0.23418994812445817, Loss: 0.0020870971083562398\n",
      "Iteration:530, Price of Hedge: 0.27549622956393593, Loss: 0.001518580530490732\n",
      "Iteration:540, Price of Hedge: 0.2817375579859913, Loss: 0.0012516909645500563\n",
      "Iteration:550, Price of Hedge: 0.272976550213636, Loss: 0.0020668268602994423\n",
      "Iteration:560, Price of Hedge: 0.24441938273211009, Loss: 0.0013802928843635986\n",
      "Iteration:570, Price of Hedge: 0.23901872414926686, Loss: 0.0022956807825476933\n",
      "Iteration:580, Price of Hedge: 0.23162497924517994, Loss: 0.002091031008714306\n",
      "Iteration:590, Price of Hedge: 0.2743211063448797, Loss: 0.0022499229735976735\n",
      "Iteration:600, Price of Hedge: 0.23928609845663404, Loss: 0.0018975475238015794\n",
      "Iteration:610, Price of Hedge: 0.258943935466462, Loss: 0.0017426243188275238\n",
      "Iteration:620, Price of Hedge: 0.24878581885271842, Loss: 0.0013888052962815146\n",
      "Iteration:630, Price of Hedge: 0.27381317944353045, Loss: 0.0017639058811987907\n",
      "Iteration:640, Price of Hedge: 0.2710837602439227, Loss: 0.001602987898563446\n",
      "Iteration:650, Price of Hedge: 0.24732874538593422, Loss: 0.0014067684230383737\n",
      "Iteration:660, Price of Hedge: 0.24047993738142567, Loss: 0.0017078674095939218\n",
      "Iteration:670, Price of Hedge: 0.2401589196472884, Loss: 0.0019036446529786088\n",
      "Iteration:680, Price of Hedge: 0.2744144369834146, Loss: 0.0015829750301933454\n",
      "Iteration:690, Price of Hedge: 0.265601248336128, Loss: 0.0017069815896639362\n",
      "Iteration:700, Price of Hedge: 0.23167408628234795, Loss: 0.0012761997467099718\n",
      "Iteration:710, Price of Hedge: 0.21080731383806892, Loss: 0.0016983135685825436\n",
      "Iteration:720, Price of Hedge: 0.24958070338266794, Loss: 0.0018008420933777636\n",
      "Iteration:730, Price of Hedge: 0.30170505936144426, Loss: 0.0016654944630698498\n",
      "Iteration:740, Price of Hedge: 0.2896435926579301, Loss: 0.001719287979574502\n",
      "Iteration:750, Price of Hedge: 0.26369636132747587, Loss: 0.001341734831562924\n",
      "Iteration:760, Price of Hedge: 0.21652033878908697, Loss: 0.0015943179408403174\n",
      "Iteration:770, Price of Hedge: 0.2159277574041795, Loss: 0.0013183484301210302\n",
      "Iteration:780, Price of Hedge: 0.268596579291264, Loss: 0.0018620537223874801\n",
      "Iteration:790, Price of Hedge: 0.2568495612331191, Loss: 0.0014103953656813052\n",
      "Iteration:800, Price of Hedge: 0.2559229974596377, Loss: 0.0015519085854516113\n",
      "Iteration:810, Price of Hedge: 0.2419292518867593, Loss: 0.0013330432802844405\n",
      "Iteration:820, Price of Hedge: 0.23107954656531718, Loss: 0.001372388093790311\n",
      "Iteration:830, Price of Hedge: 0.2291706437363615, Loss: 0.0017467942958131922\n",
      "Iteration:840, Price of Hedge: 0.23584476355766812, Loss: 0.0014687674905778936\n",
      "Iteration:850, Price of Hedge: 0.24465728290157074, Loss: 0.001608380574309054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:860, Price of Hedge: 0.2620769446065708, Loss: 0.001432440739553198\n",
      "Iteration:870, Price of Hedge: 0.24591326788500964, Loss: 0.001554877069904348\n",
      "Iteration:880, Price of Hedge: 0.24115043063802374, Loss: 0.0016540018500166953\n",
      "Iteration:890, Price of Hedge: 0.2691840045612139, Loss: 0.0016884547064977661\n",
      "Iteration:900, Price of Hedge: 0.24460497808156845, Loss: 0.001374127004404946\n",
      "Iteration:910, Price of Hedge: 0.22096694258167987, Loss: 0.0012747516228519774\n",
      "Iteration:920, Price of Hedge: 0.2073055929004653, Loss: 0.001251685445121109\n",
      "Iteration:930, Price of Hedge: 0.2435181037531322, Loss: 0.001298414092573319\n",
      "Iteration:940, Price of Hedge: 0.23437512206067482, Loss: 0.002183975674551242\n",
      "Iteration:950, Price of Hedge: 0.2591450735278357, Loss: 0.0016468225254376635\n",
      "Iteration:960, Price of Hedge: 0.28142003550285893, Loss: 0.001843158102634801\n",
      "Iteration:970, Price of Hedge: 0.2293159073596854, Loss: 0.0012978992363678389\n",
      "Iteration:980, Price of Hedge: 0.2173644543012756, Loss: 0.001841806326703166\n",
      "Iteration:990, Price of Hedge: 0.2936684857406277, Loss: 0.0013633108603101297\n",
      "tf.Tensor(0.31158233, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.3081600195080398, Loss: 0.0038514284697444\n",
      "Iteration:20, Price of Hedge: 0.30320015917604054, Loss: 0.0030761065389613984\n",
      "Iteration:30, Price of Hedge: 0.3276251219323143, Loss: 0.003746384247334289\n",
      "Iteration:40, Price of Hedge: 0.30486714601523207, Loss: 0.0035226246611722357\n",
      "Iteration:50, Price of Hedge: 0.32390751346987656, Loss: 0.00399626990516988\n",
      "Iteration:60, Price of Hedge: 0.32553773820098114, Loss: 0.0034690315870872456\n",
      "Iteration:70, Price of Hedge: 0.281810834312023, Loss: 0.0029408106169878322\n",
      "Iteration:80, Price of Hedge: 0.30187345113503455, Loss: 0.003424649955754733\n",
      "Iteration:90, Price of Hedge: 0.3452951774699415, Loss: 0.0032337485952684377\n",
      "Iteration:100, Price of Hedge: 0.3011318134076277, Loss: 0.003676738737229046\n",
      "Iteration:110, Price of Hedge: 0.3287969482124794, Loss: 0.0036534324159229305\n",
      "Iteration:120, Price of Hedge: 0.30843227725120814, Loss: 0.003461891576335452\n",
      "Iteration:130, Price of Hedge: 0.2772844346826588, Loss: 0.00325853799681588\n",
      "Iteration:140, Price of Hedge: 0.31724008668240916, Loss: 0.003242058918621216\n",
      "Iteration:150, Price of Hedge: 0.3401092909062925, Loss: 0.004001542993288298\n",
      "Iteration:160, Price of Hedge: 0.3099327067038615, Loss: 0.0035833984154854726\n",
      "Iteration:170, Price of Hedge: 0.2861044403088556, Loss: 0.0030348262457047027\n",
      "Iteration:180, Price of Hedge: 0.2831314938335595, Loss: 0.0035586438734892755\n",
      "Iteration:190, Price of Hedge: 0.3014135901322561, Loss: 0.0035567943806315227\n",
      "Iteration:200, Price of Hedge: 0.30826249729282157, Loss: 0.0035433842985956865\n",
      "Iteration:210, Price of Hedge: 0.3096063345426529, Loss: 0.0035903075785423512\n",
      "Iteration:220, Price of Hedge: 0.3204938678997934, Loss: 0.0036166745684478308\n",
      "Iteration:230, Price of Hedge: 0.33485674668340837, Loss: 0.004412378685179963\n",
      "Iteration:240, Price of Hedge: 0.31736948533663284, Loss: 0.0031165736363532037\n",
      "Iteration:250, Price of Hedge: 0.2910219857935829, Loss: 0.003455414671714019\n",
      "Iteration:260, Price of Hedge: 0.27604357099789356, Loss: 0.0032991226483610526\n",
      "Iteration:270, Price of Hedge: 0.30411098192549274, Loss: 0.003369450631014015\n",
      "Iteration:280, Price of Hedge: 0.32248886297513196, Loss: 0.003083166566409501\n",
      "Iteration:290, Price of Hedge: 0.31214688624292536, Loss: 0.003640774525537305\n",
      "Iteration:300, Price of Hedge: 0.3133977894784494, Loss: 0.0038487342137614624\n",
      "Iteration:310, Price of Hedge: 0.3352473471804586, Loss: 0.003075657431742851\n",
      "Iteration:320, Price of Hedge: 0.2986362041901344, Loss: 0.00327377278269525\n",
      "Iteration:330, Price of Hedge: 0.2816440290353427, Loss: 0.0039119651791091675\n",
      "Iteration:340, Price of Hedge: 0.2932526500271024, Loss: 0.003066578648949281\n",
      "Iteration:350, Price of Hedge: 0.3717144907871841, Loss: 0.0037116242394739096\n",
      "Iteration:360, Price of Hedge: 0.31549974915014334, Loss: 0.002613999031769354\n",
      "Iteration:370, Price of Hedge: 0.33828348085299925, Loss: 0.004256176134675194\n",
      "Iteration:380, Price of Hedge: 0.3375211442987194, Loss: 0.003289690815779034\n",
      "Iteration:390, Price of Hedge: 0.30918601201755397, Loss: 0.003295675813399557\n",
      "Iteration:400, Price of Hedge: 0.3033889027303047, Loss: 0.0034738294233236824\n",
      "Iteration:410, Price of Hedge: 0.3345846872523538, Loss: 0.003395755648383947\n",
      "Iteration:420, Price of Hedge: 0.33084970169094846, Loss: 0.0034705138926718784\n",
      "Iteration:430, Price of Hedge: 0.30501290541884035, Loss: 0.0034088891779799012\n",
      "Iteration:440, Price of Hedge: 0.29078195376889937, Loss: 0.002942161230934426\n",
      "Iteration:450, Price of Hedge: 0.3215491610241145, Loss: 0.003454845299043674\n",
      "Iteration:460, Price of Hedge: 0.2783192025032065, Loss: 0.0031884491894172973\n",
      "Iteration:470, Price of Hedge: 0.2930275161999646, Loss: 0.0030756434879223526\n",
      "Iteration:480, Price of Hedge: 0.3060692892597871, Loss: 0.003175842813701846\n",
      "Iteration:490, Price of Hedge: 0.3159776069772448, Loss: 0.0028482193882676922\n",
      "Iteration:500, Price of Hedge: 0.3359875471450408, Loss: 0.0033394931073302382\n",
      "Iteration:510, Price of Hedge: 0.3363024172036518, Loss: 0.0028012300688378343\n",
      "Iteration:520, Price of Hedge: 0.3163852127380494, Loss: 0.002348994786558545\n",
      "Iteration:530, Price of Hedge: 0.34486741824057676, Loss: 0.003277644129525248\n",
      "Iteration:540, Price of Hedge: 0.3380753522896157, Loss: 0.003196658032743116\n",
      "Iteration:550, Price of Hedge: 0.27078948985612783, Loss: 0.0024300808140542474\n",
      "Iteration:560, Price of Hedge: 0.2906398879284097, Loss: 0.002628418104149577\n",
      "Iteration:570, Price of Hedge: 0.2730942980311767, Loss: 0.0020658000528510855\n",
      "Iteration:580, Price of Hedge: 0.28210681514179897, Loss: 0.0024859066423965183\n",
      "Iteration:590, Price of Hedge: 0.2869425073015748, Loss: 0.0031726390272782015\n",
      "Iteration:600, Price of Hedge: 0.2713487300169106, Loss: 0.002282798241720707\n",
      "Iteration:610, Price of Hedge: 0.26718940611010283, Loss: 0.0022459391078828218\n",
      "Iteration:620, Price of Hedge: 0.2671285986582234, Loss: 0.0017652489422426143\n",
      "Iteration:630, Price of Hedge: 0.2685375070703799, Loss: 0.0027312369315410034\n",
      "Iteration:640, Price of Hedge: 0.273431949193855, Loss: 0.0023552398751641944\n",
      "Iteration:650, Price of Hedge: 0.3118482529886279, Loss: 0.0019694085520526538\n",
      "Iteration:660, Price of Hedge: 0.3406197710761063, Loss: 0.0027090815564185136\n",
      "Iteration:670, Price of Hedge: 0.32357330798017475, Loss: 0.0029808220225791882\n",
      "Iteration:680, Price of Hedge: 0.33674688422860016, Loss: 0.002072114279566706\n",
      "Iteration:690, Price of Hedge: 0.3402105540293775, Loss: 0.0023691585193198693\n",
      "Iteration:700, Price of Hedge: 0.2877139166350588, Loss: 0.00226048212533414\n",
      "Iteration:710, Price of Hedge: 0.3243601856585315, Loss: 0.0021866803883995533\n",
      "Iteration:720, Price of Hedge: 0.3151256085585345, Loss: 0.0022267506678996796\n",
      "Iteration:730, Price of Hedge: 0.28644459516197, Loss: 0.0027906153354835483\n",
      "Iteration:740, Price of Hedge: 0.2901724910653087, Loss: 0.001969706601215804\n",
      "Iteration:750, Price of Hedge: 0.3326912279792566, Loss: 0.0022744807527935065\n",
      "Iteration:760, Price of Hedge: 0.29414857457900895, Loss: 0.0025027745982517447\n",
      "Iteration:770, Price of Hedge: 0.29074296064953276, Loss: 0.002155060257785535\n",
      "Iteration:780, Price of Hedge: 0.27512677409601455, Loss: 0.0022418220012165426\n",
      "Iteration:790, Price of Hedge: 0.31972454084350377, Loss: 0.0030596741338325684\n",
      "Iteration:800, Price of Hedge: 0.3153604844682604, Loss: 0.0022157176199304462\n",
      "Iteration:810, Price of Hedge: 0.31126110039783444, Loss: 0.002809566343189873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:820, Price of Hedge: 0.3156940702326068, Loss: 0.0022530332202254756\n",
      "Iteration:830, Price of Hedge: 0.3105135876740576, Loss: 0.0023250059927047094\n",
      "Iteration:840, Price of Hedge: 0.3089730991744261, Loss: 0.0021116820005363745\n",
      "Iteration:850, Price of Hedge: 0.31000932954681276, Loss: 0.002390396700916253\n",
      "Iteration:860, Price of Hedge: 0.3155163330006559, Loss: 0.0019912883430561303\n",
      "Iteration:870, Price of Hedge: 0.33830338643141716, Loss: 0.002948945867927688\n",
      "Iteration:880, Price of Hedge: 0.3106244689346596, Loss: 0.0021604826609817884\n",
      "Iteration:890, Price of Hedge: 0.30065484798503805, Loss: 0.0017211793038937496\n",
      "Iteration:900, Price of Hedge: 0.2869037372833361, Loss: 0.002278741945604934\n",
      "Iteration:910, Price of Hedge: 0.30383835234711115, Loss: 0.002726182296610391\n",
      "Iteration:920, Price of Hedge: 0.2704625723366064, Loss: 0.0019191137725080188\n",
      "Iteration:930, Price of Hedge: 0.29521556811804145, Loss: 0.0018741222926928814\n",
      "Iteration:940, Price of Hedge: 0.3023418891367328, Loss: 0.0021800971621468213\n",
      "Iteration:950, Price of Hedge: 0.30365662408387095, Loss: 0.0029174256680272403\n",
      "Iteration:960, Price of Hedge: 0.3418629153501797, Loss: 0.0021021444273155777\n",
      "Iteration:970, Price of Hedge: 0.28900143324458444, Loss: 0.0018463245118729432\n",
      "Iteration:980, Price of Hedge: 0.28264461280528225, Loss: 0.0020836467874396193\n",
      "Iteration:990, Price of Hedge: 0.29856089516493683, Loss: 0.002026144214682435\n",
      "tf.Tensor(0.26196644, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.15955280436824068, Loss: 0.0033496976599648675\n",
      "Iteration:20, Price of Hedge: 0.2622280832262646, Loss: 0.00271697550179808\n",
      "Iteration:30, Price of Hedge: 0.29942784135922124, Loss: 0.002529447383887318\n",
      "Iteration:40, Price of Hedge: 0.2597940994981201, Loss: 0.002200726076253101\n",
      "Iteration:50, Price of Hedge: 0.2476638928581764, Loss: 0.0031637990324106637\n",
      "Iteration:60, Price of Hedge: 0.23438359990353774, Loss: 0.002407825314554013\n",
      "Iteration:70, Price of Hedge: 0.2575020328763799, Loss: 0.0020469861593796603\n",
      "Iteration:80, Price of Hedge: 0.24354257051016645, Loss: 0.0020187983389141186\n",
      "Iteration:90, Price of Hedge: 0.23398610806053455, Loss: 0.0022256520110429225\n",
      "Iteration:100, Price of Hedge: 0.2464792010796316, Loss: 0.002453468861641617\n",
      "Iteration:110, Price of Hedge: 0.24487084025906825, Loss: 0.0018839406789653791\n",
      "Iteration:120, Price of Hedge: 0.221943828054026, Loss: 0.0022449192723447142\n",
      "Iteration:130, Price of Hedge: 0.2543729899785461, Loss: 0.002287328821397594\n",
      "Iteration:140, Price of Hedge: 0.2720115138900866, Loss: 0.002293211177006116\n",
      "Iteration:150, Price of Hedge: 0.2647843759505662, Loss: 0.0019981756220613933\n",
      "Iteration:160, Price of Hedge: 0.280447810365186, Loss: 0.001987499303499907\n",
      "Iteration:170, Price of Hedge: 0.2492300131985104, Loss: 0.0021896093653608786\n",
      "Iteration:180, Price of Hedge: 0.2414369916423965, Loss: 0.0020767914630229977\n",
      "Iteration:190, Price of Hedge: 0.29404014743081464, Loss: 0.0022904421666521736\n",
      "Iteration:200, Price of Hedge: 0.2927804193062286, Loss: 0.001824060103820724\n",
      "Iteration:210, Price of Hedge: 0.27456921958819863, Loss: 0.0026044814059584366\n",
      "Iteration:220, Price of Hedge: 0.2672188058809667, Loss: 0.002061705992221463\n",
      "Iteration:230, Price of Hedge: 0.2867848987491698, Loss: 0.00217802960342961\n",
      "Iteration:240, Price of Hedge: 0.2982129069833292, Loss: 0.001954209400381224\n",
      "Iteration:250, Price of Hedge: 0.2857464869435319, Loss: 0.0024742685875490003\n",
      "Iteration:260, Price of Hedge: 0.3075193722245615, Loss: 0.0026577473812542385\n",
      "Iteration:270, Price of Hedge: 0.2612579155767719, Loss: 0.0025969755635827374\n",
      "Iteration:280, Price of Hedge: 0.31383204342953946, Loss: 0.0022975335676963973\n",
      "Iteration:290, Price of Hedge: 0.2846359391065164, Loss: 0.0025521103528087785\n",
      "Iteration:300, Price of Hedge: 0.26776751071070637, Loss: 0.0021045590322318563\n",
      "Iteration:310, Price of Hedge: 0.2812931901170998, Loss: 0.0022238863747723325\n",
      "Iteration:320, Price of Hedge: 0.2592877838826951, Loss: 0.0017231579707552847\n",
      "Iteration:330, Price of Hedge: 0.265529508928978, Loss: 0.0024690597959362128\n",
      "Iteration:340, Price of Hedge: 0.2827503379509267, Loss: 0.002381135099142817\n",
      "Iteration:350, Price of Hedge: 0.26309577309097565, Loss: 0.0021034869073668807\n",
      "Iteration:360, Price of Hedge: 0.22592695164776444, Loss: 0.001989535488620997\n",
      "Iteration:370, Price of Hedge: 0.2417208754332336, Loss: 0.002314888782612368\n",
      "Iteration:380, Price of Hedge: 0.24636750178156036, Loss: 0.0026852804231488835\n",
      "Iteration:390, Price of Hedge: 0.24151381279746148, Loss: 0.002311528128208118\n",
      "Iteration:400, Price of Hedge: 0.26353054761136435, Loss: 0.0022169911555359524\n",
      "Iteration:410, Price of Hedge: 0.2672436196842, Loss: 0.0022489627866250305\n",
      "Iteration:420, Price of Hedge: 0.26912711377358106, Loss: 0.002788144761621103\n",
      "Iteration:430, Price of Hedge: 0.25939707864638706, Loss: 0.0023357076812729363\n",
      "Iteration:440, Price of Hedge: 0.21453201195857333, Loss: 0.00227745446617893\n",
      "Iteration:450, Price of Hedge: 0.19178324516027345, Loss: 0.0025833216583523557\n",
      "Iteration:460, Price of Hedge: 0.19489470025251876, Loss: 0.002530859583041112\n",
      "Iteration:470, Price of Hedge: 0.20914005431972102, Loss: 0.00266865938911498\n",
      "Iteration:480, Price of Hedge: 0.18437098286256487, Loss: 0.0024506458189832436\n",
      "Iteration:490, Price of Hedge: 0.23090218116857955, Loss: 0.00221184201248863\n",
      "Iteration:500, Price of Hedge: 0.21853774313327962, Loss: 0.0020177407388621616\n",
      "Iteration:510, Price of Hedge: 0.21665881022251485, Loss: 0.0020111478294007504\n",
      "Iteration:520, Price of Hedge: 0.24333104585183493, Loss: 0.0018442672173569318\n",
      "Iteration:530, Price of Hedge: 0.2687510396388632, Loss: 0.0019028661230007903\n",
      "Iteration:540, Price of Hedge: 0.24313469207020547, Loss: 0.002030045773123512\n",
      "Iteration:550, Price of Hedge: 0.2630750494750885, Loss: 0.002881043916377246\n",
      "Iteration:560, Price of Hedge: 0.2755194816592734, Loss: 0.0019508801195730952\n",
      "Iteration:570, Price of Hedge: 0.25678706812827273, Loss: 0.0017723709422262646\n",
      "Iteration:580, Price of Hedge: 0.23204039354546355, Loss: 0.0024520839691362984\n",
      "Iteration:590, Price of Hedge: 0.2336708413776961, Loss: 0.0021614720912446427\n",
      "Iteration:600, Price of Hedge: 0.2522692702868426, Loss: 0.00176979888833686\n",
      "Iteration:610, Price of Hedge: 0.2547836695771139, Loss: 0.0015607531314272283\n",
      "Iteration:620, Price of Hedge: 0.273498706009147, Loss: 0.0022564651430456053\n",
      "Iteration:630, Price of Hedge: 0.2711395355259157, Loss: 0.0015773205204850482\n",
      "Iteration:640, Price of Hedge: 0.2791942547051406, Loss: 0.0015641968677619466\n",
      "Iteration:650, Price of Hedge: 0.2554421153728015, Loss: 0.0015534454075011085\n",
      "Iteration:660, Price of Hedge: 0.2129818309543822, Loss: 0.0023336135905639432\n",
      "Iteration:670, Price of Hedge: 0.26772145272228726, Loss: 0.0018014287021595576\n",
      "Iteration:680, Price of Hedge: 0.2692040092956887, Loss: 0.0016595935157006636\n",
      "Iteration:690, Price of Hedge: 0.3022925342094226, Loss: 0.00179670639495082\n",
      "Iteration:700, Price of Hedge: 0.2784936180072521, Loss: 0.00145947712967468\n",
      "Iteration:710, Price of Hedge: 0.25702571196816, Loss: 0.0015133205147040308\n",
      "Iteration:720, Price of Hedge: 0.25192975994809785, Loss: 0.0017850557519320188\n",
      "Iteration:730, Price of Hedge: 0.29344186457263677, Loss: 0.001518557968614509\n",
      "Iteration:740, Price of Hedge: 0.24141473110762776, Loss: 0.001443497317719522\n",
      "Iteration:750, Price of Hedge: 0.23556769674574127, Loss: 0.001397659525465811\n",
      "Iteration:760, Price of Hedge: 0.2231295857601822, Loss: 0.0017453869382637378\n",
      "Iteration:770, Price of Hedge: 0.21783844504215893, Loss: 0.0017570672119010978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:780, Price of Hedge: 0.26644127366097053, Loss: 0.0014290415459784044\n",
      "Iteration:790, Price of Hedge: 0.3135053242221318, Loss: 0.0020739614484543757\n",
      "Iteration:800, Price of Hedge: 0.2718449812925627, Loss: 0.00175200851002284\n",
      "Iteration:810, Price of Hedge: 0.2981407957409658, Loss: 0.0015907072659879673\n",
      "Iteration:820, Price of Hedge: 0.2849940907839539, Loss: 0.0015638951389794987\n",
      "Iteration:830, Price of Hedge: 0.26916744549971555, Loss: 0.0019386816006072172\n",
      "Iteration:840, Price of Hedge: 0.24034820855986538, Loss: 0.0018385643884373248\n",
      "Iteration:850, Price of Hedge: 0.2516528914482848, Loss: 0.0016414669363812972\n",
      "Iteration:860, Price of Hedge: 0.2541966409313915, Loss: 0.0013805357392372764\n",
      "Iteration:870, Price of Hedge: 0.24452785945833286, Loss: 0.0015012117590826103\n",
      "Iteration:880, Price of Hedge: 0.23475253480216055, Loss: 0.0016367903339175262\n",
      "Iteration:890, Price of Hedge: 0.2212026117398608, Loss: 0.0013665252014312347\n",
      "Iteration:900, Price of Hedge: 0.2850229699855191, Loss: 0.0018278282276462\n",
      "Iteration:910, Price of Hedge: 0.24432570504737613, Loss: 0.0019153958077035016\n",
      "Iteration:920, Price of Hedge: 0.2447088936291749, Loss: 0.0019306954710810232\n",
      "Iteration:930, Price of Hedge: 0.2604977356667291, Loss: 0.0018012356189784917\n",
      "Iteration:940, Price of Hedge: 0.2690498712052744, Loss: 0.0016754701046512999\n",
      "Iteration:950, Price of Hedge: 0.2791230110782749, Loss: 0.0018065511195509254\n",
      "Iteration:960, Price of Hedge: 0.25321645852015423, Loss: 0.00190354104264574\n",
      "Iteration:970, Price of Hedge: 0.24559403495989615, Loss: 0.0013603287225331551\n",
      "Iteration:980, Price of Hedge: 0.23326001304504304, Loss: 0.0015745487020005888\n",
      "Iteration:990, Price of Hedge: 0.2345656504239628, Loss: 0.0018299103111764305\n",
      "tf.Tensor(0.23535126, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.3261393179980502, Loss: 0.0034056813246086115\n",
      "Iteration:20, Price of Hedge: 0.23995983907409482, Loss: 0.002047606659391832\n",
      "Iteration:30, Price of Hedge: 0.23951827236381007, Loss: 0.002675138230378149\n",
      "Iteration:40, Price of Hedge: 0.27140232386565233, Loss: 0.002268576125805022\n",
      "Iteration:50, Price of Hedge: 0.2620465532751382, Loss: 0.002088150254132204\n",
      "Iteration:60, Price of Hedge: 0.27775515327366523, Loss: 0.0018395145048729412\n",
      "Iteration:70, Price of Hedge: 0.24809249491402455, Loss: 0.0021243646799362194\n",
      "Iteration:80, Price of Hedge: 0.27232001317204324, Loss: 0.0022438893662695804\n",
      "Iteration:90, Price of Hedge: 0.25028771085721074, Loss: 0.002118659139718182\n",
      "Iteration:100, Price of Hedge: 0.2373153222481875, Loss: 0.002662668968897597\n",
      "Iteration:110, Price of Hedge: 0.23086817064107096, Loss: 0.0025709937717185217\n",
      "Iteration:120, Price of Hedge: 0.2308067186748218, Loss: 0.002429396598528966\n",
      "Iteration:130, Price of Hedge: 0.2541185803256156, Loss: 0.001918064112687179\n",
      "Iteration:140, Price of Hedge: 0.2501951982561451, Loss: 0.002338567907452638\n",
      "Iteration:150, Price of Hedge: 0.2495953289010572, Loss: 0.0022422099105562365\n",
      "Iteration:160, Price of Hedge: 0.257420923221855, Loss: 0.0024013772658944446\n",
      "Iteration:170, Price of Hedge: 0.2589104702972662, Loss: 0.002588911000066241\n",
      "Iteration:180, Price of Hedge: 0.258043771993124, Loss: 0.0019921888814633084\n",
      "Iteration:190, Price of Hedge: 0.2621193338208855, Loss: 0.0022003220927869992\n",
      "Iteration:200, Price of Hedge: 0.24332122940220416, Loss: 0.0021440947986128833\n",
      "Iteration:210, Price of Hedge: 0.25536586436506353, Loss: 0.0022938256734289066\n",
      "Iteration:220, Price of Hedge: 0.23273267634556022, Loss: 0.0023845110530167804\n",
      "Iteration:230, Price of Hedge: 0.23916668977514063, Loss: 0.002902490093296062\n",
      "Iteration:240, Price of Hedge: 0.2568654757802477, Loss: 0.0022662965048177333\n",
      "Iteration:250, Price of Hedge: 0.2532433298115677, Loss: 0.0020328213680593566\n",
      "Iteration:260, Price of Hedge: 0.23502893231070346, Loss: 0.0026138843825785907\n",
      "Iteration:270, Price of Hedge: 0.26511848228421114, Loss: 0.002627747251452273\n",
      "Iteration:280, Price of Hedge: 0.2590380593534519, Loss: 0.0023987256160296956\n",
      "Iteration:290, Price of Hedge: 0.24435453467091292, Loss: 0.001746725545031569\n",
      "Iteration:300, Price of Hedge: 0.2352305909413758, Loss: 0.002270150809200455\n",
      "Iteration:310, Price of Hedge: 0.2276355344528156, Loss: 0.0022408163031631067\n",
      "Iteration:320, Price of Hedge: 0.2645034420524212, Loss: 0.00223782729030797\n",
      "Iteration:330, Price of Hedge: 0.2606905941973537, Loss: 0.002199782544399387\n",
      "Iteration:340, Price of Hedge: 0.2534820480184976, Loss: 0.0025884533716240554\n",
      "Iteration:350, Price of Hedge: 0.2586898976487447, Loss: 0.0027489835417517927\n",
      "Iteration:360, Price of Hedge: 0.277481780024857, Loss: 0.002524400495523649\n",
      "Iteration:370, Price of Hedge: 0.26449637718336877, Loss: 0.002311415221994917\n",
      "Iteration:380, Price of Hedge: 0.27192542164370365, Loss: 0.0020395695961879846\n",
      "Iteration:390, Price of Hedge: 0.2584980058896747, Loss: 0.0020946223171492973\n",
      "Iteration:400, Price of Hedge: 0.24355940225082123, Loss: 0.001948957227993553\n",
      "Iteration:410, Price of Hedge: 0.28303412258570687, Loss: 0.0029264242738529455\n",
      "Iteration:420, Price of Hedge: 0.22631703157551614, Loss: 0.002156244901535365\n",
      "Iteration:430, Price of Hedge: 0.2184581456086221, Loss: 0.0022769958694158765\n",
      "Iteration:440, Price of Hedge: 0.19564220058178847, Loss: 0.0029138481097485736\n",
      "Iteration:450, Price of Hedge: 0.23627708396564914, Loss: 0.0021331510298276735\n",
      "Iteration:460, Price of Hedge: 0.22586978818097522, Loss: 0.00201488322398089\n",
      "Iteration:470, Price of Hedge: 0.2516869019757934, Loss: 0.0024320459244236317\n",
      "Iteration:480, Price of Hedge: 0.2990324317934125, Loss: 0.002107324169302327\n",
      "Iteration:490, Price of Hedge: 0.26298994878927434, Loss: 0.0021387851079656575\n",
      "Iteration:500, Price of Hedge: 0.23423722077457398, Loss: 0.003102974538083947\n",
      "Iteration:510, Price of Hedge: 0.20896950590189364, Loss: 0.0023351104209615946\n",
      "Iteration:520, Price of Hedge: 0.2653922025792184, Loss: 0.0023294500044960032\n",
      "Iteration:530, Price of Hedge: 0.2470533642269743, Loss: 0.001955383392601506\n",
      "Iteration:540, Price of Hedge: 0.2325862228495538, Loss: 0.002129511111685112\n",
      "Iteration:550, Price of Hedge: 0.2760703679222644, Loss: 0.002728540157923809\n",
      "Iteration:560, Price of Hedge: 0.3013251677185366, Loss: 0.0020510319976300598\n",
      "Iteration:570, Price of Hedge: 0.28162375162171144, Loss: 0.0019252829447576226\n",
      "Iteration:580, Price of Hedge: 0.24356983842580746, Loss: 0.0024338551351332782\n",
      "Iteration:590, Price of Hedge: 0.24505413023020425, Loss: 0.002008243835117818\n",
      "Iteration:600, Price of Hedge: 0.2623935251071629, Loss: 0.002013965449462263\n",
      "Iteration:610, Price of Hedge: 0.2652977812240579, Loss: 0.002555377854745533\n",
      "Iteration:620, Price of Hedge: 0.21993490155269627, Loss: 0.001982082710228861\n",
      "Iteration:630, Price of Hedge: 0.20776534235267974, Loss: 0.0018067899074769578\n",
      "Iteration:640, Price of Hedge: 0.2168645342515191, Loss: 0.002112033694675608\n",
      "Iteration:650, Price of Hedge: 0.24681759591273647, Loss: 0.0020178596486647438\n",
      "Iteration:660, Price of Hedge: 0.2589620066578277, Loss: 0.001671295673389639\n",
      "Iteration:670, Price of Hedge: 0.23513832623045233, Loss: 0.001510584427259598\n",
      "Iteration:680, Price of Hedge: 0.23484160173024976, Loss: 0.0016154813680656966\n",
      "Iteration:690, Price of Hedge: 0.24849878685707552, Loss: 0.0017771151334866175\n",
      "Iteration:700, Price of Hedge: 0.2656708063100268, Loss: 0.0016035257039734962\n",
      "Iteration:710, Price of Hedge: 0.25578606294509143, Loss: 0.0013586452967042529\n",
      "Iteration:720, Price of Hedge: 0.23852688531814578, Loss: 0.0013413796514685661\n",
      "Iteration:730, Price of Hedge: 0.2554984360131073, Loss: 0.00160033072926975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:740, Price of Hedge: 0.24082611596499534, Loss: 0.0016984626899962053\n",
      "Iteration:750, Price of Hedge: 0.22353168835983014, Loss: 0.0013499816330667658\n",
      "Iteration:760, Price of Hedge: 0.2186605231207068, Loss: 0.00123561296485889\n",
      "Iteration:770, Price of Hedge: 0.23629971633563115, Loss: 0.0014279684527925608\n",
      "Iteration:780, Price of Hedge: 0.22843835146731523, Loss: 0.0017142953171794372\n",
      "Iteration:790, Price of Hedge: 0.24087323988102582, Loss: 0.001302801748090099\n",
      "Iteration:800, Price of Hedge: 0.2515527686198539, Loss: 0.0017794453008232126\n",
      "Iteration:810, Price of Hedge: 0.25407130767549974, Loss: 0.0013551861640677344\n",
      "Iteration:820, Price of Hedge: 0.24075085651782616, Loss: 0.0012577682431492933\n",
      "Iteration:830, Price of Hedge: 0.20450944167457977, Loss: 0.0019301861343044902\n",
      "Iteration:840, Price of Hedge: 0.2180313035727835, Loss: 0.0021541781174748476\n",
      "Iteration:850, Price of Hedge: 0.24156522521295187, Loss: 0.0016700296906869028\n",
      "Iteration:860, Price of Hedge: 0.2564318415545131, Loss: 0.0014830076172617224\n",
      "Iteration:870, Price of Hedge: 0.25357941926635025, Loss: 0.001478519934199285\n",
      "Iteration:880, Price of Hedge: 0.2376907518685357, Loss: 0.0018054855792678515\n",
      "Iteration:890, Price of Hedge: 0.21812317165947945, Loss: 0.0015056094851364167\n",
      "Iteration:900, Price of Hedge: 0.24409281225878773, Loss: 0.0014171956894726279\n",
      "Iteration:910, Price of Hedge: 0.22662991851298955, Loss: 0.0010940333182770435\n",
      "Iteration:920, Price of Hedge: 0.2647425320945644, Loss: 0.0016452939341155437\n",
      "Iteration:930, Price of Hedge: 0.28399392842725607, Loss: 0.0012955063218390017\n",
      "Iteration:940, Price of Hedge: 0.2815912780130844, Loss: 0.0014995811067410104\n",
      "Iteration:950, Price of Hedge: 0.2785364038457942, Loss: 0.0017711591854921327\n",
      "Iteration:960, Price of Hedge: 0.2689727030040103, Loss: 0.0015832046190711324\n",
      "Iteration:970, Price of Hedge: 0.23510166327842227, Loss: 0.0013690415768707331\n",
      "Iteration:980, Price of Hedge: 0.2672627320141629, Loss: 0.001357672521560327\n",
      "Iteration:990, Price of Hedge: 0.2666767197180235, Loss: 0.0014498033137077648\n",
      "tf.Tensor(0.38213146, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.4661307889888178, Loss: 0.010641730140084071\n",
      "Iteration:20, Price of Hedge: 0.36083580710811985, Loss: 0.005842112193250593\n",
      "Iteration:30, Price of Hedge: 0.3254036792120843, Loss: 0.00462346953576267\n",
      "Iteration:40, Price of Hedge: 0.4060018620065819, Loss: 0.00528517276285001\n",
      "Iteration:50, Price of Hedge: 0.37358038467646965, Loss: 0.0047553207530806494\n",
      "Iteration:60, Price of Hedge: 0.3627722753208872, Loss: 0.004154585331808481\n",
      "Iteration:70, Price of Hedge: 0.364283388838669, Loss: 0.0038980399503715903\n",
      "Iteration:80, Price of Hedge: 0.40649620452813906, Loss: 0.005386747685254489\n",
      "Iteration:90, Price of Hedge: 0.3553310842435849, Loss: 0.004844317962067368\n",
      "Iteration:100, Price of Hedge: 0.3467710162204895, Loss: 0.005176319940802143\n",
      "Iteration:110, Price of Hedge: 0.37258389109387624, Loss: 0.004422422109222168\n",
      "Iteration:120, Price of Hedge: 0.40456553694469904, Loss: 0.004986427183331888\n",
      "Iteration:130, Price of Hedge: 0.3870518009307375, Loss: 0.004076129651118432\n",
      "Iteration:140, Price of Hedge: 0.3870665751832121, Loss: 0.006186589630719475\n",
      "Iteration:150, Price of Hedge: 0.3914645925079356, Loss: 0.0053206012994376104\n",
      "Iteration:160, Price of Hedge: 0.3690837566531826, Loss: 0.005744414040272971\n",
      "Iteration:170, Price of Hedge: 0.32823931933762085, Loss: 0.005251100650134211\n",
      "Iteration:180, Price of Hedge: 0.2984252496791299, Loss: 0.004959514060456894\n",
      "Iteration:190, Price of Hedge: 0.35560790316536955, Loss: 0.005564508156906234\n",
      "Iteration:200, Price of Hedge: 0.4187775745767908, Loss: 0.005560269622803116\n",
      "Iteration:210, Price of Hedge: 0.3627571292331993, Loss: 0.005110943951067793\n",
      "Iteration:220, Price of Hedge: 0.3482661904021285, Loss: 0.004601894572168419\n",
      "Iteration:230, Price of Hedge: 0.3200368328446359, Loss: 0.003931827764080564\n",
      "Iteration:240, Price of Hedge: 0.40449496262121726, Loss: 0.0049546255893872185\n",
      "Iteration:250, Price of Hedge: 0.3757317736425165, Loss: 0.004556439653985889\n",
      "Iteration:260, Price of Hedge: 0.34713095270695077, Loss: 0.004163713886294662\n",
      "Iteration:270, Price of Hedge: 0.34922406270056855, Loss: 0.003944331110455668\n",
      "Iteration:280, Price of Hedge: 0.36494860203523843, Loss: 0.004505591963225664\n",
      "Iteration:290, Price of Hedge: 0.34651078114921746, Loss: 0.004911767707772486\n",
      "Iteration:300, Price of Hedge: 0.3267233967510805, Loss: 0.004266332658594774\n",
      "Iteration:310, Price of Hedge: 0.3310707205417259, Loss: 0.004398477470799911\n",
      "Iteration:320, Price of Hedge: 0.3476846649175627, Loss: 0.004484596830167132\n",
      "Iteration:330, Price of Hedge: 0.35900132089984993, Loss: 0.003550327159218769\n",
      "Iteration:340, Price of Hedge: 0.32692089082736403, Loss: 0.004338993132554414\n",
      "Iteration:350, Price of Hedge: 0.34960754875053796, Loss: 0.005104681626350693\n",
      "Iteration:360, Price of Hedge: 0.4114934219045665, Loss: 0.004450073867255222\n",
      "Iteration:370, Price of Hedge: 0.36710098256185403, Loss: 0.004585892488833299\n",
      "Iteration:380, Price of Hedge: 0.3733163320970078, Loss: 0.005869773634492326\n",
      "Iteration:390, Price of Hedge: 0.36913640851938395, Loss: 0.0049990188405701465\n",
      "Iteration:400, Price of Hedge: 0.381381834497418, Loss: 0.005135638457170177\n",
      "Iteration:410, Price of Hedge: 0.37071061007835343, Loss: 0.003877889580438243\n",
      "Iteration:420, Price of Hedge: 0.40015398481821196, Loss: 0.004167462837366953\n",
      "Iteration:430, Price of Hedge: 0.3822789489220071, Loss: 0.00476816301175953\n",
      "Iteration:440, Price of Hedge: 0.32058419906760777, Loss: 0.003896601412890188\n",
      "Iteration:450, Price of Hedge: 0.37088993380721436, Loss: 0.00412600824635403\n",
      "Iteration:460, Price of Hedge: 0.3765189983670723, Loss: 0.005245204738033538\n",
      "Iteration:470, Price of Hedge: 0.3758272361362742, Loss: 0.004319221569744603\n",
      "Iteration:480, Price of Hedge: 0.38333171356687784, Loss: 0.0044510836322563035\n",
      "Iteration:490, Price of Hedge: 0.3383871485104635, Loss: 0.004357803346406542\n",
      "Iteration:500, Price of Hedge: 0.3313296665842586, Loss: 0.003919714070022717\n",
      "Iteration:510, Price of Hedge: 0.3898792358925675, Loss: 0.0038395192850538607\n",
      "Iteration:520, Price of Hedge: 0.35118725347066404, Loss: 0.003653554811680637\n",
      "Iteration:530, Price of Hedge: 0.358954940654246, Loss: 0.003589844721167479\n",
      "Iteration:540, Price of Hedge: 0.3880557807956251, Loss: 0.003817647240617328\n",
      "Iteration:550, Price of Hedge: 0.38182379783193027, Loss: 0.003428497288227206\n",
      "Iteration:560, Price of Hedge: 0.3522796309602569, Loss: 0.0036333703568527387\n",
      "Iteration:570, Price of Hedge: 0.3723749444930235, Loss: 0.0029345692080014808\n",
      "Iteration:580, Price of Hedge: 0.3613919734311395, Loss: 0.0029579262693210763\n",
      "Iteration:590, Price of Hedge: 0.3263282598644281, Loss: 0.0028530726124577745\n",
      "Iteration:600, Price of Hedge: 0.37163144758955013, Loss: 0.0033620569201948227\n",
      "Iteration:610, Price of Hedge: 0.34065732643264823, Loss: 0.004648854260979718\n",
      "Iteration:620, Price of Hedge: 0.33706842253203606, Loss: 0.003834377113916787\n",
      "Iteration:630, Price of Hedge: 0.36174628281137305, Loss: 0.00291386573318837\n",
      "Iteration:640, Price of Hedge: 0.35622889276057207, Loss: 0.0032074594583607397\n",
      "Iteration:650, Price of Hedge: 0.35934665665693616, Loss: 0.003945101119209849\n",
      "Iteration:660, Price of Hedge: 0.3574607084551474, Loss: 0.002851702244765475\n",
      "Iteration:670, Price of Hedge: 0.37190043318284155, Loss: 0.003000421417938681\n",
      "Iteration:680, Price of Hedge: 0.3708912228359537, Loss: 0.0035690215618950916\n",
      "Iteration:690, Price of Hedge: 0.3796798951481776, Loss: 0.00320702913656703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:700, Price of Hedge: 0.3526845099294974, Loss: 0.0026170126399745366\n",
      "Iteration:710, Price of Hedge: 0.38243752424596666, Loss: 0.003891775301684408\n",
      "Iteration:720, Price of Hedge: 0.3608942596036485, Loss: 0.0034517675879970344\n",
      "Iteration:730, Price of Hedge: 0.3942989931827611, Loss: 0.003358659663261765\n",
      "Iteration:740, Price of Hedge: 0.35233991784283775, Loss: 0.002615148428639591\n",
      "Iteration:750, Price of Hedge: 0.35848989874749576, Loss: 0.003395420609363642\n",
      "Iteration:760, Price of Hedge: 0.369411913623415, Loss: 0.003703016254286329\n",
      "Iteration:770, Price of Hedge: 0.3768360002809061, Loss: 0.003470218361142985\n",
      "Iteration:780, Price of Hedge: 0.3876932414626708, Loss: 0.0028380729348851386\n",
      "Iteration:790, Price of Hedge: 0.38706193963755314, Loss: 0.003605098873464208\n",
      "Iteration:800, Price of Hedge: 0.4031921759789327, Loss: 0.0032109605192908396\n",
      "Iteration:810, Price of Hedge: 0.3834435615990344, Loss: 0.0032864678566022045\n",
      "Iteration:820, Price of Hedge: 0.39369622351300965, Loss: 0.003266286500401083\n",
      "Iteration:830, Price of Hedge: 0.3626232933454304, Loss: 0.003845531782987033\n",
      "Iteration:840, Price of Hedge: 0.40390669452478395, Loss: 0.003316988168374424\n",
      "Iteration:850, Price of Hedge: 0.3905796990673565, Loss: 0.002997242807857603\n",
      "Iteration:860, Price of Hedge: 0.38644588305618016, Loss: 0.003118413446002277\n",
      "Iteration:870, Price of Hedge: 0.39228463788731743, Loss: 0.002868984641952177\n",
      "Iteration:880, Price of Hedge: 0.3494774064258877, Loss: 0.0027840530249615635\n",
      "Iteration:890, Price of Hedge: 0.3670333333420501, Loss: 0.0026623726627120095\n",
      "Iteration:900, Price of Hedge: 0.4190512948717981, Loss: 0.00327362482326663\n",
      "Iteration:910, Price of Hedge: 0.4101326785470377, Loss: 0.0036574610180618804\n",
      "Iteration:920, Price of Hedge: 0.37718359183828626, Loss: 0.0029529322512767964\n",
      "Iteration:930, Price of Hedge: 0.4084301938394845, Loss: 0.003049295670770058\n",
      "Iteration:940, Price of Hedge: 0.3954211670674454, Loss: 0.003005191172869948\n",
      "Iteration:950, Price of Hedge: 0.40871849007485256, Loss: 0.0027983806878518537\n",
      "Iteration:960, Price of Hedge: 0.37626984398515617, Loss: 0.004178273946193256\n",
      "Iteration:970, Price of Hedge: 0.4159628811682694, Loss: 0.0038787548719658284\n",
      "Iteration:980, Price of Hedge: 0.42833924271940876, Loss: 0.003837656235703957\n",
      "Iteration:990, Price of Hedge: 0.39663156505373537, Loss: 0.0033064129425115496\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 2 \n",
      "\n",
      "tf.Tensor(0.22193046, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.1702649163913975, Loss: 0.0028564926975004567\n",
      "Iteration:20, Price of Hedge: 0.21076774455742678, Loss: 0.0033471483005760305\n",
      "Iteration:30, Price of Hedge: 0.18203872733328125, Loss: 0.0030823974512630414\n",
      "Iteration:40, Price of Hedge: 0.17397989655657967, Loss: 0.0025991227663441307\n",
      "Iteration:50, Price of Hedge: 0.18328185148742476, Loss: 0.0025471271294755125\n",
      "Iteration:60, Price of Hedge: 0.16639302371449957, Loss: 0.0029189774574367887\n",
      "Iteration:70, Price of Hedge: 0.18240155069422598, Loss: 0.002262662708051266\n",
      "Iteration:80, Price of Hedge: 0.1921671031219148, Loss: 0.002229751593995921\n",
      "Iteration:90, Price of Hedge: 0.19596082009455812, Loss: 0.0028586700409590545\n",
      "Iteration:100, Price of Hedge: 0.1969204328260048, Loss: 0.0023033575948311126\n",
      "Iteration:110, Price of Hedge: 0.18565305961078593, Loss: 0.001978850349923711\n",
      "Iteration:120, Price of Hedge: 0.18119242939440028, Loss: 0.0022679732430480825\n",
      "Iteration:130, Price of Hedge: 0.18881054165750583, Loss: 0.002268823445914592\n",
      "Iteration:140, Price of Hedge: 0.1933144750138581, Loss: 0.0019152696852870576\n",
      "Iteration:150, Price of Hedge: 0.18140292726234292, Loss: 0.0023715419359328746\n",
      "Iteration:160, Price of Hedge: 0.18822563364740288, Loss: 0.002893394000569671\n",
      "Iteration:170, Price of Hedge: 0.19949050995335255, Loss: 0.002682989284526549\n",
      "Iteration:180, Price of Hedge: 0.18836453474618792, Loss: 0.0023628801243624764\n",
      "Iteration:190, Price of Hedge: 0.19831217919198707, Loss: 0.002218401528195635\n",
      "Iteration:200, Price of Hedge: 0.1823589769884279, Loss: 0.002486650505312049\n",
      "Iteration:210, Price of Hedge: 0.17460255278490422, Loss: 0.002678710653395555\n",
      "Iteration:220, Price of Hedge: 0.15479086827108404, Loss: 0.0023558961428882695\n",
      "Iteration:230, Price of Hedge: 0.16887011201293944, Loss: 0.002305264907371551\n",
      "Iteration:240, Price of Hedge: 0.19746832205205464, Loss: 0.0029734625514226563\n",
      "Iteration:250, Price of Hedge: 0.2009855694472435, Loss: 0.0023826769852309583\n",
      "Iteration:260, Price of Hedge: 0.1985070783907872, Loss: 0.0028419894946964063\n",
      "Iteration:270, Price of Hedge: 0.18305983697616737, Loss: 0.002397208681557217\n",
      "Iteration:280, Price of Hedge: 0.17742007642634688, Loss: 0.0025997463361186134\n",
      "Iteration:290, Price of Hedge: 0.1387498253605372, Loss: 0.002179867984665762\n",
      "Iteration:300, Price of Hedge: 0.14891056277660936, Loss: 0.0029106821163981775\n",
      "Iteration:310, Price of Hedge: 0.16691208626331216, Loss: 0.0030275667089346924\n",
      "Iteration:320, Price of Hedge: 0.18827091467617263, Loss: 0.0027972897337797064\n",
      "Iteration:330, Price of Hedge: 0.1878912862741913, Loss: 0.0021015471826288487\n",
      "Iteration:340, Price of Hedge: 0.18050416617364817, Loss: 0.0021721504045851604\n",
      "Iteration:350, Price of Hedge: 0.1571759496712275, Loss: 0.002056840407922067\n",
      "Iteration:360, Price of Hedge: 0.1805895239989468, Loss: 0.002570944645508533\n",
      "Iteration:370, Price of Hedge: 0.19171848708068637, Loss: 0.0021452323549739916\n",
      "Iteration:380, Price of Hedge: 0.1834609275757998, Loss: 0.0030192156959373048\n",
      "Iteration:390, Price of Hedge: 0.17126400273342596, Loss: 0.0025570003541016463\n",
      "Iteration:400, Price of Hedge: 0.1884028019848756, Loss: 0.0022764599290473696\n",
      "Iteration:410, Price of Hedge: 0.20110443916155418, Loss: 0.0022245778279057046\n",
      "Iteration:420, Price of Hedge: 0.2133621875915196, Loss: 0.002196793356038462\n",
      "Iteration:430, Price of Hedge: 0.2139639567529798, Loss: 0.0021855962785343407\n",
      "Iteration:440, Price of Hedge: 0.19118583180669474, Loss: 0.0021675973589172057\n",
      "Iteration:450, Price of Hedge: 0.2077538628488469, Loss: 0.002464410434504671\n",
      "Iteration:460, Price of Hedge: 0.18655890462746355, Loss: 0.0023491385753251492\n",
      "Iteration:470, Price of Hedge: 0.19791111664751496, Loss: 0.0021395042802863527\n",
      "Iteration:480, Price of Hedge: 0.18818355090691055, Loss: 0.0023732261222763284\n",
      "Iteration:490, Price of Hedge: 0.17994034161653188, Loss: 0.002689093692888278\n",
      "Iteration:500, Price of Hedge: 0.19688950201174293, Loss: 0.002198468994325253\n",
      "Iteration:510, Price of Hedge: 0.1934411861454805, Loss: 0.001923009841004486\n",
      "Iteration:520, Price of Hedge: 0.20168892634425217, Loss: 0.0026651052157220076\n",
      "Iteration:530, Price of Hedge: 0.22008723396347704, Loss: 0.002083548263011714\n",
      "Iteration:540, Price of Hedge: 0.19954750401155932, Loss: 0.0021728647152688295\n",
      "Iteration:550, Price of Hedge: 0.2044442096125067, Loss: 0.0015645488383098536\n",
      "Iteration:560, Price of Hedge: 0.2052725241936173, Loss: 0.001958212930150083\n",
      "Iteration:570, Price of Hedge: 0.21487840067629804, Loss: 0.0016888224586978139\n",
      "Iteration:580, Price of Hedge: 0.2082961410428311, Loss: 0.001386455886041471\n",
      "Iteration:590, Price of Hedge: 0.17755664894682466, Loss: 0.0013146544018858286\n",
      "Iteration:600, Price of Hedge: 0.17669731938597122, Loss: 0.0020205872228926222\n",
      "Iteration:610, Price of Hedge: 0.1692449149273443, Loss: 0.0015944179400980473\n",
      "Iteration:620, Price of Hedge: 0.17821269081593982, Loss: 0.0014901919235740023\n",
      "Iteration:630, Price of Hedge: 0.18237370594760022, Loss: 0.0023440226730031097\n",
      "Iteration:640, Price of Hedge: 0.18822302451749237, Loss: 0.0018147775256674768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:650, Price of Hedge: 0.18302778395549238, Loss: 0.0014817671561902833\n",
      "Iteration:660, Price of Hedge: 0.172797020859241, Loss: 0.001759496147326356\n",
      "Iteration:670, Price of Hedge: 0.1819612810631952, Loss: 0.001418718224514226\n",
      "Iteration:680, Price of Hedge: 0.18340490142062435, Loss: 0.0013932715365537083\n",
      "Iteration:690, Price of Hedge: 0.19823025812382866, Loss: 0.0017956508105232416\n",
      "Iteration:700, Price of Hedge: 0.20450299920097448, Loss: 0.0014988039810710063\n",
      "Iteration:710, Price of Hedge: 0.20351510686791696, Loss: 0.001588001856439547\n",
      "Iteration:720, Price of Hedge: 0.2050083006936461, Loss: 0.0015774470886802837\n",
      "Iteration:730, Price of Hedge: 0.21269840249815386, Loss: 0.002264269523522877\n",
      "Iteration:740, Price of Hedge: 0.22160041709094003, Loss: 0.0018940398194324359\n",
      "Iteration:750, Price of Hedge: 0.20703698336456, Loss: 0.0016263858089778259\n",
      "Iteration:760, Price of Hedge: 0.18067475557602392, Loss: 0.001733365724423308\n",
      "Iteration:770, Price of Hedge: 0.1797840322907632, Loss: 0.001383773440106495\n",
      "Iteration:780, Price of Hedge: 0.1785458598724176, Loss: 0.0013698787931825328\n",
      "Iteration:790, Price of Hedge: 0.18533342716916648, Loss: 0.0013996346880151833\n",
      "Iteration:800, Price of Hedge: 0.1835109218715047, Loss: 0.001516908765082192\n",
      "Iteration:810, Price of Hedge: 0.1879135340163316, Loss: 0.0015159041492434078\n",
      "Iteration:820, Price of Hedge: 0.16697678146302905, Loss: 0.0013645143396744607\n",
      "Iteration:830, Price of Hedge: 0.18578605509832186, Loss: 0.0014641911461970025\n",
      "Iteration:840, Price of Hedge: 0.17310788606325786, Loss: 0.0015522358010493951\n",
      "Iteration:850, Price of Hedge: 0.1804569353112356, Loss: 0.001290995244082005\n",
      "Iteration:860, Price of Hedge: 0.17200547256574053, Loss: 0.0015632813149334623\n",
      "Iteration:870, Price of Hedge: 0.18356870147420068, Loss: 0.0017896938013437058\n",
      "Iteration:880, Price of Hedge: 0.17195341621575153, Loss: 0.0018304510451010003\n",
      "Iteration:890, Price of Hedge: 0.1943061267383996, Loss: 0.0017115339877072698\n",
      "Iteration:900, Price of Hedge: 0.19128220128242218, Loss: 0.0013428108238083601\n",
      "Iteration:910, Price of Hedge: 0.17789592000067386, Loss: 0.0014437045229101384\n",
      "Iteration:920, Price of Hedge: 0.1720453950588876, Loss: 0.0012062590159294118\n",
      "Iteration:930, Price of Hedge: 0.16126006560842823, Loss: 0.0014045805059277328\n",
      "Iteration:940, Price of Hedge: 0.19949473225498193, Loss: 0.0012959949805058102\n",
      "Iteration:950, Price of Hedge: 0.21507794300413252, Loss: 0.0017240532742323288\n",
      "Iteration:960, Price of Hedge: 0.22062966646084303, Loss: 0.0015099743185004399\n",
      "Iteration:970, Price of Hedge: 0.20657614930100862, Loss: 0.0017351959948633143\n",
      "Iteration:980, Price of Hedge: 0.19501460370216817, Loss: 0.0015410512168588574\n",
      "Iteration:990, Price of Hedge: 0.19174108551233074, Loss: 0.0014218061551883208\n",
      "tf.Tensor(0.17352879, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.14408074067788448, Loss: 0.0029884501441042486\n",
      "Iteration:20, Price of Hedge: 0.2020698172284483, Loss: 0.0019902729646151585\n",
      "Iteration:30, Price of Hedge: 0.19982586731233595, Loss: 0.0022003074840505122\n",
      "Iteration:40, Price of Hedge: 0.1807516407429034, Loss: 0.0016973340217337984\n",
      "Iteration:50, Price of Hedge: 0.19260876148338182, Loss: 0.0020137218183069903\n",
      "Iteration:60, Price of Hedge: 0.1807611374146745, Loss: 0.003199059794326331\n",
      "Iteration:70, Price of Hedge: 0.185241925263756, Loss: 0.002026556177433392\n",
      "Iteration:80, Price of Hedge: 0.19352317735153973, Loss: 0.002347241345107953\n",
      "Iteration:90, Price of Hedge: 0.17634877610163358, Loss: 0.0019086556812396792\n",
      "Iteration:100, Price of Hedge: 0.1915215959655029, Loss: 0.0021106699317162024\n",
      "Iteration:110, Price of Hedge: 0.18520339150104517, Loss: 0.0023419036316745688\n",
      "Iteration:120, Price of Hedge: 0.20309322739448132, Loss: 0.0026631146144243446\n",
      "Iteration:130, Price of Hedge: 0.20077947623947237, Loss: 0.002554908272028733\n",
      "Iteration:140, Price of Hedge: 0.2001030102136383, Loss: 0.001851670828632379\n",
      "Iteration:150, Price of Hedge: 0.1878815932162979, Loss: 0.0022622377162084817\n",
      "Iteration:160, Price of Hedge: 0.1938155121221598, Loss: 0.002214505148624113\n",
      "Iteration:170, Price of Hedge: 0.179658878220539, Loss: 0.0023666335979610764\n",
      "Iteration:180, Price of Hedge: 0.17834062234703651, Loss: 0.001926207471739083\n",
      "Iteration:190, Price of Hedge: 0.2170387742697926, Loss: 0.002388693282854781\n",
      "Iteration:200, Price of Hedge: 0.18009174128924313, Loss: 0.002624142051471523\n",
      "Iteration:210, Price of Hedge: 0.20015923275493605, Loss: 0.0021481985306358808\n",
      "Iteration:220, Price of Hedge: 0.20788835928746038, Loss: 0.0023323797814668976\n",
      "Iteration:230, Price of Hedge: 0.19652725378158492, Loss: 0.002427848423530676\n",
      "Iteration:240, Price of Hedge: 0.17152724430278568, Loss: 0.0023133316426896754\n",
      "Iteration:250, Price of Hedge: 0.2115930432088021, Loss: 0.0023454745275500954\n",
      "Iteration:260, Price of Hedge: 0.17550142609424027, Loss: 0.002045607603924715\n",
      "Iteration:270, Price of Hedge: 0.1658732878418391, Loss: 0.0021614769503468523\n",
      "Iteration:280, Price of Hedge: 0.19215004558443524, Loss: 0.0018026892584610543\n",
      "Iteration:290, Price of Hedge: 0.17265148471503836, Loss: 0.002546723179002974\n",
      "Iteration:300, Price of Hedge: 0.19014281108359227, Loss: 0.002580465865544923\n",
      "Iteration:310, Price of Hedge: 0.1990350624805842, Loss: 0.0016813375391850904\n",
      "Iteration:320, Price of Hedge: 0.1860930206350531, Loss: 0.002477265615820379\n",
      "Iteration:330, Price of Hedge: 0.17551527131586225, Loss: 0.001955795583562114\n",
      "Iteration:340, Price of Hedge: 0.18114347313962753, Loss: 0.002094027522937125\n",
      "Iteration:350, Price of Hedge: 0.19877113355979645, Loss: 0.002437012816996642\n",
      "Iteration:360, Price of Hedge: 0.18084436304778817, Loss: 0.0023353816836220176\n",
      "Iteration:370, Price of Hedge: 0.15769893994248604, Loss: 0.002749486370751697\n",
      "Iteration:380, Price of Hedge: 0.15097047084096857, Loss: 0.002090580245111795\n",
      "Iteration:390, Price of Hedge: 0.1937990998533678, Loss: 0.0025975394032331065\n",
      "Iteration:400, Price of Hedge: 0.18616771749942698, Loss: 0.0019678347542379624\n",
      "Iteration:410, Price of Hedge: 0.1879329902700192, Loss: 0.001955265604049039\n",
      "Iteration:420, Price of Hedge: 0.18893545725886723, Loss: 0.002084205805831907\n",
      "Iteration:430, Price of Hedge: 0.19691576164181013, Loss: 0.0024227537817598233\n",
      "Iteration:440, Price of Hedge: 0.21176625576866853, Loss: 0.0019147348837933009\n",
      "Iteration:450, Price of Hedge: 0.17346995193487372, Loss: 0.002329634321011653\n",
      "Iteration:460, Price of Hedge: 0.17341234066313974, Loss: 0.002156518639120719\n",
      "Iteration:470, Price of Hedge: 0.1891758899828801, Loss: 0.0022349159353057145\n",
      "Iteration:480, Price of Hedge: 0.20813969144126077, Loss: 0.0021172552230604323\n",
      "Iteration:490, Price of Hedge: 0.19678118103771566, Loss: 0.002065773127134385\n",
      "Iteration:500, Price of Hedge: 0.18977079965764004, Loss: 0.0020969700270574874\n",
      "Iteration:510, Price of Hedge: 0.1761379275441868, Loss: 0.002104431603800094\n",
      "Iteration:520, Price of Hedge: 0.19376311911024685, Loss: 0.0024031780744598664\n",
      "Iteration:530, Price of Hedge: 0.17317300209037967, Loss: 0.0021672440392418225\n",
      "Iteration:540, Price of Hedge: 0.16312873567241012, Loss: 0.0020975438427585755\n",
      "Iteration:550, Price of Hedge: 0.188730808891853, Loss: 0.00280487712038191\n",
      "Iteration:560, Price of Hedge: 0.2156947216763683, Loss: 0.002125719771784773\n",
      "Iteration:570, Price of Hedge: 0.18357682344311568, Loss: 0.0021827488989419664\n",
      "Iteration:580, Price of Hedge: 0.16797188397229093, Loss: 0.0021803751693610708\n",
      "Iteration:590, Price of Hedge: 0.16387019147714454, Loss: 0.0019175138789323753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:600, Price of Hedge: 0.1737350451448151, Loss: 0.0017391065116054705\n",
      "Iteration:610, Price of Hedge: 0.17573474683510995, Loss: 0.0016437152404135346\n",
      "Iteration:620, Price of Hedge: 0.18709538943083998, Loss: 0.002036401346899197\n",
      "Iteration:630, Price of Hedge: 0.197376637788102, Loss: 0.0013987930332053367\n",
      "Iteration:640, Price of Hedge: 0.19313538489790288, Loss: 0.0018488385725248689\n",
      "Iteration:650, Price of Hedge: 0.18310229846132414, Loss: 0.001769773760786908\n",
      "Iteration:660, Price of Hedge: 0.18193241230321744, Loss: 0.0018465779403090464\n",
      "Iteration:670, Price of Hedge: 0.18765501974148718, Loss: 0.0016558866867867116\n",
      "Iteration:680, Price of Hedge: 0.20921866485232385, Loss: 0.001669025159467452\n",
      "Iteration:690, Price of Hedge: 0.221578449900403, Loss: 0.0014919976457487215\n",
      "Iteration:700, Price of Hedge: 0.1983994026854475, Loss: 0.0020546010362574307\n",
      "Iteration:710, Price of Hedge: 0.19688850605355127, Loss: 0.0019379288300518382\n",
      "Iteration:720, Price of Hedge: 0.19881536252005388, Loss: 0.0015868238684771717\n",
      "Iteration:730, Price of Hedge: 0.20280761183475987, Loss: 0.0014493863504194237\n",
      "Iteration:740, Price of Hedge: 0.18817878152965475, Loss: 0.0013912948532457392\n",
      "Iteration:750, Price of Hedge: 0.1831270150575733, Loss: 0.0017874412788226655\n",
      "Iteration:760, Price of Hedge: 0.1840027007768981, Loss: 0.001546365697112595\n",
      "Iteration:770, Price of Hedge: 0.16873494225047805, Loss: 0.0013052863893265431\n",
      "Iteration:780, Price of Hedge: 0.19115032800129939, Loss: 0.0015589624640999665\n",
      "Iteration:790, Price of Hedge: 0.18646072559389493, Loss: 0.0016411211243974044\n",
      "Iteration:800, Price of Hedge: 0.20210809849471614, Loss: 0.0016188977113414714\n",
      "Iteration:810, Price of Hedge: 0.1938630375637558, Loss: 0.0014507862590836139\n",
      "Iteration:820, Price of Hedge: 0.1869225415880578, Loss: 0.0013424373394864907\n",
      "Iteration:830, Price of Hedge: 0.16638753893065542, Loss: 0.0012115917977916445\n",
      "Iteration:840, Price of Hedge: 0.15570015004490187, Loss: 0.0014758212156482208\n",
      "Iteration:850, Price of Hedge: 0.18007601637187917, Loss: 0.0016627992152744575\n",
      "Iteration:860, Price of Hedge: 0.21100497899316223, Loss: 0.001836615837811717\n",
      "Iteration:870, Price of Hedge: 0.21076982063929106, Loss: 0.0016478759521987739\n",
      "Iteration:880, Price of Hedge: 0.2112107355390094, Loss: 0.001416380769378911\n",
      "Iteration:890, Price of Hedge: 0.21525584077577375, Loss: 0.0015106292311493517\n",
      "Iteration:900, Price of Hedge: 0.21120118275691765, Loss: 0.001385234609843433\n",
      "Iteration:910, Price of Hedge: 0.20229935052267364, Loss: 0.0018375177673800812\n",
      "Iteration:920, Price of Hedge: 0.16232084524801849, Loss: 0.0021325913134367267\n",
      "Iteration:930, Price of Hedge: 0.15894298991692038, Loss: 0.001327232976855175\n",
      "Iteration:940, Price of Hedge: 0.16696327290333102, Loss: 0.0014667299190257665\n",
      "Iteration:950, Price of Hedge: 0.1769235141161175, Loss: 0.001583821527960172\n",
      "Iteration:960, Price of Hedge: 0.18370336624377614, Loss: 0.0017405938734647462\n",
      "Iteration:970, Price of Hedge: 0.17712792401426894, Loss: 0.00171245564356024\n",
      "Iteration:980, Price of Hedge: 0.1855624975532464, Loss: 0.001735392819347492\n",
      "Iteration:990, Price of Hedge: 0.1846277978041712, Loss: 0.0016041139569341388\n",
      "tf.Tensor(0.19992203, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.09332391272906193, Loss: 0.0036825071938260123\n",
      "Iteration:20, Price of Hedge: 0.23961177391133787, Loss: 0.0030841658030874796\n",
      "Iteration:30, Price of Hedge: 0.18982540902721892, Loss: 0.0026677939083137757\n",
      "Iteration:40, Price of Hedge: 0.17266701324628, Loss: 0.0024423783664094144\n",
      "Iteration:50, Price of Hedge: 0.20591808746034984, Loss: 0.0023863506769673747\n",
      "Iteration:60, Price of Hedge: 0.17206155483123667, Loss: 0.002588437037973179\n",
      "Iteration:70, Price of Hedge: 0.19448454353050693, Loss: 0.0026848805968583632\n",
      "Iteration:80, Price of Hedge: 0.1885154574811736, Loss: 0.002564548068953698\n",
      "Iteration:90, Price of Hedge: 0.19145500704246388, Loss: 0.0018867746288121266\n",
      "Iteration:100, Price of Hedge: 0.19259014688450404, Loss: 0.002219627626374354\n",
      "Iteration:110, Price of Hedge: 0.18302333721258035, Loss: 0.0020790760951106433\n",
      "Iteration:120, Price of Hedge: 0.20721392726075008, Loss: 0.0029391701590830263\n",
      "Iteration:130, Price of Hedge: 0.18087095933977934, Loss: 0.0029797734282299257\n",
      "Iteration:140, Price of Hedge: 0.19430723491723256, Loss: 0.0027356183543119526\n",
      "Iteration:150, Price of Hedge: 0.1854554390614339, Loss: 0.002251599111739644\n",
      "Iteration:160, Price of Hedge: 0.1969644373449796, Loss: 0.0029674300344092685\n",
      "Iteration:170, Price of Hedge: 0.1856482200956293, Loss: 0.0020937419301722215\n",
      "Iteration:180, Price of Hedge: 0.1861993356651169, Loss: 0.0023273671133676285\n",
      "Iteration:190, Price of Hedge: 0.19035708237059906, Loss: 0.0025603939325966607\n",
      "Iteration:200, Price of Hedge: 0.2002009507783441, Loss: 0.0027628881893319245\n",
      "Iteration:210, Price of Hedge: 0.18962711515401906, Loss: 0.00214382850105288\n",
      "Iteration:220, Price of Hedge: 0.18778234808663682, Loss: 0.002749490754370498\n",
      "Iteration:230, Price of Hedge: 0.21150793787994643, Loss: 0.0023569444853245966\n",
      "Iteration:240, Price of Hedge: 0.1732664398018528, Loss: 0.002785134397205624\n",
      "Iteration:250, Price of Hedge: 0.18214549124591028, Loss: 0.002097469978781774\n",
      "Iteration:260, Price of Hedge: 0.19647589881060412, Loss: 0.002435582442181783\n",
      "Iteration:270, Price of Hedge: 0.17859264185226492, Loss: 0.002417238750945927\n",
      "Iteration:280, Price of Hedge: 0.1816803226600882, Loss: 0.002140350537895941\n",
      "Iteration:290, Price of Hedge: 0.17643980106931847, Loss: 0.0021754514887234676\n",
      "Iteration:300, Price of Hedge: 0.18813613768595586, Loss: 0.0019859743880186187\n",
      "Iteration:310, Price of Hedge: 0.1984427479081546, Loss: 0.001898206668283997\n",
      "Iteration:320, Price of Hedge: 0.18411754457570167, Loss: 0.0018848418912826403\n",
      "Iteration:330, Price of Hedge: 0.18223814341289424, Loss: 0.0020860366242242633\n",
      "Iteration:340, Price of Hedge: 0.20692940585228142, Loss: 0.0020630292009457206\n",
      "Iteration:350, Price of Hedge: 0.17723714275342672, Loss: 0.0018536625258347428\n",
      "Iteration:360, Price of Hedge: 0.18816459964610885, Loss: 0.0020377365971860685\n",
      "Iteration:370, Price of Hedge: 0.19114196756352156, Loss: 0.0018683406350289643\n",
      "Iteration:380, Price of Hedge: 0.19571570215877043, Loss: 0.0015545835576888933\n",
      "Iteration:390, Price of Hedge: 0.18284882008775866, Loss: 0.0016421752751286432\n",
      "Iteration:400, Price of Hedge: 0.17220950371922752, Loss: 0.0015446718668077784\n",
      "Iteration:410, Price of Hedge: 0.1794462481604114, Loss: 0.001332655184540954\n",
      "Iteration:420, Price of Hedge: 0.17702496157586436, Loss: 0.002064312943711677\n",
      "Iteration:430, Price of Hedge: 0.1931405751025636, Loss: 0.0019602329016937146\n",
      "Iteration:440, Price of Hedge: 0.19587062275410289, Loss: 0.0022156341496463836\n",
      "Iteration:450, Price of Hedge: 0.17621234385695742, Loss: 0.0016914041909908304\n",
      "Iteration:460, Price of Hedge: 0.2104476632332421, Loss: 0.0012639918234946812\n",
      "Iteration:470, Price of Hedge: 0.19029520671449518, Loss: 0.0015650183238834713\n",
      "Iteration:480, Price of Hedge: 0.1607074911706036, Loss: 0.0018640172909861973\n",
      "Iteration:490, Price of Hedge: 0.17810883061240473, Loss: 0.001569538492410416\n",
      "Iteration:500, Price of Hedge: 0.18588176527778158, Loss: 0.0015068824425694238\n",
      "Iteration:510, Price of Hedge: 0.20703026415366138, Loss: 0.0014836003855729805\n",
      "Iteration:520, Price of Hedge: 0.1916860272601866, Loss: 0.0013431644722551538\n",
      "Iteration:530, Price of Hedge: 0.1810773471267339, Loss: 0.0016388633415338027\n",
      "Iteration:540, Price of Hedge: 0.19254677360663663, Loss: 0.00158320069794744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:550, Price of Hedge: 0.18356154740831698, Loss: 0.0013834060928509472\n",
      "Iteration:560, Price of Hedge: 0.17150864373148805, Loss: 0.0016416031032846056\n",
      "Iteration:570, Price of Hedge: 0.20819877560891198, Loss: 0.0014327004342237436\n",
      "Iteration:580, Price of Hedge: 0.18008754704277408, Loss: 0.001547355299056985\n",
      "Iteration:590, Price of Hedge: 0.17957932781342834, Loss: 0.0018549423233437778\n",
      "Iteration:600, Price of Hedge: 0.18502692454258066, Loss: 0.0014522478671824322\n",
      "Iteration:610, Price of Hedge: 0.19546640400409387, Loss: 0.001779919317731071\n",
      "Iteration:620, Price of Hedge: 0.19077044710287508, Loss: 0.0015515452714977228\n",
      "Iteration:630, Price of Hedge: 0.18040845599418842, Loss: 0.0014723474169291428\n",
      "Iteration:640, Price of Hedge: 0.17554150289076914, Loss: 0.0014133863193757533\n",
      "Iteration:650, Price of Hedge: 0.19062220363570076, Loss: 0.0014172490546729753\n",
      "Iteration:660, Price of Hedge: 0.19786793975576983, Loss: 0.0018653084859041158\n",
      "Iteration:670, Price of Hedge: 0.170823803240296, Loss: 0.0013153151228296521\n",
      "Iteration:680, Price of Hedge: 0.18752672349330624, Loss: 0.0015429838447978737\n",
      "Iteration:690, Price of Hedge: 0.16560586605359048, Loss: 0.0013821035005241455\n",
      "Iteration:700, Price of Hedge: 0.1886469800727923, Loss: 0.001900619412072224\n",
      "Iteration:710, Price of Hedge: 0.18080024630817204, Loss: 0.0017088849668656534\n",
      "Iteration:720, Price of Hedge: 0.17020514487231822, Loss: 0.0013716973374422459\n",
      "Iteration:730, Price of Hedge: 0.15379245525290344, Loss: 0.0018605627801898449\n",
      "Iteration:740, Price of Hedge: 0.17300075743354454, Loss: 0.001608771990272384\n",
      "Iteration:750, Price of Hedge: 0.1925690634315174, Loss: 0.0016034615648660377\n",
      "Iteration:760, Price of Hedge: 0.17243282279544017, Loss: 0.0011262956719276572\n",
      "Iteration:770, Price of Hedge: 0.18662117305581205, Loss: 0.0015231160788952813\n",
      "Iteration:780, Price of Hedge: 0.18483224978506313, Loss: 0.0016414161419427307\n",
      "Iteration:790, Price of Hedge: 0.20189623995149758, Loss: 0.0012323795756901568\n",
      "Iteration:800, Price of Hedge: 0.1944421101005105, Loss: 0.0014345008960559014\n",
      "Iteration:810, Price of Hedge: 0.18101255373395586, Loss: 0.0017639993293304455\n",
      "Iteration:820, Price of Hedge: 0.18881337522869898, Loss: 0.0014299577135302498\n",
      "Iteration:830, Price of Hedge: 0.17796006812476434, Loss: 0.0015027849644853929\n",
      "Iteration:840, Price of Hedge: 0.178017651341338, Loss: 0.0013063908420835268\n",
      "Iteration:850, Price of Hedge: 0.19229228524729933, Loss: 0.0015666192214697004\n",
      "Iteration:860, Price of Hedge: 0.19052647942866086, Loss: 0.0017508596511545348\n",
      "Iteration:870, Price of Hedge: 0.18770212435567826, Loss: 0.0012978345661357692\n",
      "Iteration:880, Price of Hedge: 0.18739264788209764, Loss: 0.0012877975037569377\n",
      "Iteration:890, Price of Hedge: 0.16837603258439912, Loss: 0.0014904067208952652\n",
      "Iteration:900, Price of Hedge: 0.1653113850632053, Loss: 0.0014867965916314672\n",
      "Iteration:910, Price of Hedge: 0.17585973257437218, Loss: 0.0014676773286391941\n",
      "Iteration:920, Price of Hedge: 0.1742836918601938, Loss: 0.0014947995452960327\n",
      "Iteration:930, Price of Hedge: 0.18813143844660088, Loss: 0.0012142167087298538\n",
      "Iteration:940, Price of Hedge: 0.1789167911746972, Loss: 0.0015431310247991268\n",
      "Iteration:950, Price of Hedge: 0.18246421189481907, Loss: 0.001725493512189491\n",
      "Iteration:960, Price of Hedge: 0.17786556431719872, Loss: 0.00141880052695722\n",
      "Iteration:970, Price of Hedge: 0.1769622162097903, Loss: 0.0015773605122089583\n",
      "Iteration:980, Price of Hedge: 0.1789585793360061, Loss: 0.0014333619223008574\n",
      "Iteration:990, Price of Hedge: 0.17378055061486747, Loss: 0.0013870214824573067\n",
      "tf.Tensor(0.22055222, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.22349200822091006, Loss: 0.0037463300534014365\n",
      "Iteration:20, Price of Hedge: 0.18989864702325576, Loss: 0.0026272320643645486\n",
      "Iteration:30, Price of Hedge: 0.18507366443968748, Loss: 0.002362486256213181\n",
      "Iteration:40, Price of Hedge: 0.20316907452042868, Loss: 0.002650106663993412\n",
      "Iteration:50, Price of Hedge: 0.1857986238101489, Loss: 0.0030052385273894085\n",
      "Iteration:60, Price of Hedge: 0.21568717483824001, Loss: 0.0025008632933705144\n",
      "Iteration:70, Price of Hedge: 0.18406638599084316, Loss: 0.002580171724723357\n",
      "Iteration:80, Price of Hedge: 0.1997339586071007, Loss: 0.002314628974673916\n",
      "Iteration:90, Price of Hedge: 0.18444033322285802, Loss: 0.0023003307060488255\n",
      "Iteration:100, Price of Hedge: 0.18256333077625866, Loss: 0.0025902882401929615\n",
      "Iteration:110, Price of Hedge: 0.18938192708033055, Loss: 0.002501651468030985\n",
      "Iteration:120, Price of Hedge: 0.19309307771612794, Loss: 0.0024894056097286565\n",
      "Iteration:130, Price of Hedge: 0.200986467212374, Loss: 0.0027068804453554305\n",
      "Iteration:140, Price of Hedge: 0.2164713586521543, Loss: 0.002581465549812556\n",
      "Iteration:150, Price of Hedge: 0.19321962051678837, Loss: 0.0027657719529603497\n",
      "Iteration:160, Price of Hedge: 0.19049724595159886, Loss: 0.0024460461402604494\n",
      "Iteration:170, Price of Hedge: 0.16684792411164154, Loss: 0.0024731636445270767\n",
      "Iteration:180, Price of Hedge: 0.1906508058716554, Loss: 0.0022478449805982234\n",
      "Iteration:190, Price of Hedge: 0.21023946588844636, Loss: 0.0027665921280380697\n",
      "Iteration:200, Price of Hedge: 0.19299468826885685, Loss: 0.002883434199472212\n",
      "Iteration:210, Price of Hedge: 0.1799875865065246, Loss: 0.0026065718497731536\n",
      "Iteration:220, Price of Hedge: 0.1882581495782233, Loss: 0.0024997592789754107\n",
      "Iteration:230, Price of Hedge: 0.19657108996959777, Loss: 0.002204948202094492\n",
      "Iteration:240, Price of Hedge: 0.20128780768945942, Loss: 0.002351542332694834\n",
      "Iteration:250, Price of Hedge: 0.1964252452186315, Loss: 0.002207899692633397\n",
      "Iteration:260, Price of Hedge: 0.18748548240762375, Loss: 0.0024175881253643895\n",
      "Iteration:270, Price of Hedge: 0.1844910850078918, Loss: 0.0023587402347665432\n",
      "Iteration:280, Price of Hedge: 0.195397177895984, Loss: 0.0025156873770708185\n",
      "Iteration:290, Price of Hedge: 0.17818436913158847, Loss: 0.002581441878271029\n",
      "Iteration:300, Price of Hedge: 0.19107368130328267, Loss: 0.003034645157394067\n",
      "Iteration:310, Price of Hedge: 0.1874805306718258, Loss: 0.001892197384450256\n",
      "Iteration:320, Price of Hedge: 0.17903178927688257, Loss: 0.0020819225979792576\n",
      "Iteration:330, Price of Hedge: 0.18404338075937401, Loss: 0.0024224502161578343\n",
      "Iteration:340, Price of Hedge: 0.20270748296754845, Loss: 0.0029916843780558363\n",
      "Iteration:350, Price of Hedge: 0.19316310339630716, Loss: 0.002525580327981558\n",
      "Iteration:360, Price of Hedge: 0.1809756050878036, Loss: 0.0019313687445157157\n",
      "Iteration:370, Price of Hedge: 0.1664270265688174, Loss: 0.0019006588646414357\n",
      "Iteration:380, Price of Hedge: 0.21403739113513892, Loss: 0.006851751804875406\n",
      "Iteration:390, Price of Hedge: 0.21280557321060767, Loss: 0.0027319876220397886\n",
      "Iteration:400, Price of Hedge: 0.20038322515499657, Loss: 0.002102727910352975\n",
      "Iteration:410, Price of Hedge: 0.19650545492200988, Loss: 0.002153424023427952\n",
      "Iteration:420, Price of Hedge: 0.20710326368083543, Loss: 0.0024355515376692336\n",
      "Iteration:430, Price of Hedge: 0.19323771609520007, Loss: 0.001967820507476858\n",
      "Iteration:440, Price of Hedge: 0.17616915293763213, Loss: 0.002231583508292978\n",
      "Iteration:450, Price of Hedge: 0.1655593085150258, Loss: 0.0020777555299467563\n",
      "Iteration:460, Price of Hedge: 0.19307453325515098, Loss: 0.001647568879701744\n",
      "Iteration:470, Price of Hedge: 0.17960879975935312, Loss: 0.0016237053356713104\n",
      "Iteration:480, Price of Hedge: 0.17685717768952144, Loss: 0.001370572172086426\n",
      "Iteration:490, Price of Hedge: 0.1731964000940934, Loss: 0.0017178561523329527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:500, Price of Hedge: 0.18141541180868898, Loss: 0.0021580818375852573\n",
      "Iteration:510, Price of Hedge: 0.16778875391324846, Loss: 0.0015667428395198966\n",
      "Iteration:520, Price of Hedge: 0.16310860609487463, Loss: 0.0019032644876569192\n",
      "Iteration:530, Price of Hedge: 0.16967305070153316, Loss: 0.001105995023668438\n",
      "Iteration:540, Price of Hedge: 0.16329607067618782, Loss: 0.0013553267130288482\n",
      "Iteration:550, Price of Hedge: 0.18829944677422644, Loss: 0.0018007044654583025\n",
      "Iteration:560, Price of Hedge: 0.18035596478921434, Loss: 0.00153908088979815\n",
      "Iteration:570, Price of Hedge: 0.20855011038170232, Loss: 0.0016714566432260547\n",
      "Iteration:580, Price of Hedge: 0.18460334773194517, Loss: 0.001426948249632698\n",
      "Iteration:590, Price of Hedge: 0.18129819734883768, Loss: 0.0012307520476197097\n",
      "Iteration:600, Price of Hedge: 0.16718075650619538, Loss: 0.0014152873852594004\n",
      "Iteration:610, Price of Hedge: 0.1917321499437662, Loss: 0.0014414007120491235\n",
      "Iteration:620, Price of Hedge: 0.16919361606668418, Loss: 0.0011799493030173914\n",
      "Iteration:630, Price of Hedge: 0.1764286631706682, Loss: 0.0014524218968488432\n",
      "Iteration:640, Price of Hedge: 0.19003305929638825, Loss: 0.001577233387263721\n",
      "Iteration:650, Price of Hedge: 0.18116876486666342, Loss: 0.001430409007085842\n",
      "Iteration:660, Price of Hedge: 0.17983404061404826, Loss: 0.0016933595041571435\n",
      "Iteration:670, Price of Hedge: 0.18002785968917578, Loss: 0.0013118263102161797\n",
      "Iteration:680, Price of Hedge: 0.17736177780318485, Loss: 0.001332659129797875\n",
      "Iteration:690, Price of Hedge: 0.17596276515067757, Loss: 0.0015659474318884036\n",
      "Iteration:700, Price of Hedge: 0.18619317755742484, Loss: 0.0014873876130363506\n",
      "Iteration:710, Price of Hedge: 0.15804453743498925, Loss: 0.0014051041291935462\n",
      "Iteration:720, Price of Hedge: 0.1658005548386882, Loss: 0.0015494360933114848\n",
      "Iteration:730, Price of Hedge: 0.1784008146935207, Loss: 0.001475572445281248\n",
      "Iteration:740, Price of Hedge: 0.16906850407920046, Loss: 0.0014110809742481577\n",
      "Iteration:750, Price of Hedge: 0.17850011593350246, Loss: 0.0016120880883050857\n",
      "Iteration:760, Price of Hedge: 0.17951506746869653, Loss: 0.0015476906458952832\n",
      "Iteration:770, Price of Hedge: 0.20291694279455896, Loss: 0.0014562866047745258\n",
      "Iteration:780, Price of Hedge: 0.17835452367897914, Loss: 0.0013950896424515411\n",
      "Iteration:790, Price of Hedge: 0.19747612138662587, Loss: 0.0015207941856067108\n",
      "Iteration:800, Price of Hedge: 0.1872712251481971, Loss: 0.0013636057250874245\n",
      "Iteration:810, Price of Hedge: 0.18584436774906407, Loss: 0.0012524912899790407\n",
      "Iteration:820, Price of Hedge: 0.18515334109501963, Loss: 0.0013866511762590681\n",
      "Iteration:830, Price of Hedge: 0.17553161344675344, Loss: 0.0013394642596249895\n",
      "Iteration:840, Price of Hedge: 0.1924733392244775, Loss: 0.0012947949648589585\n",
      "Iteration:850, Price of Hedge: 0.19612346988656099, Loss: 0.0016024474146563604\n",
      "Iteration:860, Price of Hedge: 0.19456903164583536, Loss: 0.0015537694100870247\n",
      "Iteration:870, Price of Hedge: 0.1881105233245762, Loss: 0.001603272082943352\n",
      "Iteration:880, Price of Hedge: 0.19745810997369517, Loss: 0.0014027637151155401\n",
      "Iteration:890, Price of Hedge: 0.1884022969919897, Loss: 0.0014703545142316088\n",
      "Iteration:900, Price of Hedge: 0.19181604890072776, Loss: 0.0014728799170230288\n",
      "Iteration:910, Price of Hedge: 0.179406381777585, Loss: 0.0015995445822861497\n",
      "Iteration:920, Price of Hedge: 0.1872725577683127, Loss: 0.0015935337641858282\n",
      "Iteration:930, Price of Hedge: 0.19807598279718375, Loss: 0.0015086924387724741\n",
      "Iteration:940, Price of Hedge: 0.20126325942417223, Loss: 0.001495036370301772\n",
      "Iteration:950, Price of Hedge: 0.2063246347886661, Loss: 0.0018974739464013622\n",
      "Iteration:960, Price of Hedge: 0.1865244528905805, Loss: 0.0014615680982967838\n",
      "Iteration:970, Price of Hedge: 0.16950194227869134, Loss: 0.0015749428368495798\n",
      "Iteration:980, Price of Hedge: 0.20534539747256986, Loss: 0.0018270975767180175\n",
      "Iteration:990, Price of Hedge: 0.19845474148919492, Loss: 0.0013994687680435546\n",
      "tf.Tensor(0.22790256, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_11 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.24530728006473054, Loss: 0.003739828708357251\n",
      "Iteration:20, Price of Hedge: 0.15149099225811824, Loss: 0.0024251972108796593\n",
      "Iteration:30, Price of Hedge: 0.21714357432119868, Loss: 0.0029609889641236007\n",
      "Iteration:40, Price of Hedge: 0.17841029733771163, Loss: 0.002415421302590914\n",
      "Iteration:50, Price of Hedge: 0.20733787495908018, Loss: 0.0027195059250459505\n",
      "Iteration:60, Price of Hedge: 0.18481346685522337, Loss: 0.002075689092043831\n",
      "Iteration:70, Price of Hedge: 0.1878971918854404, Loss: 0.0024169235687541146\n",
      "Iteration:80, Price of Hedge: 0.19434408537032366, Loss: 0.002849010298568544\n",
      "Iteration:90, Price of Hedge: 0.18510035892473978, Loss: 0.0024963571524237336\n",
      "Iteration:100, Price of Hedge: 0.2004754144118351, Loss: 0.0027736436172418164\n",
      "Iteration:110, Price of Hedge: 0.1809994098913421, Loss: 0.0025697395887000593\n",
      "Iteration:120, Price of Hedge: 0.1868295948418904, Loss: 0.0026376221176473533\n",
      "Iteration:130, Price of Hedge: 0.20998523002555203, Loss: 0.002432629198195357\n",
      "Iteration:140, Price of Hedge: 0.1900897166926711, Loss: 0.00267262027261399\n",
      "Iteration:150, Price of Hedge: 0.19030299202148626, Loss: 0.0017496395804516673\n",
      "Iteration:160, Price of Hedge: 0.18901357685280118, Loss: 0.002158662447895487\n",
      "Iteration:170, Price of Hedge: 0.16039386253329438, Loss: 0.002695741231619486\n",
      "Iteration:180, Price of Hedge: 0.190783604973069, Loss: 0.002717715655127506\n",
      "Iteration:190, Price of Hedge: 0.19288091056614576, Loss: 0.0028630806190159674\n",
      "Iteration:200, Price of Hedge: 0.21198779334220033, Loss: 0.002520998569610455\n",
      "Iteration:210, Price of Hedge: 0.17090488265364456, Loss: 0.0019810908174930472\n",
      "Iteration:220, Price of Hedge: 0.18661922322216923, Loss: 0.0028224144449392695\n",
      "Iteration:230, Price of Hedge: 0.19011162777288745, Loss: 0.003026152991871278\n",
      "Iteration:240, Price of Hedge: 0.16721691960785848, Loss: 0.0029184759714459218\n",
      "Iteration:250, Price of Hedge: 0.1721082105628625, Loss: 0.0023229738506049813\n",
      "Iteration:260, Price of Hedge: 0.18854095962191195, Loss: 0.002108896977092023\n",
      "Iteration:270, Price of Hedge: 0.20408776880053664, Loss: 0.001975643951951511\n",
      "Iteration:280, Price of Hedge: 0.19005140737124293, Loss: 0.002132173335384024\n",
      "Iteration:290, Price of Hedge: 0.17534748742951933, Loss: 0.0018534676739790255\n",
      "Iteration:300, Price of Hedge: 0.1863564165077946, Loss: 0.002390538567189182\n",
      "Iteration:310, Price of Hedge: 0.20018319186185635, Loss: 0.0022667186513471546\n",
      "Iteration:320, Price of Hedge: 0.17938361501497865, Loss: 0.003150209842309515\n",
      "Iteration:330, Price of Hedge: 0.17894725907881365, Loss: 0.0025370027234920653\n",
      "Iteration:340, Price of Hedge: 0.17335700185939232, Loss: 0.0020432794639793526\n",
      "Iteration:350, Price of Hedge: 0.18649088489124777, Loss: 0.0024777085805002485\n",
      "Iteration:360, Price of Hedge: 0.17418338063444025, Loss: 0.0028303588772928376\n",
      "Iteration:370, Price of Hedge: 0.18499366515001156, Loss: 0.002250840088144201\n",
      "Iteration:380, Price of Hedge: 0.1794031834893076, Loss: 0.0021263814790428268\n",
      "Iteration:390, Price of Hedge: 0.15340303559996754, Loss: 0.0019083133206112988\n",
      "Iteration:400, Price of Hedge: 0.14850045244293142, Loss: 0.0023289807234483815\n",
      "Iteration:410, Price of Hedge: 0.20413522410423182, Loss: 0.0022701917925234127\n",
      "Iteration:420, Price of Hedge: 0.18875084027632738, Loss: 0.0023209534406994693\n",
      "Iteration:430, Price of Hedge: 0.17998476696291163, Loss: 0.0019983195352867964\n",
      "Iteration:440, Price of Hedge: 0.176659262560986, Loss: 0.0023820312781815288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:450, Price of Hedge: 0.1936689098818647, Loss: 0.0025442462151993085\n",
      "Iteration:460, Price of Hedge: 0.2037276808177239, Loss: 0.0019905381735526363\n",
      "Iteration:470, Price of Hedge: 0.19563206972583203, Loss: 0.001299955580092771\n",
      "Iteration:480, Price of Hedge: 0.22125507209487977, Loss: 0.002295616781570864\n",
      "Iteration:490, Price of Hedge: 0.1913603629590966, Loss: 0.0023682454545943085\n",
      "Iteration:500, Price of Hedge: 0.206261202071164, Loss: 0.001826836860989811\n",
      "Iteration:510, Price of Hedge: 0.20403113945941412, Loss: 0.0020270846226798866\n",
      "Iteration:520, Price of Hedge: 0.19578663963166035, Loss: 0.002322120140843431\n",
      "Iteration:530, Price of Hedge: 0.18875788212156974, Loss: 0.001236038472713119\n",
      "Iteration:540, Price of Hedge: 0.19058198656337025, Loss: 0.0016079957609731466\n",
      "Iteration:550, Price of Hedge: 0.1978797930610085, Loss: 0.0015116667241291458\n",
      "Iteration:560, Price of Hedge: 0.20746026559601205, Loss: 0.0014872814198708894\n",
      "Iteration:570, Price of Hedge: 0.18813183121884547, Loss: 0.0017176295192409263\n",
      "Iteration:580, Price of Hedge: 0.2053486518711679, Loss: 0.0017034664852558555\n",
      "Iteration:590, Price of Hedge: 0.17677504620766057, Loss: 0.001891490964280429\n",
      "Iteration:600, Price of Hedge: 0.18328704169208548, Loss: 0.0016086723725351247\n",
      "Iteration:610, Price of Hedge: 0.17763736364308896, Loss: 0.0016531144862567792\n",
      "Iteration:620, Price of Hedge: 0.18330920526874478, Loss: 0.0013629736072562793\n",
      "Iteration:630, Price of Hedge: 0.18981453765259174, Loss: 0.001402814017141285\n",
      "Iteration:640, Price of Hedge: 0.19311525532036738, Loss: 0.0015750445368057696\n",
      "Iteration:650, Price of Hedge: 0.20701566144271055, Loss: 0.0015594412648635369\n",
      "Iteration:660, Price of Hedge: 0.196154414728403, Loss: 0.001657795095231851\n",
      "Iteration:670, Price of Hedge: 0.18727894031728737, Loss: 0.0014162424662057303\n",
      "Iteration:680, Price of Hedge: 0.19384129481450144, Loss: 0.0016673773571600492\n",
      "Iteration:690, Price of Hedge: 0.19668711208513512, Loss: 0.0012626959161865514\n",
      "Iteration:700, Price of Hedge: 0.19843717895882945, Loss: 0.0013674349257008166\n",
      "Iteration:710, Price of Hedge: 0.19235149566317203, Loss: 0.001464281887106189\n",
      "Iteration:720, Price of Hedge: 0.18841151311215754, Loss: 0.0016084913290786316\n",
      "Iteration:730, Price of Hedge: 0.21060321506968194, Loss: 0.0017015291449266278\n",
      "Iteration:740, Price of Hedge: 0.2063233863340315, Loss: 0.001479534140772909\n",
      "Iteration:750, Price of Hedge: 0.21337701474375306, Loss: 0.0015063393121999445\n",
      "Iteration:760, Price of Hedge: 0.19900334612183312, Loss: 0.0012639685903150343\n",
      "Iteration:770, Price of Hedge: 0.20231847011443732, Loss: 0.0012795138888986202\n",
      "Iteration:780, Price of Hedge: 0.1990415151674597, Loss: 0.0015253170938954062\n",
      "Iteration:790, Price of Hedge: 0.1834533807376715, Loss: 0.0017861254260489899\n",
      "Iteration:800, Price of Hedge: 0.1971562645037238, Loss: 0.0015762800597649118\n",
      "Iteration:810, Price of Hedge: 0.18595844003095863, Loss: 0.0014441626110748727\n",
      "Iteration:820, Price of Hedge: 0.17933130616854667, Loss: 0.0013523488111866655\n",
      "Iteration:830, Price of Hedge: 0.1707987078993824, Loss: 0.0016786244079185053\n",
      "Iteration:840, Price of Hedge: 0.17864553985706377, Loss: 0.001461715497478977\n",
      "Iteration:850, Price of Hedge: 0.19949123938752109, Loss: 0.0017350186774828023\n",
      "Iteration:860, Price of Hedge: 0.19752981896349409, Loss: 0.0016010697528575867\n",
      "Iteration:870, Price of Hedge: 0.19791776572051276, Loss: 0.0014382987537948644\n",
      "Iteration:880, Price of Hedge: 0.2016813795061239, Loss: 0.001364095375307528\n",
      "Iteration:890, Price of Hedge: 0.19396190394875246, Loss: 0.001462077146030083\n",
      "Iteration:900, Price of Hedge: 0.18989241877766289, Loss: 0.0016981571557542095\n",
      "Iteration:910, Price of Hedge: 0.18725355039719033, Loss: 0.001623515963339095\n",
      "Iteration:920, Price of Hedge: 0.1926425118412567, Loss: 0.0014515261043468008\n",
      "Iteration:930, Price of Hedge: 0.18279617457940275, Loss: 0.0015276131238330492\n",
      "Iteration:940, Price of Hedge: 0.19197691719004978, Loss: 0.0016881355456316526\n",
      "Iteration:950, Price of Hedge: 0.17929045785510878, Loss: 0.0014134823206275015\n",
      "Iteration:960, Price of Hedge: 0.18747602781859313, Loss: 0.0015781267687754229\n",
      "Iteration:970, Price of Hedge: 0.19467690373729737, Loss: 0.0014267528498246307\n",
      "Iteration:980, Price of Hedge: 0.18578923935901911, Loss: 0.0014294277340171746\n",
      "Iteration:990, Price of Hedge: 0.19491942657075467, Loss: 0.001713141351131231\n",
      "tf.Tensor(0.15207344, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.1235170375914663, Loss: 0.0024518831478753\n",
      "Iteration:20, Price of Hedge: 0.2250532077552748, Loss: 0.0024724057168363342\n",
      "Iteration:30, Price of Hedge: 0.17390114572153834, Loss: 0.0023297682405660322\n",
      "Iteration:40, Price of Hedge: 0.187867327167271, Loss: 0.002089903852730757\n",
      "Iteration:50, Price of Hedge: 0.2119698660947506, Loss: 0.002647904553088587\n",
      "Iteration:60, Price of Hedge: 0.1746078411826261, Loss: 0.0024514954167923265\n",
      "Iteration:70, Price of Hedge: 0.1974530880999964, Loss: 0.0025938823692481347\n",
      "Iteration:80, Price of Hedge: 0.18358996728572946, Loss: 0.0025621033247482214\n",
      "Iteration:90, Price of Hedge: 0.20671137517379065, Loss: 0.0022940687065911903\n",
      "Iteration:100, Price of Hedge: 0.18954715794708363, Loss: 0.0026676766465108413\n",
      "Iteration:110, Price of Hedge: 0.16934372520202032, Loss: 0.0017286248406897186\n",
      "Iteration:120, Price of Hedge: 0.1850056447034717, Loss: 0.002215297268541505\n",
      "Iteration:130, Price of Hedge: 0.2001839072684447, Loss: 0.0021026485668526715\n",
      "Iteration:140, Price of Hedge: 0.21283633569390759, Loss: 0.002304158481986107\n",
      "Iteration:150, Price of Hedge: 0.1795904376569183, Loss: 0.002183491922328784\n",
      "Iteration:160, Price of Hedge: 0.15693499792674856, Loss: 0.0022826599002989667\n",
      "Iteration:170, Price of Hedge: 0.15873835557748633, Loss: 0.002550797314316888\n",
      "Iteration:180, Price of Hedge: 0.19202055699194032, Loss: 0.0021159421100485076\n",
      "Iteration:190, Price of Hedge: 0.2285446023202212, Loss: 0.0028182627195725727\n",
      "Iteration:200, Price of Hedge: 0.18832305519164264, Loss: 0.0016014105792193866\n",
      "Iteration:210, Price of Hedge: 0.18508220723600743, Loss: 0.002489475966810417\n",
      "Iteration:220, Price of Hedge: 0.1828263338767556, Loss: 0.0024536015264454035\n",
      "Iteration:230, Price of Hedge: 0.20428283633029876, Loss: 0.0021502360366547177\n",
      "Iteration:240, Price of Hedge: 0.20490508575879857, Loss: 0.0022876144854491187\n",
      "Iteration:250, Price of Hedge: 0.17689749295491308, Loss: 0.0021295166432095058\n",
      "Iteration:260, Price of Hedge: 0.2014463894832147, Loss: 0.002162541950534624\n",
      "Iteration:270, Price of Hedge: 0.19939586586998528, Loss: 0.0024681991962346218\n",
      "Iteration:280, Price of Hedge: 0.20460552678439398, Loss: 0.002730026829349974\n",
      "Iteration:290, Price of Hedge: 0.17878829854039394, Loss: 0.002826600581713556\n",
      "Iteration:300, Price of Hedge: 0.1747346645348898, Loss: 0.002098131686039828\n",
      "Iteration:310, Price of Hedge: 0.16965635788113786, Loss: 0.0017761468849811556\n",
      "Iteration:320, Price of Hedge: 0.19818426168847053, Loss: 0.0026539254535121516\n",
      "Iteration:330, Price of Hedge: 0.18104178721101788, Loss: 0.0021687081679214516\n",
      "Iteration:340, Price of Hedge: 0.18073724844565503, Loss: 0.0020893664210657192\n",
      "Iteration:350, Price of Hedge: 0.1787073734304272, Loss: 0.0020573820040249657\n",
      "Iteration:360, Price of Hedge: 0.19061716773442183, Loss: 0.0021248820622318475\n",
      "Iteration:370, Price of Hedge: 0.18135683263392366, Loss: 0.0022560110048821967\n",
      "Iteration:380, Price of Hedge: 0.19902389652677355, Loss: 0.0022899338581568785\n",
      "Iteration:390, Price of Hedge: 0.20028556514189402, Loss: 0.0019508182035941955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:400, Price of Hedge: 0.18647193363044606, Loss: 0.0022275255923686287\n",
      "Iteration:410, Price of Hedge: 0.2010270069190483, Loss: 0.002450309867087519\n",
      "Iteration:420, Price of Hedge: 0.21275789346562987, Loss: 0.0021740454429929556\n",
      "Iteration:430, Price of Hedge: 0.2310493950894852, Loss: 0.002572616996081223\n",
      "Iteration:440, Price of Hedge: 0.20971504480401107, Loss: 0.0024127597884357143\n",
      "Iteration:450, Price of Hedge: 0.20994065037579046, Loss: 0.0020043419699769414\n",
      "Iteration:460, Price of Hedge: 0.20507134063890362, Loss: 0.0026995030340938087\n",
      "Iteration:470, Price of Hedge: 0.17319982282365345, Loss: 0.0021100426358657384\n",
      "Iteration:480, Price of Hedge: 0.14549114372548502, Loss: 0.0027638096260039543\n",
      "Iteration:490, Price of Hedge: 0.16965191113822584, Loss: 0.0025606964022939493\n",
      "Iteration:500, Price of Hedge: 0.1851752381476558, Loss: 0.002276375544385445\n",
      "Iteration:510, Price of Hedge: 0.173465785743565, Loss: 0.002361691286943568\n",
      "Iteration:520, Price of Hedge: 0.18051338229381597, Loss: 0.0019710977008926987\n",
      "Iteration:530, Price of Hedge: 0.1782850871571668, Loss: 0.0020293270628776836\n",
      "Iteration:540, Price of Hedge: 0.17136364063533163, Loss: 0.0020326476541196567\n",
      "Iteration:550, Price of Hedge: 0.19108424407114624, Loss: 0.002187519152921524\n",
      "Iteration:560, Price of Hedge: 0.21320812267857717, Loss: 0.0030370872714282626\n",
      "Iteration:570, Price of Hedge: 0.19941470491014568, Loss: 0.0018107847064823268\n",
      "Iteration:580, Price of Hedge: 0.2055617588690211, Loss: 0.0015524358036572037\n",
      "Iteration:590, Price of Hedge: 0.20845563462929703, Loss: 0.0018235283246995414\n",
      "Iteration:600, Price of Hedge: 0.21862247404274057, Loss: 0.0018809295115024937\n",
      "Iteration:610, Price of Hedge: 0.20142060679087306, Loss: 0.002003910402705955\n",
      "Iteration:620, Price of Hedge: 0.20435732278097019, Loss: 0.001563867733538604\n",
      "Iteration:630, Price of Hedge: 0.20270408829314873, Loss: 0.001678098812024231\n",
      "Iteration:640, Price of Hedge: 0.20533860812377042, Loss: 0.0016289023349411735\n",
      "Iteration:650, Price of Hedge: 0.18151669093747386, Loss: 0.0014591029702638813\n",
      "Iteration:660, Price of Hedge: 0.19023623476748525, Loss: 0.0017152835160489488\n",
      "Iteration:670, Price of Hedge: 0.18116448645471336, Loss: 0.001217772700301456\n",
      "Iteration:680, Price of Hedge: 0.18273704832901103, Loss: 0.0018639353173146133\n",
      "Iteration:690, Price of Hedge: 0.16275014531136092, Loss: 0.0014031584599885959\n",
      "Iteration:700, Price of Hedge: 0.1663835550978888, Loss: 0.001628293121518265\n",
      "Iteration:710, Price of Hedge: 0.199494311427577, Loss: 0.0015382318924268112\n",
      "Iteration:720, Price of Hedge: 0.19167134038375477, Loss: 0.001850121438567065\n",
      "Iteration:730, Price of Hedge: 0.19732627877531284, Loss: 0.0014905792162950959\n",
      "Iteration:740, Price of Hedge: 0.19964691747218238, Loss: 0.0018689197110726141\n",
      "Iteration:750, Price of Hedge: 0.18827945747249258, Loss: 0.00179366623670143\n",
      "Iteration:760, Price of Hedge: 0.19002288930076927, Loss: 0.0014441073774779766\n",
      "Iteration:770, Price of Hedge: 0.19345769660733367, Loss: 0.0015180947531488796\n",
      "Iteration:780, Price of Hedge: 0.18829326061137408, Loss: 0.0014612029428506367\n",
      "Iteration:790, Price of Hedge: 0.1914988853132172, Loss: 0.0016050342977014685\n",
      "Iteration:800, Price of Hedge: 0.19671727138248796, Loss: 0.0017897638296540562\n",
      "Iteration:810, Price of Hedge: 0.20540316304768566, Loss: 0.001961219654285884\n",
      "Iteration:820, Price of Hedge: 0.19334394695978288, Loss: 0.0014032056934811798\n",
      "Iteration:830, Price of Hedge: 0.17427576627740107, Loss: 0.0012111157367898251\n",
      "Iteration:840, Price of Hedge: 0.1850650515054667, Loss: 0.0012369773342698841\n",
      "Iteration:850, Price of Hedge: 0.19617088310751568, Loss: 0.0017603819670956255\n",
      "Iteration:860, Price of Hedge: 0.20087793582464428, Loss: 0.0014802826436832283\n",
      "Iteration:870, Price of Hedge: 0.20531261501772632, Loss: 0.0013535747997749147\n",
      "Iteration:880, Price of Hedge: 0.19941090343592122, Loss: 0.0015107769591029552\n",
      "Iteration:890, Price of Hedge: 0.19809043120475278, Loss: 0.0014779292979297586\n",
      "Iteration:900, Price of Hedge: 0.20521191101972816, Loss: 0.0014366887601996224\n",
      "Iteration:910, Price of Hedge: 0.20605171418899315, Loss: 0.0014877351244168223\n",
      "Iteration:920, Price of Hedge: 0.17898044833348192, Loss: 0.0016854426886020234\n",
      "Iteration:930, Price of Hedge: 0.2067294988073627, Loss: 0.001881237679904224\n",
      "Iteration:940, Price of Hedge: 0.18792057586157396, Loss: 0.0013575504132562698\n",
      "Iteration:950, Price of Hedge: 0.1893837506657519, Loss: 0.0015979063143496397\n",
      "Iteration:960, Price of Hedge: 0.19673606833990787, Loss: 0.0016533065983507455\n",
      "Iteration:970, Price of Hedge: 0.18798910059067564, Loss: 0.0015068712643414805\n",
      "Iteration:980, Price of Hedge: 0.17871496235129597, Loss: 0.0014121006039813366\n",
      "Iteration:990, Price of Hedge: 0.19052734913863104, Loss: 0.001608682893220248\n",
      "tf.Tensor(0.1964497, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_13 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.19834658884612963, Loss: 0.0057177766903507175\n",
      "Iteration:20, Price of Hedge: 0.17899489674105096, Loss: 0.00252470119323096\n",
      "Iteration:30, Price of Hedge: 0.20588763358381357, Loss: 0.0027320172114666972\n",
      "Iteration:40, Price of Hedge: 0.17880842811792944, Loss: 0.0027224330865005084\n",
      "Iteration:50, Price of Hedge: 0.19008821574159354, Loss: 0.0026852591223418543\n",
      "Iteration:60, Price of Hedge: 0.20359394186843927, Loss: 0.002498756526174617\n",
      "Iteration:70, Price of Hedge: 0.18223846604723803, Loss: 0.0022792775000318954\n",
      "Iteration:80, Price of Hedge: 0.18091280361140888, Loss: 0.002300155361296774\n",
      "Iteration:90, Price of Hedge: 0.19107314825523644, Loss: 0.002028853412866205\n",
      "Iteration:100, Price of Hedge: 0.19871796903097447, Loss: 0.002280777574385695\n",
      "Iteration:110, Price of Hedge: 0.2019373127062181, Loss: 0.002326969080780472\n",
      "Iteration:120, Price of Hedge: 0.2101796943693671, Loss: 0.0024954994974052624\n",
      "Iteration:130, Price of Hedge: 0.20550919752614616, Loss: 0.0026413183850205967\n",
      "Iteration:140, Price of Hedge: 0.20971584437608043, Loss: 0.0025786692393792165\n",
      "Iteration:150, Price of Hedge: 0.18735286566475223, Loss: 0.0028380657175073763\n",
      "Iteration:160, Price of Hedge: 0.1937454724144004, Loss: 0.0021431711774136273\n",
      "Iteration:170, Price of Hedge: 0.16956447723106294, Loss: 0.002398420532974832\n",
      "Iteration:180, Price of Hedge: 0.2158752987158209, Loss: 0.0029819906626196158\n",
      "Iteration:190, Price of Hedge: 0.2125086654488541, Loss: 0.002446242964744627\n",
      "Iteration:200, Price of Hedge: 0.2020145906453422, Loss: 0.0021394630742696207\n",
      "Iteration:210, Price of Hedge: 0.17535663341178634, Loss: 0.0026925970810342645\n",
      "Iteration:220, Price of Hedge: 0.16528278282725067, Loss: 0.0023180144434741478\n",
      "Iteration:230, Price of Hedge: 0.18624169895721251, Loss: 0.0018603368046406386\n",
      "Iteration:240, Price of Hedge: 0.1817472903277917, Loss: 0.0019503164984223885\n",
      "Iteration:250, Price of Hedge: 0.21349756776768344, Loss: 0.0028173265977775586\n",
      "Iteration:260, Price of Hedge: 0.1787399314439881, Loss: 0.0024282865662298646\n",
      "Iteration:270, Price of Hedge: 0.2030694787012635, Loss: 0.002060676951096951\n",
      "Iteration:280, Price of Hedge: 0.1800749081930462, Loss: 0.0022531572690425604\n",
      "Iteration:290, Price of Hedge: 0.1936072306118831, Loss: 0.002518582099746247\n",
      "Iteration:300, Price of Hedge: 0.19875599780079936, Loss: 0.0027942119950193243\n",
      "Iteration:310, Price of Hedge: 0.1918463625014624, Loss: 0.0021889966516384974\n",
      "Iteration:320, Price of Hedge: 0.17344047998894893, Loss: 0.0018729673254927802\n",
      "Iteration:330, Price of Hedge: 0.18957578823819857, Loss: 0.0021121246356154088\n",
      "Iteration:340, Price of Hedge: 0.17524167739234145, Loss: 0.002091989797737348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:350, Price of Hedge: 0.1933020044950922, Loss: 0.0026783547035488906\n",
      "Iteration:360, Price of Hedge: 0.17354666877079125, Loss: 0.002251773579767935\n",
      "Iteration:370, Price of Hedge: 0.18615014094148136, Loss: 0.0018738732003180658\n",
      "Iteration:380, Price of Hedge: 0.18588083945749076, Loss: 0.0020175342515784678\n",
      "Iteration:390, Price of Hedge: 0.20278561658906255, Loss: 0.0016971294163262483\n",
      "Iteration:400, Price of Hedge: 0.20136664268998172, Loss: 0.0024963597825950145\n",
      "Iteration:410, Price of Hedge: 0.21494901551484416, Loss: 0.0021828854486676263\n",
      "Iteration:420, Price of Hedge: 0.20659807440880512, Loss: 0.002163056368200955\n",
      "Iteration:430, Price of Hedge: 0.19357993294088371, Loss: 0.001529841207679272\n",
      "Iteration:440, Price of Hedge: 0.18652509815926804, Loss: 0.002392378152819141\n",
      "Iteration:450, Price of Hedge: 0.1608712631690196, Loss: 0.0015850052146269887\n",
      "Iteration:460, Price of Hedge: 0.17212330423911906, Loss: 0.0016216481033678675\n",
      "Iteration:470, Price of Hedge: 0.1808327482114123, Loss: 0.0017745610012893209\n",
      "Iteration:480, Price of Hedge: 0.17656243017511314, Loss: 0.0024643109263578823\n",
      "Iteration:490, Price of Hedge: 0.1918313109079463, Loss: 0.002000450412386101\n",
      "Iteration:500, Price of Hedge: 0.18092618592288545, Loss: 0.0021372714840499183\n",
      "Iteration:510, Price of Hedge: 0.17748411232979605, Loss: 0.001655263226602699\n",
      "Iteration:520, Price of Hedge: 0.17847504864774918, Loss: 0.001739740163703196\n",
      "Iteration:530, Price of Hedge: 0.18168064529443198, Loss: 0.0012221821824536683\n",
      "Iteration:540, Price of Hedge: 0.1847507214891493, Loss: 0.0014869405935090895\n",
      "Iteration:550, Price of Hedge: 0.186865631695332, Loss: 0.0013953882764823787\n",
      "Iteration:560, Price of Hedge: 0.18531781447244383, Loss: 0.0015422396159158857\n",
      "Iteration:570, Price of Hedge: 0.20153811582990783, Loss: 0.0014706238876069477\n",
      "Iteration:580, Price of Hedge: 0.18841841468159826, Loss: 0.0014595758531420699\n",
      "Iteration:590, Price of Hedge: 0.1751290078684633, Loss: 0.0016831423846360492\n",
      "Iteration:600, Price of Hedge: 0.17724087408975037, Loss: 0.0016736365072654634\n",
      "Iteration:610, Price of Hedge: 0.17986832401996933, Loss: 0.0013080962889781666\n",
      "Iteration:620, Price of Hedge: 0.16593788484849484, Loss: 0.001477848639343815\n",
      "Iteration:630, Price of Hedge: 0.18260950957015892, Loss: 0.0013890478102482006\n",
      "Iteration:640, Price of Hedge: 0.1771926612967263, Loss: 0.001471324609072333\n",
      "Iteration:650, Price of Hedge: 0.18927169835540097, Loss: 0.0012745950302416986\n",
      "Iteration:660, Price of Hedge: 0.18335731986870768, Loss: 0.0013747532676990915\n",
      "Iteration:670, Price of Hedge: 0.18443762589988635, Loss: 0.001493343635901656\n",
      "Iteration:680, Price of Hedge: 0.1962968507773894, Loss: 0.0018023797749736835\n",
      "Iteration:690, Price of Hedge: 0.1875650748974749, Loss: 0.0016682104639132332\n",
      "Iteration:700, Price of Hedge: 0.172788814724845, Loss: 0.0011976460817086476\n",
      "Iteration:710, Price of Hedge: 0.17896741671150948, Loss: 0.001335551879844843\n",
      "Iteration:720, Price of Hedge: 0.18609515282723804, Loss: 0.0014725646252407463\n",
      "Iteration:730, Price of Hedge: 0.17634939331516078, Loss: 0.0013095488010679724\n",
      "Iteration:740, Price of Hedge: 0.17517124491233743, Loss: 0.0011802432246580173\n",
      "Iteration:750, Price of Hedge: 0.1778060452945624, Loss: 0.0019477067109690436\n",
      "Iteration:760, Price of Hedge: 0.18244469953081077, Loss: 0.001354268178678808\n",
      "Iteration:770, Price of Hedge: 0.1884904322781608, Loss: 0.0019478281372098394\n",
      "Iteration:780, Price of Hedge: 0.18200695486420954, Loss: 0.0018471927428459266\n",
      "Iteration:790, Price of Hedge: 0.18057377102642247, Loss: 0.0014116904068520062\n",
      "Iteration:800, Price of Hedge: 0.17781599084889876, Loss: 0.001452690283909952\n",
      "Iteration:810, Price of Hedge: 0.19805697542606138, Loss: 0.0015645514684811345\n",
      "Iteration:820, Price of Hedge: 0.20410937127398937, Loss: 0.0012727392252221746\n",
      "Iteration:830, Price of Hedge: 0.21386946697299436, Loss: 0.0015240516527379455\n",
      "Iteration:840, Price of Hedge: 0.20375064396645257, Loss: 0.0012622976644184546\n",
      "Iteration:850, Price of Hedge: 0.20857606140500592, Loss: 0.0016777244509786015\n",
      "Iteration:860, Price of Hedge: 0.2048650089622697, Loss: 0.0017507769103496606\n",
      "Iteration:870, Price of Hedge: 0.21968302924104818, Loss: 0.0014450497459297827\n",
      "Iteration:880, Price of Hedge: 0.18429778495323035, Loss: 0.0014821487502069352\n",
      "Iteration:890, Price of Hedge: 0.21182577479130485, Loss: 0.0014969935465060757\n",
      "Iteration:900, Price of Hedge: 0.20906308496072368, Loss: 0.0014806690596805615\n",
      "Iteration:910, Price of Hedge: 0.19810151299308243, Loss: 0.001408573434703353\n",
      "Iteration:920, Price of Hedge: 0.20228567363201364, Loss: 0.0014539830130944507\n",
      "Iteration:930, Price of Hedge: 0.19020782891765292, Loss: 0.0013999589662160082\n",
      "Iteration:940, Price of Hedge: 0.18909980438806995, Loss: 0.0016715065068899193\n",
      "Iteration:950, Price of Hedge: 0.17924945523828908, Loss: 0.001592676547529237\n",
      "Iteration:960, Price of Hedge: 0.1862827015740322, Loss: 0.0015387085013809807\n",
      "Iteration:970, Price of Hedge: 0.19234476242469326, Loss: 0.0012878391481355499\n",
      "Iteration:980, Price of Hedge: 0.19405649192179908, Loss: 0.0013303197020340994\n",
      "Iteration:990, Price of Hedge: 0.1967699449460042, Loss: 0.0017782588029291446\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 3 \n",
      "\n",
      "tf.Tensor(1.6458079, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_14 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 2.170898502863781, Loss: 0.01587418662075679\n",
      "Iteration:20, Price of Hedge: 1.7602659126201388, Loss: 0.019618612681343704\n",
      "Iteration:30, Price of Hedge: 1.5844993825667757, Loss: 0.018731129491066412\n",
      "Iteration:40, Price of Hedge: 1.4970971502825592, Loss: 0.01325862610848345\n",
      "Iteration:50, Price of Hedge: 1.6593270148183137, Loss: 0.013916782629935297\n",
      "Iteration:60, Price of Hedge: 1.6987279313386578, Loss: 0.01601285586923762\n",
      "Iteration:70, Price of Hedge: 1.611584955327703, Loss: 0.015628894875999676\n",
      "Iteration:80, Price of Hedge: 1.780555482968259, Loss: 0.013328917772603076\n",
      "Iteration:90, Price of Hedge: 1.8254685299556854, Loss: 0.016344661136819916\n",
      "Iteration:100, Price of Hedge: 1.7490687582721762, Loss: 0.014046198527742781\n",
      "Iteration:110, Price of Hedge: 1.639672169563528, Loss: 0.01838935816960161\n",
      "Iteration:120, Price of Hedge: 1.6576666678832794, Loss: 0.01699474472228859\n",
      "Iteration:130, Price of Hedge: 1.8344331624628125, Loss: 0.015067958146904736\n",
      "Iteration:140, Price of Hedge: 1.754400449056186, Loss: 0.015201888705114363\n",
      "Iteration:150, Price of Hedge: 1.829295494646567, Loss: 0.01679986231830144\n",
      "Iteration:160, Price of Hedge: 1.8054365389320992, Loss: 0.01856731911283598\n",
      "Iteration:170, Price of Hedge: 1.6348888410133895, Loss: 0.015577978520262903\n",
      "Iteration:180, Price of Hedge: 1.9824156706102711, Loss: 0.017320178894822822\n",
      "Iteration:190, Price of Hedge: 1.7989393687825213, Loss: 0.013678803953769235\n",
      "Iteration:200, Price of Hedge: 1.709057600109918, Loss: 0.018239909285082234\n",
      "Iteration:210, Price of Hedge: 1.6942390749850573, Loss: 0.016249950216973195\n",
      "Iteration:220, Price of Hedge: 1.5863941669339054, Loss: 0.018574692446771922\n",
      "Iteration:230, Price of Hedge: 1.5463516498304444, Loss: 0.017500622508243514\n",
      "Iteration:240, Price of Hedge: 1.8128915821947884, Loss: 0.014318138035871808\n",
      "Iteration:250, Price of Hedge: 1.8973076718800599, Loss: 0.013284609642945354\n",
      "Iteration:260, Price of Hedge: 2.023587948071406, Loss: 0.016475397631750256\n",
      "Iteration:270, Price of Hedge: 2.0650050600467464, Loss: 0.01784061862226638\n",
      "Iteration:280, Price of Hedge: 2.008060744414331, Loss: 0.015189166166761137\n",
      "Iteration:290, Price of Hedge: 1.782402474296657, Loss: 0.01607992726775409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:300, Price of Hedge: 1.8634056379318509, Loss: 0.01762823961651758\n",
      "Iteration:310, Price of Hedge: 1.7307886755841422, Loss: 0.013872326457147732\n",
      "Iteration:320, Price of Hedge: 1.620023193629288, Loss: 0.015422939369946676\n",
      "Iteration:330, Price of Hedge: 1.773790336412037, Loss: 0.01673486221348659\n",
      "Iteration:340, Price of Hedge: 1.653704876514712, Loss: 0.016528457337579284\n",
      "Iteration:350, Price of Hedge: 1.7748810238643613, Loss: 0.01381677097997045\n",
      "Iteration:360, Price of Hedge: 1.8828683048624726, Loss: 0.01656171070679786\n",
      "Iteration:370, Price of Hedge: 1.653488885518618, Loss: 0.014876361514330404\n",
      "Iteration:380, Price of Hedge: 1.8003414656135306, Loss: 0.013596252222312621\n",
      "Iteration:390, Price of Hedge: 1.6722031302321851, Loss: 0.017564923011011136\n",
      "Iteration:400, Price of Hedge: 1.894484193307676, Loss: 0.015014019353109998\n",
      "Iteration:410, Price of Hedge: 1.646587738420601, Loss: 0.013067831267019424\n",
      "Iteration:420, Price of Hedge: 1.4976894485730894, Loss: 0.014565653047808968\n",
      "Iteration:430, Price of Hedge: 1.508787327556388, Loss: 0.015288516208048364\n",
      "Iteration:440, Price of Hedge: 1.7433116255960157, Loss: 0.01812664974017064\n",
      "Iteration:450, Price of Hedge: 2.1010177016633063, Loss: 0.015129305647772638\n",
      "Iteration:460, Price of Hedge: 1.9184892112563035, Loss: 0.017232217693604033\n",
      "Iteration:470, Price of Hedge: 1.6645047617091449, Loss: 0.016349225581637403\n",
      "Iteration:480, Price of Hedge: 1.8514431241846865, Loss: 0.013209969703180136\n",
      "Iteration:490, Price of Hedge: 1.7481861801569265, Loss: 0.014290837834635627\n",
      "Iteration:500, Price of Hedge: 1.7140134866841095, Loss: 0.019063669733833156\n",
      "Iteration:510, Price of Hedge: 1.7242515940548515, Loss: 0.016470102142096897\n",
      "Iteration:520, Price of Hedge: 1.6992779705212568, Loss: 0.014581137311097692\n",
      "Iteration:530, Price of Hedge: 1.843503610434641, Loss: 0.012110776976528825\n",
      "Iteration:540, Price of Hedge: 1.812876154266496, Loss: 0.01901232234986878\n",
      "Iteration:550, Price of Hedge: 1.7269714371958798, Loss: 0.013066620719656807\n",
      "Iteration:560, Price of Hedge: 1.6318998476016076, Loss: 0.012514562648003923\n",
      "Iteration:570, Price of Hedge: 1.582762063685152, Loss: 0.024960766053273353\n",
      "Iteration:580, Price of Hedge: 1.7232482756312264, Loss: 0.01307107511471406\n",
      "Iteration:590, Price of Hedge: 1.5769522748189502, Loss: 0.009934404095506189\n",
      "Iteration:600, Price of Hedge: 1.634332597120499, Loss: 0.016258302207705543\n",
      "Iteration:610, Price of Hedge: 1.881644970765808, Loss: 0.009612773190281131\n",
      "Iteration:620, Price of Hedge: 1.9388025942763534, Loss: 0.011034732692897098\n",
      "Iteration:630, Price of Hedge: 1.9964544145768741, Loss: 0.011051227055770862\n",
      "Iteration:640, Price of Hedge: 1.89227548413877, Loss: 0.011600616420737975\n",
      "Iteration:650, Price of Hedge: 1.7214681945570531, Loss: 0.010191857648885793\n",
      "Iteration:660, Price of Hedge: 1.7070410692651763, Loss: 0.011186407464828907\n",
      "Iteration:670, Price of Hedge: 1.598627340205678, Loss: 0.010513201638664515\n",
      "Iteration:680, Price of Hedge: 1.3901153677414186, Loss: 0.009869766892876886\n",
      "Iteration:690, Price of Hedge: 1.1966956822817736, Loss: 0.012651088546392497\n",
      "Iteration:700, Price of Hedge: 1.3437814420972358, Loss: 0.01082019003025505\n",
      "Iteration:710, Price of Hedge: 1.6525103859361592, Loss: 0.010611959507432366\n",
      "Iteration:720, Price of Hedge: 1.614282830440402, Loss: 0.00808326886958879\n",
      "Iteration:730, Price of Hedge: 1.7978513644481608, Loss: 0.011197083601688184\n",
      "Iteration:740, Price of Hedge: 1.7415613942091908, Loss: 0.007893353116090473\n",
      "Iteration:750, Price of Hedge: 1.783380303099625, Loss: 0.009165942341158662\n",
      "Iteration:760, Price of Hedge: 1.7421268613200822, Loss: 0.009193670950390054\n",
      "Iteration:770, Price of Hedge: 1.6033811544582135, Loss: 0.011194244579897284\n",
      "Iteration:780, Price of Hedge: 1.6470666749771568, Loss: 0.01148512312771679\n",
      "Iteration:790, Price of Hedge: 1.7850881076836458, Loss: 0.010055436559792685\n",
      "Iteration:800, Price of Hedge: 1.8305491815151982, Loss: 0.008702287634939809\n",
      "Iteration:810, Price of Hedge: 1.7623411366703408, Loss: 0.010509155999859576\n",
      "Iteration:820, Price of Hedge: 1.6440511857754814, Loss: 0.0123334796978809\n",
      "Iteration:830, Price of Hedge: 1.6256644491483825, Loss: 0.008587129076606014\n",
      "Iteration:840, Price of Hedge: 1.8325165777622259, Loss: 0.009869590027190789\n",
      "Iteration:850, Price of Hedge: 1.768721758883362, Loss: 0.011356655754033261\n",
      "Iteration:860, Price of Hedge: 1.7996535812455363, Loss: 0.009766210723551038\n",
      "Iteration:870, Price of Hedge: 1.8231357265809491, Loss: 0.00952234504027034\n",
      "Iteration:880, Price of Hedge: 1.7077101718074232, Loss: 0.010415653007143089\n",
      "Iteration:890, Price of Hedge: 1.6352564281744435, Loss: 0.011360604444239896\n",
      "Iteration:900, Price of Hedge: 1.6247656046304768, Loss: 0.011969938175631878\n",
      "Iteration:910, Price of Hedge: 1.9959283557610774, Loss: 0.009288934084212252\n",
      "Iteration:920, Price of Hedge: 1.7867435914673706, Loss: 0.009632437379284608\n",
      "Iteration:930, Price of Hedge: 1.725835304433042, Loss: 0.010709196986357883\n",
      "Iteration:940, Price of Hedge: 1.5333031440873923, Loss: 0.007771898139331634\n",
      "Iteration:950, Price of Hedge: 1.5564535889645186, Loss: 0.011244656540899633\n",
      "Iteration:960, Price of Hedge: 1.8052970167979765, Loss: 0.010233741408527796\n",
      "Iteration:970, Price of Hedge: 1.8486516753329965, Loss: 0.010054060282731614\n",
      "Iteration:980, Price of Hedge: 1.6234736833308603, Loss: 0.00867024677825814\n",
      "Iteration:990, Price of Hedge: 1.5362357920219323, Loss: 0.010749149634730948\n",
      "tf.Tensor(1.8639729, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_15 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 2.4555623939896347, Loss: 0.027818221179014557\n",
      "Iteration:20, Price of Hedge: 2.1532461020844265, Loss: 0.021244193062956194\n",
      "Iteration:30, Price of Hedge: 1.8612219152989837, Loss: 0.019933297350511834\n",
      "Iteration:40, Price of Hedge: 1.9777705226352735, Loss: 0.018515333702285464\n",
      "Iteration:50, Price of Hedge: 1.9062005309816528, Loss: 0.01819496312883837\n",
      "Iteration:60, Price of Hedge: 1.7945948977143529, Loss: 0.017163595117514686\n",
      "Iteration:70, Price of Hedge: 2.024389864952866, Loss: 0.020234190426512998\n",
      "Iteration:80, Price of Hedge: 1.9554483227346282, Loss: 0.019112192507284752\n",
      "Iteration:90, Price of Hedge: 1.8311124685927438, Loss: 0.017171370657121977\n",
      "Iteration:100, Price of Hedge: 1.6973043695639376, Loss: 0.017391036529137958\n",
      "Iteration:110, Price of Hedge: 1.8800570680157989, Loss: 0.02119614193133419\n",
      "Iteration:120, Price of Hedge: 1.9042334701243704, Loss: 0.024152010365284405\n",
      "Iteration:130, Price of Hedge: 1.7299996712078836, Loss: 0.02044224866905626\n",
      "Iteration:140, Price of Hedge: 1.552971237237125, Loss: 0.019988223971916328\n",
      "Iteration:150, Price of Hedge: 1.773108153669716, Loss: 0.02154508220860878\n",
      "Iteration:160, Price of Hedge: 1.8093917902006296, Loss: 0.01838406005971587\n",
      "Iteration:170, Price of Hedge: 1.984379209875226, Loss: 0.023771253916255296\n",
      "Iteration:180, Price of Hedge: 2.067847655834623, Loss: 0.019955495959291268\n",
      "Iteration:190, Price of Hedge: 1.858760657651726, Loss: 0.02179276753565107\n",
      "Iteration:200, Price of Hedge: 1.8899264143613776, Loss: 0.014704136259790345\n",
      "Iteration:210, Price of Hedge: 2.0116933507477026, Loss: 0.02097886440113861\n",
      "Iteration:220, Price of Hedge: 1.932869549678685, Loss: 0.019589072181416967\n",
      "Iteration:230, Price of Hedge: 2.0412928373459294, Loss: 0.020859109300140587\n",
      "Iteration:240, Price of Hedge: 2.0544694619717574, Loss: 0.021316128922898425\n",
      "Iteration:250, Price of Hedge: 1.8112642711496847, Loss: 0.020461605635812407\n",
      "Iteration:260, Price of Hedge: 1.8676246732352069, Loss: 0.022655931039031962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:270, Price of Hedge: 1.8835421028611563, Loss: 0.022676853594639113\n",
      "Iteration:280, Price of Hedge: 1.730444062620654, Loss: 0.01963899415896302\n",
      "Iteration:290, Price of Hedge: 2.0599715307464748, Loss: 0.01985852901935967\n",
      "Iteration:300, Price of Hedge: 2.277339134050578, Loss: 0.018240767411188852\n",
      "Iteration:310, Price of Hedge: 1.983377903790074, Loss: 0.019945484051342\n",
      "Iteration:320, Price of Hedge: 2.08211463252303, Loss: 0.02167574795726468\n",
      "Iteration:330, Price of Hedge: 1.9907633536805747, Loss: 0.01960311138654447\n",
      "Iteration:340, Price of Hedge: 2.0037701034003135, Loss: 0.021863347425333222\n",
      "Iteration:350, Price of Hedge: 2.1396691897973596, Loss: 0.023461788750001312\n",
      "Iteration:360, Price of Hedge: 2.2837465874432383, Loss: 0.023241694469990113\n",
      "Iteration:370, Price of Hedge: 2.207024506214316, Loss: 0.023310923629876967\n",
      "Iteration:380, Price of Hedge: 2.003534324409236, Loss: 0.020133056006970483\n",
      "Iteration:390, Price of Hedge: 1.7583228321296587, Loss: 0.017603984125314654\n",
      "Iteration:400, Price of Hedge: 1.8986279336131702, Loss: 0.022538193516971637\n",
      "Iteration:410, Price of Hedge: 1.8680963989122346, Loss: 0.01853096207835545\n",
      "Iteration:420, Price of Hedge: 1.8573173078820218, Loss: 0.022196643605143507\n",
      "Iteration:430, Price of Hedge: 2.0551913883989186, Loss: 0.019514153186902573\n",
      "Iteration:440, Price of Hedge: 1.9426169818517791, Loss: 0.02230158915269236\n",
      "Iteration:450, Price of Hedge: 1.852570201424396, Loss: 0.019012814953557465\n",
      "Iteration:460, Price of Hedge: 2.026576941483188, Loss: 0.020384467304466546\n",
      "Iteration:470, Price of Hedge: 1.837070499726451, Loss: 0.019276381509095053\n",
      "Iteration:480, Price of Hedge: 1.848899863744657, Loss: 0.021066076215894822\n",
      "Iteration:490, Price of Hedge: 1.7419152303906797, Loss: 0.018789919645124973\n",
      "Iteration:500, Price of Hedge: 1.9378053128681472, Loss: 0.019718030848672984\n",
      "Iteration:510, Price of Hedge: 1.8583660716161603, Loss: 0.01817120155144032\n",
      "Iteration:520, Price of Hedge: 1.7192274556674534, Loss: 0.01620062565241129\n",
      "Iteration:530, Price of Hedge: 1.4099892225000075, Loss: 0.014715240804644836\n",
      "Iteration:540, Price of Hedge: 1.8541730290180793, Loss: 0.024555628341886758\n",
      "Iteration:550, Price of Hedge: 1.6956995296317814, Loss: 0.020998824021343676\n",
      "Iteration:560, Price of Hedge: 1.8980820868023898, Loss: 0.012218632292143016\n",
      "Iteration:570, Price of Hedge: 1.7320925032197236, Loss: 0.024317637874674957\n",
      "Iteration:580, Price of Hedge: 1.7492810599810695, Loss: 0.020008348666761756\n",
      "Iteration:590, Price of Hedge: 2.164284449387901, Loss: 0.013981417212332214\n",
      "Iteration:600, Price of Hedge: 2.1035616328828266, Loss: 0.02220535063736424\n",
      "Iteration:610, Price of Hedge: 2.0629912123199685, Loss: 0.016354158169105213\n",
      "Iteration:620, Price of Hedge: 1.880523259762026, Loss: 0.015727568897331155\n",
      "Iteration:630, Price of Hedge: 1.9205458211756308, Loss: 0.01258013134324667\n",
      "Iteration:640, Price of Hedge: 2.0210944930085817, Loss: 0.014698328514705405\n",
      "Iteration:650, Price of Hedge: 1.9534841126901823, Loss: 0.013089528101296821\n",
      "Iteration:660, Price of Hedge: 1.6396060977836668, Loss: 0.014384157411085051\n",
      "Iteration:670, Price of Hedge: 1.7890710286061788, Loss: 0.011771420199208293\n",
      "Iteration:680, Price of Hedge: 1.8519715307287015, Loss: 0.013775994923569889\n",
      "Iteration:690, Price of Hedge: 1.8957140675043773, Loss: 0.011865355530268573\n",
      "Iteration:700, Price of Hedge: 2.010899147830389, Loss: 0.0182569316247819\n",
      "Iteration:710, Price of Hedge: 1.9117700130952129, Loss: 0.012119427673753246\n",
      "Iteration:720, Price of Hedge: 1.766862190439508, Loss: 0.014281499326409718\n",
      "Iteration:730, Price of Hedge: 1.975384392291005, Loss: 0.01317515729569152\n",
      "Iteration:740, Price of Hedge: 1.9368994251655862, Loss: 0.016389198536811467\n",
      "Iteration:750, Price of Hedge: 2.2308420412952157, Loss: 0.014276248380706935\n",
      "Iteration:760, Price of Hedge: 2.0213285950509317, Loss: 0.014919077852813255\n",
      "Iteration:770, Price of Hedge: 2.122638601606138, Loss: 0.013484496690790947\n",
      "Iteration:780, Price of Hedge: 2.286012312868877, Loss: 0.014602206599718491\n",
      "Iteration:790, Price of Hedge: 1.9983097906489091, Loss: 0.011559305836930545\n",
      "Iteration:800, Price of Hedge: 1.7207576713812387, Loss: 0.012645156340269192\n",
      "Iteration:810, Price of Hedge: 1.8678866126264324, Loss: 0.013176176566089914\n",
      "Iteration:820, Price of Hedge: 1.7667567103645523, Loss: 0.013822283948911895\n",
      "Iteration:830, Price of Hedge: 1.8550317944613994, Loss: 0.011957240529486324\n",
      "Iteration:840, Price of Hedge: 1.8149837434271376, Loss: 0.014846130583169791\n",
      "Iteration:850, Price of Hedge: 2.0843092553226255, Loss: 0.011715387839736646\n",
      "Iteration:860, Price of Hedge: 2.021741795217372, Loss: 0.016857980382752834\n",
      "Iteration:870, Price of Hedge: 1.9522881128577751, Loss: 0.013268579061204022\n",
      "Iteration:880, Price of Hedge: 2.0564771049882435, Loss: 0.014326125814302414\n",
      "Iteration:890, Price of Hedge: 1.9355347242911989, Loss: 0.012928394290449318\n",
      "Iteration:900, Price of Hedge: 1.9903860402169016, Loss: 0.01363016326986024\n",
      "Iteration:910, Price of Hedge: 2.0599227315385065, Loss: 0.011962875339233747\n",
      "Iteration:920, Price of Hedge: 2.1542385203413232, Loss: 0.013035860501554097\n",
      "Iteration:930, Price of Hedge: 2.226692934753794, Loss: 0.015159798602171913\n",
      "Iteration:940, Price of Hedge: 2.168332268226186, Loss: 0.017242868938255638\n",
      "Iteration:950, Price of Hedge: 2.1125266007796992, Loss: 0.019454511457318358\n",
      "Iteration:960, Price of Hedge: 2.21117864360192, Loss: 0.013080008797036234\n",
      "Iteration:970, Price of Hedge: 1.7734792624230977, Loss: 0.013406111128829057\n",
      "Iteration:980, Price of Hedge: 1.9663486571578346, Loss: 0.012969003962093328\n",
      "Iteration:990, Price of Hedge: 2.070291976299734, Loss: 0.009995851165204782\n",
      "tf.Tensor(1.7673867, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_16 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.937230209666427, Loss: 0.019953395843033395\n",
      "Iteration:20, Price of Hedge: 1.889418131202092, Loss: 0.02256051789690563\n",
      "Iteration:30, Price of Hedge: 1.8577464390613727, Loss: 0.01668881686975654\n",
      "Iteration:40, Price of Hedge: 1.5653011704504707, Loss: 0.016396907260492897\n",
      "Iteration:50, Price of Hedge: 1.7895865226449927, Loss: 0.016216031308728417\n",
      "Iteration:60, Price of Hedge: 1.863355832554646, Loss: 0.014009303035506803\n",
      "Iteration:70, Price of Hedge: 1.6267752599854362, Loss: 0.01491048480070134\n",
      "Iteration:80, Price of Hedge: 1.7290624245641197, Loss: 0.014758893876205903\n",
      "Iteration:90, Price of Hedge: 1.6673089553711633, Loss: 0.011826010120751107\n",
      "Iteration:100, Price of Hedge: 1.7187049184439842, Loss: 0.017047763814515626\n",
      "Iteration:110, Price of Hedge: 1.656838925991417, Loss: 0.013430591960017235\n",
      "Iteration:120, Price of Hedge: 1.792345774081116, Loss: 0.016869104579350223\n",
      "Iteration:130, Price of Hedge: 1.8015663089640497, Loss: 0.01622184822462671\n",
      "Iteration:140, Price of Hedge: 1.8150779879456194, Loss: 0.014799937196309898\n",
      "Iteration:150, Price of Hedge: 1.815725793239028, Loss: 0.015350687772001858\n",
      "Iteration:160, Price of Hedge: 1.7375176000478518, Loss: 0.01575594339384585\n",
      "Iteration:170, Price of Hedge: 1.679557724266101, Loss: 0.013744376579360562\n",
      "Iteration:180, Price of Hedge: 1.7170390375781495, Loss: 0.014741469330834889\n",
      "Iteration:190, Price of Hedge: 1.790331926354338, Loss: 0.016962589230440004\n",
      "Iteration:200, Price of Hedge: 1.876436368018392, Loss: 0.015242013633766848\n",
      "Iteration:210, Price of Hedge: 2.028554064032835, Loss: 0.016082230452021926\n",
      "Iteration:220, Price of Hedge: 1.7283301010548484, Loss: 0.013989122005665067\n",
      "Iteration:230, Price of Hedge: 1.8317946513350647, Loss: 0.018123404582359812\n",
      "Iteration:240, Price of Hedge: 1.8257452264957124, Loss: 0.016026880663086995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:250, Price of Hedge: 1.6675408773801677, Loss: 0.015812660944086596\n",
      "Iteration:260, Price of Hedge: 1.511272565570448, Loss: 0.015701289276609565\n",
      "Iteration:270, Price of Hedge: 1.841065326984949, Loss: 0.01484737650366963\n",
      "Iteration:280, Price of Hedge: 1.617808112055218, Loss: 0.01628138514491546\n",
      "Iteration:290, Price of Hedge: 1.60541814407743, Loss: 0.016291465178906783\n",
      "Iteration:300, Price of Hedge: 1.812322761186442, Loss: 0.015779672218339067\n",
      "Iteration:310, Price of Hedge: 1.8685615844892254, Loss: 0.015801544608186367\n",
      "Iteration:320, Price of Hedge: 1.7661293638456186, Loss: 0.017386371205373584\n",
      "Iteration:330, Price of Hedge: 1.7670642627611641, Loss: 0.013529821470614678\n",
      "Iteration:340, Price of Hedge: 1.785948046991075, Loss: 0.014574374491307829\n",
      "Iteration:350, Price of Hedge: 1.6130777750848664, Loss: 0.01939278664298678\n",
      "Iteration:360, Price of Hedge: 1.6597922003953045, Loss: 0.013841741794614925\n",
      "Iteration:370, Price of Hedge: 1.4487200303088683, Loss: 0.017926784964300335\n",
      "Iteration:380, Price of Hedge: 1.6942605399287685, Loss: 0.012730050559479443\n",
      "Iteration:390, Price of Hedge: 1.6789268561548396, Loss: 0.016830843946040817\n",
      "Iteration:400, Price of Hedge: 1.5866975269586987, Loss: 0.01561895895478962\n",
      "Iteration:410, Price of Hedge: 1.818907635754465, Loss: 0.018309982159797577\n",
      "Iteration:420, Price of Hedge: 1.7377723285595492, Loss: 0.014502758299716766\n",
      "Iteration:430, Price of Hedge: 1.6686444773376934, Loss: 0.014794772718275872\n",
      "Iteration:440, Price of Hedge: 1.7220812870118039, Loss: 0.01815818161671121\n",
      "Iteration:450, Price of Hedge: 1.6783335516950728, Loss: 0.014201373930143113\n",
      "Iteration:460, Price of Hedge: 1.7983925158025045, Loss: 0.01302817404984795\n",
      "Iteration:470, Price of Hedge: 1.6857433173421212, Loss: 0.01524851836066663\n",
      "Iteration:480, Price of Hedge: 1.4676923574315879, Loss: 0.012246689740538929\n",
      "Iteration:490, Price of Hedge: 1.6026354153591227, Loss: 0.011797503302500888\n",
      "Iteration:500, Price of Hedge: 1.815561619958612, Loss: 0.015873780484736866\n",
      "Iteration:510, Price of Hedge: 1.8745819981155931, Loss: 0.014083716325170581\n",
      "Iteration:520, Price of Hedge: 1.7215656252781173, Loss: 0.011513772748632078\n",
      "Iteration:530, Price of Hedge: 1.9178992606939913, Loss: 0.015785241522276828\n",
      "Iteration:540, Price of Hedge: 1.8952265785093119, Loss: 0.009622678323760648\n",
      "Iteration:550, Price of Hedge: 1.584317265934976, Loss: 0.009033209884207815\n",
      "Iteration:560, Price of Hedge: 1.6565984515439027, Loss: 0.01029396876005042\n",
      "Iteration:570, Price of Hedge: 1.7436864236365976, Loss: 0.010838603713352013\n",
      "Iteration:580, Price of Hedge: 1.6327939966630765, Loss: 0.011691728451401673\n",
      "Iteration:590, Price of Hedge: 1.437666590466847, Loss: 0.011500615251702673\n",
      "Iteration:600, Price of Hedge: 1.6137046185191821, Loss: 0.010978128467707071\n",
      "Iteration:610, Price of Hedge: 1.557655290422599, Loss: 0.011722647193563774\n",
      "Iteration:620, Price of Hedge: 1.651713332206009, Loss: 0.00819532048737015\n",
      "Iteration:630, Price of Hedge: 1.707201385563519, Loss: 0.010379108626046917\n",
      "Iteration:640, Price of Hedge: 1.6701611097667863, Loss: 0.009561334753241323\n",
      "Iteration:650, Price of Hedge: 1.747376884701066, Loss: 0.008758967846869048\n",
      "Iteration:660, Price of Hedge: 1.8820777912323592, Loss: 0.009753854362673842\n",
      "Iteration:670, Price of Hedge: 1.7026047014067445, Loss: 0.007681563007570569\n",
      "Iteration:680, Price of Hedge: 1.6868452403509195, Loss: 0.013422653966001974\n",
      "Iteration:690, Price of Hedge: 1.5828182414675211, Loss: 0.008142710151395427\n",
      "Iteration:700, Price of Hedge: 1.6843818026703161, Loss: 0.012452628215081418\n",
      "Iteration:710, Price of Hedge: 1.7847592580381957, Loss: 0.008823602429265965\n",
      "Iteration:720, Price of Hedge: 1.7638911403791098, Loss: 0.00935363875782551\n",
      "Iteration:730, Price of Hedge: 1.8961769053531496, Loss: 0.009986502831107424\n",
      "Iteration:740, Price of Hedge: 1.7847609349869231, Loss: 0.008494527443830524\n",
      "Iteration:750, Price of Hedge: 1.8073380310941387, Loss: 0.010642381715557203\n",
      "Iteration:760, Price of Hedge: 1.8592268493979531, Loss: 0.011217593470694441\n",
      "Iteration:770, Price of Hedge: 1.572223782492199, Loss: 0.012501558434669135\n",
      "Iteration:780, Price of Hedge: 1.6574832096924978, Loss: 0.010872453185438545\n",
      "Iteration:790, Price of Hedge: 1.6508050967752297, Loss: 0.010659574370362001\n",
      "Iteration:800, Price of Hedge: 1.8975060549145155, Loss: 0.012094324537373247\n",
      "Iteration:810, Price of Hedge: 1.907139622269017, Loss: 0.00925142087219113\n",
      "Iteration:820, Price of Hedge: 1.7364475390648748, Loss: 0.011505809862409145\n",
      "Iteration:830, Price of Hedge: 1.6279699182588614, Loss: 0.009532571807275314\n",
      "Iteration:840, Price of Hedge: 1.6360764561021597, Loss: 0.014244332640121727\n",
      "Iteration:850, Price of Hedge: 1.4605453696501285, Loss: 0.00893722356624691\n",
      "Iteration:860, Price of Hedge: 1.812301967022222, Loss: 0.00907429054262332\n",
      "Iteration:870, Price of Hedge: 1.8437177567871343, Loss: 0.010534249965426222\n",
      "Iteration:880, Price of Hedge: 1.8334219623801686, Loss: 0.010327533281864908\n",
      "Iteration:890, Price of Hedge: 2.037025673614096, Loss: 0.009738391716302308\n",
      "Iteration:900, Price of Hedge: 1.757300396490541, Loss: 0.007691861830966173\n",
      "Iteration:910, Price of Hedge: 1.6246166915834805, Loss: 0.006851433428945874\n",
      "Iteration:920, Price of Hedge: 1.6306139633174097, Loss: 0.011617663652645315\n",
      "Iteration:930, Price of Hedge: 1.8609004442279342, Loss: 0.009675426221935667\n",
      "Iteration:940, Price of Hedge: 1.677849416597462, Loss: 0.010608963926756365\n",
      "Iteration:950, Price of Hedge: 1.5348766250783454, Loss: 0.010076475060682943\n",
      "Iteration:960, Price of Hedge: 1.8061172124205653, Loss: 0.0109698203658672\n",
      "Iteration:970, Price of Hedge: 1.771292688977394, Loss: 0.010148091907332102\n",
      "Iteration:980, Price of Hedge: 1.8551101079669705, Loss: 0.010447917238635718\n",
      "Iteration:990, Price of Hedge: 1.712343413446456, Loss: 0.01184768599316941\n",
      "tf.Tensor(1.6413069, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_17 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 2.063237053003411, Loss: 0.025426541182551075\n",
      "Iteration:20, Price of Hedge: 1.6979592180420013, Loss: 0.013861951647012915\n",
      "Iteration:30, Price of Hedge: 1.4223595701776843, Loss: 0.012366451392117917\n",
      "Iteration:40, Price of Hedge: 1.654960408026943, Loss: 0.013108464520754913\n",
      "Iteration:50, Price of Hedge: 1.6877175890789318, Loss: 0.013739523908980544\n",
      "Iteration:60, Price of Hedge: 1.7449178070871538, Loss: 0.014407595389783355\n",
      "Iteration:70, Price of Hedge: 1.6996100063692892, Loss: 0.015051357664619314\n",
      "Iteration:80, Price of Hedge: 1.538018891603815, Loss: 0.011881411004217579\n",
      "Iteration:90, Price of Hedge: 1.410228187693667, Loss: 0.013624313601057115\n",
      "Iteration:100, Price of Hedge: 1.549199444159376, Loss: 0.014539995732279197\n",
      "Iteration:110, Price of Hedge: 1.6626146727984519, Loss: 0.014219898973116507\n",
      "Iteration:120, Price of Hedge: 1.7750876239475815, Loss: 0.01600760361341864\n",
      "Iteration:130, Price of Hedge: 1.659826577844217, Loss: 0.014185055122839251\n",
      "Iteration:140, Price of Hedge: 1.6446416394224115, Loss: 0.015327607455024327\n",
      "Iteration:150, Price of Hedge: 1.593480113781686, Loss: 0.011256473788963283\n",
      "Iteration:160, Price of Hedge: 1.4346846402397204, Loss: 0.01512027239661977\n",
      "Iteration:170, Price of Hedge: 1.463663488113923, Loss: 0.016252859985038535\n",
      "Iteration:180, Price of Hedge: 1.496186064038943, Loss: 0.014741426097000509\n",
      "Iteration:190, Price of Hedge: 1.6208514386057686, Loss: 0.016326609045792306\n",
      "Iteration:200, Price of Hedge: 1.675647247528593, Loss: 0.016492374117383156\n",
      "Iteration:210, Price of Hedge: 1.7034403249576258, Loss: 0.013888007237865452\n",
      "Iteration:220, Price of Hedge: 1.7166650780119312, Loss: 0.012769677643978471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:230, Price of Hedge: 1.6054570492879066, Loss: 0.01490044144996343\n",
      "Iteration:240, Price of Hedge: 1.5722504459769653, Loss: 0.01425942517866865\n",
      "Iteration:250, Price of Hedge: 1.5538310088496814, Loss: 0.01484438026793553\n",
      "Iteration:260, Price of Hedge: 1.8991863575394063, Loss: 0.015070954382638835\n",
      "Iteration:270, Price of Hedge: 1.7460061468112598, Loss: 0.014081436722994223\n",
      "Iteration:280, Price of Hedge: 1.627353471906656, Loss: 0.014981990942532164\n",
      "Iteration:290, Price of Hedge: 1.5959532777649088, Loss: 0.010582220524902342\n",
      "Iteration:300, Price of Hedge: 1.6226576800800898, Loss: 0.014706156458960428\n",
      "Iteration:310, Price of Hedge: 1.6167038413182013, Loss: 0.014331193343738136\n",
      "Iteration:320, Price of Hedge: 1.5105107277635739, Loss: 0.014903404932792696\n",
      "Iteration:330, Price of Hedge: 1.7715380265762177, Loss: 0.018248334642321406\n",
      "Iteration:340, Price of Hedge: 1.604679112773249, Loss: 0.014660137317554245\n",
      "Iteration:350, Price of Hedge: 1.6874928779494553, Loss: 0.014817051244143098\n",
      "Iteration:360, Price of Hedge: 1.4900038248603777, Loss: 0.01462022200749269\n",
      "Iteration:370, Price of Hedge: 1.5907946480895703, Loss: 0.01632080654117214\n",
      "Iteration:380, Price of Hedge: 1.7679082710556826, Loss: 0.013621177182890331\n",
      "Iteration:390, Price of Hedge: 1.692387723589968, Loss: 0.01470495377229497\n",
      "Iteration:400, Price of Hedge: 1.7756613081072372, Loss: 0.01134743515626475\n",
      "Iteration:410, Price of Hedge: 1.6878187090871961, Loss: 0.01727382305355496\n",
      "Iteration:420, Price of Hedge: 1.597115403233022, Loss: 0.012425804896139602\n",
      "Iteration:430, Price of Hedge: 1.7261874636658034, Loss: 0.01696200884896637\n",
      "Iteration:440, Price of Hedge: 1.6871291477704744, Loss: 0.013796641044660251\n",
      "Iteration:450, Price of Hedge: 1.6208423830826404, Loss: 0.013692116044409453\n",
      "Iteration:460, Price of Hedge: 1.6867130967911976, Loss: 0.012664734716662006\n",
      "Iteration:470, Price of Hedge: 1.665682650495296, Loss: 0.01217619107806076\n",
      "Iteration:480, Price of Hedge: 1.513140518757939, Loss: 0.013667436075559891\n",
      "Iteration:490, Price of Hedge: 1.6576061300342189, Loss: 0.01265181042041501\n",
      "Iteration:500, Price of Hedge: 1.6431322178728465, Loss: 0.01579295548642303\n",
      "Iteration:510, Price of Hedge: 1.6465738197461632, Loss: 0.012185887248007442\n",
      "Iteration:520, Price of Hedge: 1.6147889335663421, Loss: 0.01028701728352872\n",
      "Iteration:530, Price of Hedge: 1.6233235964197548, Loss: 0.015724266094407822\n",
      "Iteration:540, Price of Hedge: 1.693708823797442, Loss: 0.01418844308331515\n",
      "Iteration:550, Price of Hedge: 1.7095296611766913, Loss: 0.011767675887127816\n",
      "Iteration:560, Price of Hedge: 1.7578403739807753, Loss: 0.015114517056182563\n",
      "Iteration:570, Price of Hedge: 1.7050089427972692, Loss: 0.013680042013571913\n",
      "Iteration:580, Price of Hedge: 1.7778931591685818, Loss: 0.014215172073891046\n",
      "Iteration:590, Price of Hedge: 1.7007411082859447, Loss: 0.014819448756776854\n",
      "Iteration:600, Price of Hedge: 1.4047973892398657, Loss: 0.010785566934556368\n",
      "Iteration:610, Price of Hedge: 1.5950653334137315, Loss: 0.014800626317427578\n",
      "Iteration:620, Price of Hedge: 1.4110671651420035, Loss: 0.009024860513707855\n",
      "Iteration:630, Price of Hedge: 1.6981591103303117, Loss: 0.015014877479216615\n",
      "Iteration:640, Price of Hedge: 1.8802477370861084, Loss: 0.010739812436621232\n",
      "Iteration:650, Price of Hedge: 1.6288395838689098, Loss: 0.008306203481507079\n",
      "Iteration:660, Price of Hedge: 1.5454784626280684, Loss: 0.009962398658324823\n",
      "Iteration:670, Price of Hedge: 1.459820424715258, Loss: 0.008905939301666875\n",
      "Iteration:680, Price of Hedge: 1.6690444296091869, Loss: 0.008900817402409134\n",
      "Iteration:690, Price of Hedge: 1.6168336371497047, Loss: 0.0083773185536542\n",
      "Iteration:700, Price of Hedge: 1.737276119431101, Loss: 0.00878497299824814\n",
      "Iteration:710, Price of Hedge: 1.6093700414485055, Loss: 0.00785038261506612\n",
      "Iteration:720, Price of Hedge: 1.6558213535036088, Loss: 0.008842093409218332\n",
      "Iteration:730, Price of Hedge: 1.4782782639684, Loss: 0.008146752514909882\n",
      "Iteration:740, Price of Hedge: 1.6177224199752458, Loss: 0.008742417804057068\n",
      "Iteration:750, Price of Hedge: 1.8641188442256293, Loss: 0.00965003682516743\n",
      "Iteration:760, Price of Hedge: 1.6595508874734264, Loss: 0.008514846690930654\n",
      "Iteration:770, Price of Hedge: 1.5642614622394604, Loss: 0.008689551340366553\n",
      "Iteration:780, Price of Hedge: 1.5548650154350183, Loss: 0.009467875649417312\n",
      "Iteration:790, Price of Hedge: 1.6779290716620152, Loss: 0.009734440405863286\n",
      "Iteration:800, Price of Hedge: 1.6197421370225698, Loss: 0.009218143920881073\n",
      "Iteration:810, Price of Hedge: 1.5486745592076885, Loss: 0.008526546028536907\n",
      "Iteration:820, Price of Hedge: 1.6843660393522781, Loss: 0.008613565256212707\n",
      "Iteration:830, Price of Hedge: 1.6806024633232937, Loss: 0.009738355688106992\n",
      "Iteration:840, Price of Hedge: 1.5417539595044332, Loss: 0.009131157446110105\n",
      "Iteration:850, Price of Hedge: 1.534214398025881, Loss: 0.008204691748500892\n",
      "Iteration:860, Price of Hedge: 1.6781618321453833, Loss: 0.008207564178254722\n",
      "Iteration:870, Price of Hedge: 1.7015923274599913, Loss: 0.009778776047961069\n",
      "Iteration:880, Price of Hedge: 1.6642755228181045, Loss: 0.010168367920597854\n",
      "Iteration:890, Price of Hedge: 1.5373360380820031, Loss: 0.01108206195049659\n",
      "Iteration:900, Price of Hedge: 1.8303397306191413, Loss: 0.009065469530293769\n",
      "Iteration:910, Price of Hedge: 2.11161652070532, Loss: 0.010437915811615994\n",
      "Iteration:920, Price of Hedge: 1.7066057333755338, Loss: 0.01114902198913663\n",
      "Iteration:930, Price of Hedge: 1.5011288704130605, Loss: 0.010341581657805765\n",
      "Iteration:940, Price of Hedge: 1.536973649462004, Loss: 0.009275665227406416\n",
      "Iteration:950, Price of Hedge: 1.516687265316466, Loss: 0.008304003141360415\n",
      "Iteration:960, Price of Hedge: 1.735825558781869, Loss: 0.008834569411920156\n",
      "Iteration:970, Price of Hedge: 1.6732518939663237, Loss: 0.007063442981928158\n",
      "Iteration:980, Price of Hedge: 1.6203376215156822, Loss: 0.008134970639983452\n",
      "Iteration:990, Price of Hedge: 1.638618374983207, Loss: 0.008543339752960843\n",
      "tf.Tensor(1.6781716, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_18 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 1.9018168193132623, Loss: 0.01742394271756531\n",
      "Iteration:20, Price of Hedge: 1.7228231691288214, Loss: 0.024100428470521428\n",
      "Iteration:30, Price of Hedge: 1.6736129410273406, Loss: 0.01433218117134789\n",
      "Iteration:40, Price of Hedge: 1.8664342073336002, Loss: 0.015221540448014003\n",
      "Iteration:50, Price of Hedge: 1.5692582663626011, Loss: 0.01605996371720044\n",
      "Iteration:60, Price of Hedge: 1.7056720083240975, Loss: 0.01461651699889801\n",
      "Iteration:70, Price of Hedge: 1.6824365421464904, Loss: 0.015470378677306407\n",
      "Iteration:80, Price of Hedge: 1.5589519071786526, Loss: 0.01359670290228312\n",
      "Iteration:90, Price of Hedge: 1.8344412118167042, Loss: 0.01661227726151102\n",
      "Iteration:100, Price of Hedge: 1.814885977316328, Loss: 0.01241370204274581\n",
      "Iteration:110, Price of Hedge: 1.6607059697568842, Loss: 0.014166279847672936\n",
      "Iteration:120, Price of Hedge: 1.6752566861699734, Loss: 0.013860589126171873\n",
      "Iteration:130, Price of Hedge: 1.8945145460796424, Loss: 0.015716472213173825\n",
      "Iteration:140, Price of Hedge: 1.693600325214777, Loss: 0.012743373131049207\n",
      "Iteration:150, Price of Hedge: 1.6667092785062323, Loss: 0.01720729928360729\n",
      "Iteration:160, Price of Hedge: 1.6871665437270962, Loss: 0.014981200942467599\n",
      "Iteration:170, Price of Hedge: 1.5471540697965225, Loss: 0.011236216772382334\n",
      "Iteration:180, Price of Hedge: 1.7438583108811598, Loss: 0.019054363978512078\n",
      "Iteration:190, Price of Hedge: 1.6361316277152922, Loss: 0.013472468514020175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:200, Price of Hedge: 1.77791076713022, Loss: 0.01690464148109374\n",
      "Iteration:210, Price of Hedge: 1.85850358141181, Loss: 0.015390917509949809\n",
      "Iteration:220, Price of Hedge: 1.7079838498397406, Loss: 0.014587670860553724\n",
      "Iteration:230, Price of Hedge: 1.6950029251304044, Loss: 0.014715352164521267\n",
      "Iteration:240, Price of Hedge: 1.9098695271024098, Loss: 0.019279648938881167\n",
      "Iteration:250, Price of Hedge: 1.7598114595150036, Loss: 0.01644524530756124\n",
      "Iteration:260, Price of Hedge: 1.701606246134429, Loss: 0.012386783085321883\n",
      "Iteration:270, Price of Hedge: 1.6333978658998263, Loss: 0.019104068476770042\n",
      "Iteration:280, Price of Hedge: 1.620841376913404, Loss: 0.01523506215724515\n",
      "Iteration:290, Price of Hedge: 1.945190091979157, Loss: 0.01632683176554517\n",
      "Iteration:300, Price of Hedge: 2.146791694127398, Loss: 0.015985209797326403\n",
      "Iteration:310, Price of Hedge: 1.98302742150604, Loss: 0.015714115314142064\n",
      "Iteration:320, Price of Hedge: 1.9991259615945522, Loss: 0.01719602835399625\n",
      "Iteration:330, Price of Hedge: 1.9096978075527204, Loss: 0.01717309477003237\n",
      "Iteration:340, Price of Hedge: 1.7809145176908032, Loss: 0.017009148139717833\n",
      "Iteration:350, Price of Hedge: 1.8037359452276063, Loss: 0.015039263982038874\n",
      "Iteration:360, Price of Hedge: 1.775329272259205, Loss: 0.014289113721725233\n",
      "Iteration:370, Price of Hedge: 1.746053101375628, Loss: 0.015293748812124442\n",
      "Iteration:380, Price of Hedge: 1.6693258216056506, Loss: 0.013766381290943385\n",
      "Iteration:390, Price of Hedge: 1.6453898939445935, Loss: 0.017755996907224337\n",
      "Iteration:400, Price of Hedge: 1.4959826501583051, Loss: 0.014502314170327235\n",
      "Iteration:410, Price of Hedge: 1.5931579719311457, Loss: 0.014425022555386757\n",
      "Iteration:420, Price of Hedge: 1.623877324889554, Loss: 0.013956055983062132\n",
      "Iteration:430, Price of Hedge: 1.7706403559224213, Loss: 0.017485564032717615\n",
      "Iteration:440, Price of Hedge: 1.9608906921346487, Loss: 0.014111528781838344\n",
      "Iteration:450, Price of Hedge: 1.8466230704574171, Loss: 0.012336952815909363\n",
      "Iteration:460, Price of Hedge: 1.7504686750698397, Loss: 0.015655386735544584\n",
      "Iteration:470, Price of Hedge: 1.699133417540952, Loss: 0.01519480097650856\n",
      "Iteration:480, Price of Hedge: 1.697377987613072, Loss: 0.014609286467627136\n",
      "Iteration:490, Price of Hedge: 1.974801652608221, Loss: 0.017481708360760705\n",
      "Iteration:500, Price of Hedge: 1.8993610955968052, Loss: 0.013218731760280988\n",
      "Iteration:510, Price of Hedge: 1.8777195691846258, Loss: 0.014880380950811479\n",
      "Iteration:520, Price of Hedge: 1.8174139775229377, Loss: 0.013505060274561132\n",
      "Iteration:530, Price of Hedge: 1.8207890045317754, Loss: 0.0156191777441939\n",
      "Iteration:540, Price of Hedge: 1.6783312039668543, Loss: 0.014265863089642571\n",
      "Iteration:550, Price of Hedge: 1.7782392813859247, Loss: 0.01319367709820014\n",
      "Iteration:560, Price of Hedge: 1.6582153655068963, Loss: 0.0138235364199927\n",
      "Iteration:570, Price of Hedge: 1.6236244410214566, Loss: 0.014932691270177934\n",
      "Iteration:580, Price of Hedge: 1.7746871685914698, Loss: 0.018365823242305002\n",
      "Iteration:590, Price of Hedge: 1.6637736120639828, Loss: 0.013697416774527581\n",
      "Iteration:600, Price of Hedge: 1.7200954443287741, Loss: 0.01272500137167043\n",
      "Iteration:610, Price of Hedge: 1.679973104465887, Loss: 0.014909325347870261\n",
      "Iteration:620, Price of Hedge: 1.7685710011927653, Loss: 0.013401143168224027\n",
      "Iteration:630, Price of Hedge: 1.5974507929785091, Loss: 0.011038344683242052\n",
      "Iteration:640, Price of Hedge: 1.608174209310971, Loss: 0.012355002286704586\n",
      "Iteration:650, Price of Hedge: 1.6656628625003123, Loss: 0.011850515844146958\n",
      "Iteration:660, Price of Hedge: 1.6687380510766843, Loss: 0.011136387228568356\n",
      "Iteration:670, Price of Hedge: 1.847183003637508, Loss: 0.01183380269186891\n",
      "Iteration:680, Price of Hedge: 1.9631760378603984, Loss: 0.00947029412391016\n",
      "Iteration:690, Price of Hedge: 1.746970727719281, Loss: 0.011086364372075419\n",
      "Iteration:700, Price of Hedge: 1.7972689601551224, Loss: 0.01165002483273625\n",
      "Iteration:710, Price of Hedge: 1.7661063896480527, Loss: 0.010957058524028174\n",
      "Iteration:720, Price of Hedge: 1.673181797509517, Loss: 0.010981898982111415\n",
      "Iteration:730, Price of Hedge: 1.6546640911868054, Loss: 0.00983843808434628\n",
      "Iteration:740, Price of Hedge: 1.6347961057487623, Loss: 0.011352982188227223\n",
      "Iteration:750, Price of Hedge: 1.615782525687348, Loss: 0.010800836338789388\n",
      "Iteration:760, Price of Hedge: 1.7382579729110148, Loss: 0.009327694526849405\n",
      "Iteration:770, Price of Hedge: 1.843593830276177, Loss: 0.010461125175038565\n",
      "Iteration:780, Price of Hedge: 1.8378640318642738, Loss: 0.011648104202396857\n",
      "Iteration:790, Price of Hedge: 1.6938909404292417, Loss: 0.012057895446502086\n",
      "Iteration:800, Price of Hedge: 1.6938961389702967, Loss: 0.010019680868644886\n",
      "Iteration:810, Price of Hedge: 1.6239021437307202, Loss: 0.008814806309144085\n",
      "Iteration:820, Price of Hedge: 1.5573782584928266, Loss: 0.012199799371864195\n",
      "Iteration:830, Price of Hedge: 1.6758451274784305, Loss: 0.009635313084328922\n",
      "Iteration:840, Price of Hedge: 1.5959960399574584, Loss: 0.012732427110254107\n",
      "Iteration:850, Price of Hedge: 1.6164029967164992, Loss: 0.00966418214970659\n",
      "Iteration:860, Price of Hedge: 1.6929335704007484, Loss: 0.010146642918822302\n",
      "Iteration:870, Price of Hedge: 1.869245947264892, Loss: 0.01015779659303404\n",
      "Iteration:880, Price of Hedge: 1.6439846109110021, Loss: 0.009101443355787752\n",
      "Iteration:890, Price of Hedge: 1.4319996776322228, Loss: 0.012289103442181126\n",
      "Iteration:900, Price of Hedge: 1.5470289694214556, Loss: 0.009592124448958383\n",
      "Iteration:910, Price of Hedge: 1.7017402343377512, Loss: 0.010016429815311189\n",
      "Iteration:920, Price of Hedge: 1.685770316216633, Loss: 0.010781194421761198\n",
      "Iteration:930, Price of Hedge: 1.6625199251953517, Loss: 0.01104356156592381\n",
      "Iteration:940, Price of Hedge: 1.791972820684134, Loss: 0.01275100717810762\n",
      "Iteration:950, Price of Hedge: 1.679683998505277, Loss: 0.009595754780930043\n",
      "Iteration:960, Price of Hedge: 1.6012916763438283, Loss: 0.009165297763991553\n",
      "Iteration:970, Price of Hedge: 1.5411609904344117, Loss: 0.008241760176074387\n",
      "Iteration:980, Price of Hedge: 1.6894252259680798, Loss: 0.01003064588612479\n",
      "Iteration:990, Price of Hedge: 1.7699246342055517, Loss: 0.00965344181715384\n",
      "tf.Tensor(1.8409859, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_19 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 2.0263359639510554, Loss: 0.017325317170532983\n",
      "Iteration:20, Price of Hedge: 1.6548607972725335, Loss: 0.020150438628623313\n",
      "Iteration:30, Price of Hedge: 1.4733069494659161, Loss: 0.016598949449476486\n",
      "Iteration:40, Price of Hedge: 1.567598590207058, Loss: 0.013278715430191657\n",
      "Iteration:50, Price of Hedge: 1.7705171001909548, Loss: 0.016179088652309482\n",
      "Iteration:60, Price of Hedge: 1.8195539317940188, Loss: 0.016073579754797507\n",
      "Iteration:70, Price of Hedge: 1.841218264708891, Loss: 0.02136437264160085\n",
      "Iteration:80, Price of Hedge: 1.9288245816532366, Loss: 0.016023534626329283\n",
      "Iteration:90, Price of Hedge: 1.7196285818030559, Loss: 0.016417211441256806\n",
      "Iteration:100, Price of Hedge: 1.7177339651307988, Loss: 0.0162628142478753\n",
      "Iteration:110, Price of Hedge: 1.7535478883231577, Loss: 0.013913061899946299\n",
      "Iteration:120, Price of Hedge: 1.9274773210456146, Loss: 0.017436422884422775\n",
      "Iteration:130, Price of Hedge: 1.8352238437877986, Loss: 0.017780699148049185\n",
      "Iteration:140, Price of Hedge: 1.7296934603702538, Loss: 0.01590095098446991\n",
      "Iteration:150, Price of Hedge: 1.8858564597998906, Loss: 0.018392186710462964\n",
      "Iteration:160, Price of Hedge: 1.5604564655769082, Loss: 0.01595145072325721\n",
      "Iteration:170, Price of Hedge: 1.3067812453750889, Loss: 0.013688167354202817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:180, Price of Hedge: 1.2347512666855323, Loss: 0.014191825803326273\n",
      "Iteration:190, Price of Hedge: 1.3845515034060951, Loss: 0.018282527364850587\n",
      "Iteration:200, Price of Hedge: 1.6360201106249177, Loss: 0.017072728078579135\n",
      "Iteration:210, Price of Hedge: 1.9211002204249212, Loss: 0.015621605389500104\n",
      "Iteration:220, Price of Hedge: 1.7870241449894706, Loss: 0.01395593283213996\n",
      "Iteration:230, Price of Hedge: 1.5952620394994597, Loss: 0.01454973906640884\n",
      "Iteration:240, Price of Hedge: 1.478761057507029, Loss: 0.013571514608350554\n",
      "Iteration:250, Price of Hedge: 1.5373254733050203, Loss: 0.01696287221553776\n",
      "Iteration:260, Price of Hedge: 1.6629133373668081, Loss: 0.016003044409065924\n",
      "Iteration:270, Price of Hedge: 1.5678073703236237, Loss: 0.015433759619587217\n",
      "Iteration:280, Price of Hedge: 1.5781117171690993, Loss: 0.01538871258439647\n",
      "Iteration:290, Price of Hedge: 1.697513317375376, Loss: 0.017049863930773502\n",
      "Iteration:300, Price of Hedge: 1.7824410441173881, Loss: 0.015444742323635728\n",
      "Iteration:310, Price of Hedge: 1.9058748675387847, Loss: 0.01746738355030306\n",
      "Iteration:320, Price of Hedge: 2.1530024414343303, Loss: 0.013198046335704827\n",
      "Iteration:330, Price of Hedge: 2.0918285257215756, Loss: 0.016181632897956887\n",
      "Iteration:340, Price of Hedge: 1.8670838572706088, Loss: 0.015545858401551538\n",
      "Iteration:350, Price of Hedge: 2.0642967169042774, Loss: 0.015998310959259496\n",
      "Iteration:360, Price of Hedge: 2.0487223909879617, Loss: 0.016637972570410397\n",
      "Iteration:370, Price of Hedge: 1.942144920785006, Loss: 0.014663419158618485\n",
      "Iteration:380, Price of Hedge: 1.8956221707141139, Loss: 0.016371953477358935\n",
      "Iteration:390, Price of Hedge: 2.0224798203523164, Loss: 0.015620621492238928\n",
      "Iteration:400, Price of Hedge: 1.8585496975018145, Loss: 0.013332732830957993\n",
      "Iteration:410, Price of Hedge: 1.6624521764667632, Loss: 0.013567024840156082\n",
      "Iteration:420, Price of Hedge: 1.6211714004229634, Loss: 0.012867312743168657\n",
      "Iteration:430, Price of Hedge: 1.6037240904729742, Loss: 0.015484504350102667\n",
      "Iteration:440, Price of Hedge: 1.6231282318930085, Loss: 0.015744882082825738\n",
      "Iteration:450, Price of Hedge: 1.6449924570961911, Loss: 0.011944886133783417\n",
      "Iteration:460, Price of Hedge: 1.5946098741393597, Loss: 0.01607760443174335\n",
      "Iteration:470, Price of Hedge: 1.626376481578052, Loss: 0.014352486662227992\n",
      "Iteration:480, Price of Hedge: 1.5866205550121093, Loss: 0.012378378689941804\n",
      "Iteration:490, Price of Hedge: 1.5371175316628183, Loss: 0.01239105275399588\n",
      "Iteration:500, Price of Hedge: 1.6019731883066584, Loss: 0.012301968783199424\n",
      "Iteration:510, Price of Hedge: 1.3931238137584387, Loss: 0.009997386621383341\n",
      "Iteration:520, Price of Hedge: 1.6266788354336086, Loss: 0.007946311942972616\n",
      "Iteration:530, Price of Hedge: 1.7527367482236968, Loss: 0.010304494888605563\n",
      "Iteration:540, Price of Hedge: 1.8771525928198798, Loss: 0.014482682079170495\n",
      "Iteration:550, Price of Hedge: 1.9801727516873255, Loss: 0.010843190430144789\n",
      "Iteration:560, Price of Hedge: 1.7266647232736319, Loss: 0.009172519124449075\n",
      "Iteration:570, Price of Hedge: 1.6676785548706903, Loss: 0.008980936903152869\n",
      "Iteration:580, Price of Hedge: 1.6015834654224022, Loss: 0.011730838040004342\n",
      "Iteration:590, Price of Hedge: 1.7385313155535869, Loss: 0.008891081273918555\n",
      "Iteration:600, Price of Hedge: 1.6108922078083991, Loss: 0.007605650289923549\n",
      "Iteration:610, Price of Hedge: 1.6079221639172374, Loss: 0.010696697822815614\n",
      "Iteration:620, Price of Hedge: 1.773898834994702, Loss: 0.01368224562900906\n",
      "Iteration:630, Price of Hedge: 1.7782523615859986, Loss: 0.008018880589036215\n",
      "Iteration:640, Price of Hedge: 1.681926582038477, Loss: 0.010599768221195526\n",
      "Iteration:650, Price of Hedge: 1.541964584264599, Loss: 0.010658232811380052\n",
      "Iteration:660, Price of Hedge: 1.7237221813416, Loss: 0.0107459084072687\n",
      "Iteration:670, Price of Hedge: 1.7529894643969215, Loss: 0.009999370792358108\n",
      "Iteration:680, Price of Hedge: 1.6278803691968164, Loss: 0.009051308484360287\n",
      "Iteration:690, Price of Hedge: 1.6236636816216787, Loss: 0.009739821708127304\n",
      "Iteration:700, Price of Hedge: 1.7349312420255274, Loss: 0.010801725252626548\n",
      "Iteration:710, Price of Hedge: 1.5270799873598775, Loss: 0.008883119697811814\n",
      "Iteration:720, Price of Hedge: 1.793968892754401, Loss: 0.008606629501085327\n",
      "Iteration:730, Price of Hedge: 1.8107556526006532, Loss: 0.00837025375208178\n",
      "Iteration:740, Price of Hedge: 1.6994364421759995, Loss: 0.007874919126192514\n",
      "Iteration:750, Price of Hedge: 1.7559502850700823, Loss: 0.010975887513958416\n",
      "Iteration:760, Price of Hedge: 1.9159608756599482, Loss: 0.009869812746943651\n",
      "Iteration:770, Price of Hedge: 1.9228402224245087, Loss: 0.009460229156255062\n",
      "Iteration:780, Price of Hedge: 1.6713950086404339, Loss: 0.010427433571953327\n",
      "Iteration:790, Price of Hedge: 1.6174576297711838, Loss: 0.009014149003711358\n",
      "Iteration:800, Price of Hedge: 1.4263870979363673, Loss: 0.007886264077368477\n",
      "Iteration:810, Price of Hedge: 1.6451982187050476, Loss: 0.012217989025092102\n",
      "Iteration:820, Price of Hedge: 1.5929283976503597, Loss: 0.008942887198550586\n",
      "Iteration:830, Price of Hedge: 1.666361479340162, Loss: 0.009177406512908215\n",
      "Iteration:840, Price of Hedge: 1.7466992297203092, Loss: 0.01075755534022722\n",
      "Iteration:850, Price of Hedge: 1.5933617212015292, Loss: 0.010014466606195515\n",
      "Iteration:860, Price of Hedge: 1.6885190028757733, Loss: 0.008777209904744687\n",
      "Iteration:870, Price of Hedge: 1.7885074061388877, Loss: 0.009493615502267261\n",
      "Iteration:880, Price of Hedge: 1.8821711972764774, Loss: 0.011144308191073104\n",
      "Iteration:890, Price of Hedge: 1.9994866732658239, Loss: 0.010187240799420572\n",
      "Iteration:900, Price of Hedge: 1.6736791805020743, Loss: 0.00881683174877894\n",
      "Iteration:910, Price of Hedge: 1.8812503847302422, Loss: 0.012121745269299211\n",
      "Iteration:920, Price of Hedge: 1.7584735898202553, Loss: 0.010968611783678871\n",
      "Iteration:930, Price of Hedge: 1.501087449779493, Loss: 0.008764079265197244\n",
      "Iteration:940, Price of Hedge: 1.540135368592712, Loss: 0.007423390855458933\n",
      "Iteration:950, Price of Hedge: 1.7330357868789064, Loss: 0.011553799418570066\n",
      "Iteration:960, Price of Hedge: 1.9215897217584597, Loss: 0.010065520524132588\n",
      "Iteration:970, Price of Hedge: 1.893299764421488, Loss: 0.010360001891483695\n",
      "Iteration:980, Price of Hedge: 1.8012411486058, Loss: 0.009314242908834602\n",
      "Iteration:990, Price of Hedge: 1.8023055079631034, Loss: 0.008721113349579568\n",
      "tf.Tensor(2.202828, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_20 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 1.8774396864420169, Loss: 0.026430559208223237\n",
      "Iteration:20, Price of Hedge: 2.0150153861767532, Loss: 0.033515043966332134\n",
      "Iteration:30, Price of Hedge: 2.30586990122481, Loss: 0.023605864848011925\n",
      "Iteration:40, Price of Hedge: 2.18663683436564, Loss: 0.023092553462776166\n",
      "Iteration:50, Price of Hedge: 2.115585019868797, Loss: 0.03149304731683191\n",
      "Iteration:60, Price of Hedge: 1.9180240256793126, Loss: 0.021160463537041794\n",
      "Iteration:70, Price of Hedge: 2.0831851965906254, Loss: 0.029867439422779363\n",
      "Iteration:80, Price of Hedge: 2.1527389927892497, Loss: 0.016678525907058095\n",
      "Iteration:90, Price of Hedge: 1.8810214812289472, Loss: 0.021641289281148255\n",
      "Iteration:100, Price of Hedge: 1.8002192160513004, Loss: 0.02118769430211973\n",
      "Iteration:110, Price of Hedge: 1.7861608517845866, Loss: 0.02466635412208049\n",
      "Iteration:120, Price of Hedge: 2.0469753458037188, Loss: 0.022052410293189693\n",
      "Iteration:130, Price of Hedge: 1.814106363852943, Loss: 0.022963873850269323\n",
      "Iteration:140, Price of Hedge: 1.9447037768482005, Loss: 0.029047091826712012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:150, Price of Hedge: 2.1667359807325397, Loss: 0.023323016002341213\n",
      "Iteration:160, Price of Hedge: 2.4769931279467756, Loss: 0.02286574090692568\n",
      "Iteration:170, Price of Hedge: 2.193737706057095, Loss: 0.026978523166772028\n",
      "Iteration:180, Price of Hedge: 2.296064782015492, Loss: 0.025963539468561867\n",
      "Iteration:190, Price of Hedge: 2.2334178345405573, Loss: 0.025647662593657826\n",
      "Iteration:200, Price of Hedge: 1.928557443720956, Loss: 0.022561898759373377\n",
      "Iteration:210, Price of Hedge: 2.143067861783254, Loss: 0.02324517675883193\n",
      "Iteration:220, Price of Hedge: 2.052954338796519, Loss: 0.02160862939456525\n",
      "Iteration:230, Price of Hedge: 2.1317420854678972, Loss: 0.0221346698687352\n",
      "Iteration:240, Price of Hedge: 2.1442434028411865, Loss: 0.020479759915903093\n",
      "Iteration:250, Price of Hedge: 2.216960092034628, Loss: 0.022829673408123873\n",
      "Iteration:260, Price of Hedge: 2.0435505134176766, Loss: 0.020384993971176258\n",
      "Iteration:270, Price of Hedge: 1.9419436869377136, Loss: 0.02391420069410728\n",
      "Iteration:280, Price of Hedge: 1.932730866018926, Loss: 0.021640642083748763\n",
      "Iteration:290, Price of Hedge: 1.895378174674272, Loss: 0.021757964298975807\n",
      "Iteration:300, Price of Hedge: 2.1913961825489765, Loss: 0.021347764298618264\n",
      "Iteration:310, Price of Hedge: 2.313571120560687, Loss: 0.020001980191946076\n",
      "Iteration:320, Price of Hedge: 2.24299891339989, Loss: 0.021320468027730664\n",
      "Iteration:330, Price of Hedge: 2.0927728155499947, Loss: 0.023054837837803176\n",
      "Iteration:340, Price of Hedge: 1.9978615422540655, Loss: 0.023233983126076295\n",
      "Iteration:350, Price of Hedge: 1.9394497287902708, Loss: 0.021729716883731865\n",
      "Iteration:360, Price of Hedge: 2.191858014228512, Loss: 0.021546913751047024\n",
      "Iteration:370, Price of Hedge: 2.060081203193249, Loss: 0.0177662642878313\n",
      "Iteration:380, Price of Hedge: 1.9809968042919877, Loss: 0.02639208109562574\n",
      "Iteration:390, Price of Hedge: 2.052849194111309, Loss: 0.02400863910978579\n",
      "Iteration:400, Price of Hedge: 2.1763931930640976, Loss: 0.02433791323288261\n",
      "Iteration:410, Price of Hedge: 1.9900464580995958, Loss: 0.01566856781456547\n",
      "Iteration:420, Price of Hedge: 1.8899904738027657, Loss: 0.0202103397612138\n",
      "Iteration:430, Price of Hedge: 1.789760422228028, Loss: 0.014546700906956556\n",
      "Iteration:440, Price of Hedge: 1.9231190989978812, Loss: 0.01946419714633549\n",
      "Iteration:450, Price of Hedge: 2.2917593838526726, Loss: 0.02284444627831963\n",
      "Iteration:460, Price of Hedge: 2.2588043228508465, Loss: 0.01649064869435657\n",
      "Iteration:470, Price of Hedge: 2.2287383091166473, Loss: 0.013458029723453712\n",
      "Iteration:480, Price of Hedge: 1.8512049974653906, Loss: 0.01618740133955603\n",
      "Iteration:490, Price of Hedge: 2.099444388367226, Loss: 0.01768800580714016\n",
      "Iteration:500, Price of Hedge: 2.186098869213879, Loss: 0.013077277204773185\n",
      "Iteration:510, Price of Hedge: 2.2893266343337815, Loss: 0.01735846048999132\n",
      "Iteration:520, Price of Hedge: 2.1134244391283685, Loss: 0.018416457923060212\n",
      "Iteration:530, Price of Hedge: 2.132407331028071, Loss: 0.017514656472906242\n",
      "Iteration:540, Price of Hedge: 1.852525091503628, Loss: 0.01634651495123345\n",
      "Iteration:550, Price of Hedge: 2.1302544642517884, Loss: 0.01763908999883057\n",
      "Iteration:560, Price of Hedge: 2.0416693123352387, Loss: 0.01673618412072564\n",
      "Iteration:570, Price of Hedge: 2.086356306634207, Loss: 0.014590094575511347\n",
      "Iteration:580, Price of Hedge: 2.0111942908064178, Loss: 0.018937890718578296\n",
      "Iteration:590, Price of Hedge: 2.064208174011469, Loss: 0.016134582695106568\n",
      "Iteration:600, Price of Hedge: 1.9279064522249654, Loss: 0.016803909267222573\n",
      "Iteration:610, Price of Hedge: 2.268759025886652, Loss: 0.014546229265126965\n",
      "Iteration:620, Price of Hedge: 2.310648198928766, Loss: 0.014612852603905324\n",
      "Iteration:630, Price of Hedge: 2.374676616765362, Loss: 0.01724523369798456\n",
      "Iteration:640, Price of Hedge: 2.2362384623001046, Loss: 0.014200784377856124\n",
      "Iteration:650, Price of Hedge: 2.3213791615305013, Loss: 0.01597224226724503\n",
      "Iteration:660, Price of Hedge: 2.257803519850313, Loss: 0.020387257851958294\n",
      "Iteration:670, Price of Hedge: 1.9440014707211504, Loss: 0.014133995964437407\n",
      "Iteration:680, Price of Hedge: 2.104297981069044, Loss: 0.01737190752259945\n",
      "Iteration:690, Price of Hedge: 2.09607556606868, Loss: 0.013347191273267356\n",
      "Iteration:700, Price of Hedge: 1.8651245103774727, Loss: 0.014519370573047929\n",
      "Iteration:710, Price of Hedge: 2.0271945616995026, Loss: 0.013741832333713155\n",
      "Iteration:720, Price of Hedge: 2.0791496194780508, Loss: 0.014890071880293386\n",
      "Iteration:730, Price of Hedge: 2.0919613400607884, Loss: 0.014814310481066694\n",
      "Iteration:740, Price of Hedge: 2.1144877923164356, Loss: 0.01451658002555618\n",
      "Iteration:750, Price of Hedge: 2.0270106004241026, Loss: 0.013024651147404143\n",
      "Iteration:760, Price of Hedge: 2.1940952315257847, Loss: 0.015682738031312305\n",
      "Iteration:770, Price of Hedge: 2.2181235590617234, Loss: 0.014712539345054232\n",
      "Iteration:780, Price of Hedge: 1.9926915093273805, Loss: 0.013894029842006094\n",
      "Iteration:790, Price of Hedge: 1.8170170437591537, Loss: 0.013226794215334613\n",
      "Iteration:800, Price of Hedge: 2.0082775738847887, Loss: 0.01411856541591261\n",
      "Iteration:810, Price of Hedge: 1.9459396880603208, Loss: 0.016595123910192022\n",
      "Iteration:820, Price of Hedge: 1.9493983948106575, Loss: 0.014873098014892871\n",
      "Iteration:830, Price of Hedge: 2.2221651731897167, Loss: 0.014429178243951934\n",
      "Iteration:840, Price of Hedge: 2.0254641183076614, Loss: 0.015105358033875138\n",
      "Iteration:850, Price of Hedge: 2.0479833596837804, Loss: 0.015260458759652451\n",
      "Iteration:860, Price of Hedge: 2.1789205224912167, Loss: 0.016703432526009098\n",
      "Iteration:870, Price of Hedge: 2.3953242156667898, Loss: 0.014131684919472408\n",
      "Iteration:880, Price of Hedge: 2.3748312314380313, Loss: 0.015890800204204147\n",
      "Iteration:890, Price of Hedge: 2.4372479338526887, Loss: 0.01646094967037044\n",
      "Iteration:900, Price of Hedge: 1.903999535776893, Loss: 0.01655223594648785\n",
      "Iteration:910, Price of Hedge: 1.8435405033066445, Loss: 0.015486394847769614\n",
      "Iteration:920, Price of Hedge: 1.9428961938148972, Loss: 0.012711651287660608\n",
      "Iteration:930, Price of Hedge: 2.2491041806318663, Loss: 0.013623412241116116\n",
      "Iteration:940, Price of Hedge: 2.196236191966102, Loss: 0.01370442720627798\n",
      "Iteration:950, Price of Hedge: 1.931739957015884, Loss: 0.015302634020147464\n",
      "Iteration:960, Price of Hedge: 2.0693242091891304, Loss: 0.013898150157434052\n",
      "Iteration:970, Price of Hedge: 1.925118524965603, Loss: 0.014515028847983303\n",
      "Iteration:980, Price of Hedge: 1.9794950967065688, Loss: 0.015395048306307313\n",
      "Iteration:990, Price of Hedge: 1.8206573640566717, Loss: 0.010676313724963915\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 4 \n",
      "\n",
      "tf.Tensor(1.0094041, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_21 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.8721773328575182, Loss: 0.022694132317826642\n",
      "Iteration:20, Price of Hedge: 1.2951465199652374, Loss: 0.008729472565157437\n",
      "Iteration:30, Price of Hedge: 0.9194970907041351, Loss: 0.01015429928822087\n",
      "Iteration:40, Price of Hedge: 0.9415608332096781, Loss: 0.009698283437784028\n",
      "Iteration:50, Price of Hedge: 1.1041850148419143, Loss: 0.0066189629922384086\n",
      "Iteration:60, Price of Hedge: 1.0575378388646641, Loss: 0.009225619346104707\n",
      "Iteration:70, Price of Hedge: 1.012003593391455, Loss: 0.008614840312785076\n",
      "Iteration:80, Price of Hedge: 0.9209335172352439, Loss: 0.008819325299268143\n",
      "Iteration:90, Price of Hedge: 1.0330237017067703, Loss: 0.008110088991850261\n",
      "Iteration:100, Price of Hedge: 1.0353099139162623, Loss: 0.008065586349957243\n",
      "Iteration:110, Price of Hedge: 1.0625013571854651, Loss: 0.009064605553624715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:120, Price of Hedge: 1.093827820200022, Loss: 0.009877202493334635\n",
      "Iteration:130, Price of Hedge: 1.0533896845238815, Loss: 0.008749046190767018\n",
      "Iteration:140, Price of Hedge: 1.1153305116680712, Loss: 0.00740608157678011\n",
      "Iteration:150, Price of Hedge: 1.166235900837455, Loss: 0.008552680981455296\n",
      "Iteration:160, Price of Hedge: 1.082803139005955, Loss: 0.006997840959547474\n",
      "Iteration:170, Price of Hedge: 1.199626759919738, Loss: 0.007646275359981303\n",
      "Iteration:180, Price of Hedge: 1.201693533802154, Loss: 0.007776696018819962\n",
      "Iteration:190, Price of Hedge: 1.2713893204835585, Loss: 0.007857373643570042\n",
      "Iteration:200, Price of Hedge: 0.9988247253178087, Loss: 0.00771623335734688\n",
      "Iteration:210, Price of Hedge: 1.012327882023419, Loss: 0.007722682118168222\n",
      "Iteration:220, Price of Hedge: 0.9000693822406447, Loss: 0.008202008160155571\n",
      "Iteration:230, Price of Hedge: 0.989833755059044, Loss: 0.009782871010796156\n",
      "Iteration:240, Price of Hedge: 1.113822977154814, Loss: 0.009012958852418507\n",
      "Iteration:250, Price of Hedge: 1.1345505010340275, Loss: 0.009037136840178305\n",
      "Iteration:260, Price of Hedge: 1.2753423807905164, Loss: 0.009443819228030037\n",
      "Iteration:270, Price of Hedge: 1.1484703414566866, Loss: 0.007694005920699709\n",
      "Iteration:280, Price of Hedge: 1.0437538735671297, Loss: 0.009026587941303886\n",
      "Iteration:290, Price of Hedge: 1.0286266694284676, Loss: 0.008764330373136175\n",
      "Iteration:300, Price of Hedge: 1.0185275242950411, Loss: 0.008962459482184215\n",
      "Iteration:310, Price of Hedge: 1.1578248909044304, Loss: 0.010410033788858186\n",
      "Iteration:320, Price of Hedge: 1.0028681425829744, Loss: 0.008011775023548039\n",
      "Iteration:330, Price of Hedge: 1.1056154402216634, Loss: 0.007478818998905723\n",
      "Iteration:340, Price of Hedge: 0.9493816921825782, Loss: 0.007686566403757666\n",
      "Iteration:350, Price of Hedge: 0.9046541486501609, Loss: 0.010987276612095797\n",
      "Iteration:360, Price of Hedge: 1.0053711888463113, Loss: 0.007379296219675879\n",
      "Iteration:370, Price of Hedge: 0.9350525845601169, Loss: 0.00819922431237714\n",
      "Iteration:380, Price of Hedge: 0.9368410975092046, Loss: 0.00900124227668755\n",
      "Iteration:390, Price of Hedge: 0.9568151938196023, Loss: 0.007940528158621873\n",
      "Iteration:400, Price of Hedge: 0.9648376008947707, Loss: 0.008017024261780392\n",
      "Iteration:410, Price of Hedge: 1.160099440499016, Loss: 0.008219988614538919\n",
      "Iteration:420, Price of Hedge: 1.2167316265045882, Loss: 0.007598336032794605\n",
      "Iteration:430, Price of Hedge: 1.2013558841162193, Loss: 0.009243465340728818\n",
      "Iteration:440, Price of Hedge: 1.0854764820927811, Loss: 0.008739853389332808\n",
      "Iteration:450, Price of Hedge: 0.947392084048306, Loss: 0.007661234008196516\n",
      "Iteration:460, Price of Hedge: 1.0197587793872116, Loss: 0.008507071700359603\n",
      "Iteration:470, Price of Hedge: 1.105644879832107, Loss: 0.007688249804559177\n",
      "Iteration:480, Price of Hedge: 0.9307372472007955, Loss: 0.008123304970817457\n",
      "Iteration:490, Price of Hedge: 1.0819356895613055, Loss: 0.007161044146133477\n",
      "Iteration:500, Price of Hedge: 1.0029211338817732, Loss: 0.012225133501524254\n",
      "Iteration:510, Price of Hedge: 1.104239591350506, Loss: 0.008868748106824852\n",
      "Iteration:520, Price of Hedge: 0.9890746660266814, Loss: 0.00662075519929246\n",
      "Iteration:530, Price of Hedge: 1.0275906215993926, Loss: 0.008418756407443339\n",
      "Iteration:540, Price of Hedge: 1.093157389686803, Loss: 0.0072996066972354605\n",
      "Iteration:550, Price of Hedge: 0.9116382433108355, Loss: 0.006904654596471715\n",
      "Iteration:560, Price of Hedge: 1.0942544680929132, Loss: 0.006152080227904477\n",
      "Iteration:570, Price of Hedge: 1.1092309640719578, Loss: 0.0061113570552308255\n",
      "Iteration:580, Price of Hedge: 1.0399473319367643, Loss: 0.006955206600624919\n",
      "Iteration:590, Price of Hedge: 1.0373599298665794, Loss: 0.005048219565385992\n",
      "Iteration:600, Price of Hedge: 1.0804039239840677, Loss: 0.007661589618875552\n",
      "Iteration:610, Price of Hedge: 1.1863490426925636, Loss: 0.006186551906377246\n",
      "Iteration:620, Price of Hedge: 1.034214760407758, Loss: 0.007592582570465111\n",
      "Iteration:630, Price of Hedge: 1.0856021665835214, Loss: 0.0066635638251398175\n",
      "Iteration:640, Price of Hedge: 1.0153584634600519, Loss: 0.006036807522468379\n",
      "Iteration:650, Price of Hedge: 0.9176897816960717, Loss: 0.005956823427002788\n",
      "Iteration:660, Price of Hedge: 1.1444237537719346, Loss: 0.005382971731969377\n",
      "Iteration:670, Price of Hedge: 0.9756573371084414, Loss: 0.005554628633615622\n",
      "Iteration:680, Price of Hedge: 0.9700163680596233, Loss: 0.006459441526165221\n",
      "Iteration:690, Price of Hedge: 1.0298896287165007, Loss: 0.006291856897556158\n",
      "Iteration:700, Price of Hedge: 1.1874451020352352, Loss: 0.0059089818485226426\n",
      "Iteration:710, Price of Hedge: 1.092553651214166, Loss: 0.00518794360111876\n",
      "Iteration:720, Price of Hedge: 1.1103994901480292, Loss: 0.006033165166819288\n",
      "Iteration:730, Price of Hedge: 1.0633239678388235, Loss: 0.00618008501118048\n",
      "Iteration:740, Price of Hedge: 0.9975485182050761, Loss: 0.004927139436795969\n",
      "Iteration:750, Price of Hedge: 1.135104531856723, Loss: 0.0069213753752158875\n",
      "Iteration:760, Price of Hedge: 0.9762461293173146, Loss: 0.005114493188427716\n",
      "Iteration:770, Price of Hedge: 0.9045404098475046, Loss: 0.005403371135113488\n",
      "Iteration:780, Price of Hedge: 0.9033513326587581, Loss: 0.005304434405821112\n",
      "Iteration:790, Price of Hedge: 1.0620560264628693, Loss: 0.006137363961097364\n",
      "Iteration:800, Price of Hedge: 1.0700153648341255, Loss: 0.00614552575694347\n",
      "Iteration:810, Price of Hedge: 0.7938673463163922, Loss: 0.005671638258375821\n",
      "Iteration:820, Price of Hedge: 0.9699441277847654, Loss: 0.004279172991708435\n",
      "Iteration:830, Price of Hedge: 1.142226879457212, Loss: 0.004928816645371725\n",
      "Iteration:840, Price of Hedge: 0.9454430119930293, Loss: 0.006169490997518423\n",
      "Iteration:850, Price of Hedge: 1.0758062494376646, Loss: 0.006478152663187586\n",
      "Iteration:860, Price of Hedge: 1.1660042337491177, Loss: 0.006069940353272685\n",
      "Iteration:870, Price of Hedge: 1.1139949724173674, Loss: 0.005837758425593975\n",
      "Iteration:880, Price of Hedge: 0.9482475311902362, Loss: 0.00606430896625092\n",
      "Iteration:890, Price of Hedge: 0.871039774987048, Loss: 0.006021152691157638\n",
      "Iteration:900, Price of Hedge: 1.0957520384303279, Loss: 0.00600791680860766\n",
      "Iteration:910, Price of Hedge: 1.050444477957535, Loss: 0.0055338249665901175\n",
      "Iteration:920, Price of Hedge: 1.1818325535334224, Loss: 0.005799929233856815\n",
      "Iteration:930, Price of Hedge: 1.2003681851858345, Loss: 0.005805981249928038\n",
      "Iteration:940, Price of Hedge: 1.1656103091155272, Loss: 0.006118579844271465\n",
      "Iteration:950, Price of Hedge: 0.867614815999741, Loss: 0.005977614267274944\n",
      "Iteration:960, Price of Hedge: 0.9562917349000599, Loss: 0.005956197569899757\n",
      "Iteration:970, Price of Hedge: 1.0029750310147392, Loss: 0.0051886605724007495\n",
      "Iteration:980, Price of Hedge: 1.2925911617787278, Loss: 0.006133610145384693\n",
      "Iteration:990, Price of Hedge: 1.0836651534455994, Loss: 0.006678816161776523\n",
      "tf.Tensor(1.2953854, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_22 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 1.6048643564279699, Loss: 0.02047902632127574\n",
      "Iteration:20, Price of Hedge: 1.8320629648171234, Loss: 0.025779707795987858\n",
      "Iteration:30, Price of Hedge: 1.6302821763972133, Loss: 0.02139549873261899\n",
      "Iteration:40, Price of Hedge: 1.6241657576397301, Loss: 0.024372358187814313\n",
      "Iteration:50, Price of Hedge: 1.8099919756382405, Loss: 0.02477960495281337\n",
      "Iteration:60, Price of Hedge: 1.6553216973722555, Loss: 0.023053539715854752\n",
      "Iteration:70, Price of Hedge: 1.7976108077783464, Loss: 0.023108312606463243\n",
      "Iteration:80, Price of Hedge: 1.6258591013865953, Loss: 0.020162799967243926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:90, Price of Hedge: 1.7141752152150729, Loss: 0.01989183701426924\n",
      "Iteration:100, Price of Hedge: 1.757001129756736, Loss: 0.02314994559402095\n",
      "Iteration:110, Price of Hedge: 1.8235985106682164, Loss: 0.02265763533923035\n",
      "Iteration:120, Price of Hedge: 1.8276917488125946, Loss: 0.025507764702136625\n",
      "Iteration:130, Price of Hedge: 1.6294138211183962, Loss: 0.017958799285281657\n",
      "Iteration:140, Price of Hedge: 1.744814942701396, Loss: 0.021991242157203317\n",
      "Iteration:150, Price of Hedge: 1.68417466696319, Loss: 0.01809008685572593\n",
      "Iteration:160, Price of Hedge: 1.7910249404635579, Loss: 0.023023162425511143\n",
      "Iteration:170, Price of Hedge: 1.5909722571766904, Loss: 0.023883460734018057\n",
      "Iteration:180, Price of Hedge: 1.6493577984427246, Loss: 0.0255087395353911\n",
      "Iteration:190, Price of Hedge: 1.5970787117583312, Loss: 0.01888402042701216\n",
      "Iteration:200, Price of Hedge: 1.538986887221108, Loss: 0.022926698163502124\n",
      "Iteration:210, Price of Hedge: 1.7912901234160925, Loss: 0.020863395465923418\n",
      "Iteration:220, Price of Hedge: 1.6682916574410227, Loss: 0.022681151643438112\n",
      "Iteration:230, Price of Hedge: 1.6914871265095826, Loss: 0.021377180359630186\n",
      "Iteration:240, Price of Hedge: 1.5781225465936586, Loss: 0.020345042478817275\n",
      "Iteration:250, Price of Hedge: 1.8037867851323426, Loss: 0.020430180275317865\n",
      "Iteration:260, Price of Hedge: 1.552276267063189, Loss: 0.01986134295623998\n",
      "Iteration:270, Price of Hedge: 1.5958463243734513, Loss: 0.019441442820213695\n",
      "Iteration:280, Price of Hedge: 1.6592168975217645, Loss: 0.024784843575801574\n",
      "Iteration:290, Price of Hedge: 1.727331097746719, Loss: 0.02199979096715907\n",
      "Iteration:300, Price of Hedge: 1.8737862527184006, Loss: 0.018969816368650073\n",
      "Iteration:310, Price of Hedge: 1.7923105456057782, Loss: 0.02588028015748307\n",
      "Iteration:320, Price of Hedge: 1.5021090195110445, Loss: 0.016375277315981405\n",
      "Iteration:330, Price of Hedge: 1.7952611871771296, Loss: 0.025314038265599945\n",
      "Iteration:340, Price of Hedge: 1.7973302256449641, Loss: 0.027966175633028455\n",
      "Iteration:350, Price of Hedge: 1.7516837699642565, Loss: 0.023119662071667334\n",
      "Iteration:360, Price of Hedge: 1.5760817022142872, Loss: 0.024000235496501432\n",
      "Iteration:370, Price of Hedge: 1.6515680338114178, Loss: 0.020099395113933837\n",
      "Iteration:380, Price of Hedge: 1.6350136879418642, Loss: 0.026098660498558954\n",
      "Iteration:390, Price of Hedge: 1.5338200091297038, Loss: 0.019470540973637183\n",
      "Iteration:400, Price of Hedge: 1.6829575655298867, Loss: 0.025148826144058486\n",
      "Iteration:410, Price of Hedge: 1.8353785443287052, Loss: 0.027753555831111498\n",
      "Iteration:420, Price of Hedge: 1.760080513009143, Loss: 0.0297318870376813\n",
      "Iteration:430, Price of Hedge: 1.6086148495692214, Loss: 0.02215453291955356\n",
      "Iteration:440, Price of Hedge: 1.3092660968218297, Loss: 0.025143437138444823\n",
      "Iteration:450, Price of Hedge: 1.4913563150257687, Loss: 0.020149171762962225\n",
      "Iteration:460, Price of Hedge: 1.6066421692109543, Loss: 0.021503209845805313\n",
      "Iteration:470, Price of Hedge: 1.73568368137594, Loss: 0.017790101825244164\n",
      "Iteration:480, Price of Hedge: 1.820372608739217, Loss: 0.021622443806516855\n",
      "Iteration:490, Price of Hedge: 1.7497461906799798, Loss: 0.021670642322581556\n",
      "Iteration:500, Price of Hedge: 1.570727769367295, Loss: 0.02505599229554889\n",
      "Iteration:510, Price of Hedge: 1.6912692733922994, Loss: 0.01816989049204096\n",
      "Iteration:520, Price of Hedge: 1.4765699309926275, Loss: 0.02409262881237879\n",
      "Iteration:530, Price of Hedge: 1.6004445650662091, Loss: 0.015246549559437028\n",
      "Iteration:540, Price of Hedge: 1.7453194923326918, Loss: 0.03459474099820454\n",
      "Iteration:550, Price of Hedge: 1.6505765983150922, Loss: 0.0179672083278561\n",
      "Iteration:560, Price of Hedge: 1.4307012062530702, Loss: 0.016897083795851132\n",
      "Iteration:570, Price of Hedge: 1.5043432594851764, Loss: 0.013638739911520759\n",
      "Iteration:580, Price of Hedge: 1.5986318776677761, Loss: 0.014976453518067956\n",
      "Iteration:590, Price of Hedge: 1.6892651152967118, Loss: 0.01832839024086468\n",
      "Iteration:600, Price of Hedge: 1.5524214269885306, Loss: 0.013209041020540012\n",
      "Iteration:610, Price of Hedge: 1.6180680217119514, Loss: 0.013824300571494773\n",
      "Iteration:620, Price of Hedge: 1.5851803535097133, Loss: 0.01395144377370201\n",
      "Iteration:630, Price of Hedge: 1.6472158403244066, Loss: 0.015140924341726246\n",
      "Iteration:640, Price of Hedge: 1.7097556503118538, Loss: 0.01498502532771937\n",
      "Iteration:650, Price of Hedge: 1.5570734515849836, Loss: 0.01245463242624396\n",
      "Iteration:660, Price of Hedge: 1.5461926847942777, Loss: 0.012050434005523414\n",
      "Iteration:670, Price of Hedge: 1.4864132912030072, Loss: 0.013002462177148288\n",
      "Iteration:680, Price of Hedge: 1.5490717654663966, Loss: 0.015338035271939532\n",
      "Iteration:690, Price of Hedge: 1.5935826447888757, Loss: 0.015062472379833025\n",
      "Iteration:700, Price of Hedge: 1.6939295951129678, Loss: 0.015668523206487348\n",
      "Iteration:710, Price of Hedge: 1.5497158135594873, Loss: 0.013420120727451489\n",
      "Iteration:720, Price of Hedge: 1.4884014839713926, Loss: 0.01307165499233136\n",
      "Iteration:730, Price of Hedge: 1.486635333803315, Loss: 0.014888683141018077\n",
      "Iteration:740, Price of Hedge: 1.716479430878644, Loss: 0.011694230642021353\n",
      "Iteration:750, Price of Hedge: 1.662516624935415, Loss: 0.01154134281893846\n",
      "Iteration:760, Price of Hedge: 1.688745959089465, Loss: 0.014132200151094308\n",
      "Iteration:770, Price of Hedge: 1.6464775854778964, Loss: 0.012556314965356563\n",
      "Iteration:780, Price of Hedge: 1.7534270478196048, Loss: 0.012884948770592784\n",
      "Iteration:790, Price of Hedge: 1.5707784960806748, Loss: 0.013319804016419566\n",
      "Iteration:800, Price of Hedge: 1.4719265118207658, Loss: 0.013593721545682768\n",
      "Iteration:810, Price of Hedge: 1.6171815497497846, Loss: 0.016070579117096882\n",
      "Iteration:820, Price of Hedge: 1.6112830973388554, Loss: 0.013736117084526711\n",
      "Iteration:830, Price of Hedge: 1.74940186046706, Loss: 0.012370715382820661\n",
      "Iteration:840, Price of Hedge: 1.9084530924548744, Loss: 0.015745407650661035\n",
      "Iteration:850, Price of Hedge: 1.7547711924948999, Loss: 0.01333859388316938\n",
      "Iteration:860, Price of Hedge: 1.6662646270327057, Loss: 0.012631572623364206\n",
      "Iteration:870, Price of Hedge: 1.6199990336985137, Loss: 0.016556008924470688\n",
      "Iteration:880, Price of Hedge: 1.805439932488025, Loss: 0.013308656240854332\n",
      "Iteration:890, Price of Hedge: 1.7414227069733896, Loss: 0.013367799073638054\n",
      "Iteration:900, Price of Hedge: 1.7378102403134106, Loss: 0.015333888249891459\n",
      "Iteration:910, Price of Hedge: 1.6792342474136603, Loss: 0.016629740641131718\n",
      "Iteration:920, Price of Hedge: 1.669709061454614, Loss: 0.012521187353255669\n",
      "Iteration:930, Price of Hedge: 1.6712905346817932, Loss: 0.012795028806602458\n",
      "Iteration:940, Price of Hedge: 1.7754971311643202, Loss: 0.015241348089803352\n",
      "Iteration:950, Price of Hedge: 1.6529900802251176, Loss: 0.01563791768839451\n",
      "Iteration:960, Price of Hedge: 1.666624809343557, Loss: 0.013847378112277653\n",
      "Iteration:970, Price of Hedge: 1.8245060432747777, Loss: 0.016737674674445202\n",
      "Iteration:980, Price of Hedge: 1.8593345744101497, Loss: 0.013635788873646958\n",
      "Iteration:990, Price of Hedge: 1.7795293387316633, Loss: 0.012337713473360878\n",
      "tf.Tensor(0.82552695, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_23 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 0.5414969085491066, Loss: 0.012349100091919495\n",
      "Iteration:20, Price of Hedge: 1.1519545193526937, Loss: 0.008771841542976232\n",
      "Iteration:30, Price of Hedge: 1.159569867198843, Loss: 0.007571991650624454\n",
      "Iteration:40, Price of Hedge: 0.9361419633758032, Loss: 0.008337078295932087\n",
      "Iteration:50, Price of Hedge: 1.086442554232417, Loss: 0.009959154831986438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:60, Price of Hedge: 1.071720597654439, Loss: 0.009832041706304294\n",
      "Iteration:70, Price of Hedge: 0.9807536733640517, Loss: 0.00989015574500911\n",
      "Iteration:80, Price of Hedge: 1.0616838418492989, Loss: 0.009879151275239905\n",
      "Iteration:90, Price of Hedge: 1.0126479811723583, Loss: 0.007890982391153755\n",
      "Iteration:100, Price of Hedge: 0.8768939547530408, Loss: 0.009361259166650626\n",
      "Iteration:110, Price of Hedge: 0.9591135215610848, Loss: 0.009628451938744575\n",
      "Iteration:120, Price of Hedge: 1.0934284605614266, Loss: 0.010005836252741318\n",
      "Iteration:130, Price of Hedge: 1.1590793579971432, Loss: 0.008111432704838962\n",
      "Iteration:140, Price of Hedge: 1.0945301813676451, Loss: 0.008405112280295413\n",
      "Iteration:150, Price of Hedge: 1.1270809924888454, Loss: 0.008588426931527948\n",
      "Iteration:160, Price of Hedge: 1.05513420790121, Loss: 0.010172872427069279\n",
      "Iteration:170, Price of Hedge: 1.038104978469346, Loss: 0.010235354638741966\n",
      "Iteration:180, Price of Hedge: 1.027312643739242, Loss: 0.008608929391000686\n",
      "Iteration:190, Price of Hedge: 1.10226340088484, Loss: 0.008036317468023668\n",
      "Iteration:200, Price of Hedge: 1.015381675460594, Loss: 0.008931478892131394\n",
      "Iteration:210, Price of Hedge: 1.1795239219282847, Loss: 0.008915281798765306\n",
      "Iteration:220, Price of Hedge: 1.1951394839124987, Loss: 0.009342685143198536\n",
      "Iteration:230, Price of Hedge: 1.1476814731260674, Loss: 0.008112779071638697\n",
      "Iteration:240, Price of Hedge: 1.086746914512696, Loss: 0.00962153168416222\n",
      "Iteration:250, Price of Hedge: 1.1265611569059728, Loss: 0.007679578034692013\n",
      "Iteration:260, Price of Hedge: 1.006184401470182, Loss: 0.008538712204757104\n",
      "Iteration:270, Price of Hedge: 1.0994897366639633, Loss: 0.007017778599571044\n",
      "Iteration:280, Price of Hedge: 1.0899220897283157, Loss: 0.009081034413154753\n",
      "Iteration:290, Price of Hedge: 1.1306228040837596, Loss: 0.007338783582677876\n",
      "Iteration:300, Price of Hedge: 1.1523894329823634, Loss: 0.00837101788529182\n",
      "Iteration:310, Price of Hedge: 1.1326493815749927, Loss: 0.009180533750387099\n",
      "Iteration:320, Price of Hedge: 1.0756210063504112, Loss: 0.009066182801984722\n",
      "Iteration:330, Price of Hedge: 0.9655558141603251, Loss: 0.00939536152308733\n",
      "Iteration:340, Price of Hedge: 1.0068697782471645, Loss: 0.010305690361878561\n",
      "Iteration:350, Price of Hedge: 1.1016905740031688, Loss: 0.008061552557180107\n",
      "Iteration:360, Price of Hedge: 1.0786281493279601, Loss: 0.008471247905163182\n",
      "Iteration:370, Price of Hedge: 1.0011336966107591, Loss: 0.008337873554639686\n",
      "Iteration:380, Price of Hedge: 1.1145161667514911, Loss: 0.0074410349219562015\n",
      "Iteration:390, Price of Hedge: 1.117155767515578, Loss: 0.007836994144008713\n",
      "Iteration:400, Price of Hedge: 1.0371494366519072, Loss: 0.007878631554584814\n",
      "Iteration:410, Price of Hedge: 1.1438214872798198, Loss: 0.00874452940438104\n",
      "Iteration:420, Price of Hedge: 1.1703037756251433, Loss: 0.00945215131008439\n",
      "Iteration:430, Price of Hedge: 1.1303513935213232, Loss: 0.007793452181711302\n",
      "Iteration:440, Price of Hedge: 1.1562947105369858, Loss: 0.0076037153077678\n",
      "Iteration:450, Price of Hedge: 0.9628453318726314, Loss: 0.007401812479424307\n",
      "Iteration:460, Price of Hedge: 1.1052135895391075, Loss: 0.009676324036051653\n",
      "Iteration:470, Price of Hedge: 1.0239214270746742, Loss: 0.009082987618078419\n",
      "Iteration:480, Price of Hedge: 1.1680092976788727, Loss: 0.008316788141342357\n",
      "Iteration:490, Price of Hedge: 1.2289997915520872, Loss: 0.007868054348392661\n",
      "Iteration:500, Price of Hedge: 1.0914095826606172, Loss: 0.005988607679498159\n",
      "Iteration:510, Price of Hedge: 1.0588219720263623, Loss: 0.006704451976399638\n",
      "Iteration:520, Price of Hedge: 1.0395160416437648, Loss: 0.008965628132563097\n",
      "Iteration:530, Price of Hedge: 1.0486396033787968, Loss: 0.0050813678767546834\n",
      "Iteration:540, Price of Hedge: 1.142781476426262, Loss: 0.006681334186149357\n",
      "Iteration:550, Price of Hedge: 0.9643012338383414, Loss: 0.00731718996456685\n",
      "Iteration:560, Price of Hedge: 1.105637519929496, Loss: 0.005488265223300459\n",
      "Iteration:570, Price of Hedge: 1.149220598605916, Loss: 0.006097241434321887\n",
      "Iteration:580, Price of Hedge: 1.0964410385439805, Loss: 0.005334917406304385\n",
      "Iteration:590, Price of Hedge: 1.0200178479591158, Loss: 0.004675454651802013\n",
      "Iteration:600, Price of Hedge: 0.9043661499995324, Loss: 0.00570815867896961\n",
      "Iteration:610, Price of Hedge: 0.97642922104842, Loss: 0.006639843177482163\n",
      "Iteration:620, Price of Hedge: 0.9599890102839708, Loss: 0.005593609137041255\n",
      "Iteration:630, Price of Hedge: 1.1804329265153684, Loss: 0.006148015473998569\n",
      "Iteration:640, Price of Hedge: 1.1781815889213247, Loss: 0.007163601535370034\n",
      "Iteration:650, Price of Hedge: 1.045825403078925, Loss: 0.005455506579852454\n",
      "Iteration:660, Price of Hedge: 0.9941265031788133, Loss: 0.006103551754667435\n",
      "Iteration:670, Price of Hedge: 1.024292819083348, Loss: 0.006113308048645294\n",
      "Iteration:680, Price of Hedge: 1.0679810877524687, Loss: 0.006886922715722221\n",
      "Iteration:690, Price of Hedge: 1.220748095203271, Loss: 0.006113218261371855\n",
      "Iteration:700, Price of Hedge: 1.0990740720103531, Loss: 0.0071176870660050184\n",
      "Iteration:710, Price of Hedge: 1.0294823430289397, Loss: 0.004919681785478502\n",
      "Iteration:720, Price of Hedge: 0.9591343557469372, Loss: 0.004772827844091409\n",
      "Iteration:730, Price of Hedge: 0.9504460473293874, Loss: 0.004844901813457625\n",
      "Iteration:740, Price of Hedge: 1.2247040994712732, Loss: 0.006315935367402048\n",
      "Iteration:750, Price of Hedge: 1.1468919254198227, Loss: 0.006008232612121134\n",
      "Iteration:760, Price of Hedge: 1.0040693919183468, Loss: 0.005927861944847734\n",
      "Iteration:770, Price of Hedge: 0.8831161862642147, Loss: 0.0076519058623993885\n",
      "Iteration:780, Price of Hedge: 0.9730280402080097, Loss: 0.006289759059930944\n",
      "Iteration:790, Price of Hedge: 1.0381328328699964, Loss: 0.004293817605617534\n",
      "Iteration:800, Price of Hedge: 1.1680859538952972, Loss: 0.008782015369890673\n",
      "Iteration:810, Price of Hedge: 1.0563925247891348, Loss: 0.005485916158230353\n",
      "Iteration:820, Price of Hedge: 1.0873103433648794, Loss: 0.0064415026481547955\n",
      "Iteration:830, Price of Hedge: 1.1484471294561445, Loss: 0.005643234076538661\n",
      "Iteration:840, Price of Hedge: 0.9720121471891616, Loss: 0.006233781339111388\n",
      "Iteration:850, Price of Hedge: 0.9646933468035968, Loss: 0.005524732567673496\n",
      "Iteration:860, Price of Hedge: 1.0579011915951013, Loss: 0.005729613856604842\n",
      "Iteration:870, Price of Hedge: 0.9677230224060622, Loss: 0.006052111608420318\n",
      "Iteration:880, Price of Hedge: 0.9874516376570681, Loss: 0.005239515111012239\n",
      "Iteration:890, Price of Hedge: 1.0486136738757523, Loss: 0.007204764798374085\n",
      "Iteration:900, Price of Hedge: 1.05215831620244, Loss: 0.006371760051785102\n",
      "Iteration:910, Price of Hedge: 1.271276430900434, Loss: 0.007289007818253168\n",
      "Iteration:920, Price of Hedge: 1.1642732978843013, Loss: 0.005961714843046906\n",
      "Iteration:930, Price of Hedge: 0.9781785000551281, Loss: 0.005065027035290726\n",
      "Iteration:940, Price of Hedge: 0.9936265959476258, Loss: 0.005680587793798253\n",
      "Iteration:950, Price of Hedge: 0.9374516863527332, Loss: 0.006505557685169094\n",
      "Iteration:960, Price of Hedge: 1.1011730030057152, Loss: 0.006052810003025044\n",
      "Iteration:970, Price of Hedge: 1.1972421514738016, Loss: 0.006289955441947725\n",
      "Iteration:980, Price of Hedge: 1.0614163943113453, Loss: 0.006875850131469718\n",
      "Iteration:990, Price of Hedge: 0.9369812187319894, Loss: 0.0049966657475660975\n",
      "tf.Tensor(1.2591425, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_24 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Iteration:10, Price of Hedge: 1.82057959184649, Loss: 0.014503764657485617\n",
      "Iteration:20, Price of Hedge: 0.759735571499732, Loss: 0.011265603890699792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:30, Price of Hedge: 1.4001317941439992, Loss: 0.011107134218401172\n",
      "Iteration:40, Price of Hedge: 1.0046243285752097, Loss: 0.01493272932741263\n",
      "Iteration:50, Price of Hedge: 1.2398755762548717, Loss: 0.010709482749510358\n",
      "Iteration:60, Price of Hedge: 1.1303964587711561, Loss: 0.010543627521094123\n",
      "Iteration:70, Price of Hedge: 1.2075557528463832, Loss: 0.009806397930248067\n",
      "Iteration:80, Price of Hedge: 1.1645938499503246, Loss: 0.010491089139379283\n",
      "Iteration:90, Price of Hedge: 1.1706355373889892, Loss: 0.010348627255259401\n",
      "Iteration:100, Price of Hedge: 1.1379394531131766, Loss: 0.009984404074801745\n",
      "Iteration:110, Price of Hedge: 1.0628661818964247, Loss: 0.012229449482875054\n",
      "Iteration:120, Price of Hedge: 1.1019759117659305, Loss: 0.010166323706032187\n",
      "Iteration:130, Price of Hedge: 1.0539785899620255, Loss: 0.011186801625749608\n",
      "Iteration:140, Price of Hedge: 1.0228015895851057, Loss: 0.009363795325398883\n",
      "Iteration:150, Price of Hedge: 1.2822936389626192, Loss: 0.009928961539208104\n",
      "Iteration:160, Price of Hedge: 1.4178143564691708, Loss: 0.011629664304080477\n",
      "Iteration:170, Price of Hedge: 1.0181578307254313, Loss: 0.011429955292861393\n",
      "Iteration:180, Price of Hedge: 0.9051881945065361, Loss: 0.009223176955346446\n",
      "Iteration:190, Price of Hedge: 1.1487022350035658, Loss: 0.010688632640791696\n",
      "Iteration:200, Price of Hedge: 1.2917643616423446, Loss: 0.010953277754289559\n",
      "Iteration:210, Price of Hedge: 1.1439621180343238, Loss: 0.011567253745305804\n",
      "Iteration:220, Price of Hedge: 1.1925196982708257, Loss: 0.010555473248962244\n",
      "Iteration:230, Price of Hedge: 1.1563691021679914, Loss: 0.01065700717465674\n",
      "Iteration:240, Price of Hedge: 1.0910011646803468, Loss: 0.010535247670441094\n",
      "Iteration:250, Price of Hedge: 1.031564402862932, Loss: 0.01081772727871524\n",
      "Iteration:260, Price of Hedge: 1.2281882773672805, Loss: 0.012608299585168225\n",
      "Iteration:270, Price of Hedge: 1.0474335984140453, Loss: 0.008580654803602527\n",
      "Iteration:280, Price of Hedge: 1.199574900913649, Loss: 0.01178079972727488\n",
      "Iteration:290, Price of Hedge: 1.213161167904127, Loss: 0.008905552927501503\n",
      "Iteration:300, Price of Hedge: 1.1670821764084394, Loss: 0.010815736920437047\n",
      "Iteration:310, Price of Hedge: 1.1335914491091899, Loss: 0.010590138213338917\n",
      "Iteration:320, Price of Hedge: 1.2192107813917572, Loss: 0.007987727072529082\n",
      "Iteration:330, Price of Hedge: 1.2079641708266535, Loss: 0.011175474275637497\n",
      "Iteration:340, Price of Hedge: 1.1727435267260262, Loss: 0.010626747536602464\n",
      "Iteration:350, Price of Hedge: 1.3197030048704619, Loss: 0.012620727382257257\n",
      "Iteration:360, Price of Hedge: 1.1346400653873387, Loss: 0.009075635676900617\n",
      "Iteration:370, Price of Hedge: 1.1854483038422585, Loss: 0.011362225612163712\n",
      "Iteration:380, Price of Hedge: 1.1695118501042088, Loss: 0.01224923806717868\n",
      "Iteration:390, Price of Hedge: 1.1367209929286217, Loss: 0.00963838780726931\n",
      "Iteration:400, Price of Hedge: 1.2998338720942229, Loss: 0.011674673823881675\n",
      "Iteration:410, Price of Hedge: 1.2939440251078849, Loss: 0.011147312917510276\n",
      "Iteration:420, Price of Hedge: 1.1890510327849368, Loss: 0.007759693051502125\n",
      "Iteration:430, Price of Hedge: 1.1596627152010115, Loss: 0.009842211994804017\n",
      "Iteration:440, Price of Hedge: 1.197690086469629, Loss: 0.009900773642970507\n",
      "Iteration:450, Price of Hedge: 1.2513909931091802, Loss: 0.010620987882047217\n",
      "Iteration:460, Price of Hedge: 1.1064460901532585, Loss: 0.011828030486914541\n",
      "Iteration:470, Price of Hedge: 1.019111560874535, Loss: 0.008429451265924825\n",
      "Iteration:480, Price of Hedge: 1.1250522636414644, Loss: 0.01133316107368003\n",
      "Iteration:490, Price of Hedge: 1.1403446692864236, Loss: 0.009265499049170244\n",
      "Iteration:500, Price of Hedge: 1.2289551792193378, Loss: 0.009131180826521045\n",
      "Iteration:510, Price of Hedge: 1.2230720127599852, Loss: 0.010163889276707038\n",
      "Iteration:520, Price of Hedge: 1.2842637150476548, Loss: 0.009801245113816748\n",
      "Iteration:530, Price of Hedge: 1.186665405275562, Loss: 0.010831848207246253\n",
      "Iteration:540, Price of Hedge: 1.2067553351301286, Loss: 0.009033363120882853\n",
      "Iteration:550, Price of Hedge: 1.1960732857099174, Loss: 0.008538901509944451\n",
      "Iteration:560, Price of Hedge: 1.1940384424819057, Loss: 0.010180595901792345\n",
      "Iteration:570, Price of Hedge: 1.0865623508010684, Loss: 0.010715001791864864\n",
      "Iteration:580, Price of Hedge: 1.2287421949607051, Loss: 0.006502937489071314\n",
      "Iteration:590, Price of Hedge: 1.2245326703550745, Loss: 0.007750923090626571\n",
      "Iteration:600, Price of Hedge: 1.1820123616156706, Loss: 0.013168963166250335\n",
      "Iteration:610, Price of Hedge: 1.1005835314212162, Loss: 0.00792299177528548\n",
      "Iteration:620, Price of Hedge: 1.2184903035407841, Loss: 0.011122728896661726\n",
      "Iteration:630, Price of Hedge: 1.1546001212681403, Loss: 0.006360110705933763\n",
      "Iteration:640, Price of Hedge: 1.1394416658506998, Loss: 0.006729952446659837\n",
      "Iteration:650, Price of Hedge: 1.2112612939670726, Loss: 0.006402065246928856\n",
      "Iteration:660, Price of Hedge: 1.184602594417629, Loss: 0.006424778330995906\n",
      "Iteration:670, Price of Hedge: 1.232779837533053, Loss: 0.008409679489091104\n",
      "Iteration:680, Price of Hedge: 1.2365485605869253, Loss: 0.008920495652850491\n",
      "Iteration:690, Price of Hedge: 1.2111855435848156, Loss: 0.006584538640062476\n",
      "Iteration:700, Price of Hedge: 1.1473840198313154, Loss: 0.006250783421825545\n",
      "Iteration:710, Price of Hedge: 1.1135953863202304, Loss: 0.006568232298142007\n",
      "Iteration:720, Price of Hedge: 1.09557347587006, Loss: 0.006361847625257866\n",
      "Iteration:730, Price of Hedge: 1.0549837262001347, Loss: 0.006122034663940568\n",
      "Iteration:740, Price of Hedge: 1.020866161656977, Loss: 0.006048353369689252\n",
      "Iteration:750, Price of Hedge: 0.987873416691309, Loss: 0.006821435063049463\n",
      "Iteration:760, Price of Hedge: 1.1081450953636705, Loss: 0.0075118182545544695\n",
      "Iteration:770, Price of Hedge: 1.2495316552511213, Loss: 0.007230457669934509\n",
      "Iteration:780, Price of Hedge: 1.1441087499401874, Loss: 0.007958945607222745\n",
      "Iteration:790, Price of Hedge: 1.1362093098532569, Loss: 0.0064154855693459465\n",
      "Iteration:800, Price of Hedge: 1.170844785081681, Loss: 0.007893847622470673\n",
      "Iteration:810, Price of Hedge: 1.230098794855803, Loss: 0.006331306240931766\n",
      "Iteration:820, Price of Hedge: 1.267984969223562, Loss: 0.006457271593340152\n",
      "Iteration:830, Price of Hedge: 1.2903076670717382, Loss: 0.006447924870865762\n",
      "Iteration:840, Price of Hedge: 1.0910708006819732, Loss: 0.006204436823563242\n",
      "Iteration:850, Price of Hedge: 1.1790346582485653, Loss: 0.007129027685172318\n",
      "Iteration:860, Price of Hedge: 1.0875209498088225, Loss: 0.005687035670015916\n",
      "Iteration:870, Price of Hedge: 1.1082037481260159, Loss: 0.006220294229116519\n",
      "Iteration:880, Price of Hedge: 1.2567249976044876, Loss: 0.007482431720331561\n",
      "Iteration:890, Price of Hedge: 1.1381647793623415, Loss: 0.006390067367227914\n",
      "Iteration:900, Price of Hedge: 1.1415984570035107, Loss: 0.00765936837903709\n",
      "Iteration:910, Price of Hedge: 1.2106941285489483, Loss: 0.007664474311473412\n",
      "Iteration:920, Price of Hedge: 1.1959669634245074, Loss: 0.007617151553051115\n",
      "Iteration:930, Price of Hedge: 1.27341567151625, Loss: 0.006508735181584768\n",
      "Iteration:940, Price of Hedge: 1.233806940249724, Loss: 0.007895815865656885\n",
      "Iteration:950, Price of Hedge: 1.1003820965482192, Loss: 0.006146397091567479\n",
      "Iteration:960, Price of Hedge: 1.0060079902660617, Loss: 0.006537487454969692\n",
      "Iteration:970, Price of Hedge: 0.9650579450560144, Loss: 0.00783763548167613\n",
      "Iteration:980, Price of Hedge: 0.9759576211349668, Loss: 0.01015716098112307\n",
      "Iteration:990, Price of Hedge: 0.9918918102875978, Loss: 0.0065871296442388426\n",
      "tf.Tensor(0.8829555, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_25 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.5485489407723435, Loss: 0.015986904455081684\n",
      "Iteration:20, Price of Hedge: 1.2979499634843705, Loss: 0.008467228266044912\n",
      "Iteration:30, Price of Hedge: 0.9771738167341026, Loss: 0.011808638205059195\n",
      "Iteration:40, Price of Hedge: 1.0044594667567253, Loss: 0.007756709283292196\n",
      "Iteration:50, Price of Hedge: 1.2083808545437023, Loss: 0.009518260396841782\n",
      "Iteration:60, Price of Hedge: 0.9413348275848875, Loss: 0.0091623002993515\n",
      "Iteration:70, Price of Hedge: 1.0948429206139736, Loss: 0.009167587575542058\n",
      "Iteration:80, Price of Hedge: 1.0184732874742621, Loss: 0.008324240927339587\n",
      "Iteration:90, Price of Hedge: 1.006247243715552, Loss: 0.009156592836413324\n",
      "Iteration:100, Price of Hedge: 1.0655814198134976, Loss: 0.00869489871495972\n",
      "Iteration:110, Price of Hedge: 1.0166026266891095, Loss: 0.008193072778392008\n",
      "Iteration:120, Price of Hedge: 0.9330562958988593, Loss: 0.008492227166019006\n",
      "Iteration:130, Price of Hedge: 1.0531811162068152, Loss: 0.007948992046624425\n",
      "Iteration:140, Price of Hedge: 1.0921131893502205, Loss: 0.00702452149111572\n",
      "Iteration:150, Price of Hedge: 1.0625076980246375, Loss: 0.007468782285561559\n",
      "Iteration:160, Price of Hedge: 0.9940079521321422, Loss: 0.007102691264435279\n",
      "Iteration:170, Price of Hedge: 0.9227535645362877, Loss: 0.008265940237258462\n",
      "Iteration:180, Price of Hedge: 1.0106375954668692, Loss: 0.008607910327562251\n",
      "Iteration:190, Price of Hedge: 1.0278304411952377, Loss: 0.007630670951080276\n",
      "Iteration:200, Price of Hedge: 1.0071150328480143, Loss: 0.008057493995499954\n",
      "Iteration:210, Price of Hedge: 1.1404545016792327, Loss: 0.007834548214835734\n",
      "Iteration:220, Price of Hedge: 1.1651706398564783, Loss: 0.009919782006829081\n",
      "Iteration:230, Price of Hedge: 1.1029903328042565, Loss: 0.008315616041467421\n",
      "Iteration:240, Price of Hedge: 1.004582320515692, Loss: 0.008253298366079064\n",
      "Iteration:250, Price of Hedge: 1.1183502230946942, Loss: 0.008003322635393316\n",
      "Iteration:260, Price of Hedge: 1.0991416698851026, Loss: 0.007332059710112304\n",
      "Iteration:270, Price of Hedge: 1.0607707610084616, Loss: 0.010197050414829078\n",
      "Iteration:280, Price of Hedge: 1.1451822766579425, Loss: 0.009150972064635709\n",
      "Iteration:290, Price of Hedge: 0.9902728581717383, Loss: 0.008315986690409005\n",
      "Iteration:300, Price of Hedge: 1.026130869838471, Loss: 0.007841215472765839\n",
      "Iteration:310, Price of Hedge: 0.9527491307002491, Loss: 0.008716051358136667\n",
      "Iteration:320, Price of Hedge: 0.9782233388464192, Loss: 0.008011595449001162\n",
      "Iteration:330, Price of Hedge: 1.0833479982577046, Loss: 0.007428647816636413\n",
      "Iteration:340, Price of Hedge: 1.1112996628519796, Loss: 0.008935345494813162\n",
      "Iteration:350, Price of Hedge: 1.0341940394511766, Loss: 0.008179295076088522\n",
      "Iteration:360, Price of Hedge: 1.0255734421376472, Loss: 0.009744007717358016\n",
      "Iteration:370, Price of Hedge: 0.9678636531605661, Loss: 0.008558744055072509\n",
      "Iteration:380, Price of Hedge: 1.2287629159172866, Loss: 0.008573205556020013\n",
      "Iteration:390, Price of Hedge: 1.0783321680137306, Loss: 0.009737598763702237\n",
      "Iteration:400, Price of Hedge: 1.079870047971599, Loss: 0.008020642290828306\n",
      "Iteration:410, Price of Hedge: 1.1106326292168887, Loss: 0.008590400482336235\n",
      "Iteration:420, Price of Hedge: 1.1268827280354343, Loss: 0.008952640381345134\n",
      "Iteration:430, Price of Hedge: 1.2604520522866551, Loss: 0.0067733617184053685\n",
      "Iteration:440, Price of Hedge: 1.2967820035546538, Loss: 0.009439242288593873\n",
      "Iteration:450, Price of Hedge: 1.3583595911976771, Loss: 0.009352198171164616\n",
      "Iteration:460, Price of Hedge: 1.1638529908305826, Loss: 0.009420448883429343\n",
      "Iteration:470, Price of Hedge: 1.122728685772563, Loss: 0.009793830365777722\n",
      "Iteration:480, Price of Hedge: 0.9934072708498206, Loss: 0.0093868074055095\n",
      "Iteration:490, Price of Hedge: 1.062846027086198, Loss: 0.008779180215098848\n",
      "Iteration:500, Price of Hedge: 0.9723296420648694, Loss: 0.008881166173273414\n",
      "Iteration:510, Price of Hedge: 1.2212954454989813, Loss: 0.00871330554831644\n",
      "Iteration:520, Price of Hedge: 1.0219470482773432, Loss: 0.00742658138244181\n",
      "Iteration:530, Price of Hedge: 0.8908886397237893, Loss: 0.007525472112342868\n",
      "Iteration:540, Price of Hedge: 1.029577455616527, Loss: 0.007465219101941756\n",
      "Iteration:550, Price of Hedge: 1.0935247054417232, Loss: 0.007973251417922711\n",
      "Iteration:560, Price of Hedge: 1.195202099699327, Loss: 0.010755220298139533\n",
      "Iteration:570, Price of Hedge: 1.1322662137221413, Loss: 0.009951703815196566\n",
      "Iteration:580, Price of Hedge: 1.2483727536630795, Loss: 0.008007875690530141\n",
      "Iteration:590, Price of Hedge: 1.2411568786847964, Loss: 0.013610898779925405\n",
      "Iteration:600, Price of Hedge: 1.147574018547948, Loss: 0.007766470884892129\n",
      "Iteration:610, Price of Hedge: 1.1774972312077807, Loss: 0.007142853598376319\n",
      "Iteration:620, Price of Hedge: 0.9650898757104187, Loss: 0.009137338552731933\n",
      "Iteration:630, Price of Hedge: 0.9262507637984526, Loss: 0.008933998243409746\n",
      "Iteration:640, Price of Hedge: 1.065394931204264, Loss: 0.00802839938049118\n",
      "Iteration:650, Price of Hedge: 0.9954092775892605, Loss: 0.009146114705833241\n",
      "Iteration:660, Price of Hedge: 1.0545561724730759, Loss: 0.00958964879835662\n",
      "Iteration:670, Price of Hedge: 1.0294384100718161, Loss: 0.007600677578733439\n",
      "Iteration:680, Price of Hedge: 1.131466588610783, Loss: 0.007049158145883183\n",
      "Iteration:690, Price of Hedge: 0.9568011533900062, Loss: 0.006425409938022852\n",
      "Iteration:700, Price of Hedge: 1.0098729582002306, Loss: 0.0077783776504141144\n",
      "Iteration:710, Price of Hedge: 1.010425290583862, Loss: 0.006982367914292808\n",
      "Iteration:720, Price of Hedge: 1.0124985185347213, Loss: 0.006448650245882703\n",
      "Iteration:730, Price of Hedge: 1.1321079192013712, Loss: 0.006749957316563027\n",
      "Iteration:740, Price of Hedge: 1.1432279394415672, Loss: 0.007117659643290963\n",
      "Iteration:750, Price of Hedge: 1.0938301980147116, Loss: 0.006522946781992899\n",
      "Iteration:760, Price of Hedge: 1.2175963584467353, Loss: 0.0069069174126831\n",
      "Iteration:770, Price of Hedge: 1.0291924760953406, Loss: 0.005629028668356284\n",
      "Iteration:780, Price of Hedge: 1.0348620921497058, Loss: 0.006257107453528121\n",
      "Iteration:790, Price of Hedge: 1.068508509696494, Loss: 0.008633846022832613\n",
      "Iteration:800, Price of Hedge: 1.1505391534659792, Loss: 0.007083440961470444\n",
      "Iteration:810, Price of Hedge: 1.089395573618458, Loss: 0.00567356713669831\n",
      "Iteration:820, Price of Hedge: 1.0654729461719399, Loss: 0.007202113641147534\n",
      "Iteration:830, Price of Hedge: 1.030883668486058, Loss: 0.005619181702501308\n",
      "Iteration:840, Price of Hedge: 1.060543170173878, Loss: 0.005619706272483071\n",
      "Iteration:850, Price of Hedge: 0.9830428295345882, Loss: 0.006288367578343567\n",
      "Iteration:860, Price of Hedge: 1.0731077694526903, Loss: 0.006588784737722619\n",
      "Iteration:870, Price of Hedge: 1.1836408249902888, Loss: 0.0069464870621590786\n",
      "Iteration:880, Price of Hedge: 0.9949220520364178, Loss: 0.005930815636532571\n",
      "Iteration:890, Price of Hedge: 1.036045338030999, Loss: 0.005825536298860356\n",
      "Iteration:900, Price of Hedge: 1.1769566746683267, Loss: 0.005226195191112737\n",
      "Iteration:910, Price of Hedge: 1.1116126285568497, Loss: 0.005605966165835951\n",
      "Iteration:920, Price of Hedge: 1.1512301917065086, Loss: 0.004744769542292815\n",
      "Iteration:930, Price of Hedge: 0.9320242110942671, Loss: 0.006032300909024712\n",
      "Iteration:940, Price of Hedge: 0.9417544552629806, Loss: 0.0065483760416569226\n",
      "Iteration:950, Price of Hedge: 0.9774511152186278, Loss: 0.007540556374280527\n",
      "Iteration:960, Price of Hedge: 1.1426152558565263, Loss: 0.005045283123472899\n",
      "Iteration:970, Price of Hedge: 1.1992442714425124, Loss: 0.005820906283203441\n",
      "Iteration:980, Price of Hedge: 1.0240606990779269, Loss: 0.005205161084828802\n",
      "Iteration:990, Price of Hedge: 0.9690514282126969, Loss: 0.005981114201731685\n",
      "tf.Tensor(1.0174524, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_26 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.8535313026659423, Loss: 0.010511844595504272\n",
      "Iteration:20, Price of Hedge: 1.0288707917366082, Loss: 0.00882080435661976\n",
      "Iteration:30, Price of Hedge: 1.088660375962263, Loss: 0.008996546800358373\n",
      "Iteration:40, Price of Hedge: 1.0402977765303147, Loss: 0.008909425722409025\n",
      "Iteration:50, Price of Hedge: 1.1287904147921834, Loss: 0.013339586408497438\n",
      "Iteration:60, Price of Hedge: 1.067272272516402, Loss: 0.009743784797230858\n",
      "Iteration:70, Price of Hedge: 1.1422632260531826, Loss: 0.007602951894792653\n",
      "Iteration:80, Price of Hedge: 1.1559707615928345, Loss: 0.011517907013665507\n",
      "Iteration:90, Price of Hedge: 1.1106262883777163, Loss: 0.00816728569653975\n",
      "Iteration:100, Price of Hedge: 1.0597948379222544, Loss: 0.008472925113738938\n",
      "Iteration:110, Price of Hedge: 0.9783166397656714, Loss: 0.00890520262444454\n",
      "Iteration:120, Price of Hedge: 0.9982528042703052, Loss: 0.00929400717193971\n",
      "Iteration:130, Price of Hedge: 1.0384899579905322, Loss: 0.010078524137060896\n",
      "Iteration:140, Price of Hedge: 0.995453323775655, Loss: 0.00902068321174525\n",
      "Iteration:150, Price of Hedge: 1.0077826326294599, Loss: 0.008742106474903722\n",
      "Iteration:160, Price of Hedge: 1.169064594484007, Loss: 0.008952957954065964\n",
      "Iteration:170, Price of Hedge: 1.0501038843105561, Loss: 0.008970520875512733\n",
      "Iteration:180, Price of Hedge: 0.8944929538762607, Loss: 0.008220363686498899\n",
      "Iteration:190, Price of Hedge: 1.0133473983789372, Loss: 0.010816077492853538\n",
      "Iteration:200, Price of Hedge: 1.1595271797636997, Loss: 0.00774133487134776\n",
      "Iteration:210, Price of Hedge: 1.1038259648237727, Loss: 0.009087286791959314\n",
      "Iteration:220, Price of Hedge: 1.034708666487586, Loss: 0.008912934060600718\n",
      "Iteration:230, Price of Hedge: 0.8700237121242935, Loss: 0.009739193704135828\n",
      "Iteration:240, Price of Hedge: 0.999579171950063, Loss: 0.008752919870278219\n",
      "Iteration:250, Price of Hedge: 1.0607673641303335, Loss: 0.009173625880256253\n",
      "Iteration:260, Price of Hedge: 1.05086795543084, Loss: 0.007875177177217552\n",
      "Iteration:270, Price of Hedge: 1.0266787862805358, Loss: 0.0076693493623494645\n",
      "Iteration:280, Price of Hedge: 1.011084624628529, Loss: 0.009341484736005866\n",
      "Iteration:290, Price of Hedge: 0.9476562479374024, Loss: 0.0072045865507327275\n",
      "Iteration:300, Price of Hedge: 0.9810739989715329, Loss: 0.008043453565903746\n",
      "Iteration:310, Price of Hedge: 1.1645692791985311, Loss: 0.009057803835935374\n",
      "Iteration:320, Price of Hedge: 1.0004999523813238, Loss: 0.009251262237557257\n",
      "Iteration:330, Price of Hedge: 1.0600460936744638, Loss: 0.00800213107423744\n",
      "Iteration:340, Price of Hedge: 0.9620018870334206, Loss: 0.007540113187837249\n",
      "Iteration:350, Price of Hedge: 1.0751362718415294, Loss: 0.010209256176394631\n",
      "Iteration:360, Price of Hedge: 0.9888984812811031, Loss: 0.00823975154533585\n",
      "Iteration:370, Price of Hedge: 0.9387842250277572, Loss: 0.00963137555390432\n",
      "Iteration:380, Price of Hedge: 1.0923636524975335, Loss: 0.00905815944661441\n",
      "Iteration:390, Price of Hedge: 1.0829582631071388, Loss: 0.009397367804231749\n",
      "Iteration:400, Price of Hedge: 1.1460815435277254, Loss: 0.00746469718577103\n",
      "Iteration:410, Price of Hedge: 1.1354186298543028, Loss: 0.007352595342223011\n",
      "Iteration:420, Price of Hedge: 1.0137789151304786, Loss: 0.007490830147661853\n",
      "Iteration:430, Price of Hedge: 1.0066982359016947, Loss: 0.008444360376334004\n",
      "Iteration:440, Price of Hedge: 1.093121382778645, Loss: 0.007588900849952295\n",
      "Iteration:450, Price of Hedge: 1.1778776815581296, Loss: 0.0061284126564675745\n",
      "Iteration:460, Price of Hedge: 0.9314953737843552, Loss: 0.0060990132954913175\n",
      "Iteration:470, Price of Hedge: 0.9550064694456523, Loss: 0.007012742993127218\n",
      "Iteration:480, Price of Hedge: 1.1016665693977301, Loss: 0.007127894950161106\n",
      "Iteration:490, Price of Hedge: 1.0413577157355576, Loss: 0.005895339932883914\n",
      "Iteration:500, Price of Hedge: 1.0663956515008066, Loss: 0.007308396561693797\n",
      "Iteration:510, Price of Hedge: 1.006124729644398, Loss: 0.005763476043142646\n",
      "Iteration:520, Price of Hedge: 1.0340007570856868, Loss: 0.00536414117345032\n",
      "Iteration:530, Price of Hedge: 1.2783986652716521, Loss: 0.006356522753410942\n",
      "Iteration:540, Price of Hedge: 1.111505853354356, Loss: 0.006054772053985502\n",
      "Iteration:550, Price of Hedge: 0.871791164428987, Loss: 0.005025603787723654\n",
      "Iteration:560, Price of Hedge: 1.0416399963080039, Loss: 0.005881409194143927\n",
      "Iteration:570, Price of Hedge: 1.147986852469785, Loss: 0.005858697879284235\n",
      "Iteration:580, Price of Hedge: 1.0788849533144458, Loss: 0.005385552563203433\n",
      "Iteration:590, Price of Hedge: 1.0186834410011214, Loss: 0.005837744271935108\n",
      "Iteration:600, Price of Hedge: 1.075980056368553, Loss: 0.006431079363002822\n",
      "Iteration:610, Price of Hedge: 1.1019178251499397, Loss: 0.005189450965788112\n",
      "Iteration:620, Price of Hedge: 0.9740218535190251, Loss: 0.0055796792829049474\n",
      "Iteration:630, Price of Hedge: 1.0148155291059082, Loss: 0.006174489450607723\n",
      "Iteration:640, Price of Hedge: 1.1320916141863562, Loss: 0.008051445075541607\n",
      "Iteration:650, Price of Hedge: 0.9447113244442334, Loss: 0.006344146263335303\n",
      "Iteration:660, Price of Hedge: 1.0457934724245206, Loss: 0.00653633393177202\n",
      "Iteration:670, Price of Hedge: 1.2258241634193836, Loss: 0.006121551228029886\n",
      "Iteration:680, Price of Hedge: 1.1463437825192158, Loss: 0.0057949095502792146\n",
      "Iteration:690, Price of Hedge: 0.8716501373720348, Loss: 0.005958665171862876\n",
      "Iteration:700, Price of Hedge: 0.9053463191833998, Loss: 0.006578269011486171\n",
      "Iteration:710, Price of Hedge: 1.1563561940311047, Loss: 0.004984909806971416\n",
      "Iteration:720, Price of Hedge: 1.1045434987137013, Loss: 0.006908922809223839\n",
      "Iteration:730, Price of Hedge: 1.0853700465781002, Loss: 0.004625875269394086\n",
      "Iteration:740, Price of Hedge: 1.0037397815106488, Loss: 0.0052974433829444225\n",
      "Iteration:750, Price of Hedge: 0.9458771330178024, Loss: 0.004892134784606483\n",
      "Iteration:760, Price of Hedge: 1.2127932860028523, Loss: 0.004816975317607231\n",
      "Iteration:770, Price of Hedge: 1.1675337347409367, Loss: 0.005726515089916617\n",
      "Iteration:780, Price of Hedge: 0.9326038317321945, Loss: 0.004727592750352017\n",
      "Iteration:790, Price of Hedge: 0.9760061964921988, Loss: 0.005608317000113416\n",
      "Iteration:800, Price of Hedge: 1.1817448008484461, Loss: 0.007466769812191387\n",
      "Iteration:810, Price of Hedge: 0.9943492251547468, Loss: 0.0051871390540725315\n",
      "Iteration:820, Price of Hedge: 0.9774545120967559, Loss: 0.005404375602591216\n",
      "Iteration:830, Price of Hedge: 1.046509647563198, Loss: 0.006605942068382475\n",
      "Iteration:840, Price of Hedge: 1.0008036332859773, Loss: 0.005225467162284758\n",
      "Iteration:850, Price of Hedge: 0.9566265538542211, Loss: 0.0056439373364636225\n",
      "Iteration:860, Price of Hedge: 1.1639599924916182, Loss: 0.004640863109530713\n",
      "Iteration:870, Price of Hedge: 1.1303382589258943, Loss: 0.0056375880935561895\n",
      "Iteration:880, Price of Hedge: 0.9590726457942764, Loss: 0.00543483427647331\n",
      "Iteration:890, Price of Hedge: 0.9317142459650767, Loss: 0.004729116037887593\n",
      "Iteration:900, Price of Hedge: 1.0477444127627678, Loss: 0.006225209087158134\n",
      "Iteration:910, Price of Hedge: 0.9771544545287725, Loss: 0.00558482900322339\n",
      "Iteration:920, Price of Hedge: 1.0911219803124368, Loss: 0.005255022655810393\n",
      "Iteration:930, Price of Hedge: 1.0452387622261994, Loss: 0.004920040934572256\n",
      "Iteration:940, Price of Hedge: 1.0142810869470849, Loss: 0.0048075467692925145\n",
      "Iteration:950, Price of Hedge: 1.0741280784131049, Loss: 0.008715755015904136\n",
      "Iteration:960, Price of Hedge: 1.132313543557393, Loss: 0.005854102363170809\n",
      "Iteration:970, Price of Hedge: 1.0132492286010346, Loss: 0.005208118314928356\n",
      "Iteration:980, Price of Hedge: 1.0580268760858416, Loss: 0.006403933972201159\n",
      "Iteration:990, Price of Hedge: 1.1653342561529825, Loss: 0.005880761221948916\n",
      "tf.Tensor(1.542121, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_27 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 1.2500140119453136, Loss: 0.014326299890383608\n",
      "Iteration:20, Price of Hedge: 1.5359942375902391, Loss: 0.01962256719273654\n",
      "Iteration:30, Price of Hedge: 1.866364187237741, Loss: 0.01860000780056197\n",
      "Iteration:40, Price of Hedge: 1.6616422685052383, Loss: 0.017613892310762935\n",
      "Iteration:50, Price of Hedge: 1.4581694950897144, Loss: 0.01673069515141634\n",
      "Iteration:60, Price of Hedge: 1.286930151148954, Loss: 0.021096840607656018\n",
      "Iteration:70, Price of Hedge: 1.43463999967189, Loss: 0.019120899600227403\n",
      "Iteration:80, Price of Hedge: 1.5381404984208529, Loss: 0.017154211547283183\n",
      "Iteration:90, Price of Hedge: 1.6319350972943538, Loss: 0.020871820431364086\n",
      "Iteration:100, Price of Hedge: 1.6187844233091708, Loss: 0.01720634654972031\n",
      "Iteration:110, Price of Hedge: 1.5838955409723894, Loss: 0.018306855448898318\n",
      "Iteration:120, Price of Hedge: 1.3724661466881116, Loss: 0.017180505507043618\n",
      "Iteration:130, Price of Hedge: 1.3104548909373988, Loss: 0.016049985543445187\n",
      "Iteration:140, Price of Hedge: 1.4274759836996962, Loss: 0.018388900670936435\n",
      "Iteration:150, Price of Hedge: 1.6064851202121644, Loss: 0.019118274096507546\n",
      "Iteration:160, Price of Hedge: 1.582936149359739, Loss: 0.01860593995283466\n",
      "Iteration:170, Price of Hedge: 1.6181707206606915, Loss: 0.018269097025455493\n",
      "Iteration:180, Price of Hedge: 1.596066668534695, Loss: 0.0214496754003477\n",
      "Iteration:190, Price of Hedge: 1.4519583034324568, Loss: 0.015220060986867167\n",
      "Iteration:200, Price of Hedge: 1.5729118487744016, Loss: 0.018973190247082525\n",
      "Iteration:210, Price of Hedge: 1.6135456446307215, Loss: 0.019605572186851817\n",
      "Iteration:220, Price of Hedge: 1.373841995559269, Loss: 0.017629726716620553\n",
      "Iteration:230, Price of Hedge: 1.508035666010437, Loss: 0.02268781624755718\n",
      "Iteration:240, Price of Hedge: 1.5505946991605013, Loss: 0.018363721311811788\n",
      "Iteration:250, Price of Hedge: 1.4811212947672174, Loss: 0.02143900531076923\n",
      "Iteration:260, Price of Hedge: 1.2469330434831136, Loss: 0.015085643688605897\n",
      "Iteration:270, Price of Hedge: 1.448415812461917, Loss: 0.016563933204228932\n",
      "Iteration:280, Price of Hedge: 1.6240660026520344, Loss: 0.016932508634788235\n",
      "Iteration:290, Price of Hedge: 1.654785670003639, Loss: 0.0249644676604845\n",
      "Iteration:300, Price of Hedge: 1.7344142680194636, Loss: 0.017936408196953833\n",
      "Iteration:310, Price of Hedge: 1.715628965824635, Loss: 0.02053606379730297\n",
      "Iteration:320, Price of Hedge: 1.7962082367992478, Loss: 0.018446888211315127\n",
      "Iteration:330, Price of Hedge: 1.8167722576112282, Loss: 0.01755769343902358\n",
      "Iteration:340, Price of Hedge: 1.7147400028185074, Loss: 0.016344003037507094\n",
      "Iteration:350, Price of Hedge: 1.7060373142835488, Loss: 0.014610383285128136\n",
      "Iteration:360, Price of Hedge: 1.740578695987824, Loss: 0.02304055019542943\n",
      "Iteration:370, Price of Hedge: 1.883359561117595, Loss: 0.020280296566329525\n",
      "Iteration:380, Price of Hedge: 1.8109956398958273, Loss: 0.0200879624959839\n",
      "Iteration:390, Price of Hedge: 1.5671194921903406, Loss: 0.015313864361009165\n",
      "Iteration:400, Price of Hedge: 1.3732624881506126, Loss: 0.011905351040702072\n",
      "Iteration:410, Price of Hedge: 1.3725369149824473, Loss: 0.00992658726293314\n",
      "Iteration:420, Price of Hedge: 1.251623679260956, Loss: 0.0183532476042501\n",
      "Iteration:430, Price of Hedge: 1.3508627943981992, Loss: 0.013954021508823189\n",
      "Iteration:440, Price of Hedge: 1.394343400584421, Loss: 0.012752999516596475\n",
      "Iteration:450, Price of Hedge: 1.4270846633393375, Loss: 0.013597303305979835\n",
      "Iteration:460, Price of Hedge: 1.59815631472984, Loss: 0.009632232734869461\n",
      "Iteration:470, Price of Hedge: 1.4584111263538944, Loss: 0.01151294881004361\n",
      "Iteration:480, Price of Hedge: 1.6133146569180097, Loss: 0.011752722406497183\n",
      "Iteration:490, Price of Hedge: 1.6244599272856248, Loss: 0.012644248994087092\n",
      "Iteration:500, Price of Hedge: 1.6284315571930164, Loss: 0.012661699570866602\n",
      "Iteration:510, Price of Hedge: 1.7493643815783797, Loss: 0.013049473555075507\n",
      "Iteration:520, Price of Hedge: 1.6215741660865204, Loss: 0.011750231362536567\n",
      "Iteration:530, Price of Hedge: 1.534839525485222, Loss: 0.014954122582790318\n",
      "Iteration:540, Price of Hedge: 1.3243498209204516, Loss: 0.012361396967664006\n",
      "Iteration:550, Price of Hedge: 1.4218479227877652, Loss: 0.011923880833970201\n",
      "Iteration:560, Price of Hedge: 1.3627347702266888, Loss: 0.010162884366927472\n",
      "Iteration:570, Price of Hedge: 1.5380937347319559, Loss: 0.014422833151479608\n",
      "Iteration:580, Price of Hedge: 1.3964339526137337, Loss: 0.010591110392782354\n",
      "Iteration:590, Price of Hedge: 1.3962245916917708, Loss: 0.011785131631491906\n",
      "Iteration:600, Price of Hedge: 1.451453300884077, Loss: 0.012980184318091403\n",
      "Iteration:610, Price of Hedge: 1.4253347049570038, Loss: 0.012981462570407842\n",
      "Iteration:620, Price of Hedge: 1.4982415605329151, Loss: 0.0130839421374354\n",
      "Iteration:630, Price of Hedge: 1.3575425287785947, Loss: 0.009643667122026755\n",
      "Iteration:640, Price of Hedge: 1.4498111367676756, Loss: 0.013661616647268459\n",
      "Iteration:650, Price of Hedge: 1.3646092808070533, Loss: 0.009781757294764049\n",
      "Iteration:660, Price of Hedge: 1.4918467109981974, Loss: 0.010787067799797967\n",
      "Iteration:670, Price of Hedge: 1.2561127669365304, Loss: 0.013878536507669991\n",
      "Iteration:680, Price of Hedge: 1.401420456476535, Loss: 0.014036443572028644\n",
      "Iteration:690, Price of Hedge: 1.480266413771642, Loss: 0.011693485805723469\n",
      "Iteration:700, Price of Hedge: 1.6129416796995428, Loss: 0.0112116050283106\n",
      "Iteration:710, Price of Hedge: 1.545152447482178, Loss: 0.016418621127054677\n",
      "Iteration:720, Price of Hedge: 1.4247777301732638, Loss: 0.012989630116177863\n",
      "Iteration:730, Price of Hedge: 1.4124633675832228, Loss: 0.011011606751688418\n",
      "Iteration:740, Price of Hedge: 1.5172507169963865, Loss: 0.01010117706807776\n",
      "Iteration:750, Price of Hedge: 1.4979340298330497, Loss: 0.012452313880000787\n",
      "Iteration:760, Price of Hedge: 1.5749120438455064, Loss: 0.0122182132469419\n",
      "Iteration:770, Price of Hedge: 1.5086227597802462, Loss: 0.012162682250980338\n",
      "Iteration:780, Price of Hedge: 1.4632247291199745, Loss: 0.013085671537628229\n",
      "Iteration:790, Price of Hedge: 1.4611709766037164, Loss: 0.011661845301325968\n",
      "Iteration:800, Price of Hedge: 1.4861389366795263, Loss: 0.013225235460095063\n",
      "Iteration:810, Price of Hedge: 1.4743176875644166, Loss: 0.008929789299104129\n",
      "Iteration:820, Price of Hedge: 1.5218887011632432, Loss: 0.012712237863662778\n",
      "Iteration:830, Price of Hedge: 1.4452792484276868, Loss: 0.010669258935613612\n",
      "Iteration:840, Price of Hedge: 1.581532672546473, Loss: 0.012110270367591623\n",
      "Iteration:850, Price of Hedge: 1.4976920588810572, Loss: 0.008730346553592483\n",
      "Iteration:860, Price of Hedge: 1.5221272752371078, Loss: 0.01124057137578589\n",
      "Iteration:870, Price of Hedge: 1.567682581354711, Loss: 0.012153891944220162\n",
      "Iteration:880, Price of Hedge: 1.5213318396087743, Loss: 0.01133262323464308\n",
      "Iteration:890, Price of Hedge: 1.3785034181852096, Loss: 0.010661698227967519\n",
      "Iteration:900, Price of Hedge: 1.4528921052298756, Loss: 0.016984857711315724\n",
      "Iteration:910, Price of Hedge: 1.544685716427375, Loss: 0.015477275429459779\n",
      "Iteration:920, Price of Hedge: 1.616901194074944, Loss: 0.01199023584055041\n",
      "Iteration:930, Price of Hedge: 1.6400930398068339, Loss: 0.011438633254954311\n",
      "Iteration:940, Price of Hedge: 1.4654603278453577, Loss: 0.010780228044150419\n",
      "Iteration:950, Price of Hedge: 1.4035097629838673, Loss: 0.01360500289640356\n",
      "Iteration:960, Price of Hedge: 1.4065205292980862, Loss: 0.01302128654344159\n",
      "Iteration:970, Price of Hedge: 1.460750443091456, Loss: 0.01436395039217757\n",
      "Iteration:980, Price of Hedge: 1.600601274377186, Loss: 0.012768734846842022\n",
      "Iteration:990, Price of Hedge: 1.5177951233310523, Loss: 0.012032370398394221\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 5 \n",
      "\n",
      "tf.Tensor(0.17738114, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_28 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.09077539979086283, Loss: 0.000979447644817899\n",
      "Iteration:20, Price of Hedge: 0.1550001725254333, Loss: 0.0013628479106455593\n",
      "Iteration:30, Price of Hedge: 0.17569778721374404, Loss: 0.001056567162023292\n",
      "Iteration:40, Price of Hedge: 0.137574479327742, Loss: 0.0011782114658930533\n",
      "Iteration:50, Price of Hedge: 0.1360439877036697, Loss: 0.0011005436374119883\n",
      "Iteration:60, Price of Hedge: 0.15530572945258428, Loss: 0.001160330855327052\n",
      "Iteration:70, Price of Hedge: 0.14285939287505017, Loss: 0.0008881308423048129\n",
      "Iteration:80, Price of Hedge: 0.13500928863425088, Loss: 0.0009754410519815072\n",
      "Iteration:90, Price of Hedge: 0.12196470763856837, Loss: 0.0010730732003446431\n",
      "Iteration:100, Price of Hedge: 0.12370721670311582, Loss: 0.0012292794525165186\n",
      "Iteration:110, Price of Hedge: 0.12523483945917066, Loss: 0.0008542518942475486\n",
      "Iteration:120, Price of Hedge: 0.13950835717769225, Loss: 0.001161019616915393\n",
      "Iteration:130, Price of Hedge: 0.14767169863807794, Loss: 0.0011826465762166728\n",
      "Iteration:140, Price of Hedge: 0.1220566103416104, Loss: 0.0011221030063176764\n",
      "Iteration:150, Price of Hedge: 0.12541743076750436, Loss: 0.0010017517024999646\n",
      "Iteration:160, Price of Hedge: 0.14684266772756588, Loss: 0.0009746554717183997\n",
      "Iteration:170, Price of Hedge: 0.14324526012005664, Loss: 0.0008436275552881067\n",
      "Iteration:180, Price of Hedge: 0.12107025034928826, Loss: 0.0008038445650978332\n",
      "Iteration:190, Price of Hedge: 0.14473690061611819, Loss: 0.001049204024521\n",
      "Iteration:200, Price of Hedge: 0.14286823330533593, Loss: 0.0010486158054026085\n",
      "Iteration:210, Price of Hedge: 0.13532490908275463, Loss: 0.0009844078805226531\n",
      "Iteration:220, Price of Hedge: 0.1319994144047371, Loss: 0.001012913251609815\n",
      "Iteration:230, Price of Hedge: 0.15116957721000973, Loss: 0.0010447857766661352\n",
      "Iteration:240, Price of Hedge: 0.14567030795989241, Loss: 0.001112814174883603\n",
      "Iteration:250, Price of Hedge: 0.15308884092037262, Loss: 0.0009720630779282314\n",
      "Iteration:260, Price of Hedge: 0.1451214458435743, Loss: 0.0008402427659870426\n",
      "Iteration:270, Price of Hedge: 0.12187294882859306, Loss: 0.0010216410546563636\n",
      "Iteration:280, Price of Hedge: 0.12564401738098355, Loss: 0.001180858030364096\n",
      "Iteration:290, Price of Hedge: 0.13487430794436364, Loss: 0.0008917959701489231\n",
      "Iteration:300, Price of Hedge: 0.1626921382859223, Loss: 0.0010777132599239182\n",
      "Iteration:310, Price of Hedge: 0.13786158196908788, Loss: 0.0010720762771398108\n",
      "Iteration:320, Price of Hedge: 0.14630249315515018, Loss: 0.0009855819299096958\n",
      "Iteration:330, Price of Hedge: 0.15467526198081033, Loss: 0.0009759996915192914\n",
      "Iteration:340, Price of Hedge: 0.16001018736211564, Loss: 0.0010042329445169253\n",
      "Iteration:350, Price of Hedge: 0.16278036272244664, Loss: 0.001070566734884837\n",
      "Iteration:360, Price of Hedge: 0.1362656729595642, Loss: 0.0009973729409261001\n",
      "Iteration:370, Price of Hedge: 0.14708704312141663, Loss: 0.0010739416877457943\n",
      "Iteration:380, Price of Hedge: 0.1319212624828822, Loss: 0.0010344757119681081\n",
      "Iteration:390, Price of Hedge: 0.10964398970826893, Loss: 0.000916143548263193\n",
      "Iteration:400, Price of Hedge: 0.12604998468874556, Loss: 0.001129885386949381\n",
      "Iteration:410, Price of Hedge: 0.14691619708465284, Loss: 0.0009992908359660825\n",
      "Iteration:420, Price of Hedge: 0.13832793939828322, Loss: 0.0008564041776032205\n",
      "Iteration:430, Price of Hedge: 0.12910990672552317, Loss: 0.0010324091461619389\n",
      "Iteration:440, Price of Hedge: 0.1423560819076613, Loss: 0.0010022133125821232\n",
      "Iteration:450, Price of Hedge: 0.17522768856481435, Loss: 0.0009142845313432791\n",
      "Iteration:460, Price of Hedge: 0.1425275394899586, Loss: 0.0009743591138300367\n",
      "Iteration:470, Price of Hedge: 0.14346390563491696, Loss: 0.0011334143503582972\n",
      "Iteration:480, Price of Hedge: 0.13920038104835727, Loss: 0.001039587428850508\n",
      "Iteration:490, Price of Hedge: 0.14214240969691902, Loss: 0.0008967410998920845\n",
      "Iteration:500, Price of Hedge: 0.12415252977130536, Loss: 0.0007762046602195039\n",
      "Iteration:510, Price of Hedge: 0.12493184562727039, Loss: 0.0007327785336547877\n",
      "Iteration:520, Price of Hedge: 0.1467916216621518, Loss: 0.0011110105230694334\n",
      "Iteration:530, Price of Hedge: 0.15101384893856676, Loss: 0.0010860832273314359\n",
      "Iteration:540, Price of Hedge: 0.14716545584945492, Loss: 0.0008421466792300159\n",
      "Iteration:550, Price of Hedge: 0.14217749262524534, Loss: 0.0010964753560440688\n",
      "Iteration:560, Price of Hedge: 0.15551827749874292, Loss: 0.0011194213117033947\n",
      "Iteration:570, Price of Hedge: 0.1708270248923668, Loss: 0.0009632296736711067\n",
      "Iteration:580, Price of Hedge: 0.12090134686892498, Loss: 0.0009733111816572215\n",
      "Iteration:590, Price of Hedge: 0.1458601029148781, Loss: 0.0008108729825953454\n",
      "Iteration:600, Price of Hedge: 0.15694100220916882, Loss: 0.000998075192489445\n",
      "Iteration:610, Price of Hedge: 0.1537668470640597, Loss: 0.001019622195584713\n",
      "Iteration:620, Price of Hedge: 0.14008938838773588, Loss: 0.001041528228743882\n",
      "Iteration:630, Price of Hedge: 0.1495464903975119, Loss: 0.0009699708671174978\n",
      "Iteration:640, Price of Hedge: 0.16212068495813128, Loss: 0.0009377858945672113\n",
      "Iteration:650, Price of Hedge: 0.1627207010596635, Loss: 0.0010008130250726223\n",
      "Iteration:660, Price of Hedge: 0.13642351466042443, Loss: 0.0010903194307840369\n",
      "Iteration:670, Price of Hedge: 0.14614439064810655, Loss: 0.0008301446063130324\n",
      "Iteration:680, Price of Hedge: 0.13998449933542362, Loss: 0.000940388476098919\n",
      "Iteration:690, Price of Hedge: 0.1374728908226473, Loss: 0.0015182314851230672\n",
      "Iteration:700, Price of Hedge: 0.1456272569529972, Loss: 0.0011557723679403776\n",
      "Iteration:710, Price of Hedge: 0.14402811034947263, Loss: 0.001124251003795873\n",
      "Iteration:720, Price of Hedge: 0.16494316544821006, Loss: 0.0007618544885284351\n",
      "Iteration:730, Price of Hedge: 0.143856769680292, Loss: 0.0006554227311059702\n",
      "Iteration:740, Price of Hedge: 0.12371916882096912, Loss: 0.0007685515585149184\n",
      "Iteration:750, Price of Hedge: 0.1451040707557695, Loss: 0.0007483045815003475\n",
      "Iteration:760, Price of Hedge: 0.1280930054297926, Loss: 0.0006599683608602191\n",
      "Iteration:770, Price of Hedge: 0.11645515902749821, Loss: 0.0009055549015292819\n",
      "Iteration:780, Price of Hedge: 0.16555039418971093, Loss: 0.0009335588249518523\n",
      "Iteration:790, Price of Hedge: 0.17228941012930363, Loss: 0.0006357409278358262\n",
      "Iteration:800, Price of Hedge: 0.13615133193143267, Loss: 0.0006876472601975436\n",
      "Iteration:810, Price of Hedge: 0.1252633572663285, Loss: 0.0008277248420467398\n",
      "Iteration:820, Price of Hedge: 0.13894363984408642, Loss: 0.0007115425728477564\n",
      "Iteration:830, Price of Hedge: 0.17504663511363105, Loss: 0.0006115645740397025\n",
      "Iteration:840, Price of Hedge: 0.16567820720621285, Loss: 0.0005878674656576433\n",
      "Iteration:850, Price of Hedge: 0.14618922233170226, Loss: 0.0007101648388902149\n",
      "Iteration:860, Price of Hedge: 0.1261857837704497, Loss: 0.0006509158147695705\n",
      "Iteration:870, Price of Hedge: 0.1344564874452317, Loss: 0.0005797467466164052\n",
      "Iteration:880, Price of Hedge: 0.1432389737917049, Loss: 0.0006378778241887595\n",
      "Iteration:890, Price of Hedge: 0.13060332789828522, Loss: 0.0005385814906801123\n",
      "Iteration:900, Price of Hedge: 0.13429725178028776, Loss: 0.0008621541389279841\n",
      "Iteration:910, Price of Hedge: 0.1636740465864932, Loss: 0.000642560602022213\n",
      "Iteration:920, Price of Hedge: 0.16053025287845912, Loss: 0.0007380948484914107\n",
      "Iteration:930, Price of Hedge: 0.13450016798429373, Loss: 0.0007802023299995131\n",
      "Iteration:940, Price of Hedge: 0.13948350864373538, Loss: 0.0005398942690028052\n",
      "Iteration:950, Price of Hedge: 0.14950762128286785, Loss: 0.0006649731415866001\n",
      "Iteration:960, Price of Hedge: 0.1497123181635743, Loss: 0.0006177245041360636\n",
      "Iteration:970, Price of Hedge: 0.11995358619174681, Loss: 0.0006294898701479035\n",
      "Iteration:980, Price of Hedge: 0.14412041775176476, Loss: 0.0006620476437782408\n",
      "Iteration:990, Price of Hedge: 0.1414399327385752, Loss: 0.0006754393246411805\n",
      "tf.Tensor(0.18270649, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_29 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.1545859583462857, Loss: 0.002639712125823124\n",
      "Iteration:20, Price of Hedge: 0.19148639999820036, Loss: 0.0013424732706904586\n",
      "Iteration:30, Price of Hedge: 0.17457828116813517, Loss: 0.0015257584696134253\n",
      "Iteration:40, Price of Hedge: 0.17471461984883946, Loss: 0.0014578082008345206\n",
      "Iteration:50, Price of Hedge: 0.16376424955268476, Loss: 0.0015730170840246415\n",
      "Iteration:60, Price of Hedge: 0.17577459013809857, Loss: 0.0016804780843837186\n",
      "Iteration:70, Price of Hedge: 0.15919733542829137, Loss: 0.001470212513891589\n",
      "Iteration:80, Price of Hedge: 0.1601260932273476, Loss: 0.0012592818595276612\n",
      "Iteration:90, Price of Hedge: 0.1623460035139601, Loss: 0.0016315547227446993\n",
      "Iteration:100, Price of Hedge: 0.18245680428960895, Loss: 0.001443522176785006\n",
      "Iteration:110, Price of Hedge: 0.16136440098615595, Loss: 0.0013948760622364276\n",
      "Iteration:120, Price of Hedge: 0.1642216856117443, Loss: 0.0016431257488041418\n",
      "Iteration:130, Price of Hedge: 0.1595212926813474, Loss: 0.0013565601770880954\n",
      "Iteration:140, Price of Hedge: 0.1719607583649463, Loss: 0.0013951000520297187\n",
      "Iteration:150, Price of Hedge: 0.18119081510209298, Loss: 0.001082112959063153\n",
      "Iteration:160, Price of Hedge: 0.15901748708154173, Loss: 0.0014882885183142847\n",
      "Iteration:170, Price of Hedge: 0.17041423165725292, Loss: 0.001603909688865457\n",
      "Iteration:180, Price of Hedge: 0.17856852584106947, Loss: 0.0012869497982602952\n",
      "Iteration:190, Price of Hedge: 0.1915984387372646, Loss: 0.0016093417926541953\n",
      "Iteration:200, Price of Hedge: 0.20166438828554192, Loss: 0.0012032891889043995\n",
      "Iteration:210, Price of Hedge: 0.1784513069516038, Loss: 0.0016597476463378947\n",
      "Iteration:220, Price of Hedge: 0.1749166457144952, Loss: 0.0014134129741384172\n",
      "Iteration:230, Price of Hedge: 0.1829652504408159, Loss: 0.0015371663512876667\n",
      "Iteration:240, Price of Hedge: 0.16170909682745105, Loss: 0.0013988945290612342\n",
      "Iteration:250, Price of Hedge: 0.17829253893912664, Loss: 0.0016128793980783485\n",
      "Iteration:260, Price of Hedge: 0.19905639839802233, Loss: 0.0015235848973909505\n",
      "Iteration:270, Price of Hedge: 0.19053321635107068, Loss: 0.0014491233268230097\n",
      "Iteration:280, Price of Hedge: 0.19993657430043185, Loss: 0.0016460986020455871\n",
      "Iteration:290, Price of Hedge: 0.19509322360826217, Loss: 0.0013734458317372856\n",
      "Iteration:300, Price of Hedge: 0.17469949309020194, Loss: 0.0017186842229645726\n",
      "Iteration:310, Price of Hedge: 0.17951142113392962, Loss: 0.0014587495481527492\n",
      "Iteration:320, Price of Hedge: 0.1703030562765889, Loss: 0.001226133618449765\n",
      "Iteration:330, Price of Hedge: 0.16782498384167185, Loss: 0.0013388037164483002\n",
      "Iteration:340, Price of Hedge: 0.17346900951689578, Loss: 0.0013540213918965093\n",
      "Iteration:350, Price of Hedge: 0.17986618948989416, Loss: 0.0013684381000788725\n",
      "Iteration:360, Price of Hedge: 0.18356321606614756, Loss: 0.0011837815608844338\n",
      "Iteration:370, Price of Hedge: 0.16181895918388137, Loss: 0.0015401723673843294\n",
      "Iteration:380, Price of Hedge: 0.15719484756547217, Loss: 0.0014048624377946517\n",
      "Iteration:390, Price of Hedge: 0.1663203659896567, Loss: 0.0013050258026829908\n",
      "Iteration:400, Price of Hedge: 0.18731362697014903, Loss: 0.0013370342813936453\n",
      "Iteration:410, Price of Hedge: 0.15803860053537164, Loss: 0.0013339192213323691\n",
      "Iteration:420, Price of Hedge: 0.15346681203334356, Loss: 0.001150738639975968\n",
      "Iteration:430, Price of Hedge: 0.1632589870355787, Loss: 0.0012785761773178807\n",
      "Iteration:440, Price of Hedge: 0.17563951052172797, Loss: 0.0013909405025496647\n",
      "Iteration:450, Price of Hedge: 0.16654822066078623, Loss: 0.0014312125745941096\n",
      "Iteration:460, Price of Hedge: 0.21053059341688823, Loss: 0.001516731287486195\n",
      "Iteration:470, Price of Hedge: 0.20539952853783916, Loss: 0.0016037022804997747\n",
      "Iteration:480, Price of Hedge: 0.16648958423610338, Loss: 0.0012638336019268337\n",
      "Iteration:490, Price of Hedge: 0.15464977492136997, Loss: 0.001248583325705699\n",
      "Iteration:500, Price of Hedge: 0.16121809771058224, Loss: 0.0013380999894189395\n",
      "Iteration:510, Price of Hedge: 0.16739837687215414, Loss: 0.001335953678187618\n",
      "Iteration:520, Price of Hedge: 0.18607880861820833, Loss: 0.0014123341976998384\n",
      "Iteration:530, Price of Hedge: 0.15877419987900795, Loss: 0.0015661332621967007\n",
      "Iteration:540, Price of Hedge: 0.16480058540573736, Loss: 0.0014281495071448269\n",
      "Iteration:550, Price of Hedge: 0.17878799874106335, Loss: 0.0014085846872516684\n",
      "Iteration:560, Price of Hedge: 0.1556057644833004, Loss: 0.001315652530492173\n",
      "Iteration:570, Price of Hedge: 0.15484721419552444, Loss: 0.0011020254971140897\n",
      "Iteration:580, Price of Hedge: 0.15598396942250475, Loss: 0.001202802144598536\n",
      "Iteration:590, Price of Hedge: 0.16288355203790844, Loss: 0.0011016290885777825\n",
      "Iteration:600, Price of Hedge: 0.16915083254493765, Loss: 0.0011754713147204222\n",
      "Iteration:610, Price of Hedge: 0.19574478940094195, Loss: 0.0015679912252123175\n",
      "Iteration:620, Price of Hedge: 0.1718188798011738, Loss: 0.001191575956025126\n",
      "Iteration:630, Price of Hedge: 0.1570234349497582, Loss: 0.001079911142205514\n",
      "Iteration:640, Price of Hedge: 0.13905504905098384, Loss: 0.0014231694580392861\n",
      "Iteration:650, Price of Hedge: 0.16841161788800038, Loss: 0.0016352113490941456\n",
      "Iteration:660, Price of Hedge: 0.1855996806793428, Loss: 0.0013916127529706834\n",
      "Iteration:670, Price of Hedge: 0.17300632136090144, Loss: 0.001231337095266305\n",
      "Iteration:680, Price of Hedge: 0.18373732667686227, Loss: 0.001562902975265601\n",
      "Iteration:690, Price of Hedge: 0.19364145048499495, Loss: 0.001172914823936644\n",
      "Iteration:700, Price of Hedge: 0.19991614148495956, Loss: 0.0017516126898663666\n",
      "Iteration:710, Price of Hedge: 0.1796525982190019, Loss: 0.001351421058693969\n",
      "Iteration:720, Price of Hedge: 0.16878462469016994, Loss: 0.0011191009247970563\n",
      "Iteration:730, Price of Hedge: 0.15161336141436552, Loss: 0.0011663543399470734\n",
      "Iteration:740, Price of Hedge: 0.12570536978730049, Loss: 0.0013534261467494702\n",
      "Iteration:750, Price of Hedge: 0.1347284813145734, Loss: 0.0015061582385358819\n",
      "Iteration:760, Price of Hedge: 0.13796874633051745, Loss: 0.0011585815147143296\n",
      "Iteration:770, Price of Hedge: 0.14594083591861703, Loss: 0.002878360463202512\n",
      "Iteration:780, Price of Hedge: 0.17284195950545608, Loss: 0.0010224936632327708\n",
      "Iteration:790, Price of Hedge: 0.18325783900532996, Loss: 0.0011218614514527658\n",
      "Iteration:800, Price of Hedge: 0.1829451413847437, Loss: 0.0008644412517734068\n",
      "Iteration:810, Price of Hedge: 0.18003783593184153, Loss: 0.001186227602497869\n",
      "Iteration:820, Price of Hedge: 0.16416195200242784, Loss: 0.0014461315033042156\n",
      "Iteration:830, Price of Hedge: 0.1669957640715097, Loss: 0.0009411902864882027\n",
      "Iteration:840, Price of Hedge: 0.1793628515425553, Loss: 0.001205867038815267\n",
      "Iteration:850, Price of Hedge: 0.1787013751149061, Loss: 0.0010450692769220728\n",
      "Iteration:860, Price of Hedge: 0.17309281908062532, Loss: 0.0008508787681540397\n",
      "Iteration:870, Price of Hedge: 0.1624565493624573, Loss: 0.000836410348400829\n",
      "Iteration:880, Price of Hedge: 0.1661725158636159, Loss: 0.0009951747776033582\n",
      "Iteration:890, Price of Hedge: 0.1673638425361446, Loss: 0.0009068717900787338\n",
      "Iteration:900, Price of Hedge: 0.16082730212804108, Loss: 0.0011310992739188563\n",
      "Iteration:910, Price of Hedge: 0.18438234533500691, Loss: 0.000853217733090883\n",
      "Iteration:920, Price of Hedge: 0.16431395704076976, Loss: 0.0008076991146742874\n",
      "Iteration:930, Price of Hedge: 0.1777358166640397, Loss: 0.0011627962185192687\n",
      "Iteration:940, Price of Hedge: 0.1741374107983802, Loss: 0.0008825811227965108\n",
      "Iteration:950, Price of Hedge: 0.18658169689971374, Loss: 0.0011163658323650517\n",
      "Iteration:960, Price of Hedge: 0.17630397273051132, Loss: 0.0009731506369026199\n",
      "Iteration:970, Price of Hedge: 0.16928101979704024, Loss: 0.001122217249543489\n",
      "Iteration:980, Price of Hedge: 0.1498448077047442, Loss: 0.0008259232980411647\n",
      "Iteration:990, Price of Hedge: 0.15668994478103287, Loss: 0.0008992196720181589\n",
      "tf.Tensor(0.11134632, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_30 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.11719158575626808, Loss: 0.0015589639025645142\n",
      "Iteration:20, Price of Hedge: 0.11588207790939009, Loss: 0.0008917876794351187\n",
      "Iteration:30, Price of Hedge: 0.1777798299558185, Loss: 0.0012858163593188366\n",
      "Iteration:40, Price of Hedge: 0.1326093681211887, Loss: 0.000957859750235901\n",
      "Iteration:50, Price of Hedge: 0.15587943110954258, Loss: 0.000952398137126842\n",
      "Iteration:60, Price of Hedge: 0.1373525602456141, Loss: 0.0009454232579676259\n",
      "Iteration:70, Price of Hedge: 0.1385296864711222, Loss: 0.0014679117705505896\n",
      "Iteration:80, Price of Hedge: 0.1412330235019681, Loss: 0.0008626348598080646\n",
      "Iteration:90, Price of Hedge: 0.13125338281376459, Loss: 0.0009927114519594493\n",
      "Iteration:100, Price of Hedge: 0.14367258655490786, Loss: 0.0009807693110668314\n",
      "Iteration:110, Price of Hedge: 0.1382595901915977, Loss: 0.0008692565405071573\n",
      "Iteration:120, Price of Hedge: 0.15965468155418422, Loss: 0.0010372927981544323\n",
      "Iteration:130, Price of Hedge: 0.1535836352168758, Loss: 0.0010669499461178234\n",
      "Iteration:140, Price of Hedge: 0.14578689731719124, Loss: 0.0009271887463386364\n",
      "Iteration:150, Price of Hedge: 0.15987116867304393, Loss: 0.0011993000908793407\n",
      "Iteration:160, Price of Hedge: 0.15910754615466657, Loss: 0.0010807243347612072\n",
      "Iteration:170, Price of Hedge: 0.14622509667189548, Loss: 0.0009590226984976802\n",
      "Iteration:180, Price of Hedge: 0.13248471175883766, Loss: 0.0010435609993522555\n",
      "Iteration:190, Price of Hedge: 0.12592639853107812, Loss: 0.0009710488706929255\n",
      "Iteration:200, Price of Hedge: 0.1290631684587936, Loss: 0.0009240055337994768\n",
      "Iteration:210, Price of Hedge: 0.14514883049283187, Loss: 0.001093007238043242\n",
      "Iteration:220, Price of Hedge: 0.14179060913545527, Loss: 0.0009077840496383605\n",
      "Iteration:230, Price of Hedge: 0.14221949141409027, Loss: 0.0011973209991298361\n",
      "Iteration:240, Price of Hedge: 0.14427888898479183, Loss: 0.001390134898104911\n",
      "Iteration:250, Price of Hedge: 0.1458106666531478, Loss: 0.000952516385188984\n",
      "Iteration:260, Price of Hedge: 0.12980840863789922, Loss: 0.000903804436751976\n",
      "Iteration:270, Price of Hedge: 0.12869680771764253, Loss: 0.0010115320046379494\n",
      "Iteration:280, Price of Hedge: 0.13595727414434577, Loss: 0.0009544655460564489\n",
      "Iteration:290, Price of Hedge: 0.14445081421955594, Loss: 0.0008452898434058832\n",
      "Iteration:300, Price of Hedge: 0.1446654846884485, Loss: 0.0009046930888553462\n",
      "Iteration:310, Price of Hedge: 0.12781227005664847, Loss: 0.0010469126960583885\n",
      "Iteration:320, Price of Hedge: 0.15221699282919873, Loss: 0.000955559498716907\n",
      "Iteration:330, Price of Hedge: 0.1395910687110984, Loss: 0.0009719612005128387\n",
      "Iteration:340, Price of Hedge: 0.13765435796639736, Loss: 0.0009084341680691389\n",
      "Iteration:350, Price of Hedge: 0.15051994498041382, Loss: 0.001311316346651914\n",
      "Iteration:360, Price of Hedge: 0.1544303200080094, Loss: 0.0008774886572326057\n",
      "Iteration:370, Price of Hedge: 0.17888098963542234, Loss: 0.0010693702724664078\n",
      "Iteration:380, Price of Hedge: 0.15248709810203992, Loss: 0.00118218524717566\n",
      "Iteration:390, Price of Hedge: 0.14164507928511513, Loss: 0.0010217131417102898\n",
      "Iteration:400, Price of Hedge: 0.11996563723608347, Loss: 0.0009492912975190837\n",
      "Iteration:410, Price of Hedge: 0.1567923966445278, Loss: 0.0009473816229326193\n",
      "Iteration:420, Price of Hedge: 0.1442438330364155, Loss: 0.001077308911975239\n",
      "Iteration:430, Price of Hedge: 0.13996002852076686, Loss: 0.000981705107822428\n",
      "Iteration:440, Price of Hedge: 0.13030439005220273, Loss: 0.001073721492007973\n",
      "Iteration:450, Price of Hedge: 0.13697297932895935, Loss: 0.0009663825337665078\n",
      "Iteration:460, Price of Hedge: 0.14177900775695207, Loss: 0.001196239693320944\n",
      "Iteration:470, Price of Hedge: 0.16592608100024792, Loss: 0.0008636324153554753\n",
      "Iteration:480, Price of Hedge: 0.1487943343578877, Loss: 0.00115224382609318\n",
      "Iteration:490, Price of Hedge: 0.11970474111951149, Loss: 0.0010466943973483024\n",
      "Iteration:500, Price of Hedge: 0.13941882871025088, Loss: 0.0013159056080440656\n",
      "Iteration:510, Price of Hedge: 0.14896673623843526, Loss: 0.0012252841715862494\n",
      "Iteration:520, Price of Hedge: 0.17714011735450869, Loss: 0.0010784661691538133\n",
      "Iteration:530, Price of Hedge: 0.16661270274130402, Loss: 0.0010775579846908025\n",
      "Iteration:540, Price of Hedge: 0.14589777591840516, Loss: 0.0007635347632795498\n",
      "Iteration:550, Price of Hedge: 0.12131124425607141, Loss: 0.0009097671462241941\n",
      "Iteration:560, Price of Hedge: 0.1556620806322826, Loss: 0.0010721213842437294\n",
      "Iteration:570, Price of Hedge: 0.1519803606810001, Loss: 0.0009339561468718838\n",
      "Iteration:580, Price of Hedge: 0.12955989631838066, Loss: 0.0008197058247701783\n",
      "Iteration:590, Price of Hedge: 0.1224000830918385, Loss: 0.0008789651068926485\n",
      "Iteration:600, Price of Hedge: 0.13030421917918603, Loss: 0.0011952032135748249\n",
      "Iteration:610, Price of Hedge: 0.13247537669613507, Loss: 0.000844554007425602\n",
      "Iteration:620, Price of Hedge: 0.14315978763843304, Loss: 0.0011029556730467684\n",
      "Iteration:630, Price of Hedge: 0.14135646576656882, Loss: 0.0011200503520482298\n",
      "Iteration:640, Price of Hedge: 0.1561253083872771, Loss: 0.0010015379707084993\n",
      "Iteration:650, Price of Hedge: 0.14332566936439547, Loss: 0.0012800998418904363\n",
      "Iteration:660, Price of Hedge: 0.13214066343634273, Loss: 0.0008535762713327788\n",
      "Iteration:670, Price of Hedge: 0.1399422937002953, Loss: 0.0011608533810775867\n",
      "Iteration:680, Price of Hedge: 0.1318611511542656, Loss: 0.0010437394604799089\n",
      "Iteration:690, Price of Hedge: 0.16120086651584417, Loss: 0.0008568910813885111\n",
      "Iteration:700, Price of Hedge: 0.1303883246766759, Loss: 0.0008836300386133366\n",
      "Iteration:710, Price of Hedge: 0.14274125666728424, Loss: 0.0006949333221655696\n",
      "Iteration:720, Price of Hedge: 0.15334446695337647, Loss: 0.0007299922917342272\n",
      "Iteration:730, Price of Hedge: 0.1558995941255148, Loss: 0.0006348985070009583\n",
      "Iteration:740, Price of Hedge: 0.11377545643285886, Loss: 0.0007811489468392274\n",
      "Iteration:750, Price of Hedge: 0.14498106916368556, Loss: 0.0006365872129864503\n",
      "Iteration:760, Price of Hedge: 0.15287765985834767, Loss: 0.0006857637224376489\n",
      "Iteration:770, Price of Hedge: 0.11805909906880743, Loss: 0.0005930743852282206\n",
      "Iteration:780, Price of Hedge: 0.1422597095262347, Loss: 0.0006045684060136836\n",
      "Iteration:790, Price of Hedge: 0.14503533483646722, Loss: 0.0006064880575608278\n",
      "Iteration:800, Price of Hedge: 0.14521278196766615, Loss: 0.0006860310628276966\n",
      "Iteration:810, Price of Hedge: 0.14366160571525485, Loss: 0.0006696519848440108\n",
      "Iteration:820, Price of Hedge: 0.17120861131863876, Loss: 0.0006912404415083007\n",
      "Iteration:830, Price of Hedge: 0.16270942344056039, Loss: 0.0006122208051154044\n",
      "Iteration:840, Price of Hedge: 0.1482067290333589, Loss: 0.0005982517954784772\n",
      "Iteration:850, Price of Hedge: 0.13956128284629019, Loss: 0.0005468086189252208\n",
      "Iteration:860, Price of Hedge: 0.14612831959121877, Loss: 0.0007092885525972648\n",
      "Iteration:870, Price of Hedge: 0.1351307793491344, Loss: 0.0006461294732738488\n",
      "Iteration:880, Price of Hedge: 0.14498627629403701, Loss: 0.0005270262029248408\n",
      "Iteration:890, Price of Hedge: 0.1483402078393624, Loss: 0.0005955965889921977\n",
      "Iteration:900, Price of Hedge: 0.1394735350555493, Loss: 0.000604764080911524\n",
      "Iteration:910, Price of Hedge: 0.13778580428283363, Loss: 0.0006729551316921878\n",
      "Iteration:920, Price of Hedge: 0.13710144885757813, Loss: 0.0007090919643157001\n",
      "Iteration:930, Price of Hedge: 0.13373128437566492, Loss: 0.0006298999794400739\n",
      "Iteration:940, Price of Hedge: 0.12879920562123745, Loss: 0.0005856704616296282\n",
      "Iteration:950, Price of Hedge: 0.1541571570075007, Loss: 0.0007355530421075063\n",
      "Iteration:960, Price of Hedge: 0.15068291287177546, Loss: 0.0006583643185199328\n",
      "Iteration:970, Price of Hedge: 0.10202687532241726, Loss: 0.0007955414854830423\n",
      "Iteration:980, Price of Hedge: 0.15037674439909096, Loss: 0.0005328393985074342\n",
      "Iteration:990, Price of Hedge: 0.1551829167201504, Loss: 0.0006794291955293908\n",
      "tf.Tensor(0.15712748, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_31 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.08853989509314601, Loss: 0.002242542811133852\n",
      "Iteration:20, Price of Hedge: 0.16710961946054112, Loss: 0.0011474041570400217\n",
      "Iteration:30, Price of Hedge: 0.16231145119131726, Loss: 0.001094063671710721\n",
      "Iteration:40, Price of Hedge: 0.14618177586550019, Loss: 0.001198718616748451\n",
      "Iteration:50, Price of Hedge: 0.14353314517995272, Loss: 0.0010851008480059043\n",
      "Iteration:60, Price of Hedge: 0.14302540050744597, Loss: 0.0011104308054457057\n",
      "Iteration:70, Price of Hedge: 0.14689200506281283, Loss: 0.0011857724563620665\n",
      "Iteration:80, Price of Hedge: 0.13284516389093712, Loss: 0.0010617156250355198\n",
      "Iteration:90, Price of Hedge: 0.1357477388592713, Loss: 0.0011745440194594892\n",
      "Iteration:100, Price of Hedge: 0.141923755188742, Loss: 0.0008391574553418213\n",
      "Iteration:110, Price of Hedge: 0.12686271071613647, Loss: 0.0008973725993469462\n",
      "Iteration:120, Price of Hedge: 0.13403227269794799, Loss: 0.001115360477925842\n",
      "Iteration:130, Price of Hedge: 0.13029004571211544, Loss: 0.0009823183396028058\n",
      "Iteration:140, Price of Hedge: 0.12837926269937158, Loss: 0.0011038262682565136\n",
      "Iteration:150, Price of Hedge: 0.12585402031852483, Loss: 0.0012695395803122623\n",
      "Iteration:160, Price of Hedge: 0.1213748809648223, Loss: 0.0009831649760548623\n",
      "Iteration:170, Price of Hedge: 0.12427132249118814, Loss: 0.0009302034747108224\n",
      "Iteration:180, Price of Hedge: 0.1327701956031831, Loss: 0.0009701527709991887\n",
      "Iteration:190, Price of Hedge: 0.12348620594597151, Loss: 0.0010869862827935339\n",
      "Iteration:200, Price of Hedge: 0.11809109728951626, Loss: 0.0010764386680669259\n",
      "Iteration:210, Price of Hedge: 0.14812940449663756, Loss: 0.0009391724813208491\n",
      "Iteration:220, Price of Hedge: 0.1655878063870546, Loss: 0.0011941330088911962\n",
      "Iteration:230, Price of Hedge: 0.16056557862633555, Loss: 0.000964387071370254\n",
      "Iteration:240, Price of Hedge: 0.14711083044400652, Loss: 0.0013100244005041616\n",
      "Iteration:250, Price of Hedge: 0.13698502137997934, Loss: 0.001080873567609686\n",
      "Iteration:260, Price of Hedge: 0.15932279219582599, Loss: 0.0010351672839679082\n",
      "Iteration:270, Price of Hedge: 0.13580748146190444, Loss: 0.0010625860797246923\n",
      "Iteration:280, Price of Hedge: 0.14951212693451907, Loss: 0.000988258284742205\n",
      "Iteration:290, Price of Hedge: 0.15760997906292004, Loss: 0.0010602455690615464\n",
      "Iteration:300, Price of Hedge: 0.14024678941607932, Loss: 0.0010574348765612918\n",
      "Iteration:310, Price of Hedge: 0.158863845259566, Loss: 0.0014293735818558418\n",
      "Iteration:320, Price of Hedge: 0.12619877011971994, Loss: 0.0006963731662163575\n",
      "Iteration:330, Price of Hedge: 0.1295282308503886, Loss: 0.0007843949018142116\n",
      "Iteration:340, Price of Hedge: 0.14755743854979642, Loss: 0.0011587344010977052\n",
      "Iteration:350, Price of Hedge: 0.16000696775474807, Loss: 0.0008545369402297887\n",
      "Iteration:360, Price of Hedge: 0.16981507891412093, Loss: 0.0008685944075673913\n",
      "Iteration:370, Price of Hedge: 0.15763875767626132, Loss: 0.0009833604401718432\n",
      "Iteration:380, Price of Hedge: 0.14514565585204764, Loss: 0.0006637940334589309\n",
      "Iteration:390, Price of Hedge: 0.13750237990800543, Loss: 0.0006721684975247833\n",
      "Iteration:400, Price of Hedge: 0.15222190318010007, Loss: 0.0009005180821122672\n",
      "Iteration:410, Price of Hedge: 0.162372210038734, Loss: 0.0008151627946465289\n",
      "Iteration:420, Price of Hedge: 0.1438813753946988, Loss: 0.0009904740131365664\n",
      "Iteration:430, Price of Hedge: 0.1427942362957822, Loss: 0.0006285929975910154\n",
      "Iteration:440, Price of Hedge: 0.15257568227123103, Loss: 0.0009782946032565133\n",
      "Iteration:450, Price of Hedge: 0.157249814716954, Loss: 0.0007045334769290257\n",
      "Iteration:460, Price of Hedge: 0.16055516436563266, Loss: 0.0007327893537389052\n",
      "Iteration:470, Price of Hedge: 0.15241027719105205, Loss: 0.0005971354297866328\n",
      "Iteration:480, Price of Hedge: 0.14812570824348656, Loss: 0.0008458257186108487\n",
      "Iteration:490, Price of Hedge: 0.13402740731362997, Loss: 0.0007672534997222425\n",
      "Iteration:500, Price of Hedge: 0.12876501303126134, Loss: 0.0008632904585411883\n",
      "Iteration:510, Price of Hedge: 0.14334521184151755, Loss: 0.0007324712854220206\n",
      "Iteration:520, Price of Hedge: 0.1516955063688215, Loss: 0.0006227633611013861\n",
      "Iteration:530, Price of Hedge: 0.13791313166023542, Loss: 0.0006826628549542413\n",
      "Iteration:540, Price of Hedge: 0.13678246490864013, Loss: 0.0006420094100747953\n",
      "Iteration:550, Price of Hedge: 0.13758078364272705, Loss: 0.0007017223628670522\n",
      "Iteration:560, Price of Hedge: 0.14409324894210726, Loss: 0.000611275804262279\n",
      "Iteration:570, Price of Hedge: 0.16106035493620538, Loss: 0.0006485847892450991\n",
      "Iteration:580, Price of Hedge: 0.13530602311774942, Loss: 0.0005681397121601429\n",
      "Iteration:590, Price of Hedge: 0.1518385720503943, Loss: 0.0006072458850107765\n",
      "Iteration:600, Price of Hedge: 0.16757029311360158, Loss: 0.0007910063245114785\n",
      "Iteration:610, Price of Hedge: 0.158337106702254, Loss: 0.0006560835291002931\n",
      "Iteration:620, Price of Hedge: 0.15491317117997597, Loss: 0.0007813458864222245\n",
      "Iteration:630, Price of Hedge: 0.14321272230034765, Loss: 0.0005627993683055444\n",
      "Iteration:640, Price of Hedge: 0.13083706419851637, Loss: 0.0006944865370038577\n",
      "Iteration:650, Price of Hedge: 0.14319421405464255, Loss: 0.0007446874414319016\n",
      "Iteration:660, Price of Hedge: 0.1530003466843482, Loss: 0.00058194884451519\n",
      "Iteration:670, Price of Hedge: 0.15300205541451534, Loss: 0.0007805161124389226\n",
      "Iteration:680, Price of Hedge: 0.14251251165780446, Loss: 0.0006884729590842298\n",
      "Iteration:690, Price of Hedge: 0.16638999224730924, Loss: 0.0007679261014446936\n",
      "Iteration:700, Price of Hedge: 0.1554482375485236, Loss: 0.0006425819611493022\n",
      "Iteration:710, Price of Hedge: 0.15417192403347144, Loss: 0.0006619519492680582\n",
      "Iteration:720, Price of Hedge: 0.16264191960564175, Loss: 0.0006847193735394441\n",
      "Iteration:730, Price of Hedge: 0.15716466599473053, Loss: 0.0006985739994299856\n",
      "Iteration:740, Price of Hedge: 0.15322525154761024, Loss: 0.0005926887967760309\n",
      "Iteration:750, Price of Hedge: 0.1477584931372519, Loss: 0.0005825181284863757\n",
      "Iteration:760, Price of Hedge: 0.15654504446285955, Loss: 0.0007500336168902777\n",
      "Iteration:770, Price of Hedge: 0.1760131468560644, Loss: 0.0007253220904920532\n",
      "Iteration:780, Price of Hedge: 0.14550711523561405, Loss: 0.0006590351637352221\n",
      "Iteration:790, Price of Hedge: 0.12861969902052126, Loss: 0.0007017696480398517\n",
      "Iteration:800, Price of Hedge: 0.14427438333314058, Loss: 0.0007397482135528044\n",
      "Iteration:810, Price of Hedge: 0.1663646490809356, Loss: 0.0008585038360043207\n",
      "Iteration:820, Price of Hedge: 0.14053838871575977, Loss: 0.0008335442205345434\n",
      "Iteration:830, Price of Hedge: 0.1503782552762914, Loss: 0.0007650751498002872\n",
      "Iteration:840, Price of Hedge: 0.1233717659913566, Loss: 0.0005900352765366269\n",
      "Iteration:850, Price of Hedge: 0.12568446032604472, Loss: 0.0007300644490484398\n",
      "Iteration:860, Price of Hedge: 0.16163461417879718, Loss: 0.0006425823827110211\n",
      "Iteration:870, Price of Hedge: 0.1585031772878665, Loss: 0.0007881069635296889\n",
      "Iteration:880, Price of Hedge: 0.14986550132639992, Loss: 0.0006129286775016674\n",
      "Iteration:890, Price of Hedge: 0.13056335260569085, Loss: 0.0007062894220086768\n",
      "Iteration:900, Price of Hedge: 0.14620854896922425, Loss: 0.0007122193199271099\n",
      "Iteration:910, Price of Hedge: 0.14438997443228915, Loss: 0.0005858662770480416\n",
      "Iteration:920, Price of Hedge: 0.16954231161954567, Loss: 0.0006243460443145832\n",
      "Iteration:930, Price of Hedge: 0.15285116554744035, Loss: 0.0007151781211112596\n",
      "Iteration:940, Price of Hedge: 0.11995570861448074, Loss: 0.0006154817255314083\n",
      "Iteration:950, Price of Hedge: 0.1326063643534212, Loss: 0.0006661072128706369\n",
      "Iteration:960, Price of Hedge: 0.1584189278973099, Loss: 0.0005854760162868011\n",
      "Iteration:970, Price of Hedge: 0.1325061518257769, Loss: 0.0007238844245101462\n",
      "Iteration:980, Price of Hedge: 0.1567228423334086, Loss: 0.0007983714293017919\n",
      "Iteration:990, Price of Hedge: 0.16968293111898447, Loss: 0.0007379917766511479\n",
      "tf.Tensor(0.15637967, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_32 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.09494398193334633, Loss: 0.0010495759122173265\n",
      "Iteration:20, Price of Hedge: 0.15562702468390627, Loss: 0.0010373712086341415\n",
      "Iteration:30, Price of Hedge: 0.1611365463150264, Loss: 0.0010769139086446611\n",
      "Iteration:40, Price of Hedge: 0.14463313572838957, Loss: 0.001155841855363704\n",
      "Iteration:50, Price of Hedge: 0.12742119568129057, Loss: 0.0009017188304081714\n",
      "Iteration:60, Price of Hedge: 0.1340777968669272, Loss: 0.0009715129398851108\n",
      "Iteration:70, Price of Hedge: 0.15164564742120776, Loss: 0.0011243537243347036\n",
      "Iteration:80, Price of Hedge: 0.1443358256726242, Loss: 0.0010386756611128866\n",
      "Iteration:90, Price of Hedge: 0.13325185965734931, Loss: 0.0011421311225398689\n",
      "Iteration:100, Price of Hedge: 0.14505716161602322, Loss: 0.0010595615149123995\n",
      "Iteration:110, Price of Hedge: 0.15388656609555937, Loss: 0.0010734015266633534\n",
      "Iteration:120, Price of Hedge: 0.134205097264379, Loss: 0.0011812880233173396\n",
      "Iteration:130, Price of Hedge: 0.14312135919630578, Loss: 0.000978601500187848\n",
      "Iteration:140, Price of Hedge: 0.13767406232321946, Loss: 0.0011079737329672934\n",
      "Iteration:150, Price of Hedge: 0.13210170438853197, Loss: 0.0009129013873436786\n",
      "Iteration:160, Price of Hedge: 0.12304157636984883, Loss: 0.0009301139631058497\n",
      "Iteration:170, Price of Hedge: 0.13651372661993263, Loss: 0.0011368422794752586\n",
      "Iteration:180, Price of Hedge: 0.12907520151649693, Loss: 0.0010675099206010508\n",
      "Iteration:190, Price of Hedge: 0.11719860054327001, Loss: 0.0011403223417247865\n",
      "Iteration:200, Price of Hedge: 0.13545415203660696, Loss: 0.0008334361602139406\n",
      "Iteration:210, Price of Hedge: 0.127519366726051, Loss: 0.0010866024508485062\n",
      "Iteration:220, Price of Hedge: 0.1332788036340901, Loss: 0.0011613173800094857\n",
      "Iteration:230, Price of Hedge: 0.14624402760348404, Loss: 0.000885938861887281\n",
      "Iteration:240, Price of Hedge: 0.1322825689800652, Loss: 0.0009111374325913691\n",
      "Iteration:250, Price of Hedge: 0.1129329535339764, Loss: 0.0012155192564510032\n",
      "Iteration:260, Price of Hedge: 0.15015311658679595, Loss: 0.0009328954273269297\n",
      "Iteration:270, Price of Hedge: 0.16599790162716774, Loss: 0.0011339389136571399\n",
      "Iteration:280, Price of Hedge: 0.149654401204225, Loss: 0.0008944320658372806\n",
      "Iteration:290, Price of Hedge: 0.12418620074891465, Loss: 0.0008675870858401602\n",
      "Iteration:300, Price of Hedge: 0.12375615833242933, Loss: 0.000999449343172376\n",
      "Iteration:310, Price of Hedge: 0.16190984564213978, Loss: 0.0011997365477789401\n",
      "Iteration:320, Price of Hedge: 0.13660869604395884, Loss: 0.000954462173562698\n",
      "Iteration:330, Price of Hedge: 0.13975826346129452, Loss: 0.0009116260226235351\n",
      "Iteration:340, Price of Hedge: 0.13198503409138312, Loss: 0.0010636061888240622\n",
      "Iteration:350, Price of Hedge: 0.12780043485191186, Loss: 0.0010706473234334268\n",
      "Iteration:360, Price of Hedge: 0.14611663727286556, Loss: 0.000880303565350049\n",
      "Iteration:370, Price of Hedge: 0.125956166409253, Loss: 0.0010975709949514023\n",
      "Iteration:380, Price of Hedge: 0.15412886403325957, Loss: 0.0009988678690414866\n",
      "Iteration:390, Price of Hedge: 0.14659790562109834, Loss: 0.0008174099293889459\n",
      "Iteration:400, Price of Hedge: 0.12888673757237826, Loss: 0.0011857525024407069\n",
      "Iteration:410, Price of Hedge: 0.1282752459987762, Loss: 0.0008035602919787444\n",
      "Iteration:420, Price of Hedge: 0.1493865172806011, Loss: 0.0011072930513118973\n",
      "Iteration:430, Price of Hedge: 0.14124746676853875, Loss: 0.0009195375416617857\n",
      "Iteration:440, Price of Hedge: 0.14397693837762518, Loss: 0.0010156231205989742\n",
      "Iteration:450, Price of Hedge: 0.12074511497174854, Loss: 0.0010829697129964623\n",
      "Iteration:460, Price of Hedge: 0.13550974872025565, Loss: 0.000851873021467986\n",
      "Iteration:470, Price of Hedge: 0.11639635172979866, Loss: 0.0010074245180301756\n",
      "Iteration:480, Price of Hedge: 0.14184147533453598, Loss: 0.0007327529589105097\n",
      "Iteration:490, Price of Hedge: 0.15576764418334507, Loss: 0.0010436720808651768\n",
      "Iteration:500, Price of Hedge: 0.13482274925989943, Loss: 0.0006625756498311209\n",
      "Iteration:510, Price of Hedge: 0.1264248081408823, Loss: 0.0005949280623663622\n",
      "Iteration:520, Price of Hedge: 0.11644503255292876, Loss: 0.0006919641224590212\n",
      "Iteration:530, Price of Hedge: 0.14107288850535724, Loss: 0.0007035858764453007\n",
      "Iteration:540, Price of Hedge: 0.14579152887527586, Loss: 0.0006566618415182913\n",
      "Iteration:550, Price of Hedge: 0.1457035652449349, Loss: 0.0007823741457148259\n",
      "Iteration:560, Price of Hedge: 0.1513726463003991, Loss: 0.0007031241961028556\n",
      "Iteration:570, Price of Hedge: 0.1329105812763885, Loss: 0.0007300499754294255\n",
      "Iteration:580, Price of Hedge: 0.13419624784077655, Loss: 0.0007251590163671384\n",
      "Iteration:590, Price of Hedge: 0.15916859278821677, Loss: 0.0008608472975994985\n",
      "Iteration:600, Price of Hedge: 0.1459972240141326, Loss: 0.0005981265916479739\n",
      "Iteration:610, Price of Hedge: 0.16064471981302406, Loss: 0.0007273046952558815\n",
      "Iteration:620, Price of Hedge: 0.1401192641857108, Loss: 0.0007767840265417991\n",
      "Iteration:630, Price of Hedge: 0.12413692636688439, Loss: 0.0005366126569324337\n",
      "Iteration:640, Price of Hedge: 0.13546219206170917, Loss: 0.0007091042598658337\n",
      "Iteration:650, Price of Hedge: 0.1238002705506915, Loss: 0.0006587008652921611\n",
      "Iteration:660, Price of Hedge: 0.15261106197900745, Loss: 0.0005397842062640379\n",
      "Iteration:670, Price of Hedge: 0.1514294301018481, Loss: 0.0006613788361112593\n",
      "Iteration:680, Price of Hedge: 0.1319575505156422, Loss: 0.0007589689688230816\n",
      "Iteration:690, Price of Hedge: 0.12357185829392847, Loss: 0.0006825025912407856\n",
      "Iteration:700, Price of Hedge: 0.15474780207306368, Loss: 0.0005950952818481791\n",
      "Iteration:710, Price of Hedge: 0.15583903313106476, Loss: 0.0006900302783340084\n",
      "Iteration:720, Price of Hedge: 0.14133878490599727, Loss: 0.0006837015830295279\n",
      "Iteration:730, Price of Hedge: 0.14287753239477183, Loss: 0.0007017573524897181\n",
      "Iteration:740, Price of Hedge: 0.13647553200403878, Loss: 0.0007427775560645778\n",
      "Iteration:750, Price of Hedge: 0.12208460653640146, Loss: 0.0007709941573743163\n",
      "Iteration:760, Price of Hedge: 0.16280036385871882, Loss: 0.0005021144347101547\n",
      "Iteration:770, Price of Hedge: 0.16606321109281907, Loss: 0.000783682392249041\n",
      "Iteration:780, Price of Hedge: 0.1338042831270684, Loss: 0.0007798749170645269\n",
      "Iteration:790, Price of Hedge: 0.12582327216883302, Loss: 0.0007237085630130924\n",
      "Iteration:800, Price of Hedge: 0.13513283881865165, Loss: 0.0005998426991451922\n",
      "Iteration:810, Price of Hedge: 0.13288471649764802, Loss: 0.0006127216204374176\n",
      "Iteration:820, Price of Hedge: 0.1526975057388313, Loss: 0.0006261541927870873\n",
      "Iteration:830, Price of Hedge: 0.12686320534855328, Loss: 0.0006459924657152172\n",
      "Iteration:840, Price of Hedge: 0.1312905971581415, Loss: 0.0007160655085294732\n",
      "Iteration:850, Price of Hedge: 0.136019732728613, Loss: 0.0005279111312330276\n",
      "Iteration:860, Price of Hedge: 0.12306350207588822, Loss: 0.0005375264622183628\n",
      "Iteration:870, Price of Hedge: 0.11324186496824495, Loss: 0.0006738380927123533\n",
      "Iteration:880, Price of Hedge: 0.14258693135324166, Loss: 0.0006977960072778178\n",
      "Iteration:890, Price of Hedge: 0.1689858591439588, Loss: 0.0007684310621236091\n",
      "Iteration:900, Price of Hedge: 0.1260888538033896, Loss: 0.0006457001126631834\n",
      "Iteration:910, Price of Hedge: 0.10335113220863264, Loss: 0.0005839566375917205\n",
      "Iteration:920, Price of Hedge: 0.14072825561727884, Loss: 0.0008136545873369983\n",
      "Iteration:930, Price of Hedge: 0.18389532126410588, Loss: 0.0007532473223937685\n",
      "Iteration:940, Price of Hedge: 0.1716583850718962, Loss: 0.0007797282838466479\n",
      "Iteration:950, Price of Hedge: 0.14082456504548874, Loss: 0.0006857800930843982\n",
      "Iteration:960, Price of Hedge: 0.149072128916481, Loss: 0.0007577136985448707\n",
      "Iteration:970, Price of Hedge: 0.155861642329171, Loss: 0.0006149102986214849\n",
      "Iteration:980, Price of Hedge: 0.13432495119562873, Loss: 0.0006023837326659453\n",
      "Iteration:990, Price of Hedge: 0.12962452229196517, Loss: 0.0008124945197469646\n",
      "tf.Tensor(0.12696952, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_33 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.06027602772140597, Loss: 0.0023778846388935906\n",
      "Iteration:20, Price of Hedge: 0.17912413294488944, Loss: 0.001044139522551113\n",
      "Iteration:30, Price of Hedge: 0.1309108363751534, Loss: 0.0010317356310557636\n",
      "Iteration:40, Price of Hedge: 0.14566664768000806, Loss: 0.0009769899399969084\n",
      "Iteration:50, Price of Hedge: 0.15565630692298102, Loss: 0.0009862881863093697\n",
      "Iteration:60, Price of Hedge: 0.13739857005369346, Loss: 0.0009325744783382995\n",
      "Iteration:70, Price of Hedge: 0.14232429952655254, Loss: 0.0009425727981452249\n",
      "Iteration:80, Price of Hedge: 0.1406738460514305, Loss: 0.0008414280570199217\n",
      "Iteration:90, Price of Hedge: 0.14392595526542779, Loss: 0.001073637671486205\n",
      "Iteration:100, Price of Hedge: 0.1437984480216926, Loss: 0.0010824473277665004\n",
      "Iteration:110, Price of Hedge: 0.15709311516731078, Loss: 0.001003018987287163\n",
      "Iteration:120, Price of Hedge: 0.159115118527302, Loss: 0.0009165974999741256\n",
      "Iteration:130, Price of Hedge: 0.15433959542945105, Loss: 0.000996622561066518\n",
      "Iteration:140, Price of Hedge: 0.12812534539653483, Loss: 0.0010957733855218698\n",
      "Iteration:150, Price of Hedge: 0.13586202592750282, Loss: 0.0010067048419157842\n",
      "Iteration:160, Price of Hedge: 0.14691415560176893, Loss: 0.0009031999172471217\n",
      "Iteration:170, Price of Hedge: 0.14648030901233255, Loss: 0.0009937606488174212\n",
      "Iteration:180, Price of Hedge: 0.15447562833738857, Loss: 0.0008438830919500262\n",
      "Iteration:190, Price of Hedge: 0.1586367999869367, Loss: 0.0010407188302436587\n",
      "Iteration:200, Price of Hedge: 0.1515878563682918, Loss: 0.0009974554967627114\n",
      "Iteration:210, Price of Hedge: 0.1424260139380806, Loss: 0.0009622555147990931\n",
      "Iteration:220, Price of Hedge: 0.1405530118486638, Loss: 0.0009210684430438487\n",
      "Iteration:230, Price of Hedge: 0.11509772579609034, Loss: 0.0009403952210864209\n",
      "Iteration:240, Price of Hedge: 0.11800303473269197, Loss: 0.0008339510275932494\n",
      "Iteration:250, Price of Hedge: 0.13665638760225535, Loss: 0.0009950818232443482\n",
      "Iteration:260, Price of Hedge: 0.13922469897663065, Loss: 0.000939464412811164\n",
      "Iteration:270, Price of Hedge: 0.12748512017617486, Loss: 0.0009677797298234037\n",
      "Iteration:280, Price of Hedge: 0.1328934400148171, Loss: 0.0010712977931656377\n",
      "Iteration:290, Price of Hedge: 0.11817031042273812, Loss: 0.0009852539548924177\n",
      "Iteration:300, Price of Hedge: 0.12872085584641582, Loss: 0.0008297573316139673\n",
      "Iteration:310, Price of Hedge: 0.1489656210671683, Loss: 0.0008326393383049968\n",
      "Iteration:320, Price of Hedge: 0.1469910034927068, Loss: 0.000933321977526136\n",
      "Iteration:330, Price of Hedge: 0.12944336092098183, Loss: 0.0011009212161915195\n",
      "Iteration:340, Price of Hedge: 0.13444280861057792, Loss: 0.0011112827816795346\n",
      "Iteration:350, Price of Hedge: 0.12812233263545067, Loss: 0.0007923034699204301\n",
      "Iteration:360, Price of Hedge: 0.12784999702007555, Loss: 0.0009989991855169134\n",
      "Iteration:370, Price of Hedge: 0.14909102387480289, Loss: 0.0011149902062161045\n",
      "Iteration:380, Price of Hedge: 0.1482246527134805, Loss: 0.0007725261829209629\n",
      "Iteration:390, Price of Hedge: 0.15775016688315874, Loss: 0.0011311842186052079\n",
      "Iteration:400, Price of Hedge: 0.17562794511649146, Loss: 0.0011663268681750606\n",
      "Iteration:410, Price of Hedge: 0.16839051956709455, Loss: 0.001005862069779484\n",
      "Iteration:420, Price of Hedge: 0.14151138463951157, Loss: 0.0009984094909325058\n",
      "Iteration:430, Price of Hedge: 0.16556472953648155, Loss: 0.001063541900661935\n",
      "Iteration:440, Price of Hedge: 0.1469959048502915, Loss: 0.000857428923881498\n",
      "Iteration:450, Price of Hedge: 0.14606908061431909, Loss: 0.000916954070928\n",
      "Iteration:460, Price of Hedge: 0.14348742315800678, Loss: 0.0007931671093618142\n",
      "Iteration:470, Price of Hedge: 0.14241147174502658, Loss: 0.0010011320770335174\n",
      "Iteration:480, Price of Hedge: 0.11666266182300547, Loss: 0.0009398573785934339\n",
      "Iteration:490, Price of Hedge: 0.1289008930528155, Loss: 0.000960317806358324\n",
      "Iteration:500, Price of Hedge: 0.12832529380604002, Loss: 0.000968108056142114\n",
      "Iteration:510, Price of Hedge: 0.13008094210624108, Loss: 0.0009566395398406425\n",
      "Iteration:520, Price of Hedge: 0.15921498031559622, Loss: 0.000902103083914918\n",
      "Iteration:530, Price of Hedge: 0.14859337869691558, Loss: 0.000991508033772659\n",
      "Iteration:540, Price of Hedge: 0.1311209202525447, Loss: 0.00101661877911865\n",
      "Iteration:550, Price of Hedge: 0.12032849058373359, Loss: 0.0009077002993768791\n",
      "Iteration:560, Price of Hedge: 0.1081188401142981, Loss: 0.0009261028033508367\n",
      "Iteration:570, Price of Hedge: 0.13996498383825157, Loss: 0.0011024892852651291\n",
      "Iteration:580, Price of Hedge: 0.13376447870749075, Loss: 0.000835382159368514\n",
      "Iteration:590, Price of Hedge: 0.16215212559320663, Loss: 0.0011579374386681885\n",
      "Iteration:600, Price of Hedge: 0.15740234136766276, Loss: 0.0008181404255874547\n",
      "Iteration:610, Price of Hedge: 0.13659440566377157, Loss: 0.00123687458948476\n",
      "Iteration:620, Price of Hedge: 0.1401837732461786, Loss: 0.0009947475950615736\n",
      "Iteration:630, Price of Hedge: 0.12835578114954843, Loss: 0.0007027496385156429\n",
      "Iteration:640, Price of Hedge: 0.12550121250559415, Loss: 0.0006386408508999075\n",
      "Iteration:650, Price of Hedge: 0.15164730219147488, Loss: 0.0009823355533729928\n",
      "Iteration:660, Price of Hedge: 0.1368614981755286, Loss: 0.0009667834389611497\n",
      "Iteration:670, Price of Hedge: 0.11719042561841775, Loss: 0.0008788781949182756\n",
      "Iteration:680, Price of Hedge: 0.1388832227427031, Loss: 0.0006504845571311702\n",
      "Iteration:690, Price of Hedge: 0.16223756210156354, Loss: 0.0008075474929760684\n",
      "Iteration:700, Price of Hedge: 0.14473549765871782, Loss: 0.000966604204970345\n",
      "Iteration:710, Price of Hedge: 0.15000721801047234, Loss: 0.0009524893349786901\n",
      "Iteration:720, Price of Hedge: 0.15581856434232577, Loss: 0.0007905563073765887\n",
      "Iteration:730, Price of Hedge: 0.14647839343588204, Loss: 0.000682458678561737\n",
      "Iteration:740, Price of Hedge: 0.14223170433812699, Loss: 0.0008734434212386511\n",
      "Iteration:750, Price of Hedge: 0.1442486444608335, Loss: 0.0010288515165561396\n",
      "Iteration:760, Price of Hedge: 0.1475030559638981, Loss: 0.0007380699060897111\n",
      "Iteration:770, Price of Hedge: 0.12016259986445449, Loss: 0.0005840364884073024\n",
      "Iteration:780, Price of Hedge: 0.1350845177281883, Loss: 0.0007427557753757697\n",
      "Iteration:790, Price of Hedge: 0.14404048515320939, Loss: 0.0008264404137496407\n",
      "Iteration:800, Price of Hedge: 0.14709099118743438, Loss: 0.0008500535610893589\n",
      "Iteration:810, Price of Hedge: 0.15996469916640307, Loss: 0.000615055175332202\n",
      "Iteration:820, Price of Hedge: 0.15129363102014395, Loss: 0.0006463884526898056\n",
      "Iteration:830, Price of Hedge: 0.13669603913544962, Loss: 0.00048249783298586206\n",
      "Iteration:840, Price of Hedge: 0.14784676254035958, Loss: 0.0006566872054817096\n",
      "Iteration:850, Price of Hedge: 0.14436298548896503, Loss: 0.0005900855126414584\n",
      "Iteration:860, Price of Hedge: 0.14020123826715009, Loss: 0.0007243389383033705\n",
      "Iteration:870, Price of Hedge: 0.16184750397098924, Loss: 0.0006522567323369977\n",
      "Iteration:880, Price of Hedge: 0.1396503616478981, Loss: 0.0005601211164453001\n",
      "Iteration:890, Price of Hedge: 0.16339568544894975, Loss: 0.0008239866435046928\n",
      "Iteration:900, Price of Hedge: 0.1753249782645412, Loss: 0.0007695451092259997\n",
      "Iteration:910, Price of Hedge: 0.14586478843286274, Loss: 0.0005571620342200046\n",
      "Iteration:920, Price of Hedge: 0.1395767873242278, Loss: 0.0006501388062614133\n",
      "Iteration:930, Price of Hedge: 0.13077795112805007, Loss: 0.0007096940949708142\n",
      "Iteration:940, Price of Hedge: 0.1376265686178897, Loss: 0.000580851976052843\n",
      "Iteration:950, Price of Hedge: 0.15952839740151603, Loss: 0.000720003105764544\n",
      "Iteration:960, Price of Hedge: 0.15188945623610836, Loss: 0.0008427269589360353\n",
      "Iteration:970, Price of Hedge: 0.1310455112922739, Loss: 0.0006628324511781969\n",
      "Iteration:980, Price of Hedge: 0.1672144815329034, Loss: 0.000651686570112231\n",
      "Iteration:990, Price of Hedge: 0.14696352891028255, Loss: 0.000628881486327293\n",
      "tf.Tensor(0.14199612, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_34 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.13574011252673587, Loss: 0.0014443690942782083\n",
      "Iteration:20, Price of Hedge: 0.13252799659196626, Loss: 0.0020361135928039786\n",
      "Iteration:30, Price of Hedge: 0.18984470601351405, Loss: 0.0014999215139464006\n",
      "Iteration:40, Price of Hedge: 0.1600468441208591, Loss: 0.0011951470053456427\n",
      "Iteration:50, Price of Hedge: 0.13626563698629754, Loss: 0.0013988200531575678\n",
      "Iteration:60, Price of Hedge: 0.17075792024708109, Loss: 0.0013470051996888443\n",
      "Iteration:70, Price of Hedge: 0.17202723696176464, Loss: 0.0013869727636516948\n",
      "Iteration:80, Price of Hedge: 0.16785664031634726, Loss: 0.0014426680927425827\n",
      "Iteration:90, Price of Hedge: 0.1646139920714859, Loss: 0.0014903198837169286\n",
      "Iteration:100, Price of Hedge: 0.18175095483751422, Loss: 0.001301433675276531\n",
      "Iteration:110, Price of Hedge: 0.16479234752766844, Loss: 0.0012218020717884137\n",
      "Iteration:120, Price of Hedge: 0.1750607006609016, Loss: 0.0018616109296907268\n",
      "Iteration:130, Price of Hedge: 0.14773431910204524, Loss: 0.0012031274497249279\n",
      "Iteration:140, Price of Hedge: 0.15371087266111091, Loss: 0.0013026261328586309\n",
      "Iteration:150, Price of Hedge: 0.14249476784401624, Loss: 0.0012517600742985024\n",
      "Iteration:160, Price of Hedge: 0.1694559937661552, Loss: 0.0010963004079307392\n",
      "Iteration:170, Price of Hedge: 0.1651849777468101, Loss: 0.0013573659220534218\n",
      "Iteration:180, Price of Hedge: 0.17211873496555655, Loss: 0.0014751182276140362\n",
      "Iteration:190, Price of Hedge: 0.17314535803660647, Loss: 0.0013889470777017187\n",
      "Iteration:200, Price of Hedge: 0.18329744557194091, Loss: 0.0013287916256252252\n",
      "Iteration:210, Price of Hedge: 0.18138606000698018, Loss: 0.0012046962214014023\n",
      "Iteration:220, Price of Hedge: 0.17479388694196132, Loss: 0.0011986323371166562\n",
      "Iteration:230, Price of Hedge: 0.16673565936680462, Loss: 0.0010738348921103481\n",
      "Iteration:240, Price of Hedge: 0.16408745136714062, Loss: 0.0012973143146803423\n",
      "Iteration:250, Price of Hedge: 0.1479019635180748, Loss: 0.0010447314654646878\n",
      "Iteration:260, Price of Hedge: 0.17628440327343925, Loss: 0.0010800360649948716\n",
      "Iteration:270, Price of Hedge: 0.17549862122278911, Loss: 0.0012512113414611115\n",
      "Iteration:280, Price of Hedge: 0.1689775852926232, Loss: 0.0016048469610870698\n",
      "Iteration:290, Price of Hedge: 0.14068077989858238, Loss: 0.001175171724858881\n",
      "Iteration:300, Price of Hedge: 0.13623569823510592, Loss: 0.0014730667677694599\n",
      "Iteration:310, Price of Hedge: 0.14669223651964103, Loss: 0.0009464278395436843\n",
      "Iteration:320, Price of Hedge: 0.1386373634516019, Loss: 0.001275651663153532\n",
      "Iteration:330, Price of Hedge: 0.1571818971894686, Loss: 0.0016228344375488035\n",
      "Iteration:340, Price of Hedge: 0.1735573778464868, Loss: 0.0013880584255983486\n",
      "Iteration:350, Price of Hedge: 0.168103434912382, Loss: 0.0014772594801047312\n",
      "Iteration:360, Price of Hedge: 0.1905097437945642, Loss: 0.0012237099196074298\n",
      "Iteration:370, Price of Hedge: 0.1842358442064665, Loss: 0.0012966708709767794\n",
      "Iteration:380, Price of Hedge: 0.16020492864126937, Loss: 0.0013209795248923406\n",
      "Iteration:390, Price of Hedge: 0.16504023930833683, Loss: 0.001542762583105617\n",
      "Iteration:400, Price of Hedge: 0.17703401420444606, Loss: 0.0012462440797277098\n",
      "Iteration:410, Price of Hedge: 0.17676914304190633, Loss: 0.0014020222359740764\n",
      "Iteration:420, Price of Hedge: 0.18044453169825375, Loss: 0.0014717690602782164\n",
      "Iteration:430, Price of Hedge: 0.18521636753627035, Loss: 0.0014900582344100856\n",
      "Iteration:440, Price of Hedge: 0.18563743462271987, Loss: 0.001205649372447759\n",
      "Iteration:450, Price of Hedge: 0.15582271925462693, Loss: 0.0010743026148374302\n",
      "Iteration:460, Price of Hedge: 0.15555247008871903, Loss: 0.001229372898697534\n",
      "Iteration:470, Price of Hedge: 0.15378436604493118, Loss: 0.001236035541143643\n",
      "Iteration:480, Price of Hedge: 0.1732428276026667, Loss: 0.0011330767496817717\n",
      "Iteration:490, Price of Hedge: 0.18831357586395825, Loss: 0.0015006959228239581\n",
      "Iteration:500, Price of Hedge: 0.18931532342110133, Loss: 0.0009524237118711199\n",
      "Iteration:510, Price of Hedge: 0.18481260359109228, Loss: 0.0014963684512592224\n",
      "Iteration:520, Price of Hedge: 0.17390086858334827, Loss: 0.001029012904434179\n",
      "Iteration:530, Price of Hedge: 0.1694719658965596, Loss: 0.0009243571162730114\n",
      "Iteration:540, Price of Hedge: 0.14468812086650473, Loss: 0.0009083619404946397\n",
      "Iteration:550, Price of Hedge: 0.1496585741031595, Loss: 0.0008668359331174269\n",
      "Iteration:560, Price of Hedge: 0.1483153413187722, Loss: 0.0007183272574114774\n",
      "Iteration:570, Price of Hedge: 0.15713883718925672, Loss: 0.0009922506850007285\n",
      "Iteration:580, Price of Hedge: 0.17869466610067095, Loss: 0.0009200750328533403\n",
      "Iteration:590, Price of Hedge: 0.184342738768396, Loss: 0.0013800094071794611\n",
      "Iteration:600, Price of Hedge: 0.1673994920434211, Loss: 0.000840192670402784\n",
      "Iteration:610, Price of Hedge: 0.17457344276376716, Loss: 0.001178155117143298\n",
      "Iteration:620, Price of Hedge: 0.17113078315618396, Loss: 0.0011269153441193947\n",
      "Iteration:630, Price of Hedge: 0.16304821966612054, Loss: 0.0008735492332300866\n",
      "Iteration:640, Price of Hedge: 0.1667807878298504, Loss: 0.0009062081114126653\n",
      "Iteration:650, Price of Hedge: 0.16640479524654667, Loss: 0.0010326560408086217\n",
      "Iteration:660, Price of Hedge: 0.1749525290480051, Loss: 0.0008567106529728364\n",
      "Iteration:670, Price of Hedge: 0.1640664070061348, Loss: 0.0007510773334459042\n",
      "Iteration:680, Price of Hedge: 0.1576427327222291, Loss: 0.0008582800569918892\n",
      "Iteration:690, Price of Hedge: 0.15540528546811175, Loss: 0.0008432097173644238\n",
      "Iteration:700, Price of Hedge: 0.1680315783121955, Loss: 0.000795748964109011\n",
      "Iteration:710, Price of Hedge: 0.1647985349295368, Loss: 0.0008580123653004091\n",
      "Iteration:720, Price of Hedge: 0.16376579640315186, Loss: 0.0008907614576908252\n",
      "Iteration:730, Price of Hedge: 0.17464886071735464, Loss: 0.0008715015674409798\n",
      "Iteration:740, Price of Hedge: 0.1753857191253246, Loss: 0.0008355642740310642\n",
      "Iteration:750, Price of Hedge: 0.15179720279371622, Loss: 0.0008165087006942962\n",
      "Iteration:760, Price of Hedge: 0.16156836940821223, Loss: 0.0007675185917831229\n",
      "Iteration:770, Price of Hedge: 0.1263138665864517, Loss: 0.000889139780018633\n",
      "Iteration:780, Price of Hedge: 0.1388553524543454, Loss: 0.0007783365680920973\n",
      "Iteration:790, Price of Hedge: 0.1808698076569044, Loss: 0.0008696482416042705\n",
      "Iteration:800, Price of Hedge: 0.19142815927945095, Loss: 0.0008264545360672226\n",
      "Iteration:810, Price of Hedge: 0.15072493864057038, Loss: 0.000853708220150784\n",
      "Iteration:820, Price of Hedge: 0.1569158748823952, Loss: 0.0010264099716010388\n",
      "Iteration:830, Price of Hedge: 0.1598670137607428, Loss: 0.0007646949713901564\n",
      "Iteration:840, Price of Hedge: 0.1584279392006124, Loss: 0.0009225963934938798\n",
      "Iteration:850, Price of Hedge: 0.1713890712109219, Loss: 0.0008187867499627633\n",
      "Iteration:860, Price of Hedge: 0.1633812421823791, Loss: 0.0009177884820902094\n",
      "Iteration:870, Price of Hedge: 0.16119806060104339, Loss: 0.0009161807159547398\n",
      "Iteration:880, Price of Hedge: 0.17218830726330908, Loss: 0.000888786511298223\n",
      "Iteration:890, Price of Hedge: 0.1710890901401058, Loss: 0.0008056870708504249\n",
      "Iteration:900, Price of Hedge: 0.15292462295799397, Loss: 0.0008403768226136421\n",
      "Iteration:910, Price of Hedge: 0.15980141650895804, Loss: 0.0007481671523799971\n",
      "Iteration:920, Price of Hedge: 0.16000734547404818, Loss: 0.0007592839456873612\n",
      "Iteration:930, Price of Hedge: 0.16960181140262875, Loss: 0.0008523444679902515\n",
      "Iteration:940, Price of Hedge: 0.20220780045195852, Loss: 0.0009054007504607497\n",
      "Iteration:950, Price of Hedge: 0.17707252358642336, Loss: 0.0008508649268776036\n",
      "Iteration:960, Price of Hedge: 0.16789808151955868, Loss: 0.0009715218629414935\n",
      "Iteration:970, Price of Hedge: 0.1374317913654693, Loss: 0.000808273984338248\n",
      "Iteration:980, Price of Hedge: 0.17976524850359965, Loss: 0.0010021045496586556\n",
      "Iteration:990, Price of Hedge: 0.14500232037097477, Loss: 0.0009667479575164784\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 6 \n",
      "\n",
      "tf.Tensor(0.15481207, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_35 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.1716268734475193, Loss: 0.0036089022804489447\n",
      "Iteration:20, Price of Hedge: 0.16116586462545684, Loss: 0.0029266855363804466\n",
      "Iteration:30, Price of Hedge: 0.16807418570973595, Loss: 0.002805998532773657\n",
      "Iteration:40, Price of Hedge: 0.17551921110987223, Loss: 0.0024958050046295813\n",
      "Iteration:50, Price of Hedge: 0.16335100672280306, Loss: 0.0033143097618429707\n",
      "Iteration:60, Price of Hedge: 0.1736146826806703, Loss: 0.002506171321785189\n",
      "Iteration:70, Price of Hedge: 0.1779304732082437, Loss: 0.0028374007042522467\n",
      "Iteration:80, Price of Hedge: 0.15897433505579103, Loss: 0.002791167946817019\n",
      "Iteration:90, Price of Hedge: 0.16192324131608302, Loss: 0.002966299123334615\n",
      "Iteration:100, Price of Hedge: 0.1653410611437721, Loss: 0.002423710979518212\n",
      "Iteration:110, Price of Hedge: 0.18580544337326046, Loss: 0.00328992489008062\n",
      "Iteration:120, Price of Hedge: 0.15505935406513346, Loss: 0.002678730431153653\n",
      "Iteration:130, Price of Hedge: 0.17291481064547726, Loss: 0.0027563071635809066\n",
      "Iteration:140, Price of Hedge: 0.17598516590262533, Loss: 0.0029926052949921455\n",
      "Iteration:150, Price of Hedge: 0.1540497157292748, Loss: 0.0032382007230511434\n",
      "Iteration:160, Price of Hedge: 0.14026731702608117, Loss: 0.0026883260527815977\n",
      "Iteration:170, Price of Hedge: 0.1661898813754533, Loss: 0.0028231583379238145\n",
      "Iteration:180, Price of Hedge: 0.16444697166003835, Loss: 0.002646330489071325\n",
      "Iteration:190, Price of Hedge: 0.14895594151590785, Loss: 0.0033844615472018447\n",
      "Iteration:200, Price of Hedge: 0.16922184218045686, Loss: 0.003007469330331247\n",
      "Iteration:210, Price of Hedge: 0.18291722680228303, Loss: 0.002459177114993061\n",
      "Iteration:220, Price of Hedge: 0.1806794881345013, Loss: 0.0028982530173937704\n",
      "Iteration:230, Price of Hedge: 0.16316610071211243, Loss: 0.0028915348584963143\n",
      "Iteration:240, Price of Hedge: 0.15658162621489283, Loss: 0.002587865319663685\n",
      "Iteration:250, Price of Hedge: 0.16473016120257852, Loss: 0.002878086847014849\n",
      "Iteration:260, Price of Hedge: 0.16190333050318487, Loss: 0.0027782999965777935\n",
      "Iteration:270, Price of Hedge: 0.17920283332792905, Loss: 0.002924698153558936\n",
      "Iteration:280, Price of Hedge: 0.1737156117051427, Loss: 0.0029008968783394095\n",
      "Iteration:290, Price of Hedge: 0.1556213646064748, Loss: 0.003374048999192425\n",
      "Iteration:300, Price of Hedge: 0.17456665972008523, Loss: 0.002712811544637539\n",
      "Iteration:310, Price of Hedge: 0.15360612579191865, Loss: 0.002171128437771053\n",
      "Iteration:320, Price of Hedge: 0.16005179894922322, Loss: 0.0027381248407229108\n",
      "Iteration:330, Price of Hedge: 0.18160467956111007, Loss: 0.002725071967068438\n",
      "Iteration:340, Price of Hedge: 0.1807947237046051, Loss: 0.00333854751071172\n",
      "Iteration:350, Price of Hedge: 0.17631959446017617, Loss: 0.0020761582984087923\n",
      "Iteration:360, Price of Hedge: 0.13992249794816303, Loss: 0.0025530725229772956\n",
      "Iteration:370, Price of Hedge: 0.17535841041025152, Loss: 0.003374056069793596\n",
      "Iteration:380, Price of Hedge: 0.16967087974406922, Loss: 0.003168132153229131\n",
      "Iteration:390, Price of Hedge: 0.15741601806904557, Loss: 0.0026561822840186267\n",
      "Iteration:400, Price of Hedge: 0.16074025359520192, Loss: 0.003430819399888563\n",
      "Iteration:410, Price of Hedge: 0.17557734232934763, Loss: 0.002116994555473184\n",
      "Iteration:420, Price of Hedge: 0.17568424111677813, Loss: 0.0019340997228964873\n",
      "Iteration:430, Price of Hedge: 0.165090383313202, Loss: 0.0016714392629376463\n",
      "Iteration:440, Price of Hedge: 0.1673457005832802, Loss: 0.0022506819471180607\n",
      "Iteration:450, Price of Hedge: 0.1676134522840016, Loss: 0.0017766355311899852\n",
      "Iteration:460, Price of Hedge: 0.15578742148222774, Loss: 0.002472725746568116\n",
      "Iteration:470, Price of Hedge: 0.16525901606335083, Loss: 0.0016257109657013657\n",
      "Iteration:480, Price of Hedge: 0.15308724374215218, Loss: 0.0016462271308382626\n",
      "Iteration:490, Price of Hedge: 0.16396611856672508, Loss: 0.0019873505958865503\n",
      "Iteration:500, Price of Hedge: 0.18063733429810327, Loss: 0.0018086788158324651\n",
      "Iteration:510, Price of Hedge: 0.16815093980491155, Loss: 0.0021156166040833925\n",
      "Iteration:520, Price of Hedge: 0.18474211197989235, Loss: 0.001763480949657126\n",
      "Iteration:530, Price of Hedge: 0.1745233745874998, Loss: 0.0017011197430310432\n",
      "Iteration:540, Price of Hedge: 0.16909739959984335, Loss: 0.001714708350697336\n",
      "Iteration:550, Price of Hedge: 0.15027607714381475, Loss: 0.0019170118475159371\n",
      "Iteration:560, Price of Hedge: 0.14849440748056394, Loss: 0.0020341073936470445\n",
      "Iteration:570, Price of Hedge: 0.1742580073110503, Loss: 0.001955456065814865\n",
      "Iteration:580, Price of Hedge: 0.16816291413994122, Loss: 0.001963094490649375\n",
      "Iteration:590, Price of Hedge: 0.17928475657645324, Loss: 0.0018353918190035401\n",
      "Iteration:600, Price of Hedge: 0.1876890167161605, Loss: 0.001746575278229834\n",
      "Iteration:610, Price of Hedge: 0.17864339866098364, Loss: 0.0029938478171748885\n",
      "Iteration:620, Price of Hedge: 0.16448552275319345, Loss: 0.0027001744767211735\n",
      "Iteration:630, Price of Hedge: 0.16151120584007686, Loss: 0.002262447835386272\n",
      "Iteration:640, Price of Hedge: 0.16174028461574608, Loss: 0.0019690079607443066\n",
      "Iteration:650, Price of Hedge: 0.17615144903761576, Loss: 0.0019041617097527387\n",
      "Iteration:660, Price of Hedge: 0.1713034967834915, Loss: 0.0018782184502976309\n",
      "Iteration:670, Price of Hedge: 0.16965596403895233, Loss: 0.0016815026320276872\n",
      "Iteration:680, Price of Hedge: 0.1650039696890417, Loss: 0.0015117323309288722\n",
      "Iteration:690, Price of Hedge: 0.16306346604108057, Loss: 0.0015904579000733498\n",
      "Iteration:700, Price of Hedge: 0.177952176690485, Loss: 0.0023643848284448767\n",
      "Iteration:710, Price of Hedge: 0.1824665358057814, Loss: 0.001970086227422918\n",
      "Iteration:720, Price of Hedge: 0.1684416829250722, Loss: 0.001995761211952818\n",
      "Iteration:730, Price of Hedge: 0.16412021851200506, Loss: 0.0018039944065834314\n",
      "Iteration:740, Price of Hedge: 0.15383174106079878, Loss: 0.0017397525560189032\n",
      "Iteration:750, Price of Hedge: 0.1663802176078434, Loss: 0.0019954928010545102\n",
      "Iteration:760, Price of Hedge: 0.17202749153431116, Loss: 0.0020078135955415633\n",
      "Iteration:770, Price of Hedge: 0.16679051262817665, Loss: 0.0019532320898003165\n",
      "Iteration:780, Price of Hedge: 0.17196436520705446, Loss: 0.0020463179139504463\n",
      "Iteration:790, Price of Hedge: 0.17605349619234403, Loss: 0.002099864528431805\n",
      "Iteration:800, Price of Hedge: 0.15666193083964117, Loss: 0.0016026123994597797\n",
      "Iteration:810, Price of Hedge: 0.15592251565155948, Loss: 0.0017287557316011616\n",
      "Iteration:820, Price of Hedge: 0.16520161583525805, Loss: 0.0018759767977801546\n",
      "Iteration:830, Price of Hedge: 0.1678501542555182, Loss: 0.0017922506819304297\n",
      "Iteration:840, Price of Hedge: 0.1768211763805539, Loss: 0.0019649211532673408\n",
      "Iteration:850, Price of Hedge: 0.17600300557327272, Loss: 0.0019508574555915815\n",
      "Iteration:860, Price of Hedge: 0.17220026656896154, Loss: 0.0019784391908950205\n",
      "Iteration:870, Price of Hedge: 0.16753027590739294, Loss: 0.0021135683053133294\n",
      "Iteration:880, Price of Hedge: 0.15932771717561992, Loss: 0.0018774153931722993\n",
      "Iteration:890, Price of Hedge: 0.15016954385207557, Loss: 0.0017194124760457896\n",
      "Iteration:900, Price of Hedge: 0.14495515606057552, Loss: 0.00201606961019376\n",
      "Iteration:910, Price of Hedge: 0.14313453499936488, Loss: 0.00142796623898791\n",
      "Iteration:920, Price of Hedge: 0.16956255378298693, Loss: 0.0014836812164861436\n",
      "Iteration:930, Price of Hedge: 0.1655609329089316, Loss: 0.0016274084538748569\n",
      "Iteration:940, Price of Hedge: 0.1657060346983826, Loss: 0.0019378007746903238\n",
      "Iteration:950, Price of Hedge: 0.155056812999851, Loss: 0.0019277885314856746\n",
      "Iteration:960, Price of Hedge: 0.16847668348865455, Loss: 0.001810918156807251\n",
      "Iteration:970, Price of Hedge: 0.15648938206422827, Loss: 0.0016474816186537566\n",
      "Iteration:980, Price of Hedge: 0.17447535541548406, Loss: 0.0018342202747787086\n",
      "Iteration:990, Price of Hedge: 0.1797117773758032, Loss: 0.0017266666409012643\n",
      "tf.Tensor(0.10383725, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_36 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.13151384315788164, Loss: 0.0015661857500104404\n",
      "Iteration:20, Price of Hedge: 0.07034903990256396, Loss: 0.0012880476081146952\n",
      "Iteration:30, Price of Hedge: 0.1315325530563655, Loss: 0.0013243567768061128\n",
      "Iteration:40, Price of Hedge: 0.10348801644829564, Loss: 0.0011702004026898471\n",
      "Iteration:50, Price of Hedge: 0.1098206209028092, Loss: 0.0012505358933317724\n",
      "Iteration:60, Price of Hedge: 0.11071433618857328, Loss: 0.0010703168073925352\n",
      "Iteration:70, Price of Hedge: 0.11447619188912768, Loss: 0.0010873373760888593\n",
      "Iteration:80, Price of Hedge: 0.11406534862525747, Loss: 0.0011499860978337218\n",
      "Iteration:90, Price of Hedge: 0.10834313067751396, Loss: 0.0011069459887735002\n",
      "Iteration:100, Price of Hedge: 0.10844170138454956, Loss: 0.0010462491608711933\n",
      "Iteration:110, Price of Hedge: 0.11629724806425656, Loss: 0.0013230522508900222\n",
      "Iteration:120, Price of Hedge: 0.11429532373559824, Loss: 0.0010914271069874637\n",
      "Iteration:130, Price of Hedge: 0.11097421232737475, Loss: 0.0011918622771626807\n",
      "Iteration:140, Price of Hedge: 0.10878660748525136, Loss: 0.0014732947753118176\n",
      "Iteration:150, Price of Hedge: 0.10726876479517955, Loss: 0.0012478829221884702\n",
      "Iteration:160, Price of Hedge: 0.11444499422119066, Loss: 0.0012695785179899666\n",
      "Iteration:170, Price of Hedge: 0.100297752497562, Loss: 0.0013896468439942744\n",
      "Iteration:180, Price of Hedge: 0.11349615000198697, Loss: 0.0011281042868725333\n",
      "Iteration:190, Price of Hedge: 0.10470830213424734, Loss: 0.001089227606130816\n",
      "Iteration:200, Price of Hedge: 0.11230292840174912, Loss: 0.0010359990327290624\n",
      "Iteration:210, Price of Hedge: 0.12350068951471371, Loss: 0.0012645725323607415\n",
      "Iteration:220, Price of Hedge: 0.09672907867442292, Loss: 0.0011530340708309163\n",
      "Iteration:230, Price of Hedge: 0.11449021125957302, Loss: 0.0010980645658503986\n",
      "Iteration:240, Price of Hedge: 0.10974397123497398, Loss: 0.0012746251595759262\n",
      "Iteration:250, Price of Hedge: 0.10887475286280619, Loss: 0.0012527684356515856\n",
      "Iteration:260, Price of Hedge: 0.11114352385523603, Loss: 0.001250429834314204\n",
      "Iteration:270, Price of Hedge: 0.11703517516273793, Loss: 0.001424438824842067\n",
      "Iteration:280, Price of Hedge: 0.10777942319189152, Loss: 0.0011599005763798687\n",
      "Iteration:290, Price of Hedge: 0.10303620285788498, Loss: 0.0010764393361278658\n",
      "Iteration:300, Price of Hedge: 0.11468978060930796, Loss: 0.001098462491125929\n",
      "Iteration:310, Price of Hedge: 0.10972379935372488, Loss: 0.001007546661669867\n",
      "Iteration:320, Price of Hedge: 0.11592834107982526, Loss: 0.0011821215722376266\n",
      "Iteration:330, Price of Hedge: 0.10301107938024644, Loss: 0.0011558351166795157\n",
      "Iteration:340, Price of Hedge: 0.11412113893185279, Loss: 0.0012942475735301608\n",
      "Iteration:350, Price of Hedge: 0.10930441045250064, Loss: 0.0013090863178727653\n",
      "Iteration:360, Price of Hedge: 0.11390862929418973, Loss: 0.0013423452020242977\n",
      "Iteration:370, Price of Hedge: 0.1059046652569748, Loss: 0.001013580875877107\n",
      "Iteration:380, Price of Hedge: 0.11319984612595135, Loss: 0.001113938677358739\n",
      "Iteration:390, Price of Hedge: 0.11892740727261071, Loss: 0.001232832059810729\n",
      "Iteration:400, Price of Hedge: 0.10846072456505454, Loss: 0.0010590711522028063\n",
      "Iteration:410, Price of Hedge: 0.09587682974506606, Loss: 0.0009783529652724887\n",
      "Iteration:420, Price of Hedge: 0.11225357778114359, Loss: 0.001088177757829989\n",
      "Iteration:430, Price of Hedge: 0.1130045844040069, Loss: 0.0012509008451306869\n",
      "Iteration:440, Price of Hedge: 0.12059965448770527, Loss: 0.0010450601441030828\n",
      "Iteration:450, Price of Hedge: 0.10442855869393952, Loss: 0.0011543993767224592\n",
      "Iteration:460, Price of Hedge: 0.106714960502336, Loss: 0.0012366092565402555\n",
      "Iteration:470, Price of Hedge: 0.10694575362684304, Loss: 0.0011521850547979717\n",
      "Iteration:480, Price of Hedge: 0.11303759214584375, Loss: 0.0010547920107766729\n",
      "Iteration:490, Price of Hedge: 0.11519607916455926, Loss: 0.0010522553646199473\n",
      "Iteration:500, Price of Hedge: 0.1030071807595391, Loss: 0.0011695078916943659\n",
      "Iteration:510, Price of Hedge: 0.11034313180265372, Loss: 0.0008696385290450693\n",
      "Iteration:520, Price of Hedge: 0.1127400960576722, Loss: 0.000783381613881895\n",
      "Iteration:530, Price of Hedge: 0.10483679127430037, Loss: 0.000823126890782877\n",
      "Iteration:540, Price of Hedge: 0.09503429255836408, Loss: 0.0007716447558704153\n",
      "Iteration:550, Price of Hedge: 0.10739670569169561, Loss: 0.0009122464476087\n",
      "Iteration:560, Price of Hedge: 0.11720223280050278, Loss: 0.0007875980717091835\n",
      "Iteration:570, Price of Hedge: 0.11786723480628894, Loss: 0.0008133035142133593\n",
      "Iteration:580, Price of Hedge: 0.10136898555968514, Loss: 0.0007807786128526395\n",
      "Iteration:590, Price of Hedge: 0.11226847608170375, Loss: 0.0007417352970775504\n",
      "Iteration:600, Price of Hedge: 0.119845689090198, Loss: 0.000712645552114699\n",
      "Iteration:610, Price of Hedge: 0.10764538199824188, Loss: 0.0006828538460259548\n",
      "Iteration:620, Price of Hedge: 0.1067130198942607, Loss: 0.0006956515661593166\n",
      "Iteration:630, Price of Hedge: 0.1125407877762882, Loss: 0.0008067675592691615\n",
      "Iteration:640, Price of Hedge: 0.10491860139320579, Loss: 0.000847080047954485\n",
      "Iteration:650, Price of Hedge: 0.11026475908370231, Loss: 0.0008229830312436626\n",
      "Iteration:660, Price of Hedge: 0.11586930482339995, Loss: 0.0007551242962338556\n",
      "Iteration:670, Price of Hedge: 0.1100915228282986, Loss: 0.0014089028104455005\n",
      "Iteration:680, Price of Hedge: 0.11720137127494468, Loss: 0.0009193595403734989\n",
      "Iteration:690, Price of Hedge: 0.12062801521289544, Loss: 0.0009272894235466734\n",
      "Iteration:700, Price of Hedge: 0.10488272189950863, Loss: 0.000773701552959194\n",
      "Iteration:710, Price of Hedge: 0.11331219253963809, Loss: 0.0008241196303819365\n",
      "Iteration:720, Price of Hedge: 0.1146703832308333, Loss: 0.0006557372067091727\n",
      "Iteration:730, Price of Hedge: 0.11577617304034221, Loss: 0.0008785787603336815\n",
      "Iteration:740, Price of Hedge: 0.12156601639325687, Loss: 0.0006788739813917033\n",
      "Iteration:750, Price of Hedge: 0.10550760640203408, Loss: 0.0007029684826001858\n",
      "Iteration:760, Price of Hedge: 0.10436955724662766, Loss: 0.0006602746290377048\n",
      "Iteration:770, Price of Hedge: 0.10749193472383922, Loss: 0.0006004986109648503\n",
      "Iteration:780, Price of Hedge: 0.10049495482758175, Loss: 0.0006592708076310405\n",
      "Iteration:790, Price of Hedge: 0.09931591794107818, Loss: 0.0007147761825964772\n",
      "Iteration:800, Price of Hedge: 0.10424490581133342, Loss: 0.0009034489880745067\n",
      "Iteration:810, Price of Hedge: 0.11069077912104036, Loss: 0.0006825065027434186\n",
      "Iteration:820, Price of Hedge: 0.11029760148225023, Loss: 0.000773796870101906\n",
      "Iteration:830, Price of Hedge: 0.11689537306081094, Loss: 0.0007923646087102832\n",
      "Iteration:840, Price of Hedge: 0.10812645264851427, Loss: 0.0006517714832772637\n",
      "Iteration:850, Price of Hedge: 0.11562969629090958, Loss: 0.0008534593618881204\n",
      "Iteration:860, Price of Hedge: 0.11790797017131355, Loss: 0.0008706383392452999\n",
      "Iteration:870, Price of Hedge: 0.11054728725308678, Loss: 0.0006631380865389502\n",
      "Iteration:880, Price of Hedge: 0.1119534362003492, Loss: 0.0007633702488766936\n",
      "Iteration:890, Price of Hedge: 0.11020236374782827, Loss: 0.0007065188082132856\n",
      "Iteration:900, Price of Hedge: 0.10569769897062997, Loss: 0.0007084713139347887\n",
      "Iteration:910, Price of Hedge: 0.11267447217652489, Loss: 0.0006323472501154726\n",
      "Iteration:920, Price of Hedge: 0.11717365451835349, Loss: 0.0008034099755245272\n",
      "Iteration:930, Price of Hedge: 0.1141003752956749, Loss: 0.000902231756888261\n",
      "Iteration:940, Price of Hedge: 0.11534069362642185, Loss: 0.0007244793589460841\n",
      "Iteration:950, Price of Hedge: 0.11731371768863141, Loss: 0.0008051626687763935\n",
      "Iteration:960, Price of Hedge: 0.1097638907501505, Loss: 0.0007484454335621394\n",
      "Iteration:970, Price of Hedge: 0.10735330742949145, Loss: 0.0008794262126759823\n",
      "Iteration:980, Price of Hedge: 0.09848995859466073, Loss: 0.0007017946268326636\n",
      "Iteration:990, Price of Hedge: 0.0838616375184813, Loss: 0.0006875249978977926\n",
      "tf.Tensor(0.19124603, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_37 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.18363079622362194, Loss: 0.0033600443138418258\n",
      "Iteration:20, Price of Hedge: 0.14532993708290293, Loss: 0.002633456827961922\n",
      "Iteration:30, Price of Hedge: 0.158077756720445, Loss: 0.002726037919966906\n",
      "Iteration:40, Price of Hedge: 0.16975588359913446, Loss: 0.0030300454879247595\n",
      "Iteration:50, Price of Hedge: 0.16024907959974827, Loss: 0.0026930861990470236\n",
      "Iteration:60, Price of Hedge: 0.16272874160606535, Loss: 0.003033963960704611\n",
      "Iteration:70, Price of Hedge: 0.1625242380644977, Loss: 0.0025911972044925236\n",
      "Iteration:80, Price of Hedge: 0.17070206492115858, Loss: 0.003102048954951897\n",
      "Iteration:90, Price of Hedge: 0.1678998094558665, Loss: 0.0027482608194480565\n",
      "Iteration:100, Price of Hedge: 0.14912229426912518, Loss: 0.0025956584818853656\n",
      "Iteration:110, Price of Hedge: 0.15219099609338402, Loss: 0.003305484835742689\n",
      "Iteration:120, Price of Hedge: 0.17141740960728385, Loss: 0.002722176555888822\n",
      "Iteration:130, Price of Hedge: 0.1619630977509928, Loss: 0.0030105890971249493\n",
      "Iteration:140, Price of Hedge: 0.15696708493277356, Loss: 0.0025491535063050462\n",
      "Iteration:150, Price of Hedge: 0.16165406244170982, Loss: 0.0023045689022673345\n",
      "Iteration:160, Price of Hedge: 0.15954551779852863, Loss: 0.0028460798671899215\n",
      "Iteration:170, Price of Hedge: 0.16484611035950822, Loss: 0.0026500498972335863\n",
      "Iteration:180, Price of Hedge: 0.14399902803438067, Loss: 0.0021720854164449578\n",
      "Iteration:190, Price of Hedge: 0.15207523838657835, Loss: 0.002852156505004189\n",
      "Iteration:200, Price of Hedge: 0.15194792405410454, Loss: 0.002458778169919285\n",
      "Iteration:210, Price of Hedge: 0.165669380701911, Loss: 0.002438660677909965\n",
      "Iteration:220, Price of Hedge: 0.15755184322975993, Loss: 0.002869802549957967\n",
      "Iteration:230, Price of Hedge: 0.16266389222769248, Loss: 0.002868423782729579\n",
      "Iteration:240, Price of Hedge: 0.16426972365430856, Loss: 0.002999127652626399\n",
      "Iteration:250, Price of Hedge: 0.17045961944592136, Loss: 0.002790822303198226\n",
      "Iteration:260, Price of Hedge: 0.15840626772870792, Loss: 0.002432680852942504\n",
      "Iteration:270, Price of Hedge: 0.15866382035918605, Loss: 0.0028496323003860623\n",
      "Iteration:280, Price of Hedge: 0.15452249310826574, Loss: 0.0025732425006030012\n",
      "Iteration:290, Price of Hedge: 0.16798893819087654, Loss: 0.002808647288750876\n",
      "Iteration:300, Price of Hedge: 0.17584131724125882, Loss: 0.002649244392592465\n",
      "Iteration:310, Price of Hedge: 0.16661580568772935, Loss: 0.002750954446548093\n",
      "Iteration:320, Price of Hedge: 0.1559098103251472, Loss: 0.0021235261592781997\n",
      "Iteration:330, Price of Hedge: 0.1445332347963472, Loss: 0.0037157363446841175\n",
      "Iteration:340, Price of Hedge: 0.15375065323099762, Loss: 0.002104343074408277\n",
      "Iteration:350, Price of Hedge: 0.14553798245176494, Loss: 0.00201255130624558\n",
      "Iteration:360, Price of Hedge: 0.14016178449635391, Loss: 0.002237966014804016\n",
      "Iteration:370, Price of Hedge: 0.14728313735499796, Loss: 0.0028887552963974272\n",
      "Iteration:380, Price of Hedge: 0.14719407823821484, Loss: 0.0018268669855337372\n",
      "Iteration:390, Price of Hedge: 0.1473268401969449, Loss: 0.00193304756305297\n",
      "Iteration:400, Price of Hedge: 0.1728827340474254, Loss: 0.0025104327187218446\n",
      "Iteration:410, Price of Hedge: 0.16671334082363956, Loss: 0.0018494169003190565\n",
      "Iteration:420, Price of Hedge: 0.16127948157178482, Loss: 0.0015949059880755456\n",
      "Iteration:430, Price of Hedge: 0.16368056200446973, Loss: 0.0018293692984828525\n",
      "Iteration:440, Price of Hedge: 0.16370882700459788, Loss: 0.001874909408949499\n",
      "Iteration:450, Price of Hedge: 0.17779758941761656, Loss: 0.0021064131288742517\n",
      "Iteration:460, Price of Hedge: 0.1664021647538789, Loss: 0.0017434862413566066\n",
      "Iteration:470, Price of Hedge: 0.15873561415569384, Loss: 0.0015354052475425207\n",
      "Iteration:480, Price of Hedge: 0.15626200893511852, Loss: 0.0015660534481846788\n",
      "Iteration:490, Price of Hedge: 0.16169882696161722, Loss: 0.0017831542175505534\n",
      "Iteration:500, Price of Hedge: 0.15435915134336256, Loss: 0.0017478992482991452\n",
      "Iteration:510, Price of Hedge: 0.16577218941851016, Loss: 0.0016103927802101126\n",
      "Iteration:520, Price of Hedge: 0.1571737988530458, Loss: 0.001812002134356039\n",
      "Iteration:530, Price of Hedge: 0.178781538627743, Loss: 0.0016502619965912402\n",
      "Iteration:540, Price of Hedge: 0.1809161901060179, Loss: 0.0016827826827858772\n",
      "Iteration:550, Price of Hedge: 0.15521094775424446, Loss: 0.0014005431842915252\n",
      "Iteration:560, Price of Hedge: 0.1489587784586547, Loss: 0.001677769354609282\n",
      "Iteration:570, Price of Hedge: 0.15701750593361793, Loss: 0.0016023964741778585\n",
      "Iteration:580, Price of Hedge: 0.16907446039407434, Loss: 0.0021017582257877978\n",
      "Iteration:590, Price of Hedge: 0.15883732638521905, Loss: 0.0016232811264142554\n",
      "Iteration:600, Price of Hedge: 0.15731609850886344, Loss: 0.0018201342775146401\n",
      "Iteration:610, Price of Hedge: 0.15750953275235133, Loss: 0.002018238245156834\n",
      "Iteration:620, Price of Hedge: 0.15687917451673458, Loss: 0.0017278096307752123\n",
      "Iteration:630, Price of Hedge: 0.16411859988822927, Loss: 0.0017238578445859965\n",
      "Iteration:640, Price of Hedge: 0.16818461762218248, Loss: 0.0018896749997646012\n",
      "Iteration:650, Price of Hedge: 0.17989525621284203, Loss: 0.0015355519625168234\n",
      "Iteration:660, Price of Hedge: 0.19043540355435198, Loss: 0.0018463569616891107\n",
      "Iteration:670, Price of Hedge: 0.15906019173413596, Loss: 0.0017160071657432497\n",
      "Iteration:680, Price of Hedge: 0.15582423211970992, Loss: 0.0022005342522035676\n",
      "Iteration:690, Price of Hedge: 0.15255132263134782, Loss: 0.0016239363807804886\n",
      "Iteration:700, Price of Hedge: 0.1570024858011607, Loss: 0.0014091086737180625\n",
      "Iteration:710, Price of Hedge: 0.1546180267201521, Loss: 0.0013550474010552982\n",
      "Iteration:720, Price of Hedge: 0.1465577676441967, Loss: 0.0019467710560339135\n",
      "Iteration:730, Price of Hedge: 0.1559136393276276, Loss: 0.0017201392522623316\n",
      "Iteration:740, Price of Hedge: 0.16682815868438183, Loss: 0.0018563515283908317\n",
      "Iteration:750, Price of Hedge: 0.16307013198630785, Loss: 0.0016812290541516008\n",
      "Iteration:760, Price of Hedge: 0.17015134993713446, Loss: 0.001728690736459626\n",
      "Iteration:770, Price of Hedge: 0.17077224009389055, Loss: 0.001505089093209211\n",
      "Iteration:780, Price of Hedge: 0.16001182068241634, Loss: 0.0019153902323319372\n",
      "Iteration:790, Price of Hedge: 0.1612271286651435, Loss: 0.001826594087523148\n",
      "Iteration:800, Price of Hedge: 0.15572549606938538, Loss: 0.0017977046989223313\n",
      "Iteration:810, Price of Hedge: 0.1539668178255738, Loss: 0.0015213826137427944\n",
      "Iteration:820, Price of Hedge: 0.16942077626387117, Loss: 0.001728171591165939\n",
      "Iteration:830, Price of Hedge: 0.1529863843359067, Loss: 0.0015873152897989407\n",
      "Iteration:840, Price of Hedge: 0.1725630645539809, Loss: 0.0020160520696639317\n",
      "Iteration:850, Price of Hedge: 0.15960686886099892, Loss: 0.0016517141892933296\n",
      "Iteration:860, Price of Hedge: 0.16001594556236115, Loss: 0.001723612277168396\n",
      "Iteration:870, Price of Hedge: 0.15564162351050756, Loss: 0.001718501592252597\n",
      "Iteration:880, Price of Hedge: 0.15066722715174594, Loss: 0.0019354601337564503\n",
      "Iteration:890, Price of Hedge: 0.16053919615586665, Loss: 0.0018364326930798037\n",
      "Iteration:900, Price of Hedge: 0.15164235225161066, Loss: 0.0013706463709969086\n",
      "Iteration:910, Price of Hedge: 0.14493775150384636, Loss: 0.0014711457204750645\n",
      "Iteration:920, Price of Hedge: 0.13610187576181262, Loss: 0.0014690059118090738\n",
      "Iteration:930, Price of Hedge: 0.1659381940805929, Loss: 0.0017152107712997912\n",
      "Iteration:940, Price of Hedge: 0.18219363235626815, Loss: 0.00226425668552821\n",
      "Iteration:950, Price of Hedge: 0.18557732184821135, Loss: 0.002071735637376193\n",
      "Iteration:960, Price of Hedge: 0.16953220023605128, Loss: 0.0020956258390027573\n",
      "Iteration:970, Price of Hedge: 0.1768430365038057, Loss: 0.0020467210741903054\n",
      "Iteration:980, Price of Hedge: 0.17770048939562458, Loss: 0.0018513108696212477\n",
      "Iteration:990, Price of Hedge: 0.1746397066446775, Loss: 0.0017177019344547517\n",
      "tf.Tensor(0.12445977, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_38 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.11892407429999707, Loss: 0.0018619621863932958\n",
      "Iteration:20, Price of Hedge: 0.1343896415776328, Loss: 0.0016093899786016942\n",
      "Iteration:30, Price of Hedge: 0.10393015310516489, Loss: 0.002057430451475817\n",
      "Iteration:40, Price of Hedge: 0.11424954104912217, Loss: 0.0012364619976735548\n",
      "Iteration:50, Price of Hedge: 0.12242054531954523, Loss: 0.0012422734879439013\n",
      "Iteration:60, Price of Hedge: 0.1166482109507001, Loss: 0.0014048331355790645\n",
      "Iteration:70, Price of Hedge: 0.11397882187147844, Loss: 0.0014480950167644836\n",
      "Iteration:80, Price of Hedge: 0.10431499396128174, Loss: 0.0012975170467063536\n",
      "Iteration:90, Price of Hedge: 0.10822254320621597, Loss: 0.0012651631995047375\n",
      "Iteration:100, Price of Hedge: 0.10805848785448689, Loss: 0.0015166518376668492\n",
      "Iteration:110, Price of Hedge: 0.10808581300855168, Loss: 0.0015919744080514775\n",
      "Iteration:120, Price of Hedge: 0.11857670545451811, Loss: 0.001389683556731125\n",
      "Iteration:130, Price of Hedge: 0.12297050320535163, Loss: 0.0013781371290454204\n",
      "Iteration:140, Price of Hedge: 0.12044990568160757, Loss: 0.0014707486790246805\n",
      "Iteration:150, Price of Hedge: 0.12073227720998148, Loss: 0.001654019885140645\n",
      "Iteration:160, Price of Hedge: 0.12438712099348664, Loss: 0.0013985600166360969\n",
      "Iteration:170, Price of Hedge: 0.1309386399625396, Loss: 0.001204153293540955\n",
      "Iteration:180, Price of Hedge: 0.12257274816814175, Loss: 0.0012644235058437482\n",
      "Iteration:190, Price of Hedge: 0.1236221646184049, Loss: 0.0013438392744410167\n",
      "Iteration:200, Price of Hedge: 0.11053258910492901, Loss: 0.0014372241034368294\n",
      "Iteration:210, Price of Hedge: 0.10006629799989923, Loss: 0.001152286490730159\n",
      "Iteration:220, Price of Hedge: 0.11016501356908748, Loss: 0.0012348923242135434\n",
      "Iteration:230, Price of Hedge: 0.112209787916413, Loss: 0.0012497611186111258\n",
      "Iteration:240, Price of Hedge: 0.11227803118334806, Loss: 0.001124231976959944\n",
      "Iteration:250, Price of Hedge: 0.12663216087281626, Loss: 0.0014782050358790322\n",
      "Iteration:260, Price of Hedge: 0.12576189822724473, Loss: 0.001248265550490313\n",
      "Iteration:270, Price of Hedge: 0.12313441932062688, Loss: 0.001302078672246587\n",
      "Iteration:280, Price of Hedge: 0.1074681339925121, Loss: 0.0011852441944664172\n",
      "Iteration:290, Price of Hedge: 0.11429360938676042, Loss: 0.0012132092379371962\n",
      "Iteration:300, Price of Hedge: 0.10602774157988507, Loss: 0.0010299490456422867\n",
      "Iteration:310, Price of Hedge: 0.10985149658644673, Loss: 0.0011133098017737987\n",
      "Iteration:320, Price of Hedge: 0.112012794441074, Loss: 0.0011116658870014896\n",
      "Iteration:330, Price of Hedge: 0.11062056913919492, Loss: 0.001016604373716401\n",
      "Iteration:340, Price of Hedge: 0.10838522359796343, Loss: 0.0012284552217126433\n",
      "Iteration:350, Price of Hedge: 0.11696774120769078, Loss: 0.0019686416492143977\n",
      "Iteration:360, Price of Hedge: 0.11918095685504114, Loss: 0.0008481552552383587\n",
      "Iteration:370, Price of Hedge: 0.1195511778835055, Loss: 0.0010040825430018164\n",
      "Iteration:380, Price of Hedge: 0.11571195892828996, Loss: 0.0011294901926886425\n",
      "Iteration:390, Price of Hedge: 0.12004597202675882, Loss: 0.0011100924062946939\n",
      "Iteration:400, Price of Hedge: 0.11919692553584015, Loss: 0.0008493452918047151\n",
      "Iteration:410, Price of Hedge: 0.13072592147019577, Loss: 0.0010259277771992538\n",
      "Iteration:420, Price of Hedge: 0.12441177454809349, Loss: 0.0009178398370275342\n",
      "Iteration:430, Price of Hedge: 0.12002138809037888, Loss: 0.0008251897386745811\n",
      "Iteration:440, Price of Hedge: 0.11405621123297466, Loss: 0.0009792299237773693\n",
      "Iteration:450, Price of Hedge: 0.11625244873523571, Loss: 0.000917265486655472\n",
      "Iteration:460, Price of Hedge: 0.1258194725009048, Loss: 0.0008827890313849451\n",
      "Iteration:470, Price of Hedge: 0.12391736330508821, Loss: 0.0011246995884489409\n",
      "Iteration:480, Price of Hedge: 0.11136753790489706, Loss: 0.0008422157462948832\n",
      "Iteration:490, Price of Hedge: 0.12007576862787915, Loss: 0.000920056538481262\n",
      "Iteration:500, Price of Hedge: 0.12043244020892985, Loss: 0.0009443214139833512\n",
      "Iteration:510, Price of Hedge: 0.12550265735476387, Loss: 0.000873916106780559\n",
      "Iteration:520, Price of Hedge: 0.13312231137484218, Loss: 0.0010479837017142834\n",
      "Iteration:530, Price of Hedge: 0.1273252277263282, Loss: 0.000855371687558737\n",
      "Iteration:540, Price of Hedge: 0.11812418697955991, Loss: 0.000925067691088266\n",
      "Iteration:550, Price of Hedge: 0.13017960113674576, Loss: 0.0009530471477075864\n",
      "Iteration:560, Price of Hedge: 0.11947062089268456, Loss: 0.0009927668616658725\n",
      "Iteration:570, Price of Hedge: 0.11387791895384113, Loss: 0.0009327894674327375\n",
      "Iteration:580, Price of Hedge: 0.11685888440762825, Loss: 0.0009443782507389198\n",
      "Iteration:590, Price of Hedge: 0.1259625379572185, Loss: 0.0009281636625895651\n",
      "Iteration:600, Price of Hedge: 0.12955757968380227, Loss: 0.0012452576895574552\n",
      "Iteration:610, Price of Hedge: 0.12228990671673615, Loss: 0.0008234384731402589\n",
      "Iteration:620, Price of Hedge: 0.11155413215759041, Loss: 0.0009738009938223158\n",
      "Iteration:630, Price of Hedge: 0.11584837584393314, Loss: 0.0009345963459647333\n",
      "Iteration:640, Price of Hedge: 0.11516221859944267, Loss: 0.0008095815225622083\n",
      "Iteration:650, Price of Hedge: 0.11255644317506608, Loss: 0.0010217312394310341\n",
      "Iteration:660, Price of Hedge: 0.12288034760149458, Loss: 0.0007741905802113536\n",
      "Iteration:670, Price of Hedge: 0.12768294358078267, Loss: 0.0008442577903023718\n",
      "Iteration:680, Price of Hedge: 0.1182508921525482, Loss: 0.0007712405078457607\n",
      "Iteration:690, Price of Hedge: 0.11876544916996751, Loss: 0.00099689017792004\n",
      "Iteration:700, Price of Hedge: 0.11026110412678919, Loss: 0.0008375125727581257\n",
      "Iteration:710, Price of Hedge: 0.11225454373404205, Loss: 0.0008044854547545999\n",
      "Iteration:720, Price of Hedge: 0.11249864264216854, Loss: 0.0009858326415133956\n",
      "Iteration:730, Price of Hedge: 0.1160831198028177, Loss: 0.000709377846588799\n",
      "Iteration:740, Price of Hedge: 0.1260707943000739, Loss: 0.0007456591407948299\n",
      "Iteration:750, Price of Hedge: 0.10760971135922547, Loss: 0.0008267056347737612\n",
      "Iteration:760, Price of Hedge: 0.11354871176330904, Loss: 0.0010972643641601555\n",
      "Iteration:770, Price of Hedge: 0.11057692721319655, Loss: 0.0007056002419399743\n",
      "Iteration:780, Price of Hedge: 0.11135093395777745, Loss: 0.000867099367386004\n",
      "Iteration:790, Price of Hedge: 0.11674558944559976, Loss: 0.0006887420251243892\n",
      "Iteration:800, Price of Hedge: 0.1265787375859361, Loss: 0.0008471682944960257\n",
      "Iteration:810, Price of Hedge: 0.134581770479366, Loss: 0.0008688666777460608\n",
      "Iteration:820, Price of Hedge: 0.13130347428069628, Loss: 0.0009650990553904837\n",
      "Iteration:830, Price of Hedge: 0.12791856646978203, Loss: 0.0008424387421779756\n",
      "Iteration:840, Price of Hedge: 0.11738506766894262, Loss: 0.0008648691366088812\n",
      "Iteration:850, Price of Hedge: 0.10945906734359596, Loss: 0.0009988817079210845\n",
      "Iteration:860, Price of Hedge: 0.10760607380686907, Loss: 0.00080754675311554\n",
      "Iteration:870, Price of Hedge: 0.11333647189627527, Loss: 0.0010622388495140633\n",
      "Iteration:880, Price of Hedge: 0.12425501170563394, Loss: 0.0012218675969906557\n",
      "Iteration:890, Price of Hedge: 0.13644773911313451, Loss: 0.0008203507280114764\n",
      "Iteration:900, Price of Hedge: 0.12432586565607835, Loss: 0.0009343173971512186\n",
      "Iteration:910, Price of Hedge: 0.12183623083875546, Loss: 0.0010024319655476345\n",
      "Iteration:920, Price of Hedge: 0.11417259550382255, Loss: 0.0009798884414979891\n",
      "Iteration:930, Price of Hedge: 0.11968052854911662, Loss: 0.0008045381443306355\n",
      "Iteration:940, Price of Hedge: 0.11139193039115299, Loss: 0.0007413034465137081\n",
      "Iteration:950, Price of Hedge: 0.12150711937328539, Loss: 0.001071952427805778\n",
      "Iteration:960, Price of Hedge: 0.12237248263613765, Loss: 0.0009227156284140393\n",
      "Iteration:970, Price of Hedge: 0.11355602167713529, Loss: 0.0009810209614432798\n",
      "Iteration:980, Price of Hedge: 0.12581713158802474, Loss: 0.0008456411806161412\n",
      "Iteration:990, Price of Hedge: 0.1119871662312903, Loss: 0.0009034610896803575\n",
      "tf.Tensor(0.1686823, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_39 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.20425731930359917, Loss: 0.0031019048234664837\n",
      "Iteration:20, Price of Hedge: 0.12502774791757362, Loss: 0.0027338299944037916\n",
      "Iteration:30, Price of Hedge: 0.17774420964212823, Loss: 0.0026075721729126758\n",
      "Iteration:40, Price of Hedge: 0.16831435118804167, Loss: 0.0026445878578288174\n",
      "Iteration:50, Price of Hedge: 0.16537265041423552, Loss: 0.0022863251195683887\n",
      "Iteration:60, Price of Hedge: 0.17022787777307258, Loss: 0.0027026374934445486\n",
      "Iteration:70, Price of Hedge: 0.16763452920220062, Loss: 0.0026782376646412587\n",
      "Iteration:80, Price of Hedge: 0.14783595829038632, Loss: 0.0025896490147822248\n",
      "Iteration:90, Price of Hedge: 0.17127423972362976, Loss: 0.0033991047622274452\n",
      "Iteration:100, Price of Hedge: 0.17652409800174382, Loss: 0.003267057478108093\n",
      "Iteration:110, Price of Hedge: 0.17007374301867914, Loss: 0.0026772099799556416\n",
      "Iteration:120, Price of Hedge: 0.17342037820934594, Loss: 0.0031553816837478267\n",
      "Iteration:130, Price of Hedge: 0.1856821494933911, Loss: 0.002927364586039083\n",
      "Iteration:140, Price of Hedge: 0.1651880402810093, Loss: 0.0027519407954114785\n",
      "Iteration:150, Price of Hedge: 0.16284973808444647, Loss: 0.0025632909014007056\n",
      "Iteration:160, Price of Hedge: 0.17147014541417321, Loss: 0.0035655575916459627\n",
      "Iteration:170, Price of Hedge: 0.1504712692475323, Loss: 0.0030474565713626946\n",
      "Iteration:180, Price of Hedge: 0.16964056100624703, Loss: 0.0025751678796911647\n",
      "Iteration:190, Price of Hedge: 0.1760538964971488, Loss: 0.002384472134426119\n",
      "Iteration:200, Price of Hedge: 0.1709803811878146, Loss: 0.0030307718562220033\n",
      "Iteration:210, Price of Hedge: 0.16977873578211986, Loss: 0.00280087261887072\n",
      "Iteration:220, Price of Hedge: 0.16788461527784193, Loss: 0.0023046067027889805\n",
      "Iteration:230, Price of Hedge: 0.16885681641217617, Loss: 0.0030257441148968667\n",
      "Iteration:240, Price of Hedge: 0.16498928024316228, Loss: 0.0033467978144937406\n",
      "Iteration:250, Price of Hedge: 0.1451049396757867, Loss: 0.002703842758998043\n",
      "Iteration:260, Price of Hedge: 0.18767974008742386, Loss: 0.0032794280387495435\n",
      "Iteration:270, Price of Hedge: 0.1910088662940211, Loss: 0.002309706781803023\n",
      "Iteration:280, Price of Hedge: 0.17322541236486586, Loss: 0.002988061617901039\n",
      "Iteration:290, Price of Hedge: 0.16838698040327246, Loss: 0.002932109231371172\n",
      "Iteration:300, Price of Hedge: 0.14972001896087478, Loss: 0.0030257044107518285\n",
      "Iteration:310, Price of Hedge: 0.1686966422765977, Loss: 0.0023010542695928392\n",
      "Iteration:320, Price of Hedge: 0.17868416013284333, Loss: 0.0029606146319391515\n",
      "Iteration:330, Price of Hedge: 0.16855709254074328, Loss: 0.003140078183351314\n",
      "Iteration:340, Price of Hedge: 0.15852641138380932, Loss: 0.0025346740028911797\n",
      "Iteration:350, Price of Hedge: 0.14926516827531486, Loss: 0.0036620560686460024\n",
      "Iteration:360, Price of Hedge: 0.14607207608411274, Loss: 0.002839936058664527\n",
      "Iteration:370, Price of Hedge: 0.1441789650441251, Loss: 0.0030186822160040093\n",
      "Iteration:380, Price of Hedge: 0.16346135161246594, Loss: 0.0024465291692287393\n",
      "Iteration:390, Price of Hedge: 0.17830590690144846, Loss: 0.0026363002974175488\n",
      "Iteration:400, Price of Hedge: 0.16645603185695565, Loss: 0.0021549695306059212\n",
      "Iteration:410, Price of Hedge: 0.17918857899596788, Loss: 0.0025973739185079837\n",
      "Iteration:420, Price of Hedge: 0.16681470496203019, Loss: 0.0025847044889939497\n",
      "Iteration:430, Price of Hedge: 0.159468380803105, Loss: 0.0025295663093835687\n",
      "Iteration:440, Price of Hedge: 0.14929035266890198, Loss: 0.0028614695745314833\n",
      "Iteration:450, Price of Hedge: 0.16344751498986626, Loss: 0.0022827397808821816\n",
      "Iteration:460, Price of Hedge: 0.17108122318950336, Loss: 0.0032718586882495514\n",
      "Iteration:470, Price of Hedge: 0.16328594848974945, Loss: 0.002969454787026571\n",
      "Iteration:480, Price of Hedge: 0.16968170537835478, Loss: 0.002351052937990339\n",
      "Iteration:490, Price of Hedge: 0.16856535970518963, Loss: 0.002724838909175986\n",
      "Iteration:500, Price of Hedge: 0.1548813924725778, Loss: 0.0024742600670222717\n",
      "Iteration:510, Price of Hedge: 0.16779442486487142, Loss: 0.002215831497837506\n",
      "Iteration:520, Price of Hedge: 0.14849907190176737, Loss: 0.0023909254177258534\n",
      "Iteration:530, Price of Hedge: 0.1588103145131754, Loss: 0.0021152421341675168\n",
      "Iteration:540, Price of Hedge: 0.15784801657162006, Loss: 0.0017080449889589568\n",
      "Iteration:550, Price of Hedge: 0.17739524827970854, Loss: 0.0019548183519784604\n",
      "Iteration:560, Price of Hedge: 0.17568537241296553, Loss: 0.002268486536705794\n",
      "Iteration:570, Price of Hedge: 0.16923444307952878, Loss: 0.003178059277273526\n",
      "Iteration:580, Price of Hedge: 0.15926765405034757, Loss: 0.0021655935167849806\n",
      "Iteration:590, Price of Hedge: 0.1624752964509753, Loss: 0.0018222100428507916\n",
      "Iteration:600, Price of Hedge: 0.17135630220860776, Loss: 0.0018835339107011963\n",
      "Iteration:610, Price of Hedge: 0.1675130628007878, Loss: 0.002274793241004325\n",
      "Iteration:620, Price of Hedge: 0.14752706221755715, Loss: 0.0017781969102909302\n",
      "Iteration:630, Price of Hedge: 0.14896795066005097, Loss: 0.0025886751754439887\n",
      "Iteration:640, Price of Hedge: 0.15463182853363833, Loss: 0.0025934043198427405\n",
      "Iteration:650, Price of Hedge: 0.15814660914686557, Loss: 0.00176360767658581\n",
      "Iteration:660, Price of Hedge: 0.17179916115458127, Loss: 0.0018948634612932836\n",
      "Iteration:670, Price of Hedge: 0.16742059239088578, Loss: 0.0015753650220078797\n",
      "Iteration:680, Price of Hedge: 0.1462688345979359, Loss: 0.002084155420279643\n",
      "Iteration:690, Price of Hedge: 0.16528637602652907, Loss: 0.0020007710048288276\n",
      "Iteration:700, Price of Hedge: 0.17771157609826105, Loss: 0.0017124695536149483\n",
      "Iteration:710, Price of Hedge: 0.17040951172709812, Loss: 0.0015010104441182115\n",
      "Iteration:720, Price of Hedge: 0.18002324932302827, Loss: 0.0017369029677738014\n",
      "Iteration:730, Price of Hedge: 0.18886046521593017, Loss: 0.001751653737521064\n",
      "Iteration:740, Price of Hedge: 0.17296965240373083, Loss: 0.001795539463286744\n",
      "Iteration:750, Price of Hedge: 0.15899504647829873, Loss: 0.0019762131752839806\n",
      "Iteration:760, Price of Hedge: 0.1532779628747903, Loss: 0.0018276678670894775\n",
      "Iteration:770, Price of Hedge: 0.16768853554173122, Loss: 0.002002359850495861\n",
      "Iteration:780, Price of Hedge: 0.16517390778094523, Loss: 0.0015148238153178896\n",
      "Iteration:790, Price of Hedge: 0.1704870316227698, Loss: 0.001650630347717641\n",
      "Iteration:800, Price of Hedge: 0.16809284339454963, Loss: 0.0017076373416068159\n",
      "Iteration:810, Price of Hedge: 0.18202797578532, Loss: 0.0019379833865628806\n",
      "Iteration:820, Price of Hedge: 0.18128970929798244, Loss: 0.0014443777841718131\n",
      "Iteration:830, Price of Hedge: 0.16374946664456047, Loss: 0.0018858744156619702\n",
      "Iteration:840, Price of Hedge: 0.15925623666113325, Loss: 0.0017341174228585388\n",
      "Iteration:850, Price of Hedge: 0.17000671807071513, Loss: 0.0024021513568161625\n",
      "Iteration:860, Price of Hedge: 0.17408276082934435, Loss: 0.0021068585767480387\n",
      "Iteration:870, Price of Hedge: 0.14581618558880224, Loss: 0.0016344965955759072\n",
      "Iteration:880, Price of Hedge: 0.15158171477596624, Loss: 0.0021254662234611033\n",
      "Iteration:890, Price of Hedge: 0.1584197388556163, Loss: 0.002202948998476639\n",
      "Iteration:900, Price of Hedge: 0.16730974276907773, Loss: 0.0017853172776165493\n",
      "Iteration:910, Price of Hedge: 0.18261330843267842, Loss: 0.002043979312613065\n",
      "Iteration:920, Price of Hedge: 0.18316967989763952, Loss: 0.0017266936995480543\n",
      "Iteration:930, Price of Hedge: 0.17163073725911318, Loss: 0.0020540598143136356\n",
      "Iteration:940, Price of Hedge: 0.17112393397171674, Loss: 0.0019422814962363867\n",
      "Iteration:950, Price of Hedge: 0.15469039486703196, Loss: 0.0020509263142368893\n",
      "Iteration:960, Price of Hedge: 0.14969154510606586, Loss: 0.0016745273479991773\n",
      "Iteration:970, Price of Hedge: 0.13507618172237132, Loss: 0.001732057702348122\n",
      "Iteration:980, Price of Hedge: 0.14421407003504783, Loss: 0.0019769999156373785\n",
      "Iteration:990, Price of Hedge: 0.16640869146265233, Loss: 0.0021577119720486595\n",
      "tf.Tensor(0.15751283, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_40 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.1878626967877608, Loss: 0.0035826020916077898\n",
      "Iteration:20, Price of Hedge: 0.1640455181545235, Loss: 0.0024630515324886916\n",
      "Iteration:30, Price of Hedge: 0.16639673453217937, Loss: 0.0028172029881142536\n",
      "Iteration:40, Price of Hedge: 0.1643266713639264, Loss: 0.002820543847167656\n",
      "Iteration:50, Price of Hedge: 0.16113702527495663, Loss: 0.0026631946887032856\n",
      "Iteration:60, Price of Hedge: 0.16205165213563077, Loss: 0.002351792903597527\n",
      "Iteration:70, Price of Hedge: 0.17071618001666594, Loss: 0.0032277762094089723\n",
      "Iteration:80, Price of Hedge: 0.151796173723983, Loss: 0.002816217455089465\n",
      "Iteration:90, Price of Hedge: 0.17255737326393047, Loss: 0.002880240388963884\n",
      "Iteration:100, Price of Hedge: 0.16903980792162657, Loss: 0.003212018830806507\n",
      "Iteration:110, Price of Hedge: 0.14820345550572256, Loss: 0.0027559745733796606\n",
      "Iteration:120, Price of Hedge: 0.15930979048218888, Loss: 0.002620211688344831\n",
      "Iteration:130, Price of Hedge: 0.17368889571056342, Loss: 0.0025150090293568185\n",
      "Iteration:140, Price of Hedge: 0.1573285427669248, Loss: 0.002543293065718899\n",
      "Iteration:150, Price of Hedge: 0.1597050827746216, Loss: 0.0023868780424477266\n",
      "Iteration:160, Price of Hedge: 0.17558353835154322, Loss: 0.0025828655887970343\n",
      "Iteration:170, Price of Hedge: 0.16746593126116524, Loss: 0.002640989737671262\n",
      "Iteration:180, Price of Hedge: 0.18292469335711986, Loss: 0.0026039125929141703\n",
      "Iteration:190, Price of Hedge: 0.17676763996405498, Loss: 0.0026589381867982097\n",
      "Iteration:200, Price of Hedge: 0.16361952422402057, Loss: 0.0025075169115773123\n",
      "Iteration:210, Price of Hedge: 0.16384682773490342, Loss: 0.0029353010639075806\n",
      "Iteration:220, Price of Hedge: 0.1604957717868274, Loss: 0.0024395515736575393\n",
      "Iteration:230, Price of Hedge: 0.16974850406708128, Loss: 0.0026647265616416504\n",
      "Iteration:240, Price of Hedge: 0.16387763380031403, Loss: 0.0025592182351260816\n",
      "Iteration:250, Price of Hedge: 0.15968536341184744, Loss: 0.0025121427164204848\n",
      "Iteration:260, Price of Hedge: 0.15393916198493116, Loss: 0.003224293122493549\n",
      "Iteration:270, Price of Hedge: 0.17177952881459077, Loss: 0.0027729728424876754\n",
      "Iteration:280, Price of Hedge: 0.1708855959718676, Loss: 0.0027477359632841927\n",
      "Iteration:290, Price of Hedge: 0.1605732568733856, Loss: 0.00254372274071315\n",
      "Iteration:300, Price of Hedge: 0.13810573199626788, Loss: 0.003021730460947403\n",
      "Iteration:310, Price of Hedge: 0.15381555482304066, Loss: 0.0021513348336846152\n",
      "Iteration:320, Price of Hedge: 0.13948311991353535, Loss: 0.003029508122235747\n",
      "Iteration:330, Price of Hedge: 0.1487329369305371, Loss: 0.0029921000189546024\n",
      "Iteration:340, Price of Hedge: 0.15328830118148745, Loss: 0.002471242280053154\n",
      "Iteration:350, Price of Hedge: 0.16420240282888018, Loss: 0.0022805931735612184\n",
      "Iteration:360, Price of Hedge: 0.17002744689777957, Loss: 0.0031104849979877616\n",
      "Iteration:370, Price of Hedge: 0.17691359457678574, Loss: 0.0020303723485783466\n",
      "Iteration:380, Price of Hedge: 0.17472937492094617, Loss: 0.0030953106720357226\n",
      "Iteration:390, Price of Hedge: 0.18924769919859727, Loss: 0.0031852971253570673\n",
      "Iteration:400, Price of Hedge: 0.18418628005618984, Loss: 0.002780172346157173\n",
      "Iteration:410, Price of Hedge: 0.17742742930510078, Loss: 0.0025554555875181963\n",
      "Iteration:420, Price of Hedge: 0.16884423291766099, Loss: 0.003046096296475831\n",
      "Iteration:430, Price of Hedge: 0.1395058328600669, Loss: 0.0023425848053030053\n",
      "Iteration:440, Price of Hedge: 0.15876628098465062, Loss: 0.002764488121082209\n",
      "Iteration:450, Price of Hedge: 0.18691543638321947, Loss: 0.0026741095213420607\n",
      "Iteration:460, Price of Hedge: 0.15633039143850738, Loss: 0.002854074541544982\n",
      "Iteration:470, Price of Hedge: 0.15400294968534353, Loss: 0.002449045215460899\n",
      "Iteration:480, Price of Hedge: 0.16244663114604238, Loss: 0.0026351426224488607\n",
      "Iteration:490, Price of Hedge: 0.14982601271135537, Loss: 0.0027245511900975575\n",
      "Iteration:500, Price of Hedge: 0.15051610338566662, Loss: 0.0027572007787904696\n",
      "Iteration:510, Price of Hedge: 0.1394936931817483, Loss: 0.0020353462445561023\n",
      "Iteration:520, Price of Hedge: 0.1703674971271539, Loss: 0.0028148623471803804\n",
      "Iteration:530, Price of Hedge: 0.16812222228630844, Loss: 0.0026358020919811766\n",
      "Iteration:540, Price of Hedge: 0.1857628544229442, Loss: 0.002615501852126201\n",
      "Iteration:550, Price of Hedge: 0.1850703445152476, Loss: 0.0028522837758252705\n",
      "Iteration:560, Price of Hedge: 0.17136425609103298, Loss: 0.0025904923199449926\n",
      "Iteration:570, Price of Hedge: 0.17305235885730783, Loss: 0.0024596516611101295\n",
      "Iteration:580, Price of Hedge: 0.15384855386259916, Loss: 0.0035958491348482727\n",
      "Iteration:590, Price of Hedge: 0.17318003868547294, Loss: 0.002545221980107648\n",
      "Iteration:600, Price of Hedge: 0.1586868117786253, Loss: 0.0031747801500072725\n",
      "Iteration:610, Price of Hedge: 0.1510087219593288, Loss: 0.0017457371400448453\n",
      "Iteration:620, Price of Hedge: 0.16882310378579177, Loss: 0.0020006988031130214\n",
      "Iteration:630, Price of Hedge: 0.18232957934887964, Loss: 0.0019679165046750493\n",
      "Iteration:640, Price of Hedge: 0.1721243304879522, Loss: 0.0028691145260747674\n",
      "Iteration:650, Price of Hedge: 0.18263918900853468, Loss: 0.002149946684312365\n",
      "Iteration:660, Price of Hedge: 0.1627432744109342, Loss: 0.001932251712501909\n",
      "Iteration:670, Price of Hedge: 0.15499673247002194, Loss: 0.00192039676185356\n",
      "Iteration:680, Price of Hedge: 0.17235271308135225, Loss: 0.002227688488082347\n",
      "Iteration:690, Price of Hedge: 0.17639302428501652, Loss: 0.00184371350866277\n",
      "Iteration:700, Price of Hedge: 0.15977327382788645, Loss: 0.0020851477519594043\n",
      "Iteration:710, Price of Hedge: 0.1613007151309944, Loss: 0.0022960765663682992\n",
      "Iteration:720, Price of Hedge: 0.16460521388981988, Loss: 0.00279923631859198\n",
      "Iteration:730, Price of Hedge: 0.15352308865176384, Loss: 0.0018404889066093945\n",
      "Iteration:740, Price of Hedge: 0.15852996191338206, Loss: 0.0017656899686307348\n",
      "Iteration:750, Price of Hedge: 0.16075424685881218, Loss: 0.0018942042637071666\n",
      "Iteration:760, Price of Hedge: 0.17099943917743304, Loss: 0.0018477238992578471\n",
      "Iteration:770, Price of Hedge: 0.1731535141410177, Loss: 0.001979203767633209\n",
      "Iteration:780, Price of Hedge: 0.17755411707353233, Loss: 0.0013227454955776709\n",
      "Iteration:790, Price of Hedge: 0.17120429081013527, Loss: 0.0017862631064962998\n",
      "Iteration:800, Price of Hedge: 0.17265965984382775, Loss: 0.0016569367800699732\n",
      "Iteration:810, Price of Hedge: 0.15668527035021498, Loss: 0.002048753464107733\n",
      "Iteration:820, Price of Hedge: 0.15860659417666056, Loss: 0.0016345295010659732\n",
      "Iteration:830, Price of Hedge: 0.16412027072567525, Loss: 0.002201088750503111\n",
      "Iteration:840, Price of Hedge: 0.16467258692891848, Loss: 0.001650514634610012\n",
      "Iteration:850, Price of Hedge: 0.160833106905352, Loss: 0.0022782492692729585\n",
      "Iteration:860, Price of Hedge: 0.17183123775263312, Loss: 0.0021900576608643086\n",
      "Iteration:870, Price of Hedge: 0.1769474116305105, Loss: 0.0020968807347375496\n",
      "Iteration:880, Price of Hedge: 0.16864146983176626, Loss: 0.0017024019693588244\n",
      "Iteration:890, Price of Hedge: 0.16830540524588286, Loss: 0.0017724505511352185\n",
      "Iteration:900, Price of Hedge: 0.15603073718530142, Loss: 0.0014306915478201176\n",
      "Iteration:910, Price of Hedge: 0.15870985541173468, Loss: 0.0019405447118371556\n",
      "Iteration:920, Price of Hedge: 0.17437138059358404, Loss: 0.0020700662956342876\n",
      "Iteration:930, Price of Hedge: 0.17594704992338847, Loss: 0.0018846522894441443\n",
      "Iteration:940, Price of Hedge: 0.1856374023780404, Loss: 0.0017822256572544326\n",
      "Iteration:950, Price of Hedge: 0.18635391316946653, Loss: 0.0019751574801398775\n",
      "Iteration:960, Price of Hedge: 0.18314231993446128, Loss: 0.001874166451934123\n",
      "Iteration:970, Price of Hedge: 0.17201379414816528, Loss: 0.0019011769642467869\n",
      "Iteration:980, Price of Hedge: 0.16177018564420678, Loss: 0.0018630199211338906\n",
      "Iteration:990, Price of Hedge: 0.15038118326190217, Loss: 0.0015248110394722404\n",
      "tf.Tensor(0.15746681, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_41 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.18746770037279248, Loss: 0.0034314345421904593\n",
      "Iteration:20, Price of Hedge: 0.14528572950881086, Loss: 0.0025602750180549806\n",
      "Iteration:30, Price of Hedge: 0.1610683642986601, Loss: 0.002805795117016885\n",
      "Iteration:40, Price of Hedge: 0.1462257931291447, Loss: 0.0021592612495437537\n",
      "Iteration:50, Price of Hedge: 0.1670301733743372, Loss: 0.003426887329798767\n",
      "Iteration:60, Price of Hedge: 0.14819104605677466, Loss: 0.002637834889817903\n",
      "Iteration:70, Price of Hedge: 0.1585257500106536, Loss: 0.002527244704683618\n",
      "Iteration:80, Price of Hedge: 0.13825655118260444, Loss: 0.002516336670699815\n",
      "Iteration:90, Price of Hedge: 0.16390106033367147, Loss: 0.002883070261109566\n",
      "Iteration:100, Price of Hedge: 0.16057685961662857, Loss: 0.0031351287625314586\n",
      "Iteration:110, Price of Hedge: 0.14421580178844237, Loss: 0.0023892350001535334\n",
      "Iteration:120, Price of Hedge: 0.15206025306323454, Loss: 0.0022455772450186372\n",
      "Iteration:130, Price of Hedge: 0.1514030570011414, Loss: 0.00245274749101263\n",
      "Iteration:140, Price of Hedge: 0.14917194946947349, Loss: 0.0023229138489522685\n",
      "Iteration:150, Price of Hedge: 0.1536037065585333, Loss: 0.0021411163192881057\n",
      "Iteration:160, Price of Hedge: 0.16871255004144814, Loss: 0.0026826790899615815\n",
      "Iteration:170, Price of Hedge: 0.14440371008516878, Loss: 0.0023911894774849784\n",
      "Iteration:180, Price of Hedge: 0.14317124120950667, Loss: 0.0029314889220914964\n",
      "Iteration:190, Price of Hedge: 0.16579972342725569, Loss: 0.0022207870374468365\n",
      "Iteration:200, Price of Hedge: 0.14774186925670849, Loss: 0.0023723822222619264\n",
      "Iteration:210, Price of Hedge: 0.15623334363018557, Loss: 0.002260200064079321\n",
      "Iteration:220, Price of Hedge: 0.15639182952376132, Loss: 0.0019458956612196767\n",
      "Iteration:230, Price of Hedge: 0.16601413016160224, Loss: 0.0025692938417950727\n",
      "Iteration:240, Price of Hedge: 0.15564317251605644, Loss: 0.002456132677296452\n",
      "Iteration:250, Price of Hedge: 0.16294424482748582, Loss: 0.0021034083953226815\n",
      "Iteration:260, Price of Hedge: 0.14318211035518402, Loss: 0.0022157306057977166\n",
      "Iteration:270, Price of Hedge: 0.15637806251938854, Loss: 0.0022070891074085887\n",
      "Iteration:280, Price of Hedge: 0.15101698912377515, Loss: 0.0021112710397981796\n",
      "Iteration:290, Price of Hedge: 0.15183000818226447, Loss: 0.0024689516772198774\n",
      "Iteration:300, Price of Hedge: 0.155674239649818, Loss: 0.0028770382224719174\n",
      "Iteration:310, Price of Hedge: 0.15594200875509615, Loss: 0.002216190466820045\n",
      "Iteration:320, Price of Hedge: 0.14217758895900376, Loss: 0.0021715880268471824\n",
      "Iteration:330, Price of Hedge: 0.13947781152373295, Loss: 0.0025152437189264634\n",
      "Iteration:340, Price of Hedge: 0.15509109997660744, Loss: 0.0027863694561375495\n",
      "Iteration:350, Price of Hedge: 0.1683077548610413, Loss: 0.0024355441744706497\n",
      "Iteration:360, Price of Hedge: 0.1477354991889456, Loss: 0.002023319151963854\n",
      "Iteration:370, Price of Hedge: 0.15635722926498374, Loss: 0.0025937010131457327\n",
      "Iteration:380, Price of Hedge: 0.1759566746432597, Loss: 0.0024796921923451623\n",
      "Iteration:390, Price of Hedge: 0.14505225608256753, Loss: 0.0024807701870775745\n",
      "Iteration:400, Price of Hedge: 0.1340819116101045, Loss: 0.0028403611105733972\n",
      "Iteration:410, Price of Hedge: 0.15360342808562563, Loss: 0.0021962086759639734\n",
      "Iteration:420, Price of Hedge: 0.17701368818253513, Loss: 0.002500641295830697\n",
      "Iteration:430, Price of Hedge: 0.14880925591179447, Loss: 0.0024749935059206864\n",
      "Iteration:440, Price of Hedge: 0.16244057436030063, Loss: 0.0020717669111890657\n",
      "Iteration:450, Price of Hedge: 0.15438670275666483, Loss: 0.0030248640969972487\n",
      "Iteration:460, Price of Hedge: 0.1366563066186984, Loss: 0.002270319182140135\n",
      "Iteration:470, Price of Hedge: 0.1401601658725781, Loss: 0.001959202532623916\n",
      "Iteration:480, Price of Hedge: 0.17371973658508752, Loss: 0.0025217614534753354\n",
      "Iteration:490, Price of Hedge: 0.15968047273140656, Loss: 0.0018069284341232896\n",
      "Iteration:500, Price of Hedge: 0.14675141074236536, Loss: 0.001696109134316437\n",
      "Iteration:510, Price of Hedge: 0.1433782510072433, Loss: 0.003018296052401581\n",
      "Iteration:520, Price of Hedge: 0.15466186879855287, Loss: 0.0027558092300907335\n",
      "Iteration:530, Price of Hedge: 0.1662649646331829, Loss: 0.0026760678059202904\n",
      "Iteration:540, Price of Hedge: 0.15019048153382072, Loss: 0.0022930024865360113\n",
      "Iteration:550, Price of Hedge: 0.15625997260198118, Loss: 0.002230320791314533\n",
      "Iteration:560, Price of Hedge: 0.16441821933232179, Loss: 0.0020460443360743596\n",
      "Iteration:570, Price of Hedge: 0.16097935739554714, Loss: 0.0017308048462098215\n",
      "Iteration:580, Price of Hedge: 0.150569674611279, Loss: 0.002238958618429976\n",
      "Iteration:590, Price of Hedge: 0.1600563241339728, Loss: 0.0025357764727814923\n",
      "Iteration:600, Price of Hedge: 0.17047094981235206, Loss: 0.0022541008547305452\n",
      "Iteration:610, Price of Hedge: 0.14784664468821804, Loss: 0.0034385007922224987\n",
      "Iteration:620, Price of Hedge: 0.1444257181471528, Loss: 0.0023135684178273055\n",
      "Iteration:630, Price of Hedge: 0.1504407764641428, Loss: 0.001841127572257495\n",
      "Iteration:640, Price of Hedge: 0.16202437919523618, Loss: 0.001996505664672288\n",
      "Iteration:650, Price of Hedge: 0.1416248202372856, Loss: 0.0014418246172835049\n",
      "Iteration:660, Price of Hedge: 0.14852232438955754, Loss: 0.00239823315598251\n",
      "Iteration:670, Price of Hedge: 0.15085215056699328, Loss: 0.0015396908476908778\n",
      "Iteration:680, Price of Hedge: 0.1562471454436718, Loss: 0.0018529834747175401\n",
      "Iteration:690, Price of Hedge: 0.15780055434541965, Loss: 0.0017980166212124616\n",
      "Iteration:700, Price of Hedge: 0.154999813076563, Loss: 0.0014167715737104737\n",
      "Iteration:710, Price of Hedge: 0.15325883526694498, Loss: 0.0019158558042244424\n",
      "Iteration:720, Price of Hedge: 0.16267621465385673, Loss: 0.001877623839933751\n",
      "Iteration:730, Price of Hedge: 0.16292734500290182, Loss: 0.0020292086907932826\n",
      "Iteration:740, Price of Hedge: 0.17346162700879406, Loss: 0.0020112645928055174\n",
      "Iteration:750, Price of Hedge: 0.1609614307021161, Loss: 0.0015534651946110146\n",
      "Iteration:760, Price of Hedge: 0.16307272526526048, Loss: 0.0018408783335662094\n",
      "Iteration:770, Price of Hedge: 0.1545628194662072, Loss: 0.0015572854948130656\n",
      "Iteration:780, Price of Hedge: 0.16017434443315323, Loss: 0.001682975084721594\n",
      "Iteration:790, Price of Hedge: 0.17816658342483152, Loss: 0.0014769769268448308\n",
      "Iteration:800, Price of Hedge: 0.15139336266304326, Loss: 0.0019391445968321543\n",
      "Iteration:810, Price of Hedge: 0.15238905994896187, Loss: 0.0018100589427918479\n",
      "Iteration:820, Price of Hedge: 0.1375438258822669, Loss: 0.0017256346050764648\n",
      "Iteration:830, Price of Hedge: 0.14316645495640615, Loss: 0.002806510879412372\n",
      "Iteration:840, Price of Hedge: 0.1352355204392268, Loss: 0.0012485759770763493\n",
      "Iteration:850, Price of Hedge: 0.14537273488789992, Loss: 0.0018117675807594936\n",
      "Iteration:860, Price of Hedge: 0.15614047291547878, Loss: 0.0017384008474373048\n",
      "Iteration:870, Price of Hedge: 0.15806494696669235, Loss: 0.0014045664923310497\n",
      "Iteration:880, Price of Hedge: 0.1531875810116958, Loss: 0.0014969218689909526\n",
      "Iteration:890, Price of Hedge: 0.15411614892231001, Loss: 0.002026862067043034\n",
      "Iteration:900, Price of Hedge: 0.15117946066084187, Loss: 0.0013834603399156542\n",
      "Iteration:910, Price of Hedge: 0.1531722475972174, Loss: 0.002270912296799921\n",
      "Iteration:920, Price of Hedge: 0.14792715816764712, Loss: 0.0017324701087587436\n",
      "Iteration:930, Price of Hedge: 0.15538431454382362, Loss: 0.001702708180778778\n",
      "Iteration:940, Price of Hedge: 0.15508734059235393, Loss: 0.0016300007810158058\n",
      "Iteration:950, Price of Hedge: 0.16027473391636704, Loss: 0.0017504647887395032\n",
      "Iteration:960, Price of Hedge: 0.14919020684948237, Loss: 0.001307304118458319\n",
      "Iteration:970, Price of Hedge: 0.17121767491426, Loss: 0.001460182753359085\n",
      "Iteration:980, Price of Hedge: 0.16541778042983424, Loss: 0.0014517676501805356\n",
      "Iteration:990, Price of Hedge: 0.16651428490832815, Loss: 0.0015159926400807322\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 7 \n",
      "\n",
      "tf.Tensor(0.12115573, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_42 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.14467908141737665, Loss: 0.000830756284056866\n",
      "Iteration:20, Price of Hedge: 0.13909106629749315, Loss: 0.0010122500699174086\n",
      "Iteration:30, Price of Hedge: 0.13047354542725315, Loss: 0.0009267881826034329\n",
      "Iteration:40, Price of Hedge: 0.12149442244161718, Loss: 0.0009685698762331274\n",
      "Iteration:50, Price of Hedge: 0.10898513926746886, Loss: 0.0011892630620912836\n",
      "Iteration:60, Price of Hedge: 0.11643866398292743, Loss: 0.0008444857631171753\n",
      "Iteration:70, Price of Hedge: 0.1304622616419465, Loss: 0.0007610237833983513\n",
      "Iteration:80, Price of Hedge: 0.14287424758175574, Loss: 0.0008417638914116399\n",
      "Iteration:90, Price of Hedge: 0.13194839207748146, Loss: 0.000829808622400252\n",
      "Iteration:100, Price of Hedge: 0.1322958259264169, Loss: 0.0008678494052603902\n",
      "Iteration:110, Price of Hedge: 0.12086958283026092, Loss: 0.0009653866821183854\n",
      "Iteration:120, Price of Hedge: 0.11481956786107617, Loss: 0.0008809079962549759\n",
      "Iteration:130, Price of Hedge: 0.12076581775051522, Loss: 0.001013339592930329\n",
      "Iteration:140, Price of Hedge: 0.11671575207121236, Loss: 0.0006776777051025417\n",
      "Iteration:150, Price of Hedge: 0.10756345856062238, Loss: 0.00098693769549687\n",
      "Iteration:160, Price of Hedge: 0.11689675008687458, Loss: 0.000926444995263509\n",
      "Iteration:170, Price of Hedge: 0.10978074778731184, Loss: 0.0007931844676398292\n",
      "Iteration:180, Price of Hedge: 0.10488395346621927, Loss: 0.0008791063868118342\n",
      "Iteration:190, Price of Hedge: 0.10442863748073705, Loss: 0.0009291913874414082\n",
      "Iteration:200, Price of Hedge: 0.11351344429789946, Loss: 0.0007951853183300716\n",
      "Iteration:210, Price of Hedge: 0.10467641695324516, Loss: 0.0008347810168122027\n",
      "Iteration:220, Price of Hedge: 0.11646991041093314, Loss: 0.0008948671934247976\n",
      "Iteration:230, Price of Hedge: 0.10035367885614618, Loss: 0.0007980587305257414\n",
      "Iteration:240, Price of Hedge: 0.09411981315755895, Loss: 0.0009209522109077106\n",
      "Iteration:250, Price of Hedge: 0.10481680350737577, Loss: 0.000916474196869732\n",
      "Iteration:260, Price of Hedge: 0.12059739963063407, Loss: 0.0007789598636567918\n",
      "Iteration:270, Price of Hedge: 0.1160093845696224, Loss: 0.0008607508774208572\n",
      "Iteration:280, Price of Hedge: 0.11997351304168546, Loss: 0.001016840560454124\n",
      "Iteration:290, Price of Hedge: 0.10170470883517169, Loss: 0.0006857196754890715\n",
      "Iteration:300, Price of Hedge: 0.12397172159504634, Loss: 0.0008059941311669983\n",
      "Iteration:310, Price of Hedge: 0.1266793217900272, Loss: 0.0008433356834721017\n",
      "Iteration:320, Price of Hedge: 0.10425690284287725, Loss: 0.0009748629015918553\n",
      "Iteration:330, Price of Hedge: 0.09372779056691058, Loss: 0.001137994824578703\n",
      "Iteration:340, Price of Hedge: 0.11806465998701014, Loss: 0.0008977614033490511\n",
      "Iteration:350, Price of Hedge: 0.14511108012128487, Loss: 0.0009468472195480969\n",
      "Iteration:360, Price of Hedge: 0.1318597101657076, Loss: 0.0010201910298560434\n",
      "Iteration:370, Price of Hedge: 0.12001539519976062, Loss: 0.0010392025363376244\n",
      "Iteration:380, Price of Hedge: 0.09584292214498191, Loss: 0.0006945910731897653\n",
      "Iteration:390, Price of Hedge: 0.09547775572578132, Loss: 0.0007209941122646501\n",
      "Iteration:400, Price of Hedge: 0.09731067195501453, Loss: 0.0006717059277137282\n",
      "Iteration:410, Price of Hedge: 0.10406256886699054, Loss: 0.0009716466495123476\n",
      "Iteration:420, Price of Hedge: 0.09269807526936802, Loss: 0.000914556636366992\n",
      "Iteration:430, Price of Hedge: 0.11601540767123879, Loss: 0.0008679751843635674\n",
      "Iteration:440, Price of Hedge: 0.13197505129096498, Loss: 0.000673325370894573\n",
      "Iteration:450, Price of Hedge: 0.11278181534902387, Loss: 0.0009366077879631617\n",
      "Iteration:460, Price of Hedge: 0.08822538862664828, Loss: 0.0007538931406891435\n",
      "Iteration:470, Price of Hedge: 0.10303291710427515, Loss: 0.000905839856624624\n",
      "Iteration:480, Price of Hedge: 0.09749686076605713, Loss: 0.0008302269098913628\n",
      "Iteration:490, Price of Hedge: 0.11029670141185192, Loss: 0.0007925281230931391\n",
      "Iteration:500, Price of Hedge: 0.12061901417883973, Loss: 0.0006680879171254927\n",
      "Iteration:510, Price of Hedge: 0.13271119121257016, Loss: 0.0006195722267271941\n",
      "Iteration:520, Price of Hedge: 0.13766429009750708, Loss: 0.000634025407178318\n",
      "Iteration:530, Price of Hedge: 0.1210788284300861, Loss: 0.0006265188169839231\n",
      "Iteration:540, Price of Hedge: 0.10996025908801811, Loss: 0.0005804720006238772\n",
      "Iteration:550, Price of Hedge: 0.09243177539473776, Loss: 0.0007406230482112752\n",
      "Iteration:560, Price of Hedge: 0.09872906155781322, Loss: 0.0006621342570897414\n",
      "Iteration:570, Price of Hedge: 0.10389410627273037, Loss: 0.0007416305219512864\n",
      "Iteration:580, Price of Hedge: 0.11317334236802025, Loss: 0.0005085112144484593\n",
      "Iteration:590, Price of Hedge: 0.11356840192340768, Loss: 0.00047888283979924395\n",
      "Iteration:600, Price of Hedge: 0.11237922056313322, Loss: 0.0006540720349770489\n",
      "Iteration:610, Price of Hedge: 0.10474079679362375, Loss: 0.0005175768897378808\n",
      "Iteration:620, Price of Hedge: 0.11318227536472136, Loss: 0.0005591598881228954\n",
      "Iteration:630, Price of Hedge: 0.13684591069560384, Loss: 0.0006713381702648568\n",
      "Iteration:640, Price of Hedge: 0.1353999596847757, Loss: 0.0006437165034227643\n",
      "Iteration:650, Price of Hedge: 0.12379179096448069, Loss: 0.0005605923502928212\n",
      "Iteration:660, Price of Hedge: 0.10537359731882531, Loss: 0.0006681569616134641\n",
      "Iteration:670, Price of Hedge: 0.09657974824272059, Loss: 0.000558637214896196\n",
      "Iteration:680, Price of Hedge: 0.10223082167857739, Loss: 0.0005363414045788106\n",
      "Iteration:690, Price of Hedge: 0.09994341541661526, Loss: 0.0006669343132829741\n",
      "Iteration:700, Price of Hedge: 0.11535293002826279, Loss: 0.0005536453133068387\n",
      "Iteration:710, Price of Hedge: 0.11609744384008991, Loss: 0.0007044004534132453\n",
      "Iteration:720, Price of Hedge: 0.11158057507855118, Loss: 0.0006140513977015871\n",
      "Iteration:730, Price of Hedge: 0.11221843932947877, Loss: 0.0006204033913217887\n",
      "Iteration:740, Price of Hedge: 0.1254160588212642, Loss: 0.0005100268675327202\n",
      "Iteration:750, Price of Hedge: 0.11620306413678917, Loss: 0.0005943522756255648\n",
      "Iteration:760, Price of Hedge: 0.12376101469419609, Loss: 0.0006110482851126253\n",
      "Iteration:770, Price of Hedge: 0.1187511919155554, Loss: 0.0005508014845150732\n",
      "Iteration:780, Price of Hedge: 0.08986904731268623, Loss: 0.0005911182040124974\n",
      "Iteration:790, Price of Hedge: 0.09515046877054373, Loss: 0.0005731797411980377\n",
      "Iteration:800, Price of Hedge: 0.11163925584493199, Loss: 0.0005212468698292837\n",
      "Iteration:810, Price of Hedge: 0.12389690298256255, Loss: 0.0005926441318695907\n",
      "Iteration:820, Price of Hedge: 0.11389242954201108, Loss: 0.0004789452329849952\n",
      "Iteration:830, Price of Hedge: 0.09893790053474447, Loss: 0.0006844770236153374\n",
      "Iteration:840, Price of Hedge: 0.10888889671126094, Loss: 0.0005604797745209167\n",
      "Iteration:850, Price of Hedge: 0.11584861604293337, Loss: 0.0005638936794768457\n",
      "Iteration:860, Price of Hedge: 0.126997758343839, Loss: 0.000615367462082661\n",
      "Iteration:870, Price of Hedge: 0.12227424891038935, Loss: 0.0006344570469104527\n",
      "Iteration:880, Price of Hedge: 0.10025664211459855, Loss: 0.0005750429992781746\n",
      "Iteration:890, Price of Hedge: 0.11296585032942516, Loss: 0.0005345963312045398\n",
      "Iteration:900, Price of Hedge: 0.11404384574213963, Loss: 0.0005205047036293209\n",
      "Iteration:910, Price of Hedge: 0.12329452928609612, Loss: 0.0005665330551802183\n",
      "Iteration:920, Price of Hedge: 0.11878309910576376, Loss: 0.0007511620862156176\n",
      "Iteration:930, Price of Hedge: 0.11511253965615537, Loss: 0.00046845876012282514\n",
      "Iteration:940, Price of Hedge: 0.1115970433057555, Loss: 0.0006075308382430311\n",
      "Iteration:950, Price of Hedge: 0.10606572666564489, Loss: 0.0005685947106855326\n",
      "Iteration:960, Price of Hedge: 0.11924588678692202, Loss: 0.0006192082912952701\n",
      "Iteration:970, Price of Hedge: 0.1205957985529892, Loss: 0.0006264210329139708\n",
      "Iteration:980, Price of Hedge: 0.10057015471930413, Loss: 0.0006580276239712468\n",
      "Iteration:990, Price of Hedge: 0.12287227682467687, Loss: 0.0006220821998567771\n",
      "tf.Tensor(0.11386488, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_43 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.09183999930744448, Loss: 0.0012282835718411267\n",
      "Iteration:20, Price of Hedge: 0.14893812585023056, Loss: 0.0009661940707893723\n",
      "Iteration:30, Price of Hedge: 0.09669429518263825, Loss: 0.0007842635326285707\n",
      "Iteration:40, Price of Hedge: 0.11751698977674323, Loss: 0.0010297091426061833\n",
      "Iteration:50, Price of Hedge: 0.11838897986581855, Loss: 0.0007622328809414824\n",
      "Iteration:60, Price of Hedge: 0.11115153709758942, Loss: 0.000715078225669119\n",
      "Iteration:70, Price of Hedge: 0.1117447109510806, Loss: 0.0008204380295769642\n",
      "Iteration:80, Price of Hedge: 0.0895031883638694, Loss: 0.0008191442023854022\n",
      "Iteration:90, Price of Hedge: 0.11821291215274526, Loss: 0.001066204142975735\n",
      "Iteration:100, Price of Hedge: 0.12756588676845695, Loss: 0.0008865469107132817\n",
      "Iteration:110, Price of Hedge: 0.11996409718029781, Loss: 0.0010468399189301535\n",
      "Iteration:120, Price of Hedge: 0.1170623218464982, Loss: 0.000933806100630985\n",
      "Iteration:130, Price of Hedge: 0.11030014499948493, Loss: 0.0008539614862248079\n",
      "Iteration:140, Price of Hedge: 0.10426873302769762, Loss: 0.001017257904850144\n",
      "Iteration:150, Price of Hedge: 0.09647639613935155, Loss: 0.0009426251317358413\n",
      "Iteration:160, Price of Hedge: 0.10949147371917434, Loss: 0.0008560011527235289\n",
      "Iteration:170, Price of Hedge: 0.12021014215202398, Loss: 0.0009371231149754688\n",
      "Iteration:180, Price of Hedge: 0.1058496256579673, Loss: 0.000712100527011028\n",
      "Iteration:190, Price of Hedge: 0.12401750479151019, Loss: 0.0010727950871100233\n",
      "Iteration:200, Price of Hedge: 0.10728216446677834, Loss: 0.001005047702344708\n",
      "Iteration:210, Price of Hedge: 0.11131292826558478, Loss: 0.0008097183144078367\n",
      "Iteration:220, Price of Hedge: 0.11207601966087849, Loss: 0.0009094943004653188\n",
      "Iteration:230, Price of Hedge: 0.12671549852062183, Loss: 0.0009192618866852964\n",
      "Iteration:240, Price of Hedge: 0.11331695649137145, Loss: 0.0008964850482349628\n",
      "Iteration:250, Price of Hedge: 0.11374530829619971, Loss: 0.0009294283524921453\n",
      "Iteration:260, Price of Hedge: 0.11310830811892174, Loss: 0.0009527074138966806\n",
      "Iteration:270, Price of Hedge: 0.11742929900827334, Loss: 0.0009819612308850534\n",
      "Iteration:280, Price of Hedge: 0.106606865495678, Loss: 0.0008821009619083941\n",
      "Iteration:290, Price of Hedge: 0.11236312083792654, Loss: 0.0009096451956798645\n",
      "Iteration:300, Price of Hedge: 0.10047792121069107, Loss: 0.0008560839465451941\n",
      "Iteration:310, Price of Hedge: 0.1191528717999347, Loss: 0.0010115727290957999\n",
      "Iteration:320, Price of Hedge: 0.11987602520286486, Loss: 0.0007983221518756078\n",
      "Iteration:330, Price of Hedge: 0.11862512611147052, Loss: 0.001070618721459704\n",
      "Iteration:340, Price of Hedge: 0.12203824244135716, Loss: 0.0008190564945419476\n",
      "Iteration:350, Price of Hedge: 0.12058082974770627, Loss: 0.0010348969597915314\n",
      "Iteration:360, Price of Hedge: 0.10218754810778705, Loss: 0.0008563776958477209\n",
      "Iteration:370, Price of Hedge: 0.11108037809115102, Loss: 0.0009952693946226443\n",
      "Iteration:380, Price of Hedge: 0.09860835173965937, Loss: 0.0008911706577610978\n",
      "Iteration:390, Price of Hedge: 0.11918626570509899, Loss: 0.0008629579184799229\n",
      "Iteration:400, Price of Hedge: 0.13533191388486898, Loss: 0.0010579857145340376\n",
      "Iteration:410, Price of Hedge: 0.1213781410009176, Loss: 0.0008976569679768786\n",
      "Iteration:420, Price of Hedge: 0.12522814821640507, Loss: 0.0008692425056194163\n",
      "Iteration:430, Price of Hedge: 0.11398610529120105, Loss: 0.0008316099340238913\n",
      "Iteration:440, Price of Hedge: 0.10813670789231082, Loss: 0.0010124576501105763\n",
      "Iteration:450, Price of Hedge: 0.12110837212472347, Loss: 0.0008881995111320595\n",
      "Iteration:460, Price of Hedge: 0.11474666800037311, Loss: 0.0010214616271264187\n",
      "Iteration:470, Price of Hedge: 0.11070783527851517, Loss: 0.0007434534751254329\n",
      "Iteration:480, Price of Hedge: 0.11442951485007029, Loss: 0.0007635322674304224\n",
      "Iteration:490, Price of Hedge: 0.09375919583198424, Loss: 0.0006954081906311637\n",
      "Iteration:500, Price of Hedge: 0.09804012801280065, Loss: 0.0008253032089680534\n",
      "Iteration:510, Price of Hedge: 0.10306205417601859, Loss: 0.0007609715160756814\n",
      "Iteration:520, Price of Hedge: 0.09721890225063987, Loss: 0.00078683237474646\n",
      "Iteration:530, Price of Hedge: 0.0885718440392452, Loss: 0.0010276761274096824\n",
      "Iteration:540, Price of Hedge: 0.11861248268086227, Loss: 0.0008372063595665225\n",
      "Iteration:550, Price of Hedge: 0.12396721062231676, Loss: 0.0006255774591734431\n",
      "Iteration:560, Price of Hedge: 0.10290912584700322, Loss: 0.000824049488136147\n",
      "Iteration:570, Price of Hedge: 0.11542304706353547, Loss: 0.000581897414398913\n",
      "Iteration:580, Price of Hedge: 0.11789641976464509, Loss: 0.0006067530826125322\n",
      "Iteration:590, Price of Hedge: 0.11054547838114671, Loss: 0.0006392135221831685\n",
      "Iteration:600, Price of Hedge: 0.11756903750716674, Loss: 0.0005216173572902605\n",
      "Iteration:610, Price of Hedge: 0.12095308030013711, Loss: 0.0005380007059363922\n",
      "Iteration:620, Price of Hedge: 0.11805208009122907, Loss: 0.0006319072652407165\n",
      "Iteration:630, Price of Hedge: 0.10904969065188083, Loss: 0.00046611918938519457\n",
      "Iteration:640, Price of Hedge: 0.11222137463849435, Loss: 0.000508737904726364\n",
      "Iteration:650, Price of Hedge: 0.11753429666366627, Loss: 0.0005334298218502509\n",
      "Iteration:660, Price of Hedge: 0.11160975027119092, Loss: 0.0005995534450519369\n",
      "Iteration:670, Price of Hedge: 0.09981397591320729, Loss: 0.0005682207486636948\n",
      "Iteration:680, Price of Hedge: 0.09283340445125532, Loss: 0.0004906489934266122\n",
      "Iteration:690, Price of Hedge: 0.0904928830737731, Loss: 0.0005229391298784636\n",
      "Iteration:700, Price of Hedge: 0.10301791653157863, Loss: 0.0005431909056777595\n",
      "Iteration:710, Price of Hedge: 0.11423865622923017, Loss: 0.0007118927482715254\n",
      "Iteration:720, Price of Hedge: 0.1189959534837726, Loss: 0.0006136696923726869\n",
      "Iteration:730, Price of Hedge: 0.11570220638718637, Loss: 0.0006974471622177125\n",
      "Iteration:740, Price of Hedge: 0.10438099906731962, Loss: 0.000514766118910881\n",
      "Iteration:750, Price of Hedge: 0.10551174109355656, Loss: 0.0006337874990324898\n",
      "Iteration:760, Price of Hedge: 0.12722166778177665, Loss: 0.0005114550113198612\n",
      "Iteration:770, Price of Hedge: 0.11495297829118271, Loss: 0.000533347524394423\n",
      "Iteration:780, Price of Hedge: 0.11583481627847049, Loss: 0.000700558730742129\n",
      "Iteration:790, Price of Hedge: 0.1148760376154712, Loss: 0.0005845408603021518\n",
      "Iteration:800, Price of Hedge: 0.11210950251480084, Loss: 0.0005193203251048883\n",
      "Iteration:810, Price of Hedge: 0.11686868040022773, Loss: 0.0007516791505083552\n",
      "Iteration:820, Price of Hedge: 0.13230562299676762, Loss: 0.0006024488958907837\n",
      "Iteration:830, Price of Hedge: 0.14506433119544795, Loss: 0.0005883513615621005\n",
      "Iteration:840, Price of Hedge: 0.12219855351729052, Loss: 0.0007931616844478961\n",
      "Iteration:850, Price of Hedge: 0.11666083256660044, Loss: 0.0006530812391291718\n",
      "Iteration:860, Price of Hedge: 0.10638767669539959, Loss: 0.0005443196415918283\n",
      "Iteration:870, Price of Hedge: 0.10775115314706908, Loss: 0.0006281060956585093\n",
      "Iteration:880, Price of Hedge: 0.11383114384771602, Loss: 0.000541964633876657\n",
      "Iteration:890, Price of Hedge: 0.12315561673995602, Loss: 0.0005997164019563295\n",
      "Iteration:900, Price of Hedge: 0.11371665408914282, Loss: 0.0005514614525323758\n",
      "Iteration:910, Price of Hedge: 0.11422094271941319, Loss: 0.0006092940786069478\n",
      "Iteration:920, Price of Hedge: 0.11366782122097446, Loss: 0.0006226791790493236\n",
      "Iteration:930, Price of Hedge: 0.11655527580472835, Loss: 0.0004955747294498547\n",
      "Iteration:940, Price of Hedge: 0.1106991310071919, Loss: 0.0005397862331264047\n",
      "Iteration:950, Price of Hedge: 0.10594945793191073, Loss: 0.0005793826265207081\n",
      "Iteration:960, Price of Hedge: 0.10151132152820991, Loss: 0.0005897718116787632\n",
      "Iteration:970, Price of Hedge: 0.11189356034419119, Loss: 0.0004912187221346897\n",
      "Iteration:980, Price of Hedge: 0.1162554041274177, Loss: 0.0006971680557073867\n",
      "Iteration:990, Price of Hedge: 0.11807847245843844, Loss: 0.0006090307565302488\n",
      "tf.Tensor(0.10397647, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_44 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.15087224035219152, Loss: 0.0012537160667942969\n",
      "Iteration:20, Price of Hedge: 0.15685456531650174, Loss: 0.0011731384193195637\n",
      "Iteration:30, Price of Hedge: 0.10954192037195298, Loss: 0.0010811328418990128\n",
      "Iteration:40, Price of Hedge: 0.08292305150368406, Loss: 0.000821354221639492\n",
      "Iteration:50, Price of Hedge: 0.11317423185560073, Loss: 0.0010234883881133693\n",
      "Iteration:60, Price of Hedge: 0.11805798883015654, Loss: 0.0008560923847644286\n",
      "Iteration:70, Price of Hedge: 0.12302437920093894, Loss: 0.0007898146399702543\n",
      "Iteration:80, Price of Hedge: 0.10759870768274027, Loss: 0.0008352155354661938\n",
      "Iteration:90, Price of Hedge: 0.10525439962955829, Loss: 0.0008093105002358935\n",
      "Iteration:100, Price of Hedge: 0.1091077487769553, Loss: 0.0008334349719345546\n",
      "Iteration:110, Price of Hedge: 0.11466177276429902, Loss: 0.0008824256844391698\n",
      "Iteration:120, Price of Hedge: 0.11730004375586417, Loss: 0.0007936141715451983\n",
      "Iteration:130, Price of Hedge: 0.09519641715755824, Loss: 0.0008375179780391928\n",
      "Iteration:140, Price of Hedge: 0.10065556458747835, Loss: 0.0009747402992300369\n",
      "Iteration:150, Price of Hedge: 0.10095886714545656, Loss: 0.0009378730244824939\n",
      "Iteration:160, Price of Hedge: 0.10255590397531193, Loss: 0.0009100218380772239\n",
      "Iteration:170, Price of Hedge: 0.09015456011905484, Loss: 0.0008072724717444357\n",
      "Iteration:180, Price of Hedge: 0.10351731933363907, Loss: 0.0008529350016732273\n",
      "Iteration:190, Price of Hedge: 0.10645445815224547, Loss: 0.0008586152137691982\n",
      "Iteration:200, Price of Hedge: 0.1363047972795016, Loss: 0.0010132195716708646\n",
      "Iteration:210, Price of Hedge: 0.11650759927041462, Loss: 0.000895375769861717\n",
      "Iteration:220, Price of Hedge: 0.11271645071882402, Loss: 0.0009506309170528304\n",
      "Iteration:230, Price of Hedge: 0.11704568842874323, Loss: 0.0008768326341842325\n",
      "Iteration:240, Price of Hedge: 0.11100858373644086, Loss: 0.000851238026148593\n",
      "Iteration:250, Price of Hedge: 0.11637869981303765, Loss: 0.0008087688161976248\n",
      "Iteration:260, Price of Hedge: 0.11403590388874249, Loss: 0.0008696942978045463\n",
      "Iteration:270, Price of Hedge: 0.11529302939320019, Loss: 0.0010114447659829383\n",
      "Iteration:280, Price of Hedge: 0.11082500620679525, Loss: 0.0008571465665297317\n",
      "Iteration:290, Price of Hedge: 0.10427628731864899, Loss: 0.0007476994381344637\n",
      "Iteration:300, Price of Hedge: 0.11162249535752267, Loss: 0.0007821590407514955\n",
      "Iteration:310, Price of Hedge: 0.11116665838645758, Loss: 0.0009075853767281483\n",
      "Iteration:320, Price of Hedge: 0.11497738837178417, Loss: 0.0008015447574378331\n",
      "Iteration:330, Price of Hedge: 0.10242776058237836, Loss: 0.0008368335888226941\n",
      "Iteration:340, Price of Hedge: 0.12235296856126182, Loss: 0.0009143199691357572\n",
      "Iteration:350, Price of Hedge: 0.12978283290707962, Loss: 0.0006760001871187304\n",
      "Iteration:360, Price of Hedge: 0.11301209097664468, Loss: 0.0006286981111926826\n",
      "Iteration:370, Price of Hedge: 0.13402622235851708, Loss: 0.0010234557272412736\n",
      "Iteration:380, Price of Hedge: 0.1308215892105295, Loss: 0.0007530133322424914\n",
      "Iteration:390, Price of Hedge: 0.1092095442770585, Loss: 0.0005831599705427237\n",
      "Iteration:400, Price of Hedge: 0.09524091695051311, Loss: 0.0005129964754276628\n",
      "Iteration:410, Price of Hedge: 0.10045018825862825, Loss: 0.0006722002584511166\n",
      "Iteration:420, Price of Hedge: 0.11121696526261643, Loss: 0.00046270002295139\n",
      "Iteration:430, Price of Hedge: 0.11207554950315739, Loss: 0.0005730665201505447\n",
      "Iteration:440, Price of Hedge: 0.11095255872583606, Loss: 0.0004973976329874175\n",
      "Iteration:450, Price of Hedge: 0.11538341403834237, Loss: 0.0007779543753801298\n",
      "Iteration:460, Price of Hedge: 0.08744077798538967, Loss: 0.0007246509386613642\n",
      "Iteration:470, Price of Hedge: 0.1016873193529733, Loss: 0.0006826903547838991\n",
      "Iteration:480, Price of Hedge: 0.13210846172107152, Loss: 0.000569573246297228\n",
      "Iteration:490, Price of Hedge: 0.1236793851482389, Loss: 0.0006438645197154535\n",
      "Iteration:500, Price of Hedge: 0.12598395852050429, Loss: 0.000654959090364926\n",
      "Iteration:510, Price of Hedge: 0.10575244913979986, Loss: 0.0006487366482282652\n",
      "Iteration:520, Price of Hedge: 0.10017100352104648, Loss: 0.000722403195603638\n",
      "Iteration:530, Price of Hedge: 0.10388292414314719, Loss: 0.0005002469218033934\n",
      "Iteration:540, Price of Hedge: 0.11400479723735657, Loss: 0.0006457978646518202\n",
      "Iteration:550, Price of Hedge: 0.11194931850852186, Loss: 0.0006319168947379605\n",
      "Iteration:560, Price of Hedge: 0.11049869133441348, Loss: 0.0006220324639998775\n",
      "Iteration:570, Price of Hedge: 0.10459864397129763, Loss: 0.0007032949474203631\n",
      "Iteration:580, Price of Hedge: 0.09468533030077991, Loss: 0.0005327722860255513\n",
      "Iteration:590, Price of Hedge: 0.10148431922665963, Loss: 0.0007014929905211353\n",
      "Iteration:600, Price of Hedge: 0.12420091713060515, Loss: 0.0007540246776360337\n",
      "Iteration:610, Price of Hedge: 0.1233110229272313, Loss: 0.000557476264839285\n",
      "Iteration:620, Price of Hedge: 0.10741133077042946, Loss: 0.0005518344714591228\n",
      "Iteration:630, Price of Hedge: 0.11664685490462147, Loss: 0.0005476283169902451\n",
      "Iteration:640, Price of Hedge: 0.1018327632793472, Loss: 0.000564386521116722\n",
      "Iteration:650, Price of Hedge: 0.09131589416457757, Loss: 0.0004403277226584734\n",
      "Iteration:660, Price of Hedge: 0.1061058298485591, Loss: 0.0005562017462787949\n",
      "Iteration:670, Price of Hedge: 0.11359506113689122, Loss: 0.0005412652544118712\n",
      "Iteration:680, Price of Hedge: 0.11178192965284096, Loss: 0.0005782348301584861\n",
      "Iteration:690, Price of Hedge: 0.11059851725487418, Loss: 0.0004985755091193811\n",
      "Iteration:700, Price of Hedge: 0.10445779361292863, Loss: 0.0006264095668631286\n",
      "Iteration:710, Price of Hedge: 0.1034945548050615, Loss: 0.0005347407736632004\n",
      "Iteration:720, Price of Hedge: 0.10230105943002171, Loss: 0.0005585214623829326\n",
      "Iteration:730, Price of Hedge: 0.1117028923278326, Loss: 0.0005420824214898534\n",
      "Iteration:740, Price of Hedge: 0.11362734953606263, Loss: 0.000523490145594474\n",
      "Iteration:750, Price of Hedge: 0.11252674843183853, Loss: 0.0004700993484883398\n",
      "Iteration:760, Price of Hedge: 0.11862883654537767, Loss: 0.0005751966245048256\n",
      "Iteration:770, Price of Hedge: 0.10616269351888263, Loss: 0.0005712032620704077\n",
      "Iteration:780, Price of Hedge: 0.11507336408171795, Loss: 0.000539647002509036\n",
      "Iteration:790, Price of Hedge: 0.11089254372808455, Loss: 0.0005514684016540983\n",
      "Iteration:800, Price of Hedge: 0.10529329565075612, Loss: 0.000508266307544325\n",
      "Iteration:810, Price of Hedge: 0.11384618889479156, Loss: 0.0005143747840847368\n",
      "Iteration:820, Price of Hedge: 0.12233055347423373, Loss: 0.0007390280758662104\n",
      "Iteration:830, Price of Hedge: 0.11960217739076597, Loss: 0.0005024397667995117\n",
      "Iteration:840, Price of Hedge: 0.10248045636803908, Loss: 0.0006066351957261684\n",
      "Iteration:850, Price of Hedge: 0.1038681904167248, Loss: 0.000690545890161931\n",
      "Iteration:860, Price of Hedge: 0.11147085043201627, Loss: 0.00046743743777595266\n",
      "Iteration:870, Price of Hedge: 0.10832390690710553, Loss: 0.0006029375680576265\n",
      "Iteration:880, Price of Hedge: 0.09702794832755898, Loss: 0.0005753807762304718\n",
      "Iteration:890, Price of Hedge: 0.10532229294587978, Loss: 0.0006785071820532895\n",
      "Iteration:900, Price of Hedge: 0.11892492154698857, Loss: 0.0005247315565536148\n",
      "Iteration:910, Price of Hedge: 0.12255748716994502, Loss: 0.0005133179219439121\n",
      "Iteration:920, Price of Hedge: 0.11337782285580715, Loss: 0.0005094366389155613\n",
      "Iteration:930, Price of Hedge: 0.11368838109104899, Loss: 0.00047255199136371213\n",
      "Iteration:940, Price of Hedge: 0.11043232285394423, Loss: 0.000533028609343944\n",
      "Iteration:950, Price of Hedge: 0.11221917633347402, Loss: 0.0006422148974916997\n",
      "Iteration:960, Price of Hedge: 0.12789687780411896, Loss: 0.0005397887149555913\n",
      "Iteration:970, Price of Hedge: 0.10845830848051605, Loss: 0.0005982251700712649\n",
      "Iteration:980, Price of Hedge: 0.11372833179037797, Loss: 0.0005754226695071418\n",
      "Iteration:990, Price of Hedge: 0.11229128836232007, Loss: 0.0005359993092437287\n",
      "tf.Tensor(0.142809, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_45 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.10358190248546463, Loss: 0.0012725741962321456\n",
      "Iteration:20, Price of Hedge: 0.1449883816630404, Loss: 0.0011071868861536772\n",
      "Iteration:30, Price of Hedge: 0.13011992328615066, Loss: 0.0011962484185199073\n",
      "Iteration:40, Price of Hedge: 0.13007472461009684, Loss: 0.0009570862540403623\n",
      "Iteration:50, Price of Hedge: 0.13732859748463397, Loss: 0.001179089845709047\n",
      "Iteration:60, Price of Hedge: 0.12961343635085995, Loss: 0.0012827880153398752\n",
      "Iteration:70, Price of Hedge: 0.13346696339577305, Loss: 0.0013663726470571013\n",
      "Iteration:80, Price of Hedge: 0.13018376308049823, Loss: 0.0013988478783296897\n",
      "Iteration:90, Price of Hedge: 0.12684433444317164, Loss: 0.001326905408053669\n",
      "Iteration:100, Price of Hedge: 0.11951223748941402, Loss: 0.0014184427139432908\n",
      "Iteration:110, Price of Hedge: 0.1267162355246171, Loss: 0.0011544630517830168\n",
      "Iteration:120, Price of Hedge: 0.1426963246517289, Loss: 0.0013434929616052747\n",
      "Iteration:130, Price of Hedge: 0.12447101638790059, Loss: 0.0011072088255236867\n",
      "Iteration:140, Price of Hedge: 0.14481990000833206, Loss: 0.0013014408478674076\n",
      "Iteration:150, Price of Hedge: 0.12684913767610623, Loss: 0.0010728184163043774\n",
      "Iteration:160, Price of Hedge: 0.12806377108814784, Loss: 0.0009347211014155032\n",
      "Iteration:170, Price of Hedge: 0.13718863026036274, Loss: 0.0011643847099588988\n",
      "Iteration:180, Price of Hedge: 0.13204077171619702, Loss: 0.001352640586894438\n",
      "Iteration:190, Price of Hedge: 0.1307858953446214, Loss: 0.0013651742213794725\n",
      "Iteration:200, Price of Hedge: 0.1415781116934113, Loss: 0.0009495710767169818\n",
      "Iteration:210, Price of Hedge: 0.13105374546903475, Loss: 0.001379085072516739\n",
      "Iteration:220, Price of Hedge: 0.1561776906816874, Loss: 0.0014765362795385428\n",
      "Iteration:230, Price of Hedge: 0.1334973203361983, Loss: 0.0012847657353820983\n",
      "Iteration:240, Price of Hedge: 0.12574488967280217, Loss: 0.0010571654203512804\n",
      "Iteration:250, Price of Hedge: 0.1469052655198709, Loss: 0.0011967564985909895\n",
      "Iteration:260, Price of Hedge: 0.13605430486987302, Loss: 0.001443672294542164\n",
      "Iteration:270, Price of Hedge: 0.14316358518472042, Loss: 0.001255077101920232\n",
      "Iteration:280, Price of Hedge: 0.13521487002624324, Loss: 0.0011915821825564164\n",
      "Iteration:290, Price of Hedge: 0.10639279124898735, Loss: 0.0012502186731045304\n",
      "Iteration:300, Price of Hedge: 0.12563993013830554, Loss: 0.0013316669462579255\n",
      "Iteration:310, Price of Hedge: 0.12671238531409015, Loss: 0.0011745621950873363\n",
      "Iteration:320, Price of Hedge: 0.12409270461295704, Loss: 0.0011407428051272816\n",
      "Iteration:330, Price of Hedge: 0.12626977629404337, Loss: 0.0008891214610383002\n",
      "Iteration:340, Price of Hedge: 0.14438499140933914, Loss: 0.0011780675306305\n",
      "Iteration:350, Price of Hedge: 0.14861252256791316, Loss: 0.00112913181546066\n",
      "Iteration:360, Price of Hedge: 0.14202557477425443, Loss: 0.0010445507789615949\n",
      "Iteration:370, Price of Hedge: 0.14464228204547566, Loss: 0.0012922876632808665\n",
      "Iteration:380, Price of Hedge: 0.1317401249139948, Loss: 0.0013868057452967708\n",
      "Iteration:390, Price of Hedge: 0.13463215400530543, Loss: 0.0008541828653882532\n",
      "Iteration:400, Price of Hedge: 0.12588741099712591, Loss: 0.0010065106910136289\n",
      "Iteration:410, Price of Hedge: 0.12546576847004756, Loss: 0.001134763482977741\n",
      "Iteration:420, Price of Hedge: 0.12557353624390544, Loss: 0.0010411616922975319\n",
      "Iteration:430, Price of Hedge: 0.11834068069019849, Loss: 0.0011778187520728345\n",
      "Iteration:440, Price of Hedge: 0.12278560261344182, Loss: 0.0012069715089767284\n",
      "Iteration:450, Price of Hedge: 0.1324085240028637, Loss: 0.0014087790667296485\n",
      "Iteration:460, Price of Hedge: 0.13365157018961896, Loss: 0.0010977020299146377\n",
      "Iteration:470, Price of Hedge: 0.13965090978064723, Loss: 0.0011567443491713458\n",
      "Iteration:480, Price of Hedge: 0.14503965426857235, Loss: 0.0014213457591794485\n",
      "Iteration:490, Price of Hedge: 0.11801739007559035, Loss: 0.0010269317772000353\n",
      "Iteration:500, Price of Hedge: 0.1087440500122625, Loss: 0.0011442071408522825\n",
      "Iteration:510, Price of Hedge: 0.13133645003604213, Loss: 0.0014043567449386174\n",
      "Iteration:520, Price of Hedge: 0.13948982357982231, Loss: 0.0011696354663324193\n",
      "Iteration:530, Price of Hedge: 0.13744021546901877, Loss: 0.00104050678721177\n",
      "Iteration:540, Price of Hedge: 0.13508058281552165, Loss: 0.0012599291772532161\n",
      "Iteration:550, Price of Hedge: 0.15941956794536621, Loss: 0.0011914408175659474\n",
      "Iteration:560, Price of Hedge: 0.14108870291966583, Loss: 0.0012383812413429228\n",
      "Iteration:570, Price of Hedge: 0.13709135843995454, Loss: 0.0010631597327491083\n",
      "Iteration:580, Price of Hedge: 0.1317846755348114, Loss: 0.0013222181261786758\n",
      "Iteration:590, Price of Hedge: 0.12840838399075663, Loss: 0.0012305439225911206\n",
      "Iteration:600, Price of Hedge: 0.11522809679982515, Loss: 0.000965760147774386\n",
      "Iteration:610, Price of Hedge: 0.13314427000854037, Loss: 0.0008136655148193838\n",
      "Iteration:620, Price of Hedge: 0.13912298619466695, Loss: 0.001138344861767182\n",
      "Iteration:630, Price of Hedge: 0.12919354738501168, Loss: 0.0015323737631300015\n",
      "Iteration:640, Price of Hedge: 0.11193748832370147, Loss: 0.001364030594490284\n",
      "Iteration:650, Price of Hedge: 0.12787765216541516, Loss: 0.0012564432992508755\n",
      "Iteration:660, Price of Hedge: 0.12062489750383633, Loss: 0.0012286486985510602\n",
      "Iteration:670, Price of Hedge: 0.14397774587409912, Loss: 0.0010367887092707305\n",
      "Iteration:680, Price of Hedge: 0.12855544170174085, Loss: 0.0010143805713643593\n",
      "Iteration:690, Price of Hedge: 0.12718561812083634, Loss: 0.0013978667616156403\n",
      "Iteration:700, Price of Hedge: 0.14705304752788492, Loss: 0.0013511559566750098\n",
      "Iteration:710, Price of Hedge: 0.13096064153328937, Loss: 0.0012237968217644112\n",
      "Iteration:720, Price of Hedge: 0.12119848992359152, Loss: 0.0012180789851379715\n",
      "Iteration:730, Price of Hedge: 0.12129530429324403, Loss: 0.0010633201581877305\n",
      "Iteration:740, Price of Hedge: 0.11985460125914073, Loss: 0.0014035846975152476\n",
      "Iteration:750, Price of Hedge: 0.12415167763954287, Loss: 0.001134753257841492\n",
      "Iteration:760, Price of Hedge: 0.12386648250731014, Loss: 0.0012872883658405331\n",
      "Iteration:770, Price of Hedge: 0.11510210723753289, Loss: 0.0011326010155708664\n",
      "Iteration:780, Price of Hedge: 0.1283475049193555, Loss: 0.0009491561148769811\n",
      "Iteration:790, Price of Hedge: 0.13808834694801816, Loss: 0.0009443173421484374\n",
      "Iteration:800, Price of Hedge: 0.13853013001531167, Loss: 0.001003069188117145\n",
      "Iteration:810, Price of Hedge: 0.1299071070290381, Loss: 0.0013414410845069558\n",
      "Iteration:820, Price of Hedge: 0.13239706232004095, Loss: 0.001112563917996212\n",
      "Iteration:830, Price of Hedge: 0.15138393714331072, Loss: 0.0011215446650908677\n",
      "Iteration:840, Price of Hedge: 0.15592545741779418, Loss: 0.0010440956114887712\n",
      "Iteration:850, Price of Hedge: 0.15804393728125773, Loss: 0.0008115882237901939\n",
      "Iteration:860, Price of Hedge: 0.13682983638432802, Loss: 0.0008089446786137877\n",
      "Iteration:870, Price of Hedge: 0.14231877529471149, Loss: 0.0007745710961963636\n",
      "Iteration:880, Price of Hedge: 0.14644597225420738, Loss: 0.0008028611196384094\n",
      "Iteration:890, Price of Hedge: 0.14494967624632407, Loss: 0.001395098727887234\n",
      "Iteration:900, Price of Hedge: 0.15368424097518982, Loss: 0.0007960814075761879\n",
      "Iteration:910, Price of Hedge: 0.1303914965514366, Loss: 0.0007090197828051092\n",
      "Iteration:920, Price of Hedge: 0.12662630833023059, Loss: 0.0006928730021170448\n",
      "Iteration:930, Price of Hedge: 0.11911519564741865, Loss: 0.0009655435337229789\n",
      "Iteration:940, Price of Hedge: 0.10771707306577127, Loss: 0.0009657974744853525\n",
      "Iteration:950, Price of Hedge: 0.11455198458293693, Loss: 0.0007838863442287901\n",
      "Iteration:960, Price of Hedge: 0.1160871130771909, Loss: 0.0008195121583806086\n",
      "Iteration:970, Price of Hedge: 0.13136539650330406, Loss: 0.0006588918961671908\n",
      "Iteration:980, Price of Hedge: 0.13214250368147304, Loss: 0.0008918643786553381\n",
      "Iteration:990, Price of Hedge: 0.12646022829198955, Loss: 0.0009563463711232511\n",
      "tf.Tensor(0.13629928, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_46 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.11640319884239715, Loss: 0.0011023109852605017\n",
      "Iteration:20, Price of Hedge: 0.09478640785733602, Loss: 0.0009928942840910615\n",
      "Iteration:30, Price of Hedge: 0.09362929887782058, Loss: 0.000917976497712969\n",
      "Iteration:40, Price of Hedge: 0.0980821817149092, Loss: 0.0008570339907578272\n",
      "Iteration:50, Price of Hedge: 0.10423244193441406, Loss: 0.0008161814939755984\n",
      "Iteration:60, Price of Hedge: 0.11378212037506613, Loss: 0.0009449633126491275\n",
      "Iteration:70, Price of Hedge: 0.1265070534596191, Loss: 0.000975067900682669\n",
      "Iteration:80, Price of Hedge: 0.11374067025381578, Loss: 0.000862454802067214\n",
      "Iteration:90, Price of Hedge: 0.1183925886440022, Loss: 0.0010346499681508803\n",
      "Iteration:100, Price of Hedge: 0.1132151101634065, Loss: 0.0013127288026471007\n",
      "Iteration:110, Price of Hedge: 0.12036134233374013, Loss: 0.0010922969037657105\n",
      "Iteration:120, Price of Hedge: 0.1269505900881427, Loss: 0.0011073285489636485\n",
      "Iteration:130, Price of Hedge: 0.12282077549376708, Loss: 0.0008920152738698838\n",
      "Iteration:140, Price of Hedge: 0.11140701063766868, Loss: 0.0009629892351241231\n",
      "Iteration:150, Price of Hedge: 0.1409688635286443, Loss: 0.0011074867903925866\n",
      "Iteration:160, Price of Hedge: 0.12292184669684048, Loss: 0.0007022297959700551\n",
      "Iteration:170, Price of Hedge: 0.12097845611011165, Loss: 0.0009706768499393891\n",
      "Iteration:180, Price of Hedge: 0.1297453092381488, Loss: 0.0008193986395136132\n",
      "Iteration:190, Price of Hedge: 0.11486738417200967, Loss: 0.0009177342711843561\n",
      "Iteration:200, Price of Hedge: 0.10915928822876139, Loss: 0.0009976764711141506\n",
      "Iteration:210, Price of Hedge: 0.10966367851475524, Loss: 0.0008975416125562852\n",
      "Iteration:220, Price of Hedge: 0.11007178812364486, Loss: 0.000788663766139841\n",
      "Iteration:230, Price of Hedge: 0.1173930206219552, Loss: 0.0007896055706795745\n",
      "Iteration:240, Price of Hedge: 0.1167026003619867, Loss: 0.0009100286879257791\n",
      "Iteration:250, Price of Hedge: 0.09732539297447146, Loss: 0.000710136109573245\n",
      "Iteration:260, Price of Hedge: 0.08454086422202635, Loss: 0.0008416907270872186\n",
      "Iteration:270, Price of Hedge: 0.09076241051762395, Loss: 0.0009603876824975543\n",
      "Iteration:280, Price of Hedge: 0.10126947620856014, Loss: 0.0010414953494133794\n",
      "Iteration:290, Price of Hedge: 0.09585277004319437, Loss: 0.0010547899127270276\n",
      "Iteration:300, Price of Hedge: 0.1081857313649607, Loss: 0.00097788547172164\n",
      "Iteration:310, Price of Hedge: 0.11083978440759665, Loss: 0.001045594934136984\n",
      "Iteration:320, Price of Hedge: 0.1293139204685815, Loss: 0.0009073735277887795\n",
      "Iteration:330, Price of Hedge: 0.1232606652232107, Loss: 0.0009495461591519482\n",
      "Iteration:340, Price of Hedge: 0.10295067127049434, Loss: 0.0007465429057335049\n",
      "Iteration:350, Price of Hedge: 0.12049552788873824, Loss: 0.0009410627706262886\n",
      "Iteration:360, Price of Hedge: 0.11927133883868918, Loss: 0.0008778710315159088\n",
      "Iteration:370, Price of Hedge: 0.12141199235683757, Loss: 0.0010981351587442845\n",
      "Iteration:380, Price of Hedge: 0.12328399521175015, Loss: 0.000917752438174002\n",
      "Iteration:390, Price of Hedge: 0.10185526096165062, Loss: 0.0007364604250263306\n",
      "Iteration:400, Price of Hedge: 0.11156394166079621, Loss: 0.0010016779739483006\n",
      "Iteration:410, Price of Hedge: 0.11978323894125537, Loss: 0.0008729143222644175\n",
      "Iteration:420, Price of Hedge: 0.10864823949287938, Loss: 0.0008729281212346951\n",
      "Iteration:430, Price of Hedge: 0.11521375063584854, Loss: 0.0009291188187559918\n",
      "Iteration:440, Price of Hedge: 0.11008108962234359, Loss: 0.0008506538035580657\n",
      "Iteration:450, Price of Hedge: 0.11891573441097875, Loss: 0.0009446856455997298\n",
      "Iteration:460, Price of Hedge: 0.12434801296248565, Loss: 0.0010345059227848895\n",
      "Iteration:470, Price of Hedge: 0.10025646421708245, Loss: 0.000854898922745173\n",
      "Iteration:480, Price of Hedge: 0.11927757795871798, Loss: 0.0008961166455105029\n",
      "Iteration:490, Price of Hedge: 0.1080046698144713, Loss: 0.0009186814364751327\n",
      "Iteration:500, Price of Hedge: 0.09621614478026856, Loss: 0.0008937157239553794\n",
      "Iteration:510, Price of Hedge: 0.08432727284002225, Loss: 0.0008706217077349976\n",
      "Iteration:520, Price of Hedge: 0.11535488690093984, Loss: 0.0008163043445203354\n",
      "Iteration:530, Price of Hedge: 0.1077911165533635, Loss: 0.0008200939984151167\n",
      "Iteration:540, Price of Hedge: 0.10964647328355567, Loss: 0.0008889346289371325\n",
      "Iteration:550, Price of Hedge: 0.09166013856518873, Loss: 0.0008490307865431923\n",
      "Iteration:560, Price of Hedge: 0.10771725096328737, Loss: 0.0008317977092201501\n",
      "Iteration:570, Price of Hedge: 0.11298515220992157, Loss: 0.0008297943270641372\n",
      "Iteration:580, Price of Hedge: 0.12705122925439127, Loss: 0.0008587028719760692\n",
      "Iteration:590, Price of Hedge: 0.12014940285724264, Loss: 0.0008289462860310736\n",
      "Iteration:600, Price of Hedge: 0.10997943389886017, Loss: 0.0010847927457639183\n",
      "Iteration:610, Price of Hedge: 0.11457024449226764, Loss: 0.0010812307252421327\n",
      "Iteration:620, Price of Hedge: 0.10727784409853029, Loss: 0.0008126886172149517\n",
      "Iteration:630, Price of Hedge: 0.13948265685131672, Loss: 0.0008830999477925871\n",
      "Iteration:640, Price of Hedge: 0.12778378581174366, Loss: 0.0008708008958022706\n",
      "Iteration:650, Price of Hedge: 0.10172341348829263, Loss: 0.0008846405680784653\n",
      "Iteration:660, Price of Hedge: 0.11418969629140746, Loss: 0.0010111482370317225\n",
      "Iteration:670, Price of Hedge: 0.11968514116809387, Loss: 0.0009306206232333913\n",
      "Iteration:680, Price of Hedge: 0.11018278346672332, Loss: 0.0007361570958631436\n",
      "Iteration:690, Price of Hedge: 0.12565596632868506, Loss: 0.0008887311189438307\n",
      "Iteration:700, Price of Hedge: 0.09975242337263807, Loss: 0.0007079455478599783\n",
      "Iteration:710, Price of Hedge: 0.09356941094972342, Loss: 0.0007545618447451829\n",
      "Iteration:720, Price of Hedge: 0.09620373642852087, Loss: 0.0006002730762428854\n",
      "Iteration:730, Price of Hedge: 0.1143267917414903, Loss: 0.0006490934856287155\n",
      "Iteration:740, Price of Hedge: 0.13366169764107097, Loss: 0.0007798828062947072\n",
      "Iteration:750, Price of Hedge: 0.12744745785059877, Loss: 0.0006361306436041491\n",
      "Iteration:760, Price of Hedge: 0.10550654394469347, Loss: 0.0007294178376166637\n",
      "Iteration:770, Price of Hedge: 0.08725902390528403, Loss: 0.0007996398046273612\n",
      "Iteration:780, Price of Hedge: 0.10091617174159352, Loss: 0.0007557686590054624\n",
      "Iteration:790, Price of Hedge: 0.12303195255233845, Loss: 0.0006397731250281646\n",
      "Iteration:800, Price of Hedge: 0.13806697383215577, Loss: 0.0006631679389459632\n",
      "Iteration:810, Price of Hedge: 0.11966878730357848, Loss: 0.0006361926893338143\n",
      "Iteration:820, Price of Hedge: 0.11690774161197623, Loss: 0.0005174679374365887\n",
      "Iteration:830, Price of Hedge: 0.10871755598932964, Loss: 0.0008388745458725921\n",
      "Iteration:840, Price of Hedge: 0.10117429468396608, Loss: 0.0005220504364833234\n",
      "Iteration:850, Price of Hedge: 0.11086626572356408, Loss: 0.0005108798722241569\n",
      "Iteration:860, Price of Hedge: 0.10409135014370179, Loss: 0.0006049727176272279\n",
      "Iteration:870, Price of Hedge: 0.114268797151243, Loss: 0.0006465083627113621\n",
      "Iteration:880, Price of Hedge: 0.12069980506507817, Loss: 0.0006161847284338106\n",
      "Iteration:890, Price of Hedge: 0.10845265388089728, Loss: 0.0006785947409869929\n",
      "Iteration:900, Price of Hedge: 0.11262995440510508, Loss: 0.0006297786996205312\n",
      "Iteration:910, Price of Hedge: 0.11244283163210297, Loss: 0.0003739968419014139\n",
      "Iteration:920, Price of Hedge: 0.10791992706198243, Loss: 0.0006994024465240889\n",
      "Iteration:930, Price of Hedge: 0.11482401529897857, Loss: 0.00046194579506158017\n",
      "Iteration:940, Price of Hedge: 0.12165012088909748, Loss: 0.000538182177286517\n",
      "Iteration:950, Price of Hedge: 0.10523275331393904, Loss: 0.0004835020202813567\n",
      "Iteration:960, Price of Hedge: 0.10208345900042275, Loss: 0.0005696497362727592\n",
      "Iteration:970, Price of Hedge: 0.11288268324065029, Loss: 0.0005136813113734151\n",
      "Iteration:980, Price of Hedge: 0.10910387315249749, Loss: 0.000686424117885398\n",
      "Iteration:990, Price of Hedge: 0.11359981354196406, Loss: 0.0005341409651853812\n",
      "tf.Tensor(0.100548744, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_47 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.13214076282720838, Loss: 0.0013039838293251726\n",
      "Iteration:20, Price of Hedge: 0.13661670245307958, Loss: 0.0011640861955443337\n",
      "Iteration:30, Price of Hedge: 0.11015775074481553, Loss: 0.0007820955059243184\n",
      "Iteration:40, Price of Hedge: 0.08825072631572652, Loss: 0.0008773739707664151\n",
      "Iteration:50, Price of Hedge: 0.09794471776282876, Loss: 0.0008322151032527535\n",
      "Iteration:60, Price of Hedge: 0.10666283967842105, Loss: 0.0010242613289952462\n",
      "Iteration:70, Price of Hedge: 0.11793597654804557, Loss: 0.0009466406320866039\n",
      "Iteration:80, Price of Hedge: 0.12339079725623492, Loss: 0.0008693760280296558\n",
      "Iteration:90, Price of Hedge: 0.1419210726905135, Loss: 0.0010338835792980561\n",
      "Iteration:100, Price of Hedge: 0.14401143203946845, Loss: 0.0010084948638117374\n",
      "Iteration:110, Price of Hedge: 0.13403521889004535, Loss: 0.0010392264611709834\n",
      "Iteration:120, Price of Hedge: 0.11057776678031814, Loss: 0.0008159521729587559\n",
      "Iteration:130, Price of Hedge: 0.10434672202805756, Loss: 0.001005033804101263\n",
      "Iteration:140, Price of Hedge: 0.10052817725898819, Loss: 0.000971477785854491\n",
      "Iteration:150, Price of Hedge: 0.10673654007794653, Loss: 0.0009305805168737357\n",
      "Iteration:160, Price of Hedge: 0.10148414132914353, Loss: 0.0008680702880579982\n",
      "Iteration:170, Price of Hedge: 0.11861659973766336, Loss: 0.0011321744387702726\n",
      "Iteration:180, Price of Hedge: 0.10915673412870887, Loss: 0.0010964932798275928\n",
      "Iteration:190, Price of Hedge: 0.1067626401849509, Loss: 0.0009704552722296089\n",
      "Iteration:200, Price of Hedge: 0.125889660130008, Loss: 0.0009103939139088801\n",
      "Iteration:210, Price of Hedge: 0.12385682521357921, Loss: 0.000825782102727901\n",
      "Iteration:220, Price of Hedge: 0.12447212189389346, Loss: 0.0010595427148925474\n",
      "Iteration:230, Price of Hedge: 0.12971905664755923, Loss: 0.0007883668400959553\n",
      "Iteration:240, Price of Hedge: 0.1241181566647242, Loss: 0.0009679202326252412\n",
      "Iteration:250, Price of Hedge: 0.12549378732883268, Loss: 0.0009035064408233762\n",
      "Iteration:260, Price of Hedge: 0.10733835466793379, Loss: 0.0006811491388590162\n",
      "Iteration:270, Price of Hedge: 0.11811721599605107, Loss: 0.0009729110918463401\n",
      "Iteration:280, Price of Hedge: 0.11715970802959531, Loss: 0.0008092296422409939\n",
      "Iteration:290, Price of Hedge: 0.1163283929368788, Loss: 0.0010040415687924576\n",
      "Iteration:300, Price of Hedge: 0.11535395929246306, Loss: 0.0009967084584582063\n",
      "Iteration:310, Price of Hedge: 0.10791999059680961, Loss: 0.0008550877403096901\n",
      "Iteration:320, Price of Hedge: 0.0968112755064368, Loss: 0.0008304166705509707\n",
      "Iteration:330, Price of Hedge: 0.10050519671199822, Loss: 0.0010889095047454944\n",
      "Iteration:340, Price of Hedge: 0.09906017330964687, Loss: 0.0009655292383868641\n",
      "Iteration:350, Price of Hedge: 0.12317706609761103, Loss: 0.0008568491441200087\n",
      "Iteration:360, Price of Hedge: 0.11867624623341726, Loss: 0.0008374025233454318\n",
      "Iteration:370, Price of Hedge: 0.10586628448965313, Loss: 0.0009589967661482123\n",
      "Iteration:380, Price of Hedge: 0.09327745571187904, Loss: 0.0007557414085209934\n",
      "Iteration:390, Price of Hedge: 0.08026720677892171, Loss: 0.0008819099603341929\n",
      "Iteration:400, Price of Hedge: 0.10501831691873348, Loss: 0.0008195246171631254\n",
      "Iteration:410, Price of Hedge: 0.11936613280083747, Loss: 0.0011067695417576573\n",
      "Iteration:420, Price of Hedge: 0.11979730555199239, Loss: 0.0008313198578285607\n",
      "Iteration:430, Price of Hedge: 0.10542952702718934, Loss: 0.000708218549070505\n",
      "Iteration:440, Price of Hedge: 0.10610180174051606, Loss: 0.0008035725607930421\n",
      "Iteration:450, Price of Hedge: 0.09075596808614818, Loss: 0.0007823451283039073\n",
      "Iteration:460, Price of Hedge: 0.11196231773416229, Loss: 0.0008757674330973408\n",
      "Iteration:470, Price of Hedge: 0.10018623917260355, Loss: 0.0007872894284094655\n",
      "Iteration:480, Price of Hedge: 0.11453530033732022, Loss: 0.0014749030373874205\n",
      "Iteration:490, Price of Hedge: 0.11463430030502764, Loss: 0.000855383872168236\n",
      "Iteration:500, Price of Hedge: 0.1318889743071054, Loss: 0.0009753446742735594\n",
      "Iteration:510, Price of Hedge: 0.12880209660780792, Loss: 0.0006859658233077992\n",
      "Iteration:520, Price of Hedge: 0.11884812064789685, Loss: 0.0008536448048205969\n",
      "Iteration:530, Price of Hedge: 0.09703787246756405, Loss: 0.000705418201926089\n",
      "Iteration:540, Price of Hedge: 0.08610916424954951, Loss: 0.00051358069801819\n",
      "Iteration:550, Price of Hedge: 0.11255580926178936, Loss: 0.0007453911384445843\n",
      "Iteration:560, Price of Hedge: 0.12165628376733366, Loss: 0.0007780359779237855\n",
      "Iteration:570, Price of Hedge: 0.11251615082266539, Loss: 0.00064149844304211\n",
      "Iteration:580, Price of Hedge: 0.10935667822983532, Loss: 0.0006902753211440071\n",
      "Iteration:590, Price of Hedge: 0.10537198988769773, Loss: 0.0006125249734786564\n",
      "Iteration:600, Price of Hedge: 0.1143685468299111, Loss: 0.0005492359466641616\n",
      "Iteration:610, Price of Hedge: 0.11990372638751409, Loss: 0.0005619151156126988\n",
      "Iteration:620, Price of Hedge: 0.12129042481851683, Loss: 0.0005711923420219867\n",
      "Iteration:630, Price of Hedge: 0.11461353712350614, Loss: 0.0005850767864967076\n",
      "Iteration:640, Price of Hedge: 0.10932832898994888, Loss: 0.0005965014404279989\n",
      "Iteration:650, Price of Hedge: 0.11646011334058243, Loss: 0.0005544805481012993\n",
      "Iteration:660, Price of Hedge: 0.1246729936034967, Loss: 0.0007737278699119221\n",
      "Iteration:670, Price of Hedge: 0.11344715205922284, Loss: 0.0005720987556775192\n",
      "Iteration:680, Price of Hedge: 0.10234720477500048, Loss: 0.0004337760906985011\n",
      "Iteration:690, Price of Hedge: 0.09738171659876399, Loss: 0.000592096491441274\n",
      "Iteration:700, Price of Hedge: 0.12562067908567087, Loss: 0.0005792773969631959\n",
      "Iteration:710, Price of Hedge: 0.11035426396527441, Loss: 0.0006652938738272106\n",
      "Iteration:720, Price of Hedge: 0.1031979234039369, Loss: 0.0005652165937064746\n",
      "Iteration:730, Price of Hedge: 0.10783444730549831, Loss: 0.0004962344989208222\n",
      "Iteration:740, Price of Hedge: 0.11461720943651699, Loss: 0.000572105655162658\n",
      "Iteration:750, Price of Hedge: 0.12191563293187073, Loss: 0.0006334080769864413\n",
      "Iteration:760, Price of Hedge: 0.11109590600291312, Loss: 0.0005188137341313181\n",
      "Iteration:770, Price of Hedge: 0.12008251339119055, Loss: 0.0006582088967750366\n",
      "Iteration:780, Price of Hedge: 0.12232665243584506, Loss: 0.000645612422374997\n",
      "Iteration:790, Price of Hedge: 0.10236293599820953, Loss: 0.0004843833674621045\n",
      "Iteration:800, Price of Hedge: 0.0963394404658885, Loss: 0.0005620239686408235\n",
      "Iteration:810, Price of Hedge: 0.0969151168279751, Loss: 0.0005617934067093877\n",
      "Iteration:820, Price of Hedge: 0.09830655495708526, Loss: 0.0006035705834099625\n",
      "Iteration:830, Price of Hedge: 0.11130699411272643, Loss: 0.0005342830747246064\n",
      "Iteration:840, Price of Hedge: 0.12334897863298692, Loss: 0.0005916055359915795\n",
      "Iteration:850, Price of Hedge: 0.12831374251219357, Loss: 0.0006117787867154111\n",
      "Iteration:860, Price of Hedge: 0.11269248538201282, Loss: 0.0004863929541910838\n",
      "Iteration:870, Price of Hedge: 0.11763684187473017, Loss: 0.0005194305679573574\n",
      "Iteration:880, Price of Hedge: 0.12217993781292762, Loss: 0.0005427440771510028\n",
      "Iteration:890, Price of Hedge: 0.10633238233530733, Loss: 0.00048411657082454425\n",
      "Iteration:900, Price of Hedge: 0.11406742986998779, Loss: 0.0006087227118916072\n",
      "Iteration:910, Price of Hedge: 0.11025187123779573, Loss: 0.00044697381303728797\n",
      "Iteration:920, Price of Hedge: 0.10332924989171204, Loss: 0.0006687256479532833\n",
      "Iteration:930, Price of Hedge: 0.11068989304332034, Loss: 0.0005165985526725203\n",
      "Iteration:940, Price of Hedge: 0.11718593520625403, Loss: 0.0005713293886296711\n",
      "Iteration:950, Price of Hedge: 0.09567341122607331, Loss: 0.0006011305482268581\n",
      "Iteration:960, Price of Hedge: 0.10170777756732434, Loss: 0.0004985829546069409\n",
      "Iteration:970, Price of Hedge: 0.10422828675671666, Loss: 0.0005339904174269216\n",
      "Iteration:980, Price of Hedge: 0.10928169442680086, Loss: 0.0006968650740002857\n",
      "Iteration:990, Price of Hedge: 0.1223394737639694, Loss: 0.0006083553018988219\n",
      "tf.Tensor(0.109993726, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_48 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.14316957016544052, Loss: 0.001651579791343094\n",
      "Iteration:20, Price of Hedge: 0.10158984422111814, Loss: 0.000735425055526262\n",
      "Iteration:30, Price of Hedge: 0.0815576181793375, Loss: 0.0007487015014868481\n",
      "Iteration:40, Price of Hedge: 0.10833328464759688, Loss: 0.0007297210178700996\n",
      "Iteration:50, Price of Hedge: 0.10399299823123158, Loss: 0.0007440724929611564\n",
      "Iteration:60, Price of Hedge: 0.0989141702767938, Loss: 0.0008968594073494706\n",
      "Iteration:70, Price of Hedge: 0.10888089132303662, Loss: 0.0006631421775590063\n",
      "Iteration:80, Price of Hedge: 0.10638790542077742, Loss: 0.0006410438215717074\n",
      "Iteration:90, Price of Hedge: 0.1052056239427344, Loss: 0.0008154335699319226\n",
      "Iteration:100, Price of Hedge: 0.08887475268129491, Loss: 0.000753208900382396\n",
      "Iteration:110, Price of Hedge: 0.09331405812581578, Loss: 0.0005756273211418694\n",
      "Iteration:120, Price of Hedge: 0.11251838724858203, Loss: 0.0008204812134048111\n",
      "Iteration:130, Price of Hedge: 0.11507622314894092, Loss: 0.0006975966179713299\n",
      "Iteration:140, Price of Hedge: 0.10171955692428297, Loss: 0.0007477254477043393\n",
      "Iteration:150, Price of Hedge: 0.10909965443997294, Loss: 0.0006992413758098781\n",
      "Iteration:160, Price of Hedge: 0.10506939256630118, Loss: 0.0006985703884709871\n",
      "Iteration:170, Price of Hedge: 0.08604975918613889, Loss: 0.0007213987496952345\n",
      "Iteration:180, Price of Hedge: 0.08949080542605259, Loss: 0.0006903154275036626\n",
      "Iteration:190, Price of Hedge: 0.09145041645415972, Loss: 0.000801350579122273\n",
      "Iteration:200, Price of Hedge: 0.09713982680473521, Loss: 0.0008255565540914222\n",
      "Iteration:210, Price of Hedge: 0.1051623313114959, Loss: 0.0007761365844106915\n",
      "Iteration:220, Price of Hedge: 0.106606369924026, Loss: 0.0008364707453956122\n",
      "Iteration:230, Price of Hedge: 0.0987182606371931, Loss: 0.0006525307197789987\n",
      "Iteration:240, Price of Hedge: 0.10709089922304428, Loss: 0.0007988346496026421\n",
      "Iteration:250, Price of Hedge: 0.10582677853411439, Loss: 0.0007569064287777705\n",
      "Iteration:260, Price of Hedge: 0.10275241084228809, Loss: 0.0006842205017506097\n",
      "Iteration:270, Price of Hedge: 0.09430165618642262, Loss: 0.0007152880891451384\n",
      "Iteration:280, Price of Hedge: 0.10745685982758459, Loss: 0.0007717655868472394\n",
      "Iteration:290, Price of Hedge: 0.10031641568000679, Loss: 0.0007674750501860172\n",
      "Iteration:300, Price of Hedge: 0.10078290744158948, Loss: 0.0007319566992379789\n",
      "Iteration:310, Price of Hedge: 0.09618357682785755, Loss: 0.0007687621268021916\n",
      "Iteration:320, Price of Hedge: 0.1057919932162349, Loss: 0.0007786580732277004\n",
      "Iteration:330, Price of Hedge: 0.10623185753174766, Loss: 0.000796886562600907\n",
      "Iteration:340, Price of Hedge: 0.10266720428556084, Loss: 0.0006800025834113876\n",
      "Iteration:350, Price of Hedge: 0.0961830177213784, Loss: 0.000845714764930383\n",
      "Iteration:360, Price of Hedge: 0.10148013228154866, Loss: 0.0007061382798462911\n",
      "Iteration:370, Price of Hedge: 0.08999815643499288, Loss: 0.0006756274660114857\n",
      "Iteration:380, Price of Hedge: 0.10198281348069144, Loss: 0.0007372677640607338\n",
      "Iteration:390, Price of Hedge: 0.09202681075979341, Loss: 0.000659517813488053\n",
      "Iteration:400, Price of Hedge: 0.09503125202082856, Loss: 0.0006926492403975804\n",
      "Iteration:410, Price of Hedge: 0.09714758440713353, Loss: 0.0005876220016007405\n",
      "Iteration:420, Price of Hedge: 0.10387688833456536, Loss: 0.0006796681321102004\n",
      "Iteration:430, Price of Hedge: 0.10679543686273973, Loss: 0.0006881091806299366\n",
      "Iteration:440, Price of Hedge: 0.10063254591959207, Loss: 0.0006943963488717841\n",
      "Iteration:450, Price of Hedge: 0.092702554474684, Loss: 0.0007039146601682589\n",
      "Iteration:460, Price of Hedge: 0.09432398867817539, Loss: 0.0007199142187489737\n",
      "Iteration:470, Price of Hedge: 0.09789228882344218, Loss: 0.0006427745499732795\n",
      "Iteration:480, Price of Hedge: 0.09183348698765882, Loss: 0.0007470878657863\n",
      "Iteration:490, Price of Hedge: 0.09861275470318276, Loss: 0.0006670475839670509\n",
      "Iteration:500, Price of Hedge: 0.0951896951728429, Loss: 0.0006965493853277493\n",
      "Iteration:510, Price of Hedge: 0.09887092211993433, Loss: 0.0006601401569748866\n",
      "Iteration:520, Price of Hedge: 0.08210845242399784, Loss: 0.0006717477713538145\n",
      "Iteration:530, Price of Hedge: 0.10677824433850559, Loss: 0.000726707134142468\n",
      "Iteration:540, Price of Hedge: 0.10839605705684789, Loss: 0.0007222036565370348\n",
      "Iteration:550, Price of Hedge: 0.09991127314754635, Loss: 0.0006681938415951771\n",
      "Iteration:560, Price of Hedge: 0.10188612618069327, Loss: 0.0007589548313152283\n",
      "Iteration:570, Price of Hedge: 0.09054766280176522, Loss: 0.000871276116454922\n",
      "Iteration:580, Price of Hedge: 0.09563267904837004, Loss: 0.0006914502687175306\n",
      "Iteration:590, Price of Hedge: 0.09422497600350255, Loss: 0.0005878948042649324\n",
      "Iteration:600, Price of Hedge: 0.09683976452294302, Loss: 0.0006980753131848427\n",
      "Iteration:610, Price of Hedge: 0.09239215507651011, Loss: 0.0007200034156899404\n",
      "Iteration:620, Price of Hedge: 0.12362423691824914, Loss: 0.0008043956842610721\n",
      "Iteration:630, Price of Hedge: 0.11684165268474657, Loss: 0.0007408249201973138\n",
      "Iteration:640, Price of Hedge: 0.10187937878204706, Loss: 0.0006214165236323455\n",
      "Iteration:650, Price of Hedge: 0.09092131747387668, Loss: 0.001137862493446473\n",
      "Iteration:660, Price of Hedge: 0.09710029543526559, Loss: 0.0006268950622886127\n",
      "Iteration:670, Price of Hedge: 0.10629730475722282, Loss: 0.0007197014763510978\n",
      "Iteration:680, Price of Hedge: 0.09160004732564458, Loss: 0.0005158222861395334\n",
      "Iteration:690, Price of Hedge: 0.09794922238207561, Loss: 0.0006229419054870177\n",
      "Iteration:700, Price of Hedge: 0.10833442827448607, Loss: 0.0005246052810846002\n",
      "Iteration:710, Price of Hedge: 0.10262327630605056, Loss: 0.0005034522041978962\n",
      "Iteration:720, Price of Hedge: 0.09840607591037553, Loss: 0.0005244575129748297\n",
      "Iteration:730, Price of Hedge: 0.0991616574890969, Loss: 0.0005862445864021737\n",
      "Iteration:740, Price of Hedge: 0.10815451035088586, Loss: 0.0009257290371797566\n",
      "Iteration:750, Price of Hedge: 0.10364135202325428, Loss: 0.0005738298315351775\n",
      "Iteration:760, Price of Hedge: 0.1023957771503774, Loss: 0.00038570035416011226\n",
      "Iteration:770, Price of Hedge: 0.10077464791405645, Loss: 0.0003947033384442799\n",
      "Iteration:780, Price of Hedge: 0.09704198317088242, Loss: 0.0004801570605402316\n",
      "Iteration:790, Price of Hedge: 0.08814495353544202, Loss: 0.00038631373824358215\n",
      "Iteration:800, Price of Hedge: 0.09270099151793544, Loss: 0.00040058929417982055\n",
      "Iteration:810, Price of Hedge: 0.10816133399132467, Loss: 0.0004500175779883264\n",
      "Iteration:820, Price of Hedge: 0.10472211755443367, Loss: 0.00046764015358391475\n",
      "Iteration:830, Price of Hedge: 0.09688578915175014, Loss: 0.0005077924270794343\n",
      "Iteration:840, Price of Hedge: 0.1001784370958262, Loss: 0.0004562722839044131\n",
      "Iteration:850, Price of Hedge: 0.10961118604054149, Loss: 0.0004340326621998125\n",
      "Iteration:860, Price of Hedge: 0.10976549942878933, Loss: 0.0005770923945473072\n",
      "Iteration:870, Price of Hedge: 0.10108946933620189, Loss: 0.0004319935913400963\n",
      "Iteration:880, Price of Hedge: 0.1051660989267475, Loss: 0.00040352336228081096\n",
      "Iteration:890, Price of Hedge: 0.10989499611354175, Loss: 0.0004445600852435616\n",
      "Iteration:900, Price of Hedge: 0.09687986770585723, Loss: 0.0004566066855690165\n",
      "Iteration:910, Price of Hedge: 0.09538190073201917, Loss: 0.0004940245293033163\n",
      "Iteration:920, Price of Hedge: 0.09969859666705361, Loss: 0.0004048638478610811\n",
      "Iteration:930, Price of Hedge: 0.11049180415914747, Loss: 0.0004965043730265739\n",
      "Iteration:940, Price of Hedge: 0.10427187800164289, Loss: 0.0004249173999632427\n",
      "Iteration:950, Price of Hedge: 0.08174766355438975, Loss: 0.0005035627945064513\n",
      "Iteration:960, Price of Hedge: 0.11356687708755543, Loss: 0.0005599747719180259\n",
      "Iteration:970, Price of Hedge: 0.10905468448929695, Loss: 0.0006286560690062614\n",
      "Iteration:980, Price of Hedge: 0.09157712395999908, Loss: 0.0005094280517865757\n",
      "Iteration:990, Price of Hedge: 0.09897140244911497, Loss: 0.00041813585134742315\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 8 \n",
      "\n",
      "tf.Tensor(0.22007473, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_49 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.20550789415101464, Loss: 0.0033594734270170792\n",
      "Iteration:20, Price of Hedge: 0.21776421084683764, Loss: 0.002435229391483773\n",
      "Iteration:30, Price of Hedge: 0.19498391239222884, Loss: 0.0018148929682365812\n",
      "Iteration:40, Price of Hedge: 0.18034576664420002, Loss: 0.0021514821280511857\n",
      "Iteration:50, Price of Hedge: 0.16914817699432663, Loss: 0.0019901400688130625\n",
      "Iteration:60, Price of Hedge: 0.18974100693693574, Loss: 0.0024262484841933944\n",
      "Iteration:70, Price of Hedge: 0.19019859492134403, Loss: 0.0022659553263945755\n",
      "Iteration:80, Price of Hedge: 0.19474475091077467, Loss: 0.002157397762830549\n",
      "Iteration:90, Price of Hedge: 0.21235756121851637, Loss: 0.0019291399256118782\n",
      "Iteration:100, Price of Hedge: 0.2019597424803351, Loss: 0.001999056229101015\n",
      "Iteration:110, Price of Hedge: 0.19483264745683757, Loss: 0.00202517106093536\n",
      "Iteration:120, Price of Hedge: 0.19931991355729226, Loss: 0.0023598457016936083\n",
      "Iteration:130, Price of Hedge: 0.17682910791550058, Loss: 0.0017813155463187514\n",
      "Iteration:140, Price of Hedge: 0.16756243723964417, Loss: 0.002384884861693415\n",
      "Iteration:150, Price of Hedge: 0.19644753730812, Loss: 0.0022604042670442584\n",
      "Iteration:160, Price of Hedge: 0.21132945053974483, Loss: 0.0021362608548615826\n",
      "Iteration:170, Price of Hedge: 0.19865178824314855, Loss: 0.0025450378173292876\n",
      "Iteration:180, Price of Hedge: 0.18248366883557313, Loss: 0.002107940765027294\n",
      "Iteration:190, Price of Hedge: 0.1683789108857468, Loss: 0.0020066363598965965\n",
      "Iteration:200, Price of Hedge: 0.18269372803359832, Loss: 0.0022603763760278284\n",
      "Iteration:210, Price of Hedge: 0.19298677217634577, Loss: 0.002184065060914442\n",
      "Iteration:220, Price of Hedge: 0.19081597452330926, Loss: 0.0025875402399911708\n",
      "Iteration:230, Price of Hedge: 0.20266710647016453, Loss: 0.0023049561813598633\n",
      "Iteration:240, Price of Hedge: 0.19717297467659592, Loss: 0.0025655934964380124\n",
      "Iteration:250, Price of Hedge: 0.20474916287778344, Loss: 0.001632410390138972\n",
      "Iteration:260, Price of Hedge: 0.2179067897228265, Loss: 0.0022334528292304867\n",
      "Iteration:270, Price of Hedge: 0.20442656741289514, Loss: 0.0019056031450952918\n",
      "Iteration:280, Price of Hedge: 0.18039896676582431, Loss: 0.001965365624442406\n",
      "Iteration:290, Price of Hedge: 0.17987751632265372, Loss: 0.002516092171840789\n",
      "Iteration:300, Price of Hedge: 0.1955887649433862, Loss: 0.002550805779137733\n",
      "Iteration:310, Price of Hedge: 0.20063879206677485, Loss: 0.0024928806204979285\n",
      "Iteration:320, Price of Hedge: 0.19869913922018442, Loss: 0.002330844025145318\n",
      "Iteration:330, Price of Hedge: 0.19249638435661612, Loss: 0.0018378096716914706\n",
      "Iteration:340, Price of Hedge: 0.19993007337043311, Loss: 0.001832498549790529\n",
      "Iteration:350, Price of Hedge: 0.1915226691287444, Loss: 0.001640164092706442\n",
      "Iteration:360, Price of Hedge: 0.18370461003307811, Loss: 0.001338704166138971\n",
      "Iteration:370, Price of Hedge: 0.16787274471957972, Loss: 0.001714079644216593\n",
      "Iteration:380, Price of Hedge: 0.18783460018192957, Loss: 0.0013939608766845525\n",
      "Iteration:390, Price of Hedge: 0.17748967874862276, Loss: 0.0014895238413751067\n",
      "Iteration:400, Price of Hedge: 0.19435797423265058, Loss: 0.0013362305816193578\n",
      "Iteration:410, Price of Hedge: 0.19745759054596876, Loss: 0.0011096074816984826\n",
      "Iteration:420, Price of Hedge: 0.20431369645383485, Loss: 0.0014700717251173502\n",
      "Iteration:430, Price of Hedge: 0.19151681998415598, Loss: 0.0011871117603315718\n",
      "Iteration:440, Price of Hedge: 0.1900562391734866, Loss: 0.0013530407711511928\n",
      "Iteration:450, Price of Hedge: 0.17304176288791953, Loss: 0.0013137761966644846\n",
      "Iteration:460, Price of Hedge: 0.18066718271753646, Loss: 0.0015134605591451413\n",
      "Iteration:470, Price of Hedge: 0.200356965299045, Loss: 0.0011097446955382396\n",
      "Iteration:480, Price of Hedge: 0.20095348242072078, Loss: 0.0013716862891748783\n",
      "Iteration:490, Price of Hedge: 0.21459042036754, Loss: 0.0013344631129665887\n",
      "Iteration:500, Price of Hedge: 0.2118702015662848, Loss: 0.0013356731348311613\n",
      "Iteration:510, Price of Hedge: 0.19356153430520637, Loss: 0.0011801819633699751\n",
      "Iteration:520, Price of Hedge: 0.2079709418430639, Loss: 0.0013586173557620818\n",
      "Iteration:530, Price of Hedge: 0.229243866330296, Loss: 0.001339248663526682\n",
      "Iteration:540, Price of Hedge: 0.20205388661407825, Loss: 0.0011237962892263198\n",
      "Iteration:550, Price of Hedge: 0.195618855365683, Loss: 0.0012018111975843127\n",
      "Iteration:560, Price of Hedge: 0.17815933408423917, Loss: 0.001438944230160555\n",
      "Iteration:570, Price of Hedge: 0.18837273742178698, Loss: 0.0012920814683669236\n",
      "Iteration:580, Price of Hedge: 0.19425149430078364, Loss: 0.0014465233648484068\n",
      "Iteration:590, Price of Hedge: 0.1706650339072894, Loss: 0.001463428807181888\n",
      "Iteration:600, Price of Hedge: 0.18231662555374442, Loss: 0.001154450633011539\n",
      "Iteration:610, Price of Hedge: 0.17015043668529872, Loss: 0.0012117233410884332\n",
      "Iteration:620, Price of Hedge: 0.18680092723759573, Loss: 0.0012430168124956788\n",
      "Iteration:630, Price of Hedge: 0.18046271766052088, Loss: 0.0010343291303007264\n",
      "Iteration:640, Price of Hedge: 0.19064904280554631, Loss: 0.0012169093269558395\n",
      "Iteration:650, Price of Hedge: 0.16343600120317206, Loss: 0.001219198756058937\n",
      "Iteration:660, Price of Hedge: 0.20614992941150379, Loss: 0.001388810128128082\n",
      "Iteration:670, Price of Hedge: 0.19921223829614976, Loss: 0.0013468842028147244\n",
      "Iteration:680, Price of Hedge: 0.1841569545063976, Loss: 0.0015732005015548724\n",
      "Iteration:690, Price of Hedge: 0.16445504331717303, Loss: 0.001140897840269073\n",
      "Iteration:700, Price of Hedge: 0.18934380698752876, Loss: 0.0013454161890481765\n",
      "Iteration:710, Price of Hedge: 0.19805590863041972, Loss: 0.0013474751437253297\n",
      "Iteration:720, Price of Hedge: 0.1985589191272993, Loss: 0.0013902219863213717\n",
      "Iteration:730, Price of Hedge: 0.20311588089338103, Loss: 0.0015808878384448556\n",
      "Iteration:740, Price of Hedge: 0.22628131444057545, Loss: 0.0015601928287674483\n",
      "Iteration:750, Price of Hedge: 0.21067184412322607, Loss: 0.0012800210940303815\n",
      "Iteration:760, Price of Hedge: 0.1850706482669125, Loss: 0.0012372402592580657\n",
      "Iteration:770, Price of Hedge: 0.17890062948777088, Loss: 0.0017215630280489338\n",
      "Iteration:780, Price of Hedge: 0.19136208062500373, Loss: 0.0015016210716976453\n",
      "Iteration:790, Price of Hedge: 0.2109028933033301, Loss: 0.001420633155307094\n",
      "Iteration:800, Price of Hedge: 0.18331687709153358, Loss: 0.0012295859184366265\n",
      "Iteration:810, Price of Hedge: 0.19105572570053939, Loss: 0.0012001559155645936\n",
      "Iteration:820, Price of Hedge: 0.17949105839900314, Loss: 0.0010267775130889058\n",
      "Iteration:830, Price of Hedge: 0.16201030806962535, Loss: 0.001643958018021685\n",
      "Iteration:840, Price of Hedge: 0.16978756659268585, Loss: 0.001701748079550658\n",
      "Iteration:850, Price of Hedge: 0.18689645795329854, Loss: 0.0013053603314837404\n",
      "Iteration:860, Price of Hedge: 0.21239727802591235, Loss: 0.0011443115014585282\n",
      "Iteration:870, Price of Hedge: 0.21280580969685162, Loss: 0.001312062642342582\n",
      "Iteration:880, Price of Hedge: 0.2181865605242024, Loss: 0.0014106303659995767\n",
      "Iteration:890, Price of Hedge: 0.2302215181759152, Loss: 0.0015898010104096196\n",
      "Iteration:900, Price of Hedge: 0.19353128450567283, Loss: 0.0013761509685325636\n",
      "Iteration:910, Price of Hedge: 0.18577291218516623, Loss: 0.0014058669788364676\n",
      "Iteration:920, Price of Hedge: 0.18487450270165484, Loss: 0.0012608436544790714\n",
      "Iteration:930, Price of Hedge: 0.1734439991580075, Loss: 0.0014219111615242142\n",
      "Iteration:940, Price of Hedge: 0.19359140159937172, Loss: 0.0016111254356586892\n",
      "Iteration:950, Price of Hedge: 0.2114609367600565, Loss: 0.001412410036972034\n",
      "Iteration:960, Price of Hedge: 0.20921059392816235, Loss: 0.0011924618549474355\n",
      "Iteration:970, Price of Hedge: 0.2010937025136059, Loss: 0.0010880900605767963\n",
      "Iteration:980, Price of Hedge: 0.18931154903481232, Loss: 0.0012975142399243467\n",
      "Iteration:990, Price of Hedge: 0.19291250238402427, Loss: 0.0015397193285464185\n",
      "tf.Tensor(0.18092255, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_50 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.14608707178630312, Loss: 0.0019021024489929597\n",
      "Iteration:20, Price of Hedge: 0.20036880702773488, Loss: 0.0016421427361978937\n",
      "Iteration:30, Price of Hedge: 0.15116083018024257, Loss: 0.0019253806150402398\n",
      "Iteration:40, Price of Hedge: 0.17077176884273515, Loss: 0.0016148583493754921\n",
      "Iteration:50, Price of Hedge: 0.19583718624229507, Loss: 0.001921955000558029\n",
      "Iteration:60, Price of Hedge: 0.14248972036264151, Loss: 0.00162121700306761\n",
      "Iteration:70, Price of Hedge: 0.1624658400876797, Loss: 0.0017873490953506101\n",
      "Iteration:80, Price of Hedge: 0.18837541495936422, Loss: 0.0019197326842132158\n",
      "Iteration:90, Price of Hedge: 0.1686320497508632, Loss: 0.0018220924613659762\n",
      "Iteration:100, Price of Hedge: 0.1618384515952471, Loss: 0.0016834616583635055\n",
      "Iteration:110, Price of Hedge: 0.16476410765466198, Loss: 0.0015524677642972053\n",
      "Iteration:120, Price of Hedge: 0.17492767373028076, Loss: 0.001524545245960507\n",
      "Iteration:130, Price of Hedge: 0.18752918558316198, Loss: 0.0016836798059562954\n",
      "Iteration:140, Price of Hedge: 0.17554352331077328, Loss: 0.0017084424215476626\n",
      "Iteration:150, Price of Hedge: 0.16200366203885325, Loss: 0.001478563045458614\n",
      "Iteration:160, Price of Hedge: 0.1681430325753695, Loss: 0.0016622250151081099\n",
      "Iteration:170, Price of Hedge: 0.17275717889399403, Loss: 0.0016293371487661192\n",
      "Iteration:180, Price of Hedge: 0.1658765129539461, Loss: 0.0014968483460245708\n",
      "Iteration:190, Price of Hedge: 0.1697742745311416, Loss: 0.0018485150904887784\n",
      "Iteration:200, Price of Hedge: 0.16580659416018761, Loss: 0.0016490472569258509\n",
      "Iteration:210, Price of Hedge: 0.16547497794369975, Loss: 0.0015102855902703995\n",
      "Iteration:220, Price of Hedge: 0.15869844909013864, Loss: 0.001538260030722505\n",
      "Iteration:230, Price of Hedge: 0.16341614279947408, Loss: 0.0016067893787115929\n",
      "Iteration:240, Price of Hedge: 0.1854937151418426, Loss: 0.0016335139529899403\n",
      "Iteration:250, Price of Hedge: 0.16932275881945316, Loss: 0.0016123167805033314\n",
      "Iteration:260, Price of Hedge: 0.1635490315394691, Loss: 0.0015744132627157016\n",
      "Iteration:270, Price of Hedge: 0.16237191908206797, Loss: 0.00145690417703932\n",
      "Iteration:280, Price of Hedge: 0.18625568177297966, Loss: 0.001845227063386723\n",
      "Iteration:290, Price of Hedge: 0.17936773229321262, Loss: 0.001916247303267227\n",
      "Iteration:300, Price of Hedge: 0.1742083564476957, Loss: 0.0015386183804782406\n",
      "Iteration:310, Price of Hedge: 0.17327988841733488, Loss: 0.0014208918942898664\n",
      "Iteration:320, Price of Hedge: 0.17510813657544305, Loss: 0.001514028589577965\n",
      "Iteration:330, Price of Hedge: 0.16072990322509215, Loss: 0.0017388356605942514\n",
      "Iteration:340, Price of Hedge: 0.1510004966800807, Loss: 0.0013765703298867394\n",
      "Iteration:350, Price of Hedge: 0.13520017212173344, Loss: 0.0013829740574536232\n",
      "Iteration:360, Price of Hedge: 0.16536460920725632, Loss: 0.0019788688608253224\n",
      "Iteration:370, Price of Hedge: 0.17640999359604168, Loss: 0.0016853467922418376\n",
      "Iteration:380, Price of Hedge: 0.1677480160941059, Loss: 0.0018830225034856874\n",
      "Iteration:390, Price of Hedge: 0.1659930017762804, Loss: 0.0015025459577246104\n",
      "Iteration:400, Price of Hedge: 0.16344892669707178, Loss: 0.0015422123371667596\n",
      "Iteration:410, Price of Hedge: 0.17337822417240434, Loss: 0.0019476449924456852\n",
      "Iteration:420, Price of Hedge: 0.1736589990503717, Loss: 0.0013648747800061756\n",
      "Iteration:430, Price of Hedge: 0.1911107427226625, Loss: 0.0013823426496665015\n",
      "Iteration:440, Price of Hedge: 0.19866076118157708, Loss: 0.0015429023907964636\n",
      "Iteration:450, Price of Hedge: 0.1956229832361146, Loss: 0.002422773313351634\n",
      "Iteration:460, Price of Hedge: 0.1915639637707841, Loss: 0.0016380865855228244\n",
      "Iteration:470, Price of Hedge: 0.18163100061900653, Loss: 0.0014818294072175499\n",
      "Iteration:480, Price of Hedge: 0.15021129247918452, Loss: 0.0010680181162842752\n",
      "Iteration:490, Price of Hedge: 0.17083088185984255, Loss: 0.0015492804685893092\n",
      "Iteration:500, Price of Hedge: 0.16041763540514467, Loss: 0.0015414067350404182\n",
      "Iteration:510, Price of Hedge: 0.17202294390205, Loss: 0.0016079474784607584\n",
      "Iteration:520, Price of Hedge: 0.1731634952213426, Loss: 0.0011275064169788075\n",
      "Iteration:530, Price of Hedge: 0.17459848004779135, Loss: 0.0016433018320547888\n",
      "Iteration:540, Price of Hedge: 0.16931832813227177, Loss: 0.0018265347282997448\n",
      "Iteration:550, Price of Hedge: 0.19890647306746134, Loss: 0.0012413620285298245\n",
      "Iteration:560, Price of Hedge: 0.19758800893879427, Loss: 0.0010584502525142093\n",
      "Iteration:570, Price of Hedge: 0.18560497639081178, Loss: 0.0011313968402303588\n",
      "Iteration:580, Price of Hedge: 0.16550683745332437, Loss: 0.000846282667965781\n",
      "Iteration:590, Price of Hedge: 0.17737256835506515, Loss: 0.0011761395091761885\n",
      "Iteration:600, Price of Hedge: 0.18062099519432878, Loss: 0.0010853497682125736\n",
      "Iteration:610, Price of Hedge: 0.17581750871845545, Loss: 0.0009189521509628929\n",
      "Iteration:620, Price of Hedge: 0.15886161950511452, Loss: 0.0008766094790781499\n",
      "Iteration:630, Price of Hedge: 0.15663083226016852, Loss: 0.0010688608234235453\n",
      "Iteration:640, Price of Hedge: 0.1653076637205686, Loss: 0.0013212451369347456\n",
      "Iteration:650, Price of Hedge: 0.16449836205011936, Loss: 0.0012585009336124387\n",
      "Iteration:660, Price of Hedge: 0.17592234706478396, Loss: 0.0010796707090189985\n",
      "Iteration:670, Price of Hedge: 0.18328624478663189, Loss: 0.00120294103277665\n",
      "Iteration:680, Price of Hedge: 0.17522019471059594, Loss: 0.0009414093997274887\n",
      "Iteration:690, Price of Hedge: 0.1796693377760221, Loss: 0.0012345944726146918\n",
      "Iteration:700, Price of Hedge: 0.192413731321642, Loss: 0.001246368341465498\n",
      "Iteration:710, Price of Hedge: 0.19698600924017456, Loss: 0.0011098277460201977\n",
      "Iteration:720, Price of Hedge: 0.20419910422061777, Loss: 0.0009879346657122312\n",
      "Iteration:730, Price of Hedge: 0.1838432363535958, Loss: 0.0010163128410785038\n",
      "Iteration:740, Price of Hedge: 0.16975495801004856, Loss: 0.0011080825652778792\n",
      "Iteration:750, Price of Hedge: 0.1559689385959814, Loss: 0.0009550539588945473\n",
      "Iteration:760, Price of Hedge: 0.14936613093046847, Loss: 0.0009897668813674265\n",
      "Iteration:770, Price of Hedge: 0.1709282932269389, Loss: 0.001032971746748901\n",
      "Iteration:780, Price of Hedge: 0.17652358175266727, Loss: 0.0009307037941599817\n",
      "Iteration:790, Price of Hedge: 0.1720707730107961, Loss: 0.0009999107444321532\n",
      "Iteration:800, Price of Hedge: 0.18162599617377284, Loss: 0.0008319715259573979\n",
      "Iteration:810, Price of Hedge: 0.15635157146595022, Loss: 0.0009851603189150017\n",
      "Iteration:820, Price of Hedge: 0.16384534569801873, Loss: 0.0008942755119199397\n",
      "Iteration:830, Price of Hedge: 0.1593857793613097, Loss: 0.0008871787424001632\n",
      "Iteration:840, Price of Hedge: 0.15900035738969792, Loss: 0.0011664711630388958\n",
      "Iteration:850, Price of Hedge: 0.18973753251317477, Loss: 0.0011545770141797363\n",
      "Iteration:860, Price of Hedge: 0.17957932151271053, Loss: 0.0011205606822935366\n",
      "Iteration:870, Price of Hedge: 0.19123387757576896, Loss: 0.0010091117915307813\n",
      "Iteration:880, Price of Hedge: 0.15038361114754936, Loss: 0.0012557397229858937\n",
      "Iteration:890, Price of Hedge: 0.14598781164326058, Loss: 0.0012104667511875001\n",
      "Iteration:900, Price of Hedge: 0.1612867354148193, Loss: 0.0011126271822808676\n",
      "Iteration:910, Price of Hedge: 0.17162555269995894, Loss: 0.001114983724142249\n",
      "Iteration:920, Price of Hedge: 0.17704774160886247, Loss: 0.0009630162837746426\n",
      "Iteration:930, Price of Hedge: 0.1938665345231584, Loss: 0.0011724628755461098\n",
      "Iteration:940, Price of Hedge: 0.1698675899032537, Loss: 0.0007925939555001094\n",
      "Iteration:950, Price of Hedge: 0.1738297876972638, Loss: 0.0009994928149828386\n",
      "Iteration:960, Price of Hedge: 0.15920874312673733, Loss: 0.0012495718239240007\n",
      "Iteration:970, Price of Hedge: 0.1654951551018712, Loss: 0.0010155220560546408\n",
      "Iteration:980, Price of Hedge: 0.15786037982845758, Loss: 0.0009005780100387995\n",
      "Iteration:990, Price of Hedge: 0.17224001569849182, Loss: 0.0011748149349227078\n",
      "tf.Tensor(0.19363965, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_51 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.20229655439474073, Loss: 0.0025682219757095837\n",
      "Iteration:20, Price of Hedge: 0.15761807861543958, Loss: 0.0024374601747442883\n",
      "Iteration:30, Price of Hedge: 0.21241305637234975, Loss: 0.002557501366269399\n",
      "Iteration:40, Price of Hedge: 0.18588839693090906, Loss: 0.002107177497479462\n",
      "Iteration:50, Price of Hedge: 0.1919349461647471, Loss: 0.0019583587536452286\n",
      "Iteration:60, Price of Hedge: 0.18657889880909126, Loss: 0.0016035141764965566\n",
      "Iteration:70, Price of Hedge: 0.1870366461707363, Loss: 0.0020691782288363215\n",
      "Iteration:80, Price of Hedge: 0.18976516852602573, Loss: 0.0017576542523359607\n",
      "Iteration:90, Price of Hedge: 0.20445264152882603, Loss: 0.0022377878900698535\n",
      "Iteration:100, Price of Hedge: 0.20321668699561998, Loss: 0.0018229600711984874\n",
      "Iteration:110, Price of Hedge: 0.21067213100225218, Loss: 0.0023474464017020583\n",
      "Iteration:120, Price of Hedge: 0.18428644851125, Loss: 0.002189778734851622\n",
      "Iteration:130, Price of Hedge: 0.18678822487182745, Loss: 0.0024592848951005665\n",
      "Iteration:140, Price of Hedge: 0.1662616639842554, Loss: 0.002326760730534616\n",
      "Iteration:150, Price of Hedge: 0.203352508276771, Loss: 0.0021294517114487377\n",
      "Iteration:160, Price of Hedge: 0.21104137618433472, Loss: 0.0020744650706113533\n",
      "Iteration:170, Price of Hedge: 0.19044585276642467, Loss: 0.0022342175909399135\n",
      "Iteration:180, Price of Hedge: 0.16797014014895242, Loss: 0.0019340462542341897\n",
      "Iteration:190, Price of Hedge: 0.17285315586595973, Loss: 0.0020641110288156742\n",
      "Iteration:200, Price of Hedge: 0.17727383415690384, Loss: 0.0016756513021689125\n",
      "Iteration:210, Price of Hedge: 0.18574043110431832, Loss: 0.0023676320267892238\n",
      "Iteration:220, Price of Hedge: 0.220034157078851, Loss: 0.002260771581769561\n",
      "Iteration:230, Price of Hedge: 0.21529502713117382, Loss: 0.0021715855742506563\n",
      "Iteration:240, Price of Hedge: 0.2020016586935981, Loss: 0.0016393455411796156\n",
      "Iteration:250, Price of Hedge: 0.17379561721770645, Loss: 0.002216403698357006\n",
      "Iteration:260, Price of Hedge: 0.18209327429417502, Loss: 0.0020016512142501776\n",
      "Iteration:270, Price of Hedge: 0.18903684642956478, Loss: 0.0021311134681686996\n",
      "Iteration:280, Price of Hedge: 0.18074067156139792, Loss: 0.0017901936054860459\n",
      "Iteration:290, Price of Hedge: 0.19523507497960965, Loss: 0.0024015430202830148\n",
      "Iteration:300, Price of Hedge: 0.18499817943736618, Loss: 0.0021120360129307514\n",
      "Iteration:310, Price of Hedge: 0.17307752713984428, Loss: 0.001770539030332241\n",
      "Iteration:320, Price of Hedge: 0.18286454855593776, Loss: 0.0023301123840179017\n",
      "Iteration:330, Price of Hedge: 0.18717705751630548, Loss: 0.0016728767686014835\n",
      "Iteration:340, Price of Hedge: 0.1835276694248478, Loss: 0.0018662521582630378\n",
      "Iteration:350, Price of Hedge: 0.19034366008222606, Loss: 0.0014766813979573358\n",
      "Iteration:360, Price of Hedge: 0.19595383444186612, Loss: 0.0015841080057078295\n",
      "Iteration:370, Price of Hedge: 0.2098248337985638, Loss: 0.0019370171455378228\n",
      "Iteration:380, Price of Hedge: 0.20961281426052666, Loss: 0.0020340954391120827\n",
      "Iteration:390, Price of Hedge: 0.2066611318983519, Loss: 0.0014256242775998907\n",
      "Iteration:400, Price of Hedge: 0.19986050520659548, Loss: 0.0017109268387388355\n",
      "Iteration:410, Price of Hedge: 0.20393206766045752, Loss: 0.0014761593129935413\n",
      "Iteration:420, Price of Hedge: 0.1953148114111514, Loss: 0.0014149014269173145\n",
      "Iteration:430, Price of Hedge: 0.18455485571564625, Loss: 0.0012055146016096254\n",
      "Iteration:440, Price of Hedge: 0.18265020211024421, Loss: 0.0016723234307576718\n",
      "Iteration:450, Price of Hedge: 0.17401428278651568, Loss: 0.0016792158736794072\n",
      "Iteration:460, Price of Hedge: 0.16688390459194125, Loss: 0.0013119682611351991\n",
      "Iteration:470, Price of Hedge: 0.1746240919697357, Loss: 0.002269997033507565\n",
      "Iteration:480, Price of Hedge: 0.17802233341153625, Loss: 0.0014453896697386173\n",
      "Iteration:490, Price of Hedge: 0.1701359014813079, Loss: 0.0016763159550515106\n",
      "Iteration:500, Price of Hedge: 0.17933523527464104, Loss: 0.0015083190245851698\n",
      "Iteration:510, Price of Hedge: 0.18670413744172268, Loss: 0.0013589925148357552\n",
      "Iteration:520, Price of Hedge: 0.20133480839734832, Loss: 0.0016810406185266303\n",
      "Iteration:530, Price of Hedge: 0.20767893086990627, Loss: 0.0015783706742120709\n",
      "Iteration:540, Price of Hedge: 0.20665109113243718, Loss: 0.0012666228224994748\n",
      "Iteration:550, Price of Hedge: 0.1809205287730606, Loss: 0.0013984382564157906\n",
      "Iteration:560, Price of Hedge: 0.18513384134128047, Loss: 0.001053072889449247\n",
      "Iteration:570, Price of Hedge: 0.18625615990468988, Loss: 0.001587962569081114\n",
      "Iteration:580, Price of Hedge: 0.16747868450173656, Loss: 0.001745371621462244\n",
      "Iteration:590, Price of Hedge: 0.17717538683776868, Loss: 0.0014875379761026153\n",
      "Iteration:600, Price of Hedge: 0.17916580133426124, Loss: 0.0011669164231940421\n",
      "Iteration:610, Price of Hedge: 0.1858181115695061, Loss: 0.001144887625266655\n",
      "Iteration:620, Price of Hedge: 0.15723221038756494, Loss: 0.0014703659504379908\n",
      "Iteration:630, Price of Hedge: 0.17766725686580004, Loss: 0.0013175186979181854\n",
      "Iteration:640, Price of Hedge: 0.1632097652156176, Loss: 0.0015584630876949392\n",
      "Iteration:650, Price of Hedge: 0.18461184901550498, Loss: 0.0015754586777779523\n",
      "Iteration:660, Price of Hedge: 0.17694988398550324, Loss: 0.0013750037014549578\n",
      "Iteration:670, Price of Hedge: 0.1760750463953059, Loss: 0.0011025377316008723\n",
      "Iteration:680, Price of Hedge: 0.18865107382803217, Loss: 0.0010994644902280193\n",
      "Iteration:690, Price of Hedge: 0.20185426662505962, Loss: 0.0013961799556792443\n",
      "Iteration:700, Price of Hedge: 0.2069573504305595, Loss: 0.001357575427076885\n",
      "Iteration:710, Price of Hedge: 0.20070820085337573, Loss: 0.001151854651754647\n",
      "Iteration:720, Price of Hedge: 0.1960183184718517, Loss: 0.0013074374651269596\n",
      "Iteration:730, Price of Hedge: 0.21198308846306874, Loss: 0.0015110598150032573\n",
      "Iteration:740, Price of Hedge: 0.20054627358084645, Loss: 0.0016567008506664929\n",
      "Iteration:750, Price of Hedge: 0.20333060984444276, Loss: 0.0017565897867133807\n",
      "Iteration:760, Price of Hedge: 0.19349209364315814, Loss: 0.0014920200873455693\n",
      "Iteration:770, Price of Hedge: 0.18419058310335004, Loss: 0.0013454918932356288\n",
      "Iteration:780, Price of Hedge: 0.19154751603995238, Loss: 0.0012893562421321114\n",
      "Iteration:790, Price of Hedge: 0.191093992175081, Loss: 0.0012512289736457127\n",
      "Iteration:800, Price of Hedge: 0.1767381353887686, Loss: 0.001437284839196451\n",
      "Iteration:810, Price of Hedge: 0.18796849299851603, Loss: 0.001365771775016711\n",
      "Iteration:820, Price of Hedge: 0.18182081890796556, Loss: 0.0012750523841615015\n",
      "Iteration:830, Price of Hedge: 0.1876592214706193, Loss: 0.0011419703992669563\n",
      "Iteration:840, Price of Hedge: 0.18350425690877048, Loss: 0.001251176677989907\n",
      "Iteration:850, Price of Hedge: 0.18155955180377534, Loss: 0.0010959580665062419\n",
      "Iteration:860, Price of Hedge: 0.1879757765382351, Loss: 0.0016929350164127223\n",
      "Iteration:870, Price of Hedge: 0.1942396844475411, Loss: 0.001397438164255238\n",
      "Iteration:880, Price of Hedge: 0.20835241125920448, Loss: 0.0014680336887025194\n",
      "Iteration:890, Price of Hedge: 0.2104814202007674, Loss: 0.0012932045798320858\n",
      "Iteration:900, Price of Hedge: 0.2103966155730973, Loss: 0.0015597448293160456\n",
      "Iteration:910, Price of Hedge: 0.19370809761211377, Loss: 0.001301985020441876\n",
      "Iteration:920, Price of Hedge: 0.2063930753238765, Loss: 0.0013103792202795008\n",
      "Iteration:930, Price of Hedge: 0.19474513341614286, Loss: 0.0011990811153243187\n",
      "Iteration:940, Price of Hedge: 0.1784410014747323, Loss: 0.0016566737067308602\n",
      "Iteration:950, Price of Hedge: 0.180584449993944, Loss: 0.0013272534097329648\n",
      "Iteration:960, Price of Hedge: 0.20955001962925054, Loss: 0.0012904803497050033\n",
      "Iteration:970, Price of Hedge: 0.21196208254326623, Loss: 0.001482394698354117\n",
      "Iteration:980, Price of Hedge: 0.19669589485613417, Loss: 0.0017685384724707377\n",
      "Iteration:990, Price of Hedge: 0.17691333878511842, Loss: 0.001284739531832191\n",
      "tf.Tensor(0.17212895, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_52 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.2068615647112779, Loss: 0.0026399937788720964\n",
      "Iteration:20, Price of Hedge: 0.1334845319502449, Loss: 0.0018374868082736031\n",
      "Iteration:30, Price of Hedge: 0.18746984943792314, Loss: 0.0016707855649365833\n",
      "Iteration:40, Price of Hedge: 0.15551772570104277, Loss: 0.0020690576998010357\n",
      "Iteration:50, Price of Hedge: 0.15731510248839414, Loss: 0.0015138070801215876\n",
      "Iteration:60, Price of Hedge: 0.1922022058530388, Loss: 0.0017740825590669474\n",
      "Iteration:70, Price of Hedge: 0.1740376315516983, Loss: 0.0015324521000914084\n",
      "Iteration:80, Price of Hedge: 0.17425114923576077, Loss: 0.0020337281243867802\n",
      "Iteration:90, Price of Hedge: 0.18229420117653491, Loss: 0.0018644668841846014\n",
      "Iteration:100, Price of Hedge: 0.19277486420237439, Loss: 0.0022853166723354693\n",
      "Iteration:110, Price of Hedge: 0.15648302581081452, Loss: 0.0015190989024352675\n",
      "Iteration:120, Price of Hedge: 0.15768388547649012, Loss: 0.001708796288818615\n",
      "Iteration:130, Price of Hedge: 0.1593183627901681, Loss: 0.0015149147519169404\n",
      "Iteration:140, Price of Hedge: 0.18378624305373706, Loss: 0.0019111857063525586\n",
      "Iteration:150, Price of Hedge: 0.1688532653554603, Loss: 0.0019166987890956834\n",
      "Iteration:160, Price of Hedge: 0.20179167918419127, Loss: 0.0018012751794647564\n",
      "Iteration:170, Price of Hedge: 0.19918308819954975, Loss: 0.0014831928296724862\n",
      "Iteration:180, Price of Hedge: 0.1812393310597145, Loss: 0.001676507705789465\n",
      "Iteration:190, Price of Hedge: 0.14871175987185553, Loss: 0.0017697659262205792\n",
      "Iteration:200, Price of Hedge: 0.15595425995247753, Loss: 0.0019594387834510844\n",
      "Iteration:210, Price of Hedge: 0.160887351997269, Loss: 0.0013803449556147207\n",
      "Iteration:220, Price of Hedge: 0.18188689671031855, Loss: 0.0017121504325712247\n",
      "Iteration:230, Price of Hedge: 0.18702915544060944, Loss: 0.0015700901551690906\n",
      "Iteration:240, Price of Hedge: 0.15331188099364682, Loss: 0.0019542866652464855\n",
      "Iteration:250, Price of Hedge: 0.14973324045757863, Loss: 0.0017004401901016487\n",
      "Iteration:260, Price of Hedge: 0.16261348715979695, Loss: 0.0018258954761642522\n",
      "Iteration:270, Price of Hedge: 0.14996639341720766, Loss: 0.001468745034134944\n",
      "Iteration:280, Price of Hedge: 0.1573985683472756, Loss: 0.0018668264143691716\n",
      "Iteration:290, Price of Hedge: 0.1441877254428846, Loss: 0.0020809765023265037\n",
      "Iteration:300, Price of Hedge: 0.16747195878234608, Loss: 0.00172329712709276\n",
      "Iteration:310, Price of Hedge: 0.17352877191023028, Loss: 0.0014742569962568732\n",
      "Iteration:320, Price of Hedge: 0.14767854912150824, Loss: 0.001385117556774329\n",
      "Iteration:330, Price of Hedge: 0.16168514663122552, Loss: 0.0015409141597681143\n",
      "Iteration:340, Price of Hedge: 0.1695437034827478, Loss: 0.001677815221698076\n",
      "Iteration:350, Price of Hedge: 0.17088832141596413, Loss: 0.0016736278338296275\n",
      "Iteration:360, Price of Hedge: 0.18812726460175783, Loss: 0.001775869700847377\n",
      "Iteration:370, Price of Hedge: 0.20098322221309675, Loss: 0.0018946937732403414\n",
      "Iteration:380, Price of Hedge: 0.19831161346904766, Loss: 0.001723125173995932\n",
      "Iteration:390, Price of Hedge: 0.17653488159875225, Loss: 0.0016655750499163348\n",
      "Iteration:400, Price of Hedge: 0.18561648342730452, Loss: 0.0015054248335767185\n",
      "Iteration:410, Price of Hedge: 0.1805012869518123, Loss: 0.0014913271699061427\n",
      "Iteration:420, Price of Hedge: 0.17980834660190795, Loss: 0.001830622629908696\n",
      "Iteration:430, Price of Hedge: 0.1916008117879187, Loss: 0.0016213762557908851\n",
      "Iteration:440, Price of Hedge: 0.16922703685106627, Loss: 0.0016475858423730119\n",
      "Iteration:450, Price of Hedge: 0.1894623677139407, Loss: 0.0017746350253164957\n",
      "Iteration:460, Price of Hedge: 0.18383271745597088, Loss: 0.001388930283622969\n",
      "Iteration:470, Price of Hedge: 0.2094027391247778, Loss: 0.001411296886584168\n",
      "Iteration:480, Price of Hedge: 0.17707247695600473, Loss: 0.0017205171149328182\n",
      "Iteration:490, Price of Hedge: 0.17300709833892827, Loss: 0.0012387938137758958\n",
      "Iteration:500, Price of Hedge: 0.18361429095301676, Loss: 0.001424640372189945\n",
      "Iteration:510, Price of Hedge: 0.17928093545008325, Loss: 0.0015202927375492338\n",
      "Iteration:520, Price of Hedge: 0.1766198615413828, Loss: 0.0014504995778781727\n",
      "Iteration:530, Price of Hedge: 0.18467505802759662, Loss: 0.0012835717200326614\n",
      "Iteration:540, Price of Hedge: 0.16593004776776754, Loss: 0.0011745478535376997\n",
      "Iteration:550, Price of Hedge: 0.1615713672219158, Loss: 0.0014500500842651754\n",
      "Iteration:560, Price of Hedge: 0.1688070459568053, Loss: 0.0013375754515678297\n",
      "Iteration:570, Price of Hedge: 0.18017674708463574, Loss: 0.0015339365496354952\n",
      "Iteration:580, Price of Hedge: 0.18014434569240623, Loss: 0.0010784454965115488\n",
      "Iteration:590, Price of Hedge: 0.17419871412487284, Loss: 0.000792008430925284\n",
      "Iteration:600, Price of Hedge: 0.1851795029196069, Loss: 0.0012997145173856417\n",
      "Iteration:610, Price of Hedge: 0.16722559344979118, Loss: 0.0011664908361665562\n",
      "Iteration:620, Price of Hedge: 0.18817300586870261, Loss: 0.0010942660530139925\n",
      "Iteration:630, Price of Hedge: 0.18635102123599837, Loss: 0.0011327953754827647\n",
      "Iteration:640, Price of Hedge: 0.1578080881570827, Loss: 0.0010133989146856592\n",
      "Iteration:650, Price of Hedge: 0.15556714858215628, Loss: 0.0010594027805306716\n",
      "Iteration:660, Price of Hedge: 0.19030966491762913, Loss: 0.0012251224842136034\n",
      "Iteration:670, Price of Hedge: 0.19146333298350557, Loss: 0.0011238032619804274\n",
      "Iteration:680, Price of Hedge: 0.17201789164364528, Loss: 0.0010870640696152734\n",
      "Iteration:690, Price of Hedge: 0.16718801229736757, Loss: 0.0013285416260543138\n",
      "Iteration:700, Price of Hedge: 0.17592183705762637, Loss: 0.0011464577400754905\n",
      "Iteration:710, Price of Hedge: 0.17389001635502838, Loss: 0.000978437899131368\n",
      "Iteration:720, Price of Hedge: 0.15856108184979123, Loss: 0.0011355918234202456\n",
      "Iteration:730, Price of Hedge: 0.14781247381354207, Loss: 0.0010020581659270446\n",
      "Iteration:740, Price of Hedge: 0.18348516351580885, Loss: 0.0011609077768554245\n",
      "Iteration:750, Price of Hedge: 0.17491079568090984, Loss: 0.0013187214980017183\n",
      "Iteration:760, Price of Hedge: 0.16815350365982343, Loss: 0.0013753430006503643\n",
      "Iteration:770, Price of Hedge: 0.17246266569821958, Loss: 0.0012145793064627598\n",
      "Iteration:780, Price of Hedge: 0.17996603443993991, Loss: 0.0009230096090293572\n",
      "Iteration:790, Price of Hedge: 0.17892283073684895, Loss: 0.0009835104532310624\n",
      "Iteration:800, Price of Hedge: 0.16837664772898508, Loss: 0.0009062882598556588\n",
      "Iteration:810, Price of Hedge: 0.165491887868518, Loss: 0.0011440922332445426\n",
      "Iteration:820, Price of Hedge: 0.1825520416701352, Loss: 0.0010387207202537498\n",
      "Iteration:830, Price of Hedge: 0.18174093903691074, Loss: 0.0010301175245631012\n",
      "Iteration:840, Price of Hedge: 0.17192530940682219, Loss: 0.0011460734915187843\n",
      "Iteration:850, Price of Hedge: 0.1886260994150348, Loss: 0.0010210144695623757\n",
      "Iteration:860, Price of Hedge: 0.1937928225511655, Loss: 0.0012866937706842664\n",
      "Iteration:870, Price of Hedge: 0.1968998339682685, Loss: 0.0010674940391050215\n",
      "Iteration:880, Price of Hedge: 0.16557390339454514, Loss: 0.0011895318040607173\n",
      "Iteration:890, Price of Hedge: 0.1572026937233204, Loss: 0.0011886034316566985\n",
      "Iteration:900, Price of Hedge: 0.16941862422735313, Loss: 0.001226683634052872\n",
      "Iteration:910, Price of Hedge: 0.17630885280160558, Loss: 0.0009915389570184453\n",
      "Iteration:920, Price of Hedge: 0.17306095190722318, Loss: 0.0010232937508179774\n",
      "Iteration:930, Price of Hedge: 0.1781016873377098, Loss: 0.001315381673297722\n",
      "Iteration:940, Price of Hedge: 0.16562240188768557, Loss: 0.0009893583526848105\n",
      "Iteration:950, Price of Hedge: 0.17566249841800075, Loss: 0.0010360577507520397\n",
      "Iteration:960, Price of Hedge: 0.18340249454311108, Loss: 0.0010343622508827367\n",
      "Iteration:970, Price of Hedge: 0.1740164343792117, Loss: 0.0011905113514993461\n",
      "Iteration:980, Price of Hedge: 0.1596496443144588, Loss: 0.0011260504810184813\n",
      "Iteration:990, Price of Hedge: 0.1651345959791911, Loss: 0.0010982710286544517\n",
      "tf.Tensor(0.18345985, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_53 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.23178389322769136, Loss: 0.0025109445361209738\n",
      "Iteration:20, Price of Hedge: 0.1802560372599146, Loss: 0.001964812286598594\n",
      "Iteration:30, Price of Hedge: 0.17269567521833554, Loss: 0.0019545085482432613\n",
      "Iteration:40, Price of Hedge: 0.19138923850614448, Loss: 0.002088907512069849\n",
      "Iteration:50, Price of Hedge: 0.21490442539936797, Loss: 0.002071275160120667\n",
      "Iteration:60, Price of Hedge: 0.21042538316432913, Loss: 0.0025048187226106577\n",
      "Iteration:70, Price of Hedge: 0.19359637416915804, Loss: 0.0033882873372583335\n",
      "Iteration:80, Price of Hedge: 0.20274271503127467, Loss: 0.0021302448622284587\n",
      "Iteration:90, Price of Hedge: 0.2017595487332642, Loss: 0.002217434171803312\n",
      "Iteration:100, Price of Hedge: 0.19474506966524815, Loss: 0.0024942353270102306\n",
      "Iteration:110, Price of Hedge: 0.18822470784430154, Loss: 0.0017260493727497385\n",
      "Iteration:120, Price of Hedge: 0.17190838354428026, Loss: 0.0023912945659066765\n",
      "Iteration:130, Price of Hedge: 0.1932122112777165, Loss: 0.0022809579539375237\n",
      "Iteration:140, Price of Hedge: 0.19494065741017721, Loss: 0.0021062137632510414\n",
      "Iteration:150, Price of Hedge: 0.20414050121066796, Loss: 0.0021666872144901817\n",
      "Iteration:160, Price of Hedge: 0.21670752382951833, Loss: 0.0021613226763122387\n",
      "Iteration:170, Price of Hedge: 0.19714052547119537, Loss: 0.0025079004308992126\n",
      "Iteration:180, Price of Hedge: 0.19240206490791253, Loss: 0.0020038579664117154\n",
      "Iteration:190, Price of Hedge: 0.21218259688802166, Loss: 0.002313064498279083\n",
      "Iteration:200, Price of Hedge: 0.24276965459221175, Loss: 0.0026124718203561774\n",
      "Iteration:210, Price of Hedge: 0.2155094213900384, Loss: 0.0021561523791415738\n",
      "Iteration:220, Price of Hedge: 0.21761053931517155, Loss: 0.0020398555565721566\n",
      "Iteration:230, Price of Hedge: 0.21335188392309876, Loss: 0.00229885751178518\n",
      "Iteration:240, Price of Hedge: 0.20690571220585527, Loss: 0.0019387106531916667\n",
      "Iteration:250, Price of Hedge: 0.21382899561900787, Loss: 0.002128178187716401\n",
      "Iteration:260, Price of Hedge: 0.22488749675437705, Loss: 0.0026508623103101317\n",
      "Iteration:270, Price of Hedge: 0.21019817497563056, Loss: 0.0023822299855670082\n",
      "Iteration:280, Price of Hedge: 0.17341977381802282, Loss: 0.0020277384040950255\n",
      "Iteration:290, Price of Hedge: 0.17600272100527264, Loss: 0.0021416565214060768\n",
      "Iteration:300, Price of Hedge: 0.17664359281193356, Loss: 0.0022487276432105576\n",
      "Iteration:310, Price of Hedge: 0.2046248008199541, Loss: 0.002625127120034243\n",
      "Iteration:320, Price of Hedge: 0.21486579235718184, Loss: 0.0019583720765861123\n",
      "Iteration:330, Price of Hedge: 0.20624590638346946, Loss: 0.0018810093697640975\n",
      "Iteration:340, Price of Hedge: 0.19434522405371127, Loss: 0.0015763953925842069\n",
      "Iteration:350, Price of Hedge: 0.1773179179005865, Loss: 0.0015546215982356062\n",
      "Iteration:360, Price of Hedge: 0.18701842935257676, Loss: 0.0013109435153083383\n",
      "Iteration:370, Price of Hedge: 0.18135285546544538, Loss: 0.001166973699388496\n",
      "Iteration:380, Price of Hedge: 0.1739870770922039, Loss: 0.001384206118201714\n",
      "Iteration:390, Price of Hedge: 0.16472018328821605, Loss: 0.0009756031010462963\n",
      "Iteration:400, Price of Hedge: 0.17032382318114972, Loss: 0.0012143792133225695\n",
      "Iteration:410, Price of Hedge: 0.17385881029207442, Loss: 0.0011828268784190854\n",
      "Iteration:420, Price of Hedge: 0.1650365311654241, Loss: 0.001548868204502707\n",
      "Iteration:430, Price of Hedge: 0.1671778918428345, Loss: 0.001331907723099679\n",
      "Iteration:440, Price of Hedge: 0.17190873417420108, Loss: 0.0011587345188162957\n",
      "Iteration:450, Price of Hedge: 0.19008285517202242, Loss: 0.001679064589817969\n",
      "Iteration:460, Price of Hedge: 0.18644406566680802, Loss: 0.0013397983904799738\n",
      "Iteration:470, Price of Hedge: 0.1701871253251966, Loss: 0.001457880238100895\n",
      "Iteration:480, Price of Hedge: 0.1966527992513193, Loss: 0.0014532670141780282\n",
      "Iteration:490, Price of Hedge: 0.1782126935831002, Loss: 0.0020646014873590525\n",
      "Iteration:500, Price of Hedge: 0.188321625141964, Loss: 0.0015904067684227032\n",
      "Iteration:510, Price of Hedge: 0.19218626812936465, Loss: 0.0014822820136672023\n",
      "Iteration:520, Price of Hedge: 0.20305911072165375, Loss: 0.0013779290208299601\n",
      "Iteration:530, Price of Hedge: 0.1913483104317493, Loss: 0.002001845953311321\n",
      "Iteration:540, Price of Hedge: 0.20348168352714993, Loss: 0.0012415719582338448\n",
      "Iteration:550, Price of Hedge: 0.2079731093734836, Loss: 0.0017045071734482777\n",
      "Iteration:560, Price of Hedge: 0.19189208962578733, Loss: 0.0012127920401688642\n",
      "Iteration:570, Price of Hedge: 0.21565096431398845, Loss: 0.0013119320277165337\n",
      "Iteration:580, Price of Hedge: 0.21526880957572986, Loss: 0.00135477910365287\n",
      "Iteration:590, Price of Hedge: 0.21500945499838056, Loss: 0.0014311945120240035\n",
      "Iteration:600, Price of Hedge: 0.21400588841406717, Loss: 0.0015053497519565975\n",
      "Iteration:610, Price of Hedge: 0.19007534850417188, Loss: 0.0011902003168607679\n",
      "Iteration:620, Price of Hedge: 0.17675209683470713, Loss: 0.0012534730798471117\n",
      "Iteration:630, Price of Hedge: 0.18020862253198403, Loss: 0.0012218596088317214\n",
      "Iteration:640, Price of Hedge: 0.17465733806131994, Loss: 0.0011922435828411793\n",
      "Iteration:650, Price of Hedge: 0.19332737726898588, Loss: 0.0016080498285299784\n",
      "Iteration:660, Price of Hedge: 0.21085581326759667, Loss: 0.001453405971206312\n",
      "Iteration:670, Price of Hedge: 0.20093408621100936, Loss: 0.0014215571697397957\n",
      "Iteration:680, Price of Hedge: 0.21001191079905085, Loss: 0.0019889123660362888\n",
      "Iteration:690, Price of Hedge: 0.18329085078877372, Loss: 0.0012286498261977032\n",
      "Iteration:700, Price of Hedge: 0.1854370884096284, Loss: 0.0014590240188014471\n",
      "Iteration:710, Price of Hedge: 0.2150273530620666, Loss: 0.0015710533913436465\n",
      "Iteration:720, Price of Hedge: 0.2136817310522588, Loss: 0.0014825283013033543\n",
      "Iteration:730, Price of Hedge: 0.20188802272380146, Loss: 0.001369666805266512\n",
      "Iteration:740, Price of Hedge: 0.18773051090861373, Loss: 0.0013116039347330856\n",
      "Iteration:750, Price of Hedge: 0.19895682033654796, Loss: 0.001434159675708191\n",
      "Iteration:760, Price of Hedge: 0.18652555524795392, Loss: 0.0010814071738186827\n",
      "Iteration:770, Price of Hedge: 0.20579190438688785, Loss: 0.0015136769635494042\n",
      "Iteration:780, Price of Hedge: 0.18520683611570804, Loss: 0.0013238477174053467\n",
      "Iteration:790, Price of Hedge: 0.2071506272055558, Loss: 0.001464713910666582\n",
      "Iteration:800, Price of Hedge: 0.19496357585682064, Loss: 0.0015000701319626054\n",
      "Iteration:810, Price of Hedge: 0.20267128215376717, Loss: 0.001358287519590107\n",
      "Iteration:820, Price of Hedge: 0.19408947140191232, Loss: 0.0012830158919195256\n",
      "Iteration:830, Price of Hedge: 0.16833031676626434, Loss: 0.0013940557559458\n",
      "Iteration:840, Price of Hedge: 0.19158648377433565, Loss: 0.0013515020337358408\n",
      "Iteration:850, Price of Hedge: 0.19717654472669893, Loss: 0.0013692100898724747\n",
      "Iteration:860, Price of Hedge: 0.20756228267033522, Loss: 0.0013811250324804903\n",
      "Iteration:870, Price of Hedge: 0.18505722870357888, Loss: 0.0014422996190478266\n",
      "Iteration:880, Price of Hedge: 0.20746185907346446, Loss: 0.0018611862033770523\n",
      "Iteration:890, Price of Hedge: 0.19942449690004196, Loss: 0.001297097368839495\n",
      "Iteration:900, Price of Hedge: 0.18299004219214796, Loss: 0.0012990919500546205\n",
      "Iteration:910, Price of Hedge: 0.16462817480944525, Loss: 0.0011561837359476358\n",
      "Iteration:920, Price of Hedge: 0.17436875369875227, Loss: 0.0015697052840450533\n",
      "Iteration:930, Price of Hedge: 0.19302690336455727, Loss: 0.001393614978275437\n",
      "Iteration:940, Price of Hedge: 0.18661687840460675, Loss: 0.0009864284263115587\n",
      "Iteration:950, Price of Hedge: 0.1633416817544685, Loss: 0.0014903462528193857\n",
      "Iteration:960, Price of Hedge: 0.1831742504023737, Loss: 0.0014482917050954393\n",
      "Iteration:970, Price of Hedge: 0.1962995555438056, Loss: 0.0011516835702520822\n",
      "Iteration:980, Price of Hedge: 0.1982637524848542, Loss: 0.001336760510931523\n",
      "Iteration:990, Price of Hedge: 0.1957859942738537, Loss: 0.0015069873530641155\n",
      "tf.Tensor(0.17596388, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_54 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.12952837455350732, Loss: 0.0025038168872615787\n",
      "Iteration:20, Price of Hedge: 0.2027102817635978, Loss: 0.0024971663740046782\n",
      "Iteration:30, Price of Hedge: 0.20202298336787408, Loss: 0.002499626511069941\n",
      "Iteration:40, Price of Hedge: 0.19483569156205932, Loss: 0.0018929563123329276\n",
      "Iteration:50, Price of Hedge: 0.19035676089108622, Loss: 0.0021953726268343133\n",
      "Iteration:60, Price of Hedge: 0.19804701538060956, Loss: 0.00253971934913384\n",
      "Iteration:70, Price of Hedge: 0.18185360280556326, Loss: 0.002577904142841625\n",
      "Iteration:80, Price of Hedge: 0.2008173901982673, Loss: 0.0023745514891331254\n",
      "Iteration:90, Price of Hedge: 0.19502442608580853, Loss: 0.001909133848942979\n",
      "Iteration:100, Price of Hedge: 0.19422879898227166, Loss: 0.0024571455047242455\n",
      "Iteration:110, Price of Hedge: 0.1878552873472586, Loss: 0.0020825631774263444\n",
      "Iteration:120, Price of Hedge: 0.18591965080703404, Loss: 0.001899856101549169\n",
      "Iteration:130, Price of Hedge: 0.19159757643001288, Loss: 0.001829585557248681\n",
      "Iteration:140, Price of Hedge: 0.19146634521328, Loss: 0.0020082789415427627\n",
      "Iteration:150, Price of Hedge: 0.1951551632331075, Loss: 0.0022843646423728716\n",
      "Iteration:160, Price of Hedge: 0.19834675614974914, Loss: 0.0025456337387785412\n",
      "Iteration:170, Price of Hedge: 0.18476995123435247, Loss: 0.0026397029154150435\n",
      "Iteration:180, Price of Hedge: 0.1799309076969621, Loss: 0.002405887793172745\n",
      "Iteration:190, Price of Hedge: 0.20071009744249296, Loss: 0.0020538155083491107\n",
      "Iteration:200, Price of Hedge: 0.18546418253987443, Loss: 0.002088792461627076\n",
      "Iteration:210, Price of Hedge: 0.18734598144952772, Loss: 0.0021405481025299268\n",
      "Iteration:220, Price of Hedge: 0.1867413360887781, Loss: 0.001781156791649341\n",
      "Iteration:230, Price of Hedge: 0.1920063949799783, Loss: 0.0018730857063152585\n",
      "Iteration:240, Price of Hedge: 0.17851941507520908, Loss: 0.002362384780296445\n",
      "Iteration:250, Price of Hedge: 0.19645349801677414, Loss: 0.002388614787087029\n",
      "Iteration:260, Price of Hedge: 0.1969060496805014, Loss: 0.002261719129247375\n",
      "Iteration:270, Price of Hedge: 0.22997069028073158, Loss: 0.002639472814529498\n",
      "Iteration:280, Price of Hedge: 0.1971508690538599, Loss: 0.0021799060621162884\n",
      "Iteration:290, Price of Hedge: 0.17599674435889484, Loss: 0.0018880528475203385\n",
      "Iteration:300, Price of Hedge: 0.1679241757538762, Loss: 0.0023827835724377524\n",
      "Iteration:310, Price of Hedge: 0.19515524292172587, Loss: 0.0018354594800168657\n",
      "Iteration:320, Price of Hedge: 0.2050148447314314, Loss: 0.0022733212940282857\n",
      "Iteration:330, Price of Hedge: 0.2000053950525171, Loss: 0.0018661469443840952\n",
      "Iteration:340, Price of Hedge: 0.18562515354898326, Loss: 0.001639355004203047\n",
      "Iteration:350, Price of Hedge: 0.18150459853254688, Loss: 0.0020678930008381615\n",
      "Iteration:360, Price of Hedge: 0.19096035436207331, Loss: 0.0019759761639784657\n",
      "Iteration:370, Price of Hedge: 0.18547014324852854, Loss: 0.002533669737864841\n",
      "Iteration:380, Price of Hedge: 0.17412222898896063, Loss: 0.002105303818840021\n",
      "Iteration:390, Price of Hedge: 0.18525004328458863, Loss: 0.0021507108916415164\n",
      "Iteration:400, Price of Hedge: 0.18453703734057855, Loss: 0.0017379537317131267\n",
      "Iteration:410, Price of Hedge: 0.20510081281292972, Loss: 0.0018833144875639364\n",
      "Iteration:420, Price of Hedge: 0.2147620696515105, Loss: 0.002342342843749279\n",
      "Iteration:430, Price of Hedge: 0.1943121851525348, Loss: 0.001987350593629689\n",
      "Iteration:440, Price of Hedge: 0.19530948821144423, Loss: 0.002607337881117644\n",
      "Iteration:450, Price of Hedge: 0.1919604146471784, Loss: 0.0022498243578208846\n",
      "Iteration:460, Price of Hedge: 0.195222292925223, Loss: 0.0018226159159778989\n",
      "Iteration:470, Price of Hedge: 0.19728006024196248, Loss: 0.0021948175458019747\n",
      "Iteration:480, Price of Hedge: 0.17068101944413458, Loss: 0.0020090823024267127\n",
      "Iteration:490, Price of Hedge: 0.21072305202939107, Loss: 0.00200005756639623\n",
      "Iteration:500, Price of Hedge: 0.20517827014998605, Loss: 0.0021551570184927373\n",
      "Iteration:510, Price of Hedge: 0.20838994459845708, Loss: 0.0020433080659630677\n",
      "Iteration:520, Price of Hedge: 0.20555978737929764, Loss: 0.0017326812089867084\n",
      "Iteration:530, Price of Hedge: 0.22294319009247376, Loss: 0.001973723590861365\n",
      "Iteration:540, Price of Hedge: 0.21018991923476735, Loss: 0.0022586254676660645\n",
      "Iteration:550, Price of Hedge: 0.19734905464774785, Loss: 0.0018185112050510101\n",
      "Iteration:560, Price of Hedge: 0.18530316371759456, Loss: 0.0021911750288616362\n",
      "Iteration:570, Price of Hedge: 0.17833879285281, Loss: 0.0018961302850999397\n",
      "Iteration:580, Price of Hedge: 0.1812248914820657, Loss: 0.002408052584296172\n",
      "Iteration:590, Price of Hedge: 0.17695555781513123, Loss: 0.0018885316017978938\n",
      "Iteration:600, Price of Hedge: 0.19973336998484684, Loss: 0.0024646818067797227\n",
      "Iteration:610, Price of Hedge: 0.21727869997055224, Loss: 0.0023428523528529867\n",
      "Iteration:620, Price of Hedge: 0.2145606646374404, Loss: 0.001760331416372818\n",
      "Iteration:630, Price of Hedge: 0.1978223253522515, Loss: 0.0020810891870134186\n",
      "Iteration:640, Price of Hedge: 0.1980257863326756, Loss: 0.0017958949525900714\n",
      "Iteration:650, Price of Hedge: 0.2013521964538768, Loss: 0.002234699209027191\n",
      "Iteration:660, Price of Hedge: 0.18986175113149104, Loss: 0.0018132609702350424\n",
      "Iteration:670, Price of Hedge: 0.2107491102075983, Loss: 0.0024790177892246136\n",
      "Iteration:680, Price of Hedge: 0.18055469426384435, Loss: 0.002134150600636353\n",
      "Iteration:690, Price of Hedge: 0.18749055254097585, Loss: 0.0018669889044425681\n",
      "Iteration:700, Price of Hedge: 0.16940204899473202, Loss: 0.0016374743528094983\n",
      "Iteration:710, Price of Hedge: 0.16551377036312262, Loss: 0.0019787970165553227\n",
      "Iteration:720, Price of Hedge: 0.18683246799274686, Loss: 0.002212038505258818\n",
      "Iteration:730, Price of Hedge: 0.19200408401004554, Loss: 0.0024180024553805525\n",
      "Iteration:740, Price of Hedge: 0.18045025436060771, Loss: 0.002075192229253986\n",
      "Iteration:750, Price of Hedge: 0.17877285675707527, Loss: 0.0018636717411894212\n",
      "Iteration:760, Price of Hedge: 0.21395211453439061, Loss: 0.001923975480574125\n",
      "Iteration:770, Price of Hedge: 0.20811063599106774, Loss: 0.002068618914346132\n",
      "Iteration:780, Price of Hedge: 0.19453936146578601, Loss: 0.002012432088208005\n",
      "Iteration:790, Price of Hedge: 0.17486926197301503, Loss: 0.0014955504176528578\n",
      "Iteration:800, Price of Hedge: 0.1996002581167204, Loss: 0.0022550820634448243\n",
      "Iteration:810, Price of Hedge: 0.18237672670971963, Loss: 0.0019405538260318879\n",
      "Iteration:820, Price of Hedge: 0.19354232934817903, Loss: 0.002133157730256841\n",
      "Iteration:830, Price of Hedge: 0.1930692977095305, Loss: 0.002131266121678266\n",
      "Iteration:840, Price of Hedge: 0.2030509346694089, Loss: 0.0019623758070919095\n",
      "Iteration:850, Price of Hedge: 0.168708359571815, Loss: 0.0017799182562010076\n",
      "Iteration:860, Price of Hedge: 0.18560260166998435, Loss: 0.0020502897850400714\n",
      "Iteration:870, Price of Hedge: 0.20463771037613016, Loss: 0.002496142126231682\n",
      "Iteration:880, Price of Hedge: 0.1849854611338742, Loss: 0.002102175044461241\n",
      "Iteration:890, Price of Hedge: 0.180408959718568, Loss: 0.002166493471536768\n",
      "Iteration:900, Price of Hedge: 0.17847923607382657, Loss: 0.0019776800062500047\n",
      "Iteration:910, Price of Hedge: 0.19217565360539768, Loss: 0.002314818643990968\n",
      "Iteration:920, Price of Hedge: 0.18322949055262827, Loss: 0.00232573125319604\n",
      "Iteration:930, Price of Hedge: 0.19045047470629017, Loss: 0.001949679916023861\n",
      "Iteration:940, Price of Hedge: 0.18857275585389746, Loss: 0.0014536556207060515\n",
      "Iteration:950, Price of Hedge: 0.1990573236220371, Loss: 0.001443340551625294\n",
      "Iteration:960, Price of Hedge: 0.190452929115736, Loss: 0.0016626569523223724\n",
      "Iteration:970, Price of Hedge: 0.1965781469536296, Loss: 0.001245899423751773\n",
      "Iteration:980, Price of Hedge: 0.19808937785013542, Loss: 0.0013680443948018708\n",
      "Iteration:990, Price of Hedge: 0.19681641592255802, Loss: 0.0013390798232665092\n",
      "tf.Tensor(0.22964992, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_55 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.2525583175938437, Loss: 0.002856788657365073\n",
      "Iteration:20, Price of Hedge: 0.20088507771071137, Loss: 0.0026382082557667276\n",
      "Iteration:30, Price of Hedge: 0.17981446668779882, Loss: 0.0022302366463984313\n",
      "Iteration:40, Price of Hedge: 0.18898305661216455, Loss: 0.0016244005633715198\n",
      "Iteration:50, Price of Hedge: 0.19897095709744692, Loss: 0.002079916394675241\n",
      "Iteration:60, Price of Hedge: 0.19340601399759408, Loss: 0.0020477448543043232\n",
      "Iteration:70, Price of Hedge: 0.1858927479294721, Loss: 0.002012030905819895\n",
      "Iteration:80, Price of Hedge: 0.19910891403357028, Loss: 0.0023967405358915174\n",
      "Iteration:90, Price of Hedge: 0.1763007086248081, Loss: 0.001991800455884896\n",
      "Iteration:100, Price of Hedge: 0.1712230933017395, Loss: 0.002072490660577753\n",
      "Iteration:110, Price of Hedge: 0.1619975897661334, Loss: 0.001740237557710245\n",
      "Iteration:120, Price of Hedge: 0.19453336888168452, Loss: 0.0018511392117890326\n",
      "Iteration:130, Price of Hedge: 0.20251781781250885, Loss: 0.0023262213381990194\n",
      "Iteration:140, Price of Hedge: 0.1812912880388922, Loss: 0.0018937693852672413\n",
      "Iteration:150, Price of Hedge: 0.17993321866689485, Loss: 0.001783779418788001\n",
      "Iteration:160, Price of Hedge: 0.1860810999478531, Loss: 0.0018266259966704724\n",
      "Iteration:170, Price of Hedge: 0.21305161720907792, Loss: 0.0025714267033027484\n",
      "Iteration:180, Price of Hedge: 0.2019216513207539, Loss: 0.001819887825933364\n",
      "Iteration:190, Price of Hedge: 0.1767506943150238, Loss: 0.0020309977930998537\n",
      "Iteration:200, Price of Hedge: 0.18121234849353415, Loss: 0.0020044843936601886\n",
      "Iteration:210, Price of Hedge: 0.20075916969368565, Loss: 0.001811067790041321\n",
      "Iteration:220, Price of Hedge: 0.20641599377051992, Loss: 0.0020340722796073686\n",
      "Iteration:230, Price of Hedge: 0.20932787963668034, Loss: 0.002039850825060441\n",
      "Iteration:240, Price of Hedge: 0.1848975167746403, Loss: 0.0020926368148961316\n",
      "Iteration:250, Price of Hedge: 0.18602342132587638, Loss: 0.0023947201803888873\n",
      "Iteration:260, Price of Hedge: 0.1993081833926681, Loss: 0.002066317905490678\n",
      "Iteration:270, Price of Hedge: 0.1980542511071576, Loss: 0.0020790816563978076\n",
      "Iteration:280, Price of Hedge: 0.19834125763508156, Loss: 0.002120323380214373\n",
      "Iteration:290, Price of Hedge: 0.1808112597395507, Loss: 0.0020634753875707016\n",
      "Iteration:300, Price of Hedge: 0.1900962906730797, Loss: 0.0017796117040472126\n",
      "Iteration:310, Price of Hedge: 0.18289105299040787, Loss: 0.002012396103816272\n",
      "Iteration:320, Price of Hedge: 0.18877570682716396, Loss: 0.002183373015069279\n",
      "Iteration:330, Price of Hedge: 0.19069146902596687, Loss: 0.0023443318218584253\n",
      "Iteration:340, Price of Hedge: 0.17852110447391853, Loss: 0.002177333364877576\n",
      "Iteration:350, Price of Hedge: 0.1817590283532809, Loss: 0.001930982226857836\n",
      "Iteration:360, Price of Hedge: 0.1683675791642145, Loss: 0.0019546299488728104\n",
      "Iteration:370, Price of Hedge: 0.19975931659898835, Loss: 0.002234785123318872\n",
      "Iteration:380, Price of Hedge: 0.2130487802942639, Loss: 0.002205658435250513\n",
      "Iteration:390, Price of Hedge: 0.1850491960908471, Loss: 0.001468683524482639\n",
      "Iteration:400, Price of Hedge: 0.20650577096797634, Loss: 0.0018451778805675723\n",
      "Iteration:410, Price of Hedge: 0.17057441201047824, Loss: 0.0018805126855474088\n",
      "Iteration:420, Price of Hedge: 0.1583208844162982, Loss: 0.001689482382508345\n",
      "Iteration:430, Price of Hedge: 0.1633270668618593, Loss: 0.001717126613248077\n",
      "Iteration:440, Price of Hedge: 0.21041124640343015, Loss: 0.0015708662476039417\n",
      "Iteration:450, Price of Hedge: 0.20846128184962257, Loss: 0.0015774088076856432\n",
      "Iteration:460, Price of Hedge: 0.1990672368861624, Loss: 0.0014436163489529364\n",
      "Iteration:470, Price of Hedge: 0.19063028410478183, Loss: 0.0018007802384365946\n",
      "Iteration:480, Price of Hedge: 0.17369163950845634, Loss: 0.0016927742695278527\n",
      "Iteration:490, Price of Hedge: 0.1691245732255652, Loss: 0.0012251202429712116\n",
      "Iteration:500, Price of Hedge: 0.18822757663456288, Loss: 0.001219639035675435\n",
      "Iteration:510, Price of Hedge: 0.18422323949915836, Loss: 0.0012472237489783212\n",
      "Iteration:520, Price of Hedge: 0.19403563377134106, Loss: 0.002112810984744407\n",
      "Iteration:530, Price of Hedge: 0.1686842617336197, Loss: 0.0011579301618246164\n",
      "Iteration:540, Price of Hedge: 0.16229025418596166, Loss: 0.0015475273189851535\n",
      "Iteration:550, Price of Hedge: 0.16433651446620845, Loss: 0.001347658303034116\n",
      "Iteration:560, Price of Hedge: 0.1755778372298437, Loss: 0.0015792958092659683\n",
      "Iteration:570, Price of Hedge: 0.19503080117527818, Loss: 0.0015543646024413606\n",
      "Iteration:580, Price of Hedge: 0.19381421097633622, Loss: 0.0013564790860069566\n",
      "Iteration:590, Price of Hedge: 0.19563484090252817, Loss: 0.0011540449681386455\n",
      "Iteration:600, Price of Hedge: 0.21481992358844765, Loss: 0.0014435090183450685\n",
      "Iteration:610, Price of Hedge: 0.2221501608378958, Loss: 0.0013610698975059067\n",
      "Iteration:620, Price of Hedge: 0.19711735202097316, Loss: 0.0013161817968315504\n",
      "Iteration:630, Price of Hedge: 0.19547946403442895, Loss: 0.0012339737729856637\n",
      "Iteration:640, Price of Hedge: 0.1869331465931964, Loss: 0.0013118991561614558\n",
      "Iteration:650, Price of Hedge: 0.1797075564373927, Loss: 0.001143339549341338\n",
      "Iteration:660, Price of Hedge: 0.19856202698341577, Loss: 0.0012119357610617778\n",
      "Iteration:670, Price of Hedge: 0.18795411717176194, Loss: 0.0015070268238329021\n",
      "Iteration:680, Price of Hedge: 0.20286285359233036, Loss: 0.0011403428837502005\n",
      "Iteration:690, Price of Hedge: 0.20044298119371434, Loss: 0.0011864660334958367\n",
      "Iteration:700, Price of Hedge: 0.209584381361492, Loss: 0.0012245608039675561\n",
      "Iteration:710, Price of Hedge: 0.19988771090090723, Loss: 0.001167123613601806\n",
      "Iteration:720, Price of Hedge: 0.18830449208901429, Loss: 0.0012301558165714434\n",
      "Iteration:730, Price of Hedge: 0.18295885206691767, Loss: 0.0015263052438053038\n",
      "Iteration:740, Price of Hedge: 0.1941514213338337, Loss: 0.0013316117545905117\n",
      "Iteration:750, Price of Hedge: 0.20501463754102361, Loss: 0.0023080466055910524\n",
      "Iteration:760, Price of Hedge: 0.2458547994524338, Loss: 0.00131478537830807\n",
      "Iteration:770, Price of Hedge: 0.2141917700852787, Loss: 0.0014892738183349687\n",
      "Iteration:780, Price of Hedge: 0.2249948213855987, Loss: 0.0016018936337339085\n",
      "Iteration:790, Price of Hedge: 0.18325680781100576, Loss: 0.0011190647775105589\n",
      "Iteration:800, Price of Hedge: 0.18170173223667235, Loss: 0.0011127844427886837\n",
      "Iteration:810, Price of Hedge: 0.17872469295613203, Loss: 0.0014724427105408113\n",
      "Iteration:820, Price of Hedge: 0.17059486010995217, Loss: 0.0016190828422568695\n",
      "Iteration:830, Price of Hedge: 0.1922613188701462, Loss: 0.001090647318145699\n",
      "Iteration:840, Price of Hedge: 0.2008443727644476, Loss: 0.0010692555311114127\n",
      "Iteration:850, Price of Hedge: 0.16975747617038908, Loss: 0.0011295709747619399\n",
      "Iteration:860, Price of Hedge: 0.17314510308822265, Loss: 0.0012426411553681405\n",
      "Iteration:870, Price of Hedge: 0.20697862729166447, Loss: 0.0014622586296265006\n",
      "Iteration:880, Price of Hedge: 0.20869964644489303, Loss: 0.0014281156675451713\n",
      "Iteration:890, Price of Hedge: 0.19662101943031304, Loss: 0.0010875734542055149\n",
      "Iteration:900, Price of Hedge: 0.18537169592939337, Loss: 0.0011222206958249716\n",
      "Iteration:910, Price of Hedge: 0.1755406067073409, Loss: 0.001268038042556352\n",
      "Iteration:920, Price of Hedge: 0.19357689827082825, Loss: 0.0013669451899222197\n",
      "Iteration:930, Price of Hedge: 0.20240835752631484, Loss: 0.0011632421553198213\n",
      "Iteration:940, Price of Hedge: 0.21012071763857423, Loss: 0.0012922565343004067\n",
      "Iteration:950, Price of Hedge: 0.19703028423654134, Loss: 0.0010414866001352775\n",
      "Iteration:960, Price of Hedge: 0.192077572853907, Loss: 0.0012528634619165758\n",
      "Iteration:970, Price of Hedge: 0.1832713270772729, Loss: 0.001141946617194911\n",
      "Iteration:980, Price of Hedge: 0.1843659140014893, Loss: 0.0011596818172671776\n",
      "Iteration:990, Price of Hedge: 0.17459596188745083, Loss: 0.001514744292981707\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 9 \n",
      "\n",
      "tf.Tensor(0.24866389, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_56 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.3064646696392856, Loss: 0.0042687954231393375\n",
      "Iteration:20, Price of Hedge: 0.18837596463965267, Loss: 0.0016733953267500379\n",
      "Iteration:30, Price of Hedge: 0.1873429838456559, Loss: 0.0019192795264766803\n",
      "Iteration:40, Price of Hedge: 0.2543875705215953, Loss: 0.001589890244409542\n",
      "Iteration:50, Price of Hedge: 0.20301809749967673, Loss: 0.0016316299530605427\n",
      "Iteration:60, Price of Hedge: 0.1975739706439157, Loss: 0.0018326365450111125\n",
      "Iteration:70, Price of Hedge: 0.2190923920314901, Loss: 0.0019908728476951687\n",
      "Iteration:80, Price of Hedge: 0.2352696714098613, Loss: 0.002125916510593084\n",
      "Iteration:90, Price of Hedge: 0.21059595119483843, Loss: 0.0014529327455597096\n",
      "Iteration:100, Price of Hedge: 0.2018734606572792, Loss: 0.0019281841011115296\n",
      "Iteration:110, Price of Hedge: 0.20772681476125, Loss: 0.0012747812682960102\n",
      "Iteration:120, Price of Hedge: 0.22359089949684402, Loss: 0.0015003761608469723\n",
      "Iteration:130, Price of Hedge: 0.2449184398464922, Loss: 0.0019695455986138643\n",
      "Iteration:140, Price of Hedge: 0.21667153508701062, Loss: 0.0016648379264731171\n",
      "Iteration:150, Price of Hedge: 0.2129648063943449, Loss: 0.001628250921945895\n",
      "Iteration:160, Price of Hedge: 0.20641090576615112, Loss: 0.0017927168656015624\n",
      "Iteration:170, Price of Hedge: 0.21501048424586883, Loss: 0.0017284858292628156\n",
      "Iteration:180, Price of Hedge: 0.21726171160011062, Loss: 0.0017338456442786308\n",
      "Iteration:190, Price of Hedge: 0.20269407977089882, Loss: 0.0015804807250638486\n",
      "Iteration:200, Price of Hedge: 0.20320492943013446, Loss: 0.0017136434788615595\n",
      "Iteration:210, Price of Hedge: 0.2195005624371845, Loss: 0.001778178317632717\n",
      "Iteration:220, Price of Hedge: 0.24496878629595925, Loss: 0.001403043690848471\n",
      "Iteration:230, Price of Hedge: 0.22049789071259054, Loss: 0.0016618860491386831\n",
      "Iteration:240, Price of Hedge: 0.18309224865146517, Loss: 0.001957402454237833\n",
      "Iteration:250, Price of Hedge: 0.2028728262194619, Loss: 0.0018903279703784469\n",
      "Iteration:260, Price of Hedge: 0.18259692057085886, Loss: 0.0016754938912929783\n",
      "Iteration:270, Price of Hedge: 0.18120252510269097, Loss: 0.0016400657925737415\n",
      "Iteration:280, Price of Hedge: 0.1964001751345279, Loss: 0.0016412195255832707\n",
      "Iteration:290, Price of Hedge: 0.18173409142183627, Loss: 0.0013102956134818154\n",
      "Iteration:300, Price of Hedge: 0.20708307033896745, Loss: 0.0021048033357863537\n",
      "Iteration:310, Price of Hedge: 0.2034997630258374, Loss: 0.0015581119529087582\n",
      "Iteration:320, Price of Hedge: 0.19764868813644795, Loss: 0.0015487639102831794\n",
      "Iteration:330, Price of Hedge: 0.22801400188537854, Loss: 0.0016680796794748874\n",
      "Iteration:340, Price of Hedge: 0.23960402449318963, Loss: 0.0014934048201582506\n",
      "Iteration:350, Price of Hedge: 0.21130090335171586, Loss: 0.0015314710460901714\n",
      "Iteration:360, Price of Hedge: 0.22000456171963378, Loss: 0.0017501377709241428\n",
      "Iteration:370, Price of Hedge: 0.20222397584719543, Loss: 0.0017095653241401719\n",
      "Iteration:380, Price of Hedge: 0.19117933490948358, Loss: 0.0019259363212285052\n",
      "Iteration:390, Price of Hedge: 0.21959763915209007, Loss: 0.0016154322299868572\n",
      "Iteration:400, Price of Hedge: 0.2051665182699537, Loss: 0.0015870418230442328\n",
      "Iteration:410, Price of Hedge: 0.2063849048936646, Loss: 0.0015824480795844087\n",
      "Iteration:420, Price of Hedge: 0.22417185728727984, Loss: 0.0017383903456300142\n",
      "Iteration:430, Price of Hedge: 0.2187285580792718, Loss: 0.001904539836229402\n",
      "Iteration:440, Price of Hedge: 0.19883824715226978, Loss: 0.0016011847514080689\n",
      "Iteration:450, Price of Hedge: 0.18125450138157928, Loss: 0.0018354843695150612\n",
      "Iteration:460, Price of Hedge: 0.21006346809664364, Loss: 0.0017179743048921557\n",
      "Iteration:470, Price of Hedge: 0.22784350644826076, Loss: 0.0019365847258044687\n",
      "Iteration:480, Price of Hedge: 0.25088802116106873, Loss: 0.0016525562107845948\n",
      "Iteration:490, Price of Hedge: 0.23491706800099904, Loss: 0.001587707820845474\n",
      "Iteration:500, Price of Hedge: 0.2105766351695877, Loss: 0.001541803611529624\n",
      "Iteration:510, Price of Hedge: 0.23268308118610434, Loss: 0.0018484334756813325\n",
      "Iteration:520, Price of Hedge: 0.219000586796119, Loss: 0.0018075950276844387\n",
      "Iteration:530, Price of Hedge: 0.22562553780064717, Loss: 0.0017943449044387715\n",
      "Iteration:540, Price of Hedge: 0.24394843667997745, Loss: 0.0017249655409595553\n",
      "Iteration:550, Price of Hedge: 0.2427233142768614, Loss: 0.0015370575689460208\n",
      "Iteration:560, Price of Hedge: 0.2263481888863964, Loss: 0.0013430482811533472\n",
      "Iteration:570, Price of Hedge: 0.20233118806381467, Loss: 0.0011167893803390116\n",
      "Iteration:580, Price of Hedge: 0.2054896574188092, Loss: 0.0018879271950333898\n",
      "Iteration:590, Price of Hedge: 0.22574008424966222, Loss: 0.0013715004632467664\n",
      "Iteration:600, Price of Hedge: 0.2071135023101931, Loss: 0.0009349859073652044\n",
      "Iteration:610, Price of Hedge: 0.1616443810515733, Loss: 0.0016440309415442387\n",
      "Iteration:620, Price of Hedge: 0.20807246592898707, Loss: 0.0011876284677518223\n",
      "Iteration:630, Price of Hedge: 0.1735776100829895, Loss: 0.0011810661760487172\n",
      "Iteration:640, Price of Hedge: 0.20565073040458515, Loss: 0.0024909809919826387\n",
      "Iteration:650, Price of Hedge: 0.17653864088324553, Loss: 0.000862934892960232\n",
      "Iteration:660, Price of Hedge: 0.18435233598888487, Loss: 0.0015285869125201356\n",
      "Iteration:670, Price of Hedge: 0.20441231470525167, Loss: 0.0011228163868787888\n",
      "Iteration:680, Price of Hedge: 0.23385072663603523, Loss: 0.001253227410851565\n",
      "Iteration:690, Price of Hedge: 0.22569432169544257, Loss: 0.001096240935856052\n",
      "Iteration:700, Price of Hedge: 0.2350998635570306, Loss: 0.0010097766148910114\n",
      "Iteration:710, Price of Hedge: 0.23096475712045503, Loss: 0.001096264909787359\n",
      "Iteration:720, Price of Hedge: 0.2005495935107092, Loss: 0.0011597056022081276\n",
      "Iteration:730, Price of Hedge: 0.22036427016612947, Loss: 0.0012181893610313077\n",
      "Iteration:740, Price of Hedge: 0.22193779407413103, Loss: 0.000991098932865131\n",
      "Iteration:750, Price of Hedge: 0.235477194534144, Loss: 0.0009664789986126409\n",
      "Iteration:760, Price of Hedge: 0.22187940034189635, Loss: 0.0015207948874609522\n",
      "Iteration:770, Price of Hedge: 0.2152048923365271, Loss: 0.0011113054181602466\n",
      "Iteration:780, Price of Hedge: 0.20013151679806354, Loss: 0.0012977564515932016\n",
      "Iteration:790, Price of Hedge: 0.17853282631149056, Loss: 0.001565899203077059\n",
      "Iteration:800, Price of Hedge: 0.22755265829481458, Loss: 0.001126362937081904\n",
      "Iteration:810, Price of Hedge: 0.21499815866087033, Loss: 0.001026078390795182\n",
      "Iteration:820, Price of Hedge: 0.23868156650682407, Loss: 0.0010193138625678166\n",
      "Iteration:830, Price of Hedge: 0.22386185863813352, Loss: 0.0012003050072302067\n",
      "Iteration:840, Price of Hedge: 0.2505118616238519, Loss: 0.0010261751818124497\n",
      "Iteration:850, Price of Hedge: 0.24401686404958695, Loss: 0.0013412867443252097\n",
      "Iteration:860, Price of Hedge: 0.2291815200048859, Loss: 0.0010862881731955598\n",
      "Iteration:870, Price of Hedge: 0.21452079690302525, Loss: 0.0009989861573112878\n",
      "Iteration:880, Price of Hedge: 0.25054766693895086, Loss: 0.0010434855539386944\n",
      "Iteration:890, Price of Hedge: 0.23327865650916235, Loss: 0.0009655936542614762\n",
      "Iteration:900, Price of Hedge: 0.2058091803836362, Loss: 0.0008621201772033737\n",
      "Iteration:910, Price of Hedge: 0.21669267193731798, Loss: 0.001127442062421391\n",
      "Iteration:920, Price of Hedge: 0.1927263740893892, Loss: 0.0014258133548839202\n",
      "Iteration:930, Price of Hedge: 0.19011305720973154, Loss: 0.001642686909237656\n",
      "Iteration:940, Price of Hedge: 0.19114866101045322, Loss: 0.0009821707822065483\n",
      "Iteration:950, Price of Hedge: 0.24780323792217585, Loss: 0.0010675261347640852\n",
      "Iteration:960, Price of Hedge: 0.2159643164485942, Loss: 0.001160130169589113\n",
      "Iteration:970, Price of Hedge: 0.24045767311867505, Loss: 0.0013484165517051005\n",
      "Iteration:980, Price of Hedge: 0.27016910694360946, Loss: 0.0010973397576204303\n",
      "Iteration:990, Price of Hedge: 0.2410718641496544, Loss: 0.00123392531236588\n",
      "tf.Tensor(0.3575807, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_57 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.38986074917908126, Loss: 0.006138618022529662\n",
      "Iteration:20, Price of Hedge: 0.3586455685182443, Loss: 0.006085559435041254\n",
      "Iteration:30, Price of Hedge: 0.4443606151976041, Loss: 0.00767523759471409\n",
      "Iteration:40, Price of Hedge: 0.3523088171943527, Loss: 0.005076431608448928\n",
      "Iteration:50, Price of Hedge: 0.38274183252947863, Loss: 0.004825356704425232\n",
      "Iteration:60, Price of Hedge: 0.405693625227866, Loss: 0.005654914413777234\n",
      "Iteration:70, Price of Hedge: 0.3715255247147524, Loss: 0.0038725383701972756\n",
      "Iteration:80, Price of Hedge: 0.39076645048170916, Loss: 0.005312779953175272\n",
      "Iteration:90, Price of Hedge: 0.43296449135875714, Loss: 0.0058417535065713\n",
      "Iteration:100, Price of Hedge: 0.39642435238554863, Loss: 0.004759677284518737\n",
      "Iteration:110, Price of Hedge: 0.39512168575449774, Loss: 0.003990918260775978\n",
      "Iteration:120, Price of Hedge: 0.39707506178199875, Loss: 0.004883108213836173\n",
      "Iteration:130, Price of Hedge: 0.35710802818793463, Loss: 0.004794721402429492\n",
      "Iteration:140, Price of Hedge: 0.4022771207695712, Loss: 0.00462385551336073\n",
      "Iteration:150, Price of Hedge: 0.4304756909002776, Loss: 0.005269612154242775\n",
      "Iteration:160, Price of Hedge: 0.37477734000324286, Loss: 0.004493873433752249\n",
      "Iteration:170, Price of Hedge: 0.3686032150962944, Loss: 0.005596496807088158\n",
      "Iteration:180, Price of Hedge: 0.4052436904432511, Loss: 0.0048856225917934815\n",
      "Iteration:190, Price of Hedge: 0.3537964949308048, Loss: 0.004748842261290775\n",
      "Iteration:200, Price of Hedge: 0.3649923025473413, Loss: 0.0041820074043632085\n",
      "Iteration:210, Price of Hedge: 0.3988021207147028, Loss: 0.004231207482110832\n",
      "Iteration:220, Price of Hedge: 0.40361136534565956, Loss: 0.004809701030943625\n",
      "Iteration:230, Price of Hedge: 0.30793080306807497, Loss: 0.004155050757885003\n",
      "Iteration:240, Price of Hedge: 0.3690263850258816, Loss: 0.005986429119148528\n",
      "Iteration:250, Price of Hedge: 0.36349856388272883, Loss: 0.004732351777719845\n",
      "Iteration:260, Price of Hedge: 0.39836013134851667, Loss: 0.004489424031264733\n",
      "Iteration:270, Price of Hedge: 0.42533187284843166, Loss: 0.003968790620610463\n",
      "Iteration:280, Price of Hedge: 0.4340269873449301, Loss: 0.0048305326861420635\n",
      "Iteration:290, Price of Hedge: 0.39601136888984456, Loss: 0.005256710399077757\n",
      "Iteration:300, Price of Hedge: 0.35132445115606287, Loss: 0.004885675513500764\n",
      "Iteration:310, Price of Hedge: 0.3678260920553555, Loss: 0.005345600563564989\n",
      "Iteration:320, Price of Hedge: 0.38269833645679796, Loss: 0.005199708547535397\n",
      "Iteration:330, Price of Hedge: 0.3945406515658078, Loss: 0.0049399731851732295\n",
      "Iteration:340, Price of Hedge: 0.4354491663115141, Loss: 0.004940309019165312\n",
      "Iteration:350, Price of Hedge: 0.42977924441569254, Loss: 0.005602138340666051\n",
      "Iteration:360, Price of Hedge: 0.4304280693218743, Loss: 0.0036759632748934123\n",
      "Iteration:370, Price of Hedge: 0.4106927704524878, Loss: 0.0048062471932051485\n",
      "Iteration:380, Price of Hedge: 0.41917621085289625, Loss: 0.004658588865456536\n",
      "Iteration:390, Price of Hedge: 0.40688829019367173, Loss: 0.005315083838026168\n",
      "Iteration:400, Price of Hedge: 0.40523049901137254, Loss: 0.005235790010490415\n",
      "Iteration:410, Price of Hedge: 0.3876203449108402, Loss: 0.005284728662962212\n",
      "Iteration:420, Price of Hedge: 0.392476192476812, Loss: 0.0045640599527444255\n",
      "Iteration:430, Price of Hedge: 0.375486850589283, Loss: 0.0049916152216997745\n",
      "Iteration:440, Price of Hedge: 0.40900164416530627, Loss: 0.004310576514177988\n",
      "Iteration:450, Price of Hedge: 0.42046364876529196, Loss: 0.005545290877262232\n",
      "Iteration:460, Price of Hedge: 0.4070373941196351, Loss: 0.005799390276752536\n",
      "Iteration:470, Price of Hedge: 0.3510639585755882, Loss: 0.0043127618225719646\n",
      "Iteration:480, Price of Hedge: 0.3684551043476347, Loss: 0.005717137608499811\n",
      "Iteration:490, Price of Hedge: 0.38306466608531764, Loss: 0.004360148635506889\n",
      "Iteration:500, Price of Hedge: 0.37316783251754937, Loss: 0.005712626928245967\n",
      "Iteration:510, Price of Hedge: 0.36342152897648816, Loss: 0.0055166518775630275\n",
      "Iteration:520, Price of Hedge: 0.3374274050024155, Loss: 0.004641307739536948\n",
      "Iteration:530, Price of Hedge: 0.32251329435771364, Loss: 0.004365571319919326\n",
      "Iteration:540, Price of Hedge: 0.38206863658023166, Loss: 0.004352219929196188\n",
      "Iteration:550, Price of Hedge: 0.3533061454697588, Loss: 0.004080107651758524\n",
      "Iteration:560, Price of Hedge: 0.4236623927332516, Loss: 0.004280950703696362\n",
      "Iteration:570, Price of Hedge: 0.39617967424367745, Loss: 0.00539608667859035\n",
      "Iteration:580, Price of Hedge: 0.41738614882662545, Loss: 0.004368538118787768\n",
      "Iteration:590, Price of Hedge: 0.4232993482296592, Loss: 0.005840800517932631\n",
      "Iteration:600, Price of Hedge: 0.394880802059248, Loss: 0.0041695493161427065\n",
      "Iteration:610, Price of Hedge: 0.4191601672195304, Loss: 0.004236836282646372\n",
      "Iteration:620, Price of Hedge: 0.45289547162303734, Loss: 0.00435744962843545\n",
      "Iteration:630, Price of Hedge: 0.4189419992718399, Loss: 0.0048820454027072024\n",
      "Iteration:640, Price of Hedge: 0.39122158034760446, Loss: 0.004606744293975051\n",
      "Iteration:650, Price of Hedge: 0.3822579259878637, Loss: 0.003343636440164488\n",
      "Iteration:660, Price of Hedge: 0.401794716726954, Loss: 0.0036226094399854246\n",
      "Iteration:670, Price of Hedge: 0.4071548691683915, Loss: 0.006202128050345123\n",
      "Iteration:680, Price of Hedge: 0.426180300926552, Loss: 0.005615942550207897\n",
      "Iteration:690, Price of Hedge: 0.41261938162496103, Loss: 0.004637813713133543\n",
      "Iteration:700, Price of Hedge: 0.41085244280360483, Loss: 0.005847892424616141\n",
      "Iteration:710, Price of Hedge: 0.39070859153725335, Loss: 0.0039233726543494996\n",
      "Iteration:720, Price of Hedge: 0.36500592690265987, Loss: 0.005890163339877841\n",
      "Iteration:730, Price of Hedge: 0.38717899219677177, Loss: 0.0048976071700014496\n",
      "Iteration:740, Price of Hedge: 0.3964145224768515, Loss: 0.005226547811279403\n",
      "Iteration:750, Price of Hedge: 0.4179183899970155, Loss: 0.0053225573380727195\n",
      "Iteration:760, Price of Hedge: 0.40923633960197203, Loss: 0.0050756564844956385\n",
      "Iteration:770, Price of Hedge: 0.44077580538547634, Loss: 0.005865927187480046\n",
      "Iteration:780, Price of Hedge: 0.3663268272503615, Loss: 0.004707589989417382\n",
      "Iteration:790, Price of Hedge: 0.33955158206005076, Loss: 0.004732983654946654\n",
      "Iteration:800, Price of Hedge: 0.37313113588948565, Loss: 0.005258890534673277\n",
      "Iteration:810, Price of Hedge: 0.3863972088623313, Loss: 0.0038797973980616795\n",
      "Iteration:820, Price of Hedge: 0.3888507897256602, Loss: 0.004833620448912867\n",
      "Iteration:830, Price of Hedge: 0.3581800484897883, Loss: 0.005202445753733897\n",
      "Iteration:840, Price of Hedge: 0.35901887585397385, Loss: 0.004587661044654822\n",
      "Iteration:850, Price of Hedge: 0.36759865445283135, Loss: 0.005066104315284824\n",
      "Iteration:860, Price of Hedge: 0.34634318312290585, Loss: 0.004222824763258704\n",
      "Iteration:870, Price of Hedge: 0.3898337041971217, Loss: 0.004566367418763484\n",
      "Iteration:880, Price of Hedge: 0.38822391658449645, Loss: 0.005323836213014133\n",
      "Iteration:890, Price of Hedge: 0.3956306254573803, Loss: 0.005295791289322249\n",
      "Iteration:900, Price of Hedge: 0.4067501366841327, Loss: 0.0051920870258714835\n",
      "Iteration:910, Price of Hedge: 0.4200900867687153, Loss: 0.007223235282346962\n",
      "Iteration:920, Price of Hedge: 0.37057238009631416, Loss: 0.004455866496048788\n",
      "Iteration:930, Price of Hedge: 0.3694520251656854, Loss: 0.005111333673355922\n",
      "Iteration:940, Price of Hedge: 0.3703214118315202, Loss: 0.005855886785676478\n",
      "Iteration:950, Price of Hedge: 0.37420086424371557, Loss: 0.005343681455337723\n",
      "Iteration:960, Price of Hedge: 0.39855415744790434, Loss: 0.004175199603687218\n",
      "Iteration:970, Price of Hedge: 0.4433154870812018, Loss: 0.006007482806773012\n",
      "Iteration:980, Price of Hedge: 0.4426139983118446, Loss: 0.0058390250543394195\n",
      "Iteration:990, Price of Hedge: 0.43010734945106605, Loss: 0.005196753685894162\n",
      "tf.Tensor(0.21246803, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_58 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.28433904766098406, Loss: 0.003562623281641386\n",
      "Iteration:20, Price of Hedge: 0.15680923741246885, Loss: 0.002378491327215304\n",
      "Iteration:30, Price of Hedge: 0.23315626650605736, Loss: 0.0021141927607995826\n",
      "Iteration:40, Price of Hedge: 0.22184053909663248, Loss: 0.0014888749408639823\n",
      "Iteration:50, Price of Hedge: 0.21871042622695994, Loss: 0.0020854654256190486\n",
      "Iteration:60, Price of Hedge: 0.19658004209081809, Loss: 0.0019653645847847122\n",
      "Iteration:70, Price of Hedge: 0.21260945264833422, Loss: 0.0018755908665303966\n",
      "Iteration:80, Price of Hedge: 0.20362174557158708, Loss: 0.0016414924901787308\n",
      "Iteration:90, Price of Hedge: 0.23629483411585284, Loss: 0.0015607283941586835\n",
      "Iteration:100, Price of Hedge: 0.23175751633740446, Loss: 0.0014780024148472125\n",
      "Iteration:110, Price of Hedge: 0.2351276979876161, Loss: 0.0019448102711650426\n",
      "Iteration:120, Price of Hedge: 0.22475472503406876, Loss: 0.001621086596083998\n",
      "Iteration:130, Price of Hedge: 0.18953613579372186, Loss: 0.0020269559022804804\n",
      "Iteration:140, Price of Hedge: 0.20058031834190898, Loss: 0.0018376981283005466\n",
      "Iteration:150, Price of Hedge: 0.2009388553485081, Loss: 0.0015145407751735672\n",
      "Iteration:160, Price of Hedge: 0.2095761109005508, Loss: 0.0013973834556146201\n",
      "Iteration:170, Price of Hedge: 0.23866656698293126, Loss: 0.001748299835841882\n",
      "Iteration:180, Price of Hedge: 0.19995856388377148, Loss: 0.0014459531482888365\n",
      "Iteration:190, Price of Hedge: 0.2245487808070379, Loss: 0.0015052883298425357\n",
      "Iteration:200, Price of Hedge: 0.22755123219407095, Loss: 0.0012755325177948862\n",
      "Iteration:210, Price of Hedge: 0.2385396440167483, Loss: 0.0017012500506217608\n",
      "Iteration:220, Price of Hedge: 0.20588028169213998, Loss: 0.0014528897715417653\n",
      "Iteration:230, Price of Hedge: 0.2335670853845613, Loss: 0.001587986057716284\n",
      "Iteration:240, Price of Hedge: 0.186858899041448, Loss: 0.0014209555997490408\n",
      "Iteration:250, Price of Hedge: 0.1957871300773604, Loss: 0.0020479813384672416\n",
      "Iteration:260, Price of Hedge: 0.22655219769098947, Loss: 0.001852868354542414\n",
      "Iteration:270, Price of Hedge: 0.22458285442837678, Loss: 0.0014608858237092903\n",
      "Iteration:280, Price of Hedge: 0.2056103921264082, Loss: 0.0015595091058764109\n",
      "Iteration:290, Price of Hedge: 0.20496997102818, Loss: 0.0014156798427081396\n",
      "Iteration:300, Price of Hedge: 0.22183916392805825, Loss: 0.0016727071456015706\n",
      "Iteration:310, Price of Hedge: 0.19950105293895604, Loss: 0.0018847570653948596\n",
      "Iteration:320, Price of Hedge: 0.20361345636101474, Loss: 0.0016150896315660244\n",
      "Iteration:330, Price of Hedge: 0.16604066765291065, Loss: 0.0016196420921150922\n",
      "Iteration:340, Price of Hedge: 0.21236595867940194, Loss: 0.0018762639271910685\n",
      "Iteration:350, Price of Hedge: 0.22101994544909756, Loss: 0.0016013933544535063\n",
      "Iteration:360, Price of Hedge: 0.24361449991120593, Loss: 0.0012523727053835641\n",
      "Iteration:370, Price of Hedge: 0.17690555623171347, Loss: 0.0016649241729396857\n",
      "Iteration:380, Price of Hedge: 0.15934429701381986, Loss: 0.00155449457515755\n",
      "Iteration:390, Price of Hedge: 0.17865102714366116, Loss: 0.0015524129216864856\n",
      "Iteration:400, Price of Hedge: 0.23068985073603585, Loss: 0.0019147378094320987\n",
      "Iteration:410, Price of Hedge: 0.23123648024428575, Loss: 0.0016217069339911738\n",
      "Iteration:420, Price of Hedge: 0.25535785381504184, Loss: 0.002073869603110445\n",
      "Iteration:430, Price of Hedge: 0.2644692369321717, Loss: 0.0013838175927093355\n",
      "Iteration:440, Price of Hedge: 0.26299452143283586, Loss: 0.0016702759303271362\n",
      "Iteration:450, Price of Hedge: 0.21300477541429358, Loss: 0.0015087574870225938\n",
      "Iteration:460, Price of Hedge: 0.1913057740200571, Loss: 0.001648530878293597\n",
      "Iteration:470, Price of Hedge: 0.18701221760443046, Loss: 0.001570536318462401\n",
      "Iteration:480, Price of Hedge: 0.18326953080015754, Loss: 0.0014114016399541462\n",
      "Iteration:490, Price of Hedge: 0.1685385085714614, Loss: 0.0019127134546516266\n",
      "Iteration:500, Price of Hedge: 0.19352418832415308, Loss: 0.0021942390315569326\n",
      "Iteration:510, Price of Hedge: 0.1888983504352609, Loss: 0.001618852941919835\n",
      "Iteration:520, Price of Hedge: 0.23768742149200647, Loss: 0.0017438649569808005\n",
      "Iteration:530, Price of Hedge: 0.2133070578397735, Loss: 0.0017399137347753777\n",
      "Iteration:540, Price of Hedge: 0.2127508021515041, Loss: 0.00146116963128613\n",
      "Iteration:550, Price of Hedge: 0.21157361965285018, Loss: 0.0014492263359889178\n",
      "Iteration:560, Price of Hedge: 0.2290721177049818, Loss: 0.0017299280452631738\n",
      "Iteration:570, Price of Hedge: 0.23945492056722628, Loss: 0.0015098070677247444\n",
      "Iteration:580, Price of Hedge: 0.2041552727792549, Loss: 0.0014798519887259996\n",
      "Iteration:590, Price of Hedge: 0.2182859829931374, Loss: 0.0018052489646307457\n",
      "Iteration:600, Price of Hedge: 0.18759355738613692, Loss: 0.0013830575892438413\n",
      "Iteration:610, Price of Hedge: 0.22658835953127435, Loss: 0.0012777661719590493\n",
      "Iteration:620, Price of Hedge: 0.22281601747135937, Loss: 0.0011289618703985926\n",
      "Iteration:630, Price of Hedge: 0.23428915075036227, Loss: 0.0015429266061790957\n",
      "Iteration:640, Price of Hedge: 0.2314636631859628, Loss: 0.001310840050519335\n",
      "Iteration:650, Price of Hedge: 0.17747439216582847, Loss: 0.0011835597633353067\n",
      "Iteration:660, Price of Hedge: 0.19862911966465047, Loss: 0.001014880774290816\n",
      "Iteration:670, Price of Hedge: 0.19051745863488917, Loss: 0.001447956612921697\n",
      "Iteration:680, Price of Hedge: 0.24381321177017978, Loss: 0.0013684359780690158\n",
      "Iteration:690, Price of Hedge: 0.21469322776258082, Loss: 0.001235945091209256\n",
      "Iteration:700, Price of Hedge: 0.22827607336310507, Loss: 0.0010940327477765965\n",
      "Iteration:710, Price of Hedge: 0.235154360978305, Loss: 0.0009302879121211083\n",
      "Iteration:720, Price of Hedge: 0.24939514834333634, Loss: 0.0011215184123738453\n",
      "Iteration:730, Price of Hedge: 0.20080173321539974, Loss: 0.0009654999470279035\n",
      "Iteration:740, Price of Hedge: 0.21432817143829652, Loss: 0.0012945762747884392\n",
      "Iteration:750, Price of Hedge: 0.1912553384392936, Loss: 0.0010017601699603418\n",
      "Iteration:760, Price of Hedge: 0.20453874108278283, Loss: 0.0011689678957516048\n",
      "Iteration:770, Price of Hedge: 0.22381125752781938, Loss: 0.001198468564301347\n",
      "Iteration:780, Price of Hedge: 0.21243307454564897, Loss: 0.0012292790451063462\n",
      "Iteration:790, Price of Hedge: 0.21063115805694677, Loss: 0.001154226613874032\n",
      "Iteration:800, Price of Hedge: 0.1985327560001167, Loss: 0.0010471835079735481\n",
      "Iteration:810, Price of Hedge: 0.20015905836867487, Loss: 0.0010396051592813649\n",
      "Iteration:820, Price of Hedge: 0.220432519273146, Loss: 0.0009538860197247034\n",
      "Iteration:830, Price of Hedge: 0.22169808181877781, Loss: 0.0013050171705647927\n",
      "Iteration:840, Price of Hedge: 0.2387764276723601, Loss: 0.0011893799574137275\n",
      "Iteration:850, Price of Hedge: 0.2570162052512046, Loss: 0.0012720733083041668\n",
      "Iteration:860, Price of Hedge: 0.2176689652267555, Loss: 0.0009539059151033812\n",
      "Iteration:870, Price of Hedge: 0.1972179293136179, Loss: 0.0008911068486449735\n",
      "Iteration:880, Price of Hedge: 0.2160684218028791, Loss: 0.000984618709599072\n",
      "Iteration:890, Price of Hedge: 0.21865603067002437, Loss: 0.0013094005203950986\n",
      "Iteration:900, Price of Hedge: 0.23203700661707102, Loss: 0.0010337022999045375\n",
      "Iteration:910, Price of Hedge: 0.21249102262140127, Loss: 0.0010825104386922078\n",
      "Iteration:920, Price of Hedge: 0.2182166133783937, Loss: 0.0011927465539167015\n",
      "Iteration:930, Price of Hedge: 0.22132533473691182, Loss: 0.001069532484226854\n",
      "Iteration:940, Price of Hedge: 0.21116690081398415, Loss: 0.0013452282177950801\n",
      "Iteration:950, Price of Hedge: 0.20981177404843548, Loss: 0.0008753495097783225\n",
      "Iteration:960, Price of Hedge: 0.1936913095050471, Loss: 0.0011978245508935447\n",
      "Iteration:970, Price of Hedge: 0.22705693548989528, Loss: 0.0010891531077251715\n",
      "Iteration:980, Price of Hedge: 0.22796752628078706, Loss: 0.0009327923423890772\n",
      "Iteration:990, Price of Hedge: 0.2135235450258733, Loss: 0.0010272601762886468\n",
      "tf.Tensor(0.30995435, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_59 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.2148391738940404, Loss: 0.003689369974769274\n",
      "Iteration:20, Price of Hedge: 0.30664400180779694, Loss: 0.0029944958219611183\n",
      "Iteration:30, Price of Hedge: 0.28333097269783136, Loss: 0.003095413538674263\n",
      "Iteration:40, Price of Hedge: 0.2652764354191504, Loss: 0.0030161660673708288\n",
      "Iteration:50, Price of Hedge: 0.305284545807848, Loss: 0.003109106135141726\n",
      "Iteration:60, Price of Hedge: 0.24115888176110045, Loss: 0.0033367689533524646\n",
      "Iteration:70, Price of Hedge: 0.2684756632427195, Loss: 0.002889756203003957\n",
      "Iteration:80, Price of Hedge: 0.24796706124510023, Loss: 0.0028078835364839794\n",
      "Iteration:90, Price of Hedge: 0.24179718917429793, Loss: 0.0028759824333914885\n",
      "Iteration:100, Price of Hedge: 0.24368735837955455, Loss: 0.0029249580912676263\n",
      "Iteration:110, Price of Hedge: 0.3027083712127364, Loss: 0.0024444480887005683\n",
      "Iteration:120, Price of Hedge: 0.2687958737918336, Loss: 0.003211732864883299\n",
      "Iteration:130, Price of Hedge: 0.2571572364283156, Loss: 0.00252728826748565\n",
      "Iteration:140, Price of Hedge: 0.2778029223599162, Loss: 0.0025841096679434013\n",
      "Iteration:150, Price of Hedge: 0.3301508787545572, Loss: 0.002571421589145384\n",
      "Iteration:160, Price of Hedge: 0.33708972471919196, Loss: 0.003531509296834656\n",
      "Iteration:170, Price of Hedge: 0.3265974176927045, Loss: 0.002817486836817995\n",
      "Iteration:180, Price of Hedge: 0.27589788096119033, Loss: 0.002963570047436681\n",
      "Iteration:190, Price of Hedge: 0.2620946263975213, Loss: 0.0029898391096277784\n",
      "Iteration:200, Price of Hedge: 0.2864583097642708, Loss: 0.0032216224597164888\n",
      "Iteration:210, Price of Hedge: 0.3104264793694256, Loss: 0.002863291370286669\n",
      "Iteration:220, Price of Hedge: 0.2954554010932327, Loss: 0.0030699673493452817\n",
      "Iteration:230, Price of Hedge: 0.31077190134240024, Loss: 0.002816324150888061\n",
      "Iteration:240, Price of Hedge: 0.2520294874759202, Loss: 0.003216573012608048\n",
      "Iteration:250, Price of Hedge: 0.24972928884078555, Loss: 0.0032414215447615466\n",
      "Iteration:260, Price of Hedge: 0.2926677561307088, Loss: 0.003406464454398872\n",
      "Iteration:270, Price of Hedge: 0.29530049089995597, Loss: 0.003640152786995987\n",
      "Iteration:280, Price of Hedge: 0.28878331236591065, Loss: 0.002616114567807326\n",
      "Iteration:290, Price of Hedge: 0.298782927051559, Loss: 0.0027802773058919427\n",
      "Iteration:300, Price of Hedge: 0.2994050125687977, Loss: 0.002815673572005295\n",
      "Iteration:310, Price of Hedge: 0.24680025617596468, Loss: 0.0025646233382511595\n",
      "Iteration:320, Price of Hedge: 0.28283112438718944, Loss: 0.0029900752677726847\n",
      "Iteration:330, Price of Hedge: 0.28789322177320853, Loss: 0.002802917649965986\n",
      "Iteration:340, Price of Hedge: 0.26902606173150617, Loss: 0.003350441455487463\n",
      "Iteration:350, Price of Hedge: 0.29279175049715034, Loss: 0.003246646469109926\n",
      "Iteration:360, Price of Hedge: 0.30473929146817225, Loss: 0.0027803952854875023\n",
      "Iteration:370, Price of Hedge: 0.3271420608463472, Loss: 0.002935576453821786\n",
      "Iteration:380, Price of Hedge: 0.30573073707801085, Loss: 0.0026068506826335547\n",
      "Iteration:390, Price of Hedge: 0.23331952957511815, Loss: 0.002690510551020164\n",
      "Iteration:400, Price of Hedge: 0.2896847353663077, Loss: 0.002335325119913101\n",
      "Iteration:410, Price of Hedge: 0.30541027186804964, Loss: 0.0027025808783102344\n",
      "Iteration:420, Price of Hedge: 0.33122773761250524, Loss: 0.002744946893482014\n",
      "Iteration:430, Price of Hedge: 0.31041917060311447, Loss: 0.00245828094758771\n",
      "Iteration:440, Price of Hedge: 0.28601132904548193, Loss: 0.002990705553369199\n",
      "Iteration:450, Price of Hedge: 0.25892213796289526, Loss: 0.0027459959767996978\n",
      "Iteration:460, Price of Hedge: 0.29012491664047957, Loss: 0.0025595931896600366\n",
      "Iteration:470, Price of Hedge: 0.2687918756165345, Loss: 0.0029263824014271744\n",
      "Iteration:480, Price of Hedge: 0.2527861357847541, Loss: 0.0027245624863962534\n",
      "Iteration:490, Price of Hedge: 0.24137572547238617, Loss: 0.0022394847038385455\n",
      "Iteration:500, Price of Hedge: 0.25851625950482454, Loss: 0.002389023542779789\n",
      "Iteration:510, Price of Hedge: 0.28261102101706115, Loss: 0.002040438403549105\n",
      "Iteration:520, Price of Hedge: 0.22234616820850306, Loss: 0.002507473664045223\n",
      "Iteration:530, Price of Hedge: 0.23246636480524216, Loss: 0.0021099916526379657\n",
      "Iteration:540, Price of Hedge: 0.24625887268116456, Loss: 0.002393784108989827\n",
      "Iteration:550, Price of Hedge: 0.29283702919576055, Loss: 0.0020582799822860486\n",
      "Iteration:560, Price of Hedge: 0.25664401842320217, Loss: 0.0016991469101417245\n",
      "Iteration:570, Price of Hedge: 0.2578664923535086, Loss: 0.0022534425057037844\n",
      "Iteration:580, Price of Hedge: 0.26766479763954293, Loss: 0.0018977326324147725\n",
      "Iteration:590, Price of Hedge: 0.28761966509127884, Loss: 0.001957604790238987\n",
      "Iteration:600, Price of Hedge: 0.29739960933023896, Loss: 0.002221951702424896\n",
      "Iteration:610, Price of Hedge: 0.2888453732143432, Loss: 0.0017923149789522697\n",
      "Iteration:620, Price of Hedge: 0.3214574450196494, Loss: 0.00196899250708662\n",
      "Iteration:630, Price of Hedge: 0.2948244024463463, Loss: 0.0014904424977500107\n",
      "Iteration:640, Price of Hedge: 0.28840440249154536, Loss: 0.0017273137925049031\n",
      "Iteration:650, Price of Hedge: 0.26925492543477386, Loss: 0.0017838938620192923\n",
      "Iteration:660, Price of Hedge: 0.2341250218344214, Loss: 0.001608916891377432\n",
      "Iteration:670, Price of Hedge: 0.23657427346334997, Loss: 0.0023609953312059948\n",
      "Iteration:680, Price of Hedge: 0.23063066755517525, Loss: 0.0017640155933670964\n",
      "Iteration:690, Price of Hedge: 0.27584791650299395, Loss: 0.002192084759953694\n",
      "Iteration:700, Price of Hedge: 0.2853067334137904, Loss: 0.0024743200050164394\n",
      "Iteration:710, Price of Hedge: 0.29556192572556483, Loss: 0.0020512523376756686\n",
      "Iteration:720, Price of Hedge: 0.2904041013271296, Loss: 0.001852532321596545\n",
      "Iteration:730, Price of Hedge: 0.2865089363406696, Loss: 0.002154354765921429\n",
      "Iteration:740, Price of Hedge: 0.2997338561206277, Loss: 0.0020857316257857582\n",
      "Iteration:750, Price of Hedge: 0.3014344557913205, Loss: 0.0016691397052508439\n",
      "Iteration:760, Price of Hedge: 0.299034939425826, Loss: 0.002205691806292842\n",
      "Iteration:770, Price of Hedge: 0.255767348457141, Loss: 0.0017141181825968133\n",
      "Iteration:780, Price of Hedge: 0.26497743811859775, Loss: 0.0016508750512863157\n",
      "Iteration:790, Price of Hedge: 0.24962663505332897, Loss: 0.002161587929793551\n",
      "Iteration:800, Price of Hedge: 0.272194042669139, Loss: 0.0024202839575735878\n",
      "Iteration:810, Price of Hedge: 0.281893412216084, Loss: 0.001852107356307986\n",
      "Iteration:820, Price of Hedge: 0.2755789182502269, Loss: 0.0018932209573919944\n",
      "Iteration:830, Price of Hedge: 0.2788480759424033, Loss: 0.0018352378657732426\n",
      "Iteration:840, Price of Hedge: 0.28315222624926834, Loss: 0.001962938542308734\n",
      "Iteration:850, Price of Hedge: 0.2806312366597183, Loss: 0.0020591165829594526\n",
      "Iteration:860, Price of Hedge: 0.2872244569227007, Loss: 0.0020990346707387086\n",
      "Iteration:870, Price of Hedge: 0.2767606973771706, Loss: 0.0015897052173878378\n",
      "Iteration:880, Price of Hedge: 0.265335440337418, Loss: 0.001952673521679893\n",
      "Iteration:890, Price of Hedge: 0.28167939524020086, Loss: 0.0027101618134016455\n",
      "Iteration:900, Price of Hedge: 0.32275995885419206, Loss: 0.001682876867366545\n",
      "Iteration:910, Price of Hedge: 0.29461787249936716, Loss: 0.0017864637480831114\n",
      "Iteration:920, Price of Hedge: 0.30534141157500017, Loss: 0.0022367819166451584\n",
      "Iteration:930, Price of Hedge: 0.29348656715231414, Loss: 0.0024499445849679\n",
      "Iteration:940, Price of Hedge: 0.2713469388274234, Loss: 0.0016661761891198833\n",
      "Iteration:950, Price of Hedge: 0.29089763404876406, Loss: 0.0015996596711555177\n",
      "Iteration:960, Price of Hedge: 0.27827473251129503, Loss: 0.0019599409056033413\n",
      "Iteration:970, Price of Hedge: 0.26041837230380904, Loss: 0.0016640856822053073\n",
      "Iteration:980, Price of Hedge: 0.26210417617928666, Loss: 0.001850674093228033\n",
      "Iteration:990, Price of Hedge: 0.27107878095545174, Loss: 0.0019408709861868266\n",
      "tf.Tensor(0.24963608, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_60 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.2611995953843859, Loss: 0.0023083871750908536\n",
      "Iteration:20, Price of Hedge: 0.17430694601597452, Loss: 0.0018492975319773118\n",
      "Iteration:30, Price of Hedge: 0.21288307299547568, Loss: 0.0017961014674222396\n",
      "Iteration:40, Price of Hedge: 0.21582674865900342, Loss: 0.0014967270499667727\n",
      "Iteration:50, Price of Hedge: 0.219735716263375, Loss: 0.00173164581225822\n",
      "Iteration:60, Price of Hedge: 0.22329378668655975, Loss: 0.001452623670851949\n",
      "Iteration:70, Price of Hedge: 0.2281870439309671, Loss: 0.0017260985827752594\n",
      "Iteration:80, Price of Hedge: 0.24775887600261512, Loss: 0.0019106033507890528\n",
      "Iteration:90, Price of Hedge: 0.2640141325323611, Loss: 0.001967780878525138\n",
      "Iteration:100, Price of Hedge: 0.23146478369368992, Loss: 0.0021314406614367787\n",
      "Iteration:110, Price of Hedge: 0.20683850679447743, Loss: 0.001909047731130231\n",
      "Iteration:120, Price of Hedge: 0.21847567985812474, Loss: 0.0015351898902726368\n",
      "Iteration:130, Price of Hedge: 0.21219248371037336, Loss: 0.0013279015314583197\n",
      "Iteration:140, Price of Hedge: 0.16688882833714158, Loss: 0.001921983507392788\n",
      "Iteration:150, Price of Hedge: 0.172685202076579, Loss: 0.0016236570790091774\n",
      "Iteration:160, Price of Hedge: 0.1809947091184341, Loss: 0.0014572910272128814\n",
      "Iteration:170, Price of Hedge: 0.2098113029258684, Loss: 0.0016658295121464216\n",
      "Iteration:180, Price of Hedge: 0.1972447832999421, Loss: 0.00157270909276781\n",
      "Iteration:190, Price of Hedge: 0.22082996845717842, Loss: 0.0013700279067939247\n",
      "Iteration:200, Price of Hedge: 0.2039396132409081, Loss: 0.0017313748372006276\n",
      "Iteration:210, Price of Hedge: 0.19160272130079078, Loss: 0.0016372760625755322\n",
      "Iteration:220, Price of Hedge: 0.21779448755827957, Loss: 0.0021191345739093757\n",
      "Iteration:230, Price of Hedge: 0.24785080856840977, Loss: 0.00179933148215059\n",
      "Iteration:240, Price of Hedge: 0.2041075366034704, Loss: 0.0019219578423542937\n",
      "Iteration:250, Price of Hedge: 0.22506311931987852, Loss: 0.0019907829205835447\n",
      "Iteration:260, Price of Hedge: 0.22385304737282466, Loss: 0.0018258235715366666\n",
      "Iteration:270, Price of Hedge: 0.2161488182323012, Loss: 0.0016304483665208645\n",
      "Iteration:280, Price of Hedge: 0.19037204729120843, Loss: 0.0015993008580010625\n",
      "Iteration:290, Price of Hedge: 0.18438131639328217, Loss: 0.0015351805394446581\n",
      "Iteration:300, Price of Hedge: 0.21717344615051387, Loss: 0.0015787571884089855\n",
      "Iteration:310, Price of Hedge: 0.24648195558320365, Loss: 0.0016987139867016942\n",
      "Iteration:320, Price of Hedge: 0.23872597935855422, Loss: 0.0016381692656012746\n",
      "Iteration:330, Price of Hedge: 0.17055710324189874, Loss: 0.002173848257949995\n",
      "Iteration:340, Price of Hedge: 0.19946728491063367, Loss: 0.0016069276519403263\n",
      "Iteration:350, Price of Hedge: 0.1984103023317999, Loss: 0.0016880080844813516\n",
      "Iteration:360, Price of Hedge: 0.17673118994972015, Loss: 0.0015060040660904717\n",
      "Iteration:370, Price of Hedge: 0.18042256259330713, Loss: 0.0015809993975859802\n",
      "Iteration:380, Price of Hedge: 0.2157132463194614, Loss: 0.0021488696100199433\n",
      "Iteration:390, Price of Hedge: 0.21414501935707903, Loss: 0.0013355449380387796\n",
      "Iteration:400, Price of Hedge: 0.24885587853356694, Loss: 0.0015313478936961555\n",
      "Iteration:410, Price of Hedge: 0.22482228655679817, Loss: 0.001568646158011111\n",
      "Iteration:420, Price of Hedge: 0.24650612289759122, Loss: 0.0017172532963688702\n",
      "Iteration:430, Price of Hedge: 0.22126482731964642, Loss: 0.0017134876980465117\n",
      "Iteration:440, Price of Hedge: 0.22502591337012062, Loss: 0.0019160658259588458\n",
      "Iteration:450, Price of Hedge: 0.1876902521097719, Loss: 0.00186627047848118\n",
      "Iteration:460, Price of Hedge: 0.18890699617101914, Loss: 0.001996257730888118\n",
      "Iteration:470, Price of Hedge: 0.223217108305505, Loss: 0.0018545934828275712\n",
      "Iteration:480, Price of Hedge: 0.259966884088027, Loss: 0.0014758173054070234\n",
      "Iteration:490, Price of Hedge: 0.2190278100406715, Loss: 0.0014527780589904892\n",
      "Iteration:500, Price of Hedge: 0.20085680362358005, Loss: 0.0016840781503311142\n",
      "Iteration:510, Price of Hedge: 0.1960655635145116, Loss: 0.0017142385496378143\n",
      "Iteration:520, Price of Hedge: 0.2072133548283318, Loss: 0.002259632156964253\n",
      "Iteration:530, Price of Hedge: 0.23888789272512553, Loss: 0.0016435024208096614\n",
      "Iteration:540, Price of Hedge: 0.24402445294282982, Loss: 0.0015786907378442015\n",
      "Iteration:550, Price of Hedge: 0.2566884058088476, Loss: 0.001679143300603858\n",
      "Iteration:560, Price of Hedge: 0.25062961679954016, Loss: 0.0015506995316747485\n",
      "Iteration:570, Price of Hedge: 0.21845912690306477, Loss: 0.001502996083788166\n",
      "Iteration:580, Price of Hedge: 0.21125818399461876, Loss: 0.0014820471453324212\n",
      "Iteration:590, Price of Hedge: 0.182769300498245, Loss: 0.0010391393089896229\n",
      "Iteration:600, Price of Hedge: 0.18986589612460136, Loss: 0.0016985379126003952\n",
      "Iteration:610, Price of Hedge: 0.20524226713891663, Loss: 0.0012371533375563626\n",
      "Iteration:620, Price of Hedge: 0.19494271290758147, Loss: 0.0013473846778899734\n",
      "Iteration:630, Price of Hedge: 0.2099344951106417, Loss: 0.001317137634209131\n",
      "Iteration:640, Price of Hedge: 0.21152895214027295, Loss: 0.0011092360003470692\n",
      "Iteration:650, Price of Hedge: 0.22605695874167964, Loss: 0.0010973449304188863\n",
      "Iteration:660, Price of Hedge: 0.1951748872018612, Loss: 0.0009673147039940044\n",
      "Iteration:670, Price of Hedge: 0.21453671320596754, Loss: 0.0011238024018460635\n",
      "Iteration:680, Price of Hedge: 0.2079883132520706, Loss: 0.0011252545655357604\n",
      "Iteration:690, Price of Hedge: 0.2123706062398611, Loss: 0.0009685176780657611\n",
      "Iteration:700, Price of Hedge: 0.23594818977081217, Loss: 0.0009310024546463235\n",
      "Iteration:710, Price of Hedge: 0.23234333815001945, Loss: 0.0014574479022737563\n",
      "Iteration:720, Price of Hedge: 0.21495201411538004, Loss: 0.0011434039257808503\n",
      "Iteration:730, Price of Hedge: 0.20959849558900884, Loss: 0.001136685654308911\n",
      "Iteration:740, Price of Hedge: 0.20493634306332353, Loss: 0.0010025927915580102\n",
      "Iteration:750, Price of Hedge: 0.19952724480707784, Loss: 0.0009914040284971558\n",
      "Iteration:760, Price of Hedge: 0.2365749610476371, Loss: 0.0012920944257752698\n",
      "Iteration:770, Price of Hedge: 0.2488540959076374, Loss: 0.001038883354942932\n",
      "Iteration:780, Price of Hedge: 0.22540668226866956, Loss: 0.0010986385279405208\n",
      "Iteration:790, Price of Hedge: 0.20146068089025276, Loss: 0.0011165871438147512\n",
      "Iteration:800, Price of Hedge: 0.20575791715511968, Loss: 0.0011947041597017093\n",
      "Iteration:810, Price of Hedge: 0.20807561099044847, Loss: 0.0013933078872924607\n",
      "Iteration:820, Price of Hedge: 0.21682354214663063, Loss: 0.0009906157735939392\n",
      "Iteration:830, Price of Hedge: 0.221205975197887, Loss: 0.0012646378084308907\n",
      "Iteration:840, Price of Hedge: 0.2392202505966452, Loss: 0.0012155660558757387\n",
      "Iteration:850, Price of Hedge: 0.23528181873226683, Loss: 0.0010064188718315493\n",
      "Iteration:860, Price of Hedge: 0.2113312589246874, Loss: 0.0008204638799274798\n",
      "Iteration:870, Price of Hedge: 0.22551348702793347, Loss: 0.0009415076124958065\n",
      "Iteration:880, Price of Hedge: 0.2215635954254367, Loss: 0.0009767174589109472\n",
      "Iteration:890, Price of Hedge: 0.20767440555892164, Loss: 0.0010586308114803212\n",
      "Iteration:900, Price of Hedge: 0.2153239208164507, Loss: 0.0011404939282185333\n",
      "Iteration:910, Price of Hedge: 0.19041495764394084, Loss: 0.0012249272294512447\n",
      "Iteration:920, Price of Hedge: 0.2550079752772433, Loss: 0.0009989930212169317\n",
      "Iteration:930, Price of Hedge: 0.24639542182736704, Loss: 0.0013630188643626083\n",
      "Iteration:940, Price of Hedge: 0.22211310260125855, Loss: 0.0012417600130123273\n",
      "Iteration:950, Price of Hedge: 0.18387009747581828, Loss: 0.0008810857453587229\n",
      "Iteration:960, Price of Hedge: 0.19219956992808418, Loss: 0.001145568145073428\n",
      "Iteration:970, Price of Hedge: 0.20409345385862707, Loss: 0.0009494653660593765\n",
      "Iteration:980, Price of Hedge: 0.2282944853423487, Loss: 0.0010054888623552527\n",
      "Iteration:990, Price of Hedge: 0.199404320016194, Loss: 0.0009530292252419414\n",
      "tf.Tensor(0.19391781, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_61 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.24878014239764637, Loss: 0.0020682320486082872\n",
      "Iteration:20, Price of Hedge: 0.18206879217314906, Loss: 0.001659337849037623\n",
      "Iteration:30, Price of Hedge: 0.23015496109283617, Loss: 0.0016930887673343165\n",
      "Iteration:40, Price of Hedge: 0.21133789283975374, Loss: 0.0014877340403737004\n",
      "Iteration:50, Price of Hedge: 0.20419009765009263, Loss: 0.0016311660923066683\n",
      "Iteration:60, Price of Hedge: 0.2218622362008034, Loss: 0.001594529946194112\n",
      "Iteration:70, Price of Hedge: 0.19176756326710345, Loss: 0.0015264800913950436\n",
      "Iteration:80, Price of Hedge: 0.21851971071858428, Loss: 0.0017766535358108458\n",
      "Iteration:90, Price of Hedge: 0.2224826664225361, Loss: 0.0015320818342155816\n",
      "Iteration:100, Price of Hedge: 0.19830515286804198, Loss: 0.0013380668762399848\n",
      "Iteration:110, Price of Hedge: 0.21617430978309357, Loss: 0.0015656901026471547\n",
      "Iteration:120, Price of Hedge: 0.22700424616063514, Loss: 0.001660102428440213\n",
      "Iteration:130, Price of Hedge: 0.20930338186637412, Loss: 0.0018417410682016744\n",
      "Iteration:140, Price of Hedge: 0.20879138623332663, Loss: 0.0018226785100752705\n",
      "Iteration:150, Price of Hedge: 0.19003286450898713, Loss: 0.001395665489665787\n",
      "Iteration:160, Price of Hedge: 0.20047420116693215, Loss: 0.0014792064831647966\n",
      "Iteration:170, Price of Hedge: 0.23491373194390233, Loss: 0.0012400530889986605\n",
      "Iteration:180, Price of Hedge: 0.23490540453420294, Loss: 0.0015045207661331438\n",
      "Iteration:190, Price of Hedge: 0.20541592037053816, Loss: 0.0018773211676140098\n",
      "Iteration:200, Price of Hedge: 0.18422086732658158, Loss: 0.0016532123603733905\n",
      "Iteration:210, Price of Hedge: 0.21950649603492137, Loss: 0.0017093800981646812\n",
      "Iteration:220, Price of Hedge: 0.24043337847386395, Loss: 0.001405185527840036\n",
      "Iteration:230, Price of Hedge: 0.2517027576091209, Loss: 0.0019880174629473223\n",
      "Iteration:240, Price of Hedge: 0.20978276817795347, Loss: 0.0015619633003132183\n",
      "Iteration:250, Price of Hedge: 0.21784646383716788, Loss: 0.0018268012304448965\n",
      "Iteration:260, Price of Hedge: 0.18869533480797143, Loss: 0.0014027900247703283\n",
      "Iteration:270, Price of Hedge: 0.19995134424875685, Loss: 0.0016446769444899089\n",
      "Iteration:280, Price of Hedge: 0.1942111614252269, Loss: 0.001682845432668234\n",
      "Iteration:290, Price of Hedge: 0.17078161224468147, Loss: 0.0013822987795010675\n",
      "Iteration:300, Price of Hedge: 0.18016064391208886, Loss: 0.0014649996906354046\n",
      "Iteration:310, Price of Hedge: 0.18391074134701169, Loss: 0.0014385759418750865\n",
      "Iteration:320, Price of Hedge: 0.1976313329997197, Loss: 0.0015138688087587226\n",
      "Iteration:330, Price of Hedge: 0.19739176080783238, Loss: 0.0015819545747163043\n",
      "Iteration:340, Price of Hedge: 0.22514705553507497, Loss: 0.0014903978326248788\n",
      "Iteration:350, Price of Hedge: 0.2258773719123212, Loss: 0.0014079572525205418\n",
      "Iteration:360, Price of Hedge: 0.22855026669715242, Loss: 0.0015048382963768424\n",
      "Iteration:370, Price of Hedge: 0.2261502664760485, Loss: 0.0018584651235182825\n",
      "Iteration:380, Price of Hedge: 0.21428933565911734, Loss: 0.0012920483679736304\n",
      "Iteration:390, Price of Hedge: 0.23696586544789966, Loss: 0.0018743237298624038\n",
      "Iteration:400, Price of Hedge: 0.2123383152444518, Loss: 0.0014077512358743327\n",
      "Iteration:410, Price of Hedge: 0.2140145566051217, Loss: 0.0016892497550646368\n",
      "Iteration:420, Price of Hedge: 0.2039362135185996, Loss: 0.0014590009355333498\n",
      "Iteration:430, Price of Hedge: 0.2373287571549838, Loss: 0.0016369123750533008\n",
      "Iteration:440, Price of Hedge: 0.2375565003505244, Loss: 0.0016212365077623357\n",
      "Iteration:450, Price of Hedge: 0.22481316969847284, Loss: 0.001619928983475627\n",
      "Iteration:460, Price of Hedge: 0.21997629436560828, Loss: 0.00150419428296904\n",
      "Iteration:470, Price of Hedge: 0.2076094670429171, Loss: 0.0016229525836501946\n",
      "Iteration:480, Price of Hedge: 0.226107101462469, Loss: 0.0017559237449512376\n",
      "Iteration:490, Price of Hedge: 0.20719649628025535, Loss: 0.0014930558552162408\n",
      "Iteration:500, Price of Hedge: 0.19890411518036613, Loss: 0.0013939374765507217\n",
      "Iteration:510, Price of Hedge: 0.1948791368271088, Loss: 0.0013493367129689515\n",
      "Iteration:520, Price of Hedge: 0.2173002417862733, Loss: 0.0012821501186507155\n",
      "Iteration:530, Price of Hedge: 0.22999462662351675, Loss: 0.001889511066129934\n",
      "Iteration:540, Price of Hedge: 0.22972376934656608, Loss: 0.0018654046316011197\n",
      "Iteration:550, Price of Hedge: 0.17376428921693898, Loss: 0.0016800298386777433\n",
      "Iteration:560, Price of Hedge: 0.1685979973453385, Loss: 0.0018441205554915463\n",
      "Iteration:570, Price of Hedge: 0.21065127626386582, Loss: 0.0014922915742443309\n",
      "Iteration:580, Price of Hedge: 0.22467030496326287, Loss: 0.0009963052550344463\n",
      "Iteration:590, Price of Hedge: 0.23684747362009373, Loss: 0.0011158661352914656\n",
      "Iteration:600, Price of Hedge: 0.23534334479292054, Loss: 0.0014932753012430577\n",
      "Iteration:610, Price of Hedge: 0.21473955057066405, Loss: 0.001366180737418987\n",
      "Iteration:620, Price of Hedge: 0.2104844606759883, Loss: 0.0011343562038964139\n",
      "Iteration:630, Price of Hedge: 0.20196345780063607, Loss: 0.0010262380512090718\n",
      "Iteration:640, Price of Hedge: 0.23801626504383647, Loss: 0.0011785990496157694\n",
      "Iteration:650, Price of Hedge: 0.2505351630913594, Loss: 0.0014264992480638393\n",
      "Iteration:660, Price of Hedge: 0.22392781579752635, Loss: 0.0010076074217537645\n",
      "Iteration:670, Price of Hedge: 0.21608950772101707, Loss: 0.001021396311854028\n",
      "Iteration:680, Price of Hedge: 0.19609571535880546, Loss: 0.001249311602420189\n",
      "Iteration:690, Price of Hedge: 0.19829057353454685, Loss: 0.0009055216473584426\n",
      "Iteration:700, Price of Hedge: 0.21979059567592002, Loss: 0.0012182480523984073\n",
      "Iteration:710, Price of Hedge: 0.23069884026393764, Loss: 0.001016309163002993\n",
      "Iteration:720, Price of Hedge: 0.23363500343247665, Loss: 0.001157350984141603\n",
      "Iteration:730, Price of Hedge: 0.2215982802328085, Loss: 0.0008924233258520874\n",
      "Iteration:740, Price of Hedge: 0.22824171961483442, Loss: 0.0008877933728030696\n",
      "Iteration:750, Price of Hedge: 0.21621136293634322, Loss: 0.0008894810977763123\n",
      "Iteration:760, Price of Hedge: 0.2246728006395642, Loss: 0.001306281322925984\n",
      "Iteration:770, Price of Hedge: 0.20361336722971826, Loss: 0.001459207648517813\n",
      "Iteration:780, Price of Hedge: 0.21782700774845123, Loss: 0.0008916805318891496\n",
      "Iteration:790, Price of Hedge: 0.2057568348465196, Loss: 0.001246181860400375\n",
      "Iteration:800, Price of Hedge: 0.2157518783699629, Loss: 0.0008055639324049512\n",
      "Iteration:810, Price of Hedge: 0.19653807398321987, Loss: 0.0011491861196859965\n",
      "Iteration:820, Price of Hedge: 0.18802266091346098, Loss: 0.001255680013658078\n",
      "Iteration:830, Price of Hedge: 0.23829025464920617, Loss: 0.001145318557547914\n",
      "Iteration:840, Price of Hedge: 0.2274246912191586, Loss: 0.0011724110894624884\n",
      "Iteration:850, Price of Hedge: 0.24550968593514993, Loss: 0.00100807953908979\n",
      "Iteration:860, Price of Hedge: 0.19730017203418126, Loss: 0.00098909427450955\n",
      "Iteration:870, Price of Hedge: 0.22786339546041745, Loss: 0.0011565802371716228\n",
      "Iteration:880, Price of Hedge: 0.25028483147868313, Loss: 0.001055636258558623\n",
      "Iteration:890, Price of Hedge: 0.21967462312616134, Loss: 0.0009207195281766722\n",
      "Iteration:900, Price of Hedge: 0.1880578168433999, Loss: 0.0011521748034709844\n",
      "Iteration:910, Price of Hedge: 0.24132380012566726, Loss: 0.0010548216422786583\n",
      "Iteration:920, Price of Hedge: 0.25233373078992255, Loss: 0.0010838559631521916\n",
      "Iteration:930, Price of Hedge: 0.23369220025873005, Loss: 0.0012685717216568636\n",
      "Iteration:940, Price of Hedge: 0.21678929026269883, Loss: 0.0010006050442743053\n",
      "Iteration:950, Price of Hedge: 0.21378836684074826, Loss: 0.0010905771194540392\n",
      "Iteration:960, Price of Hedge: 0.20095376574110446, Loss: 0.00106924708501972\n",
      "Iteration:970, Price of Hedge: 0.20061816094378457, Loss: 0.0010073786248989691\n",
      "Iteration:980, Price of Hedge: 0.1953045095730232, Loss: 0.0009696899137774605\n",
      "Iteration:990, Price of Hedge: 0.1763943245812072, Loss: 0.0008763269697327657\n",
      "tf.Tensor(0.2847042, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_62 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.2663439991561802, Loss: 0.007670431667040667\n",
      "Iteration:20, Price of Hedge: 0.2920528011171882, Loss: 0.0031081048007328693\n",
      "Iteration:30, Price of Hedge: 0.28480118070017396, Loss: 0.002919459008601066\n",
      "Iteration:40, Price of Hedge: 0.28677874950814725, Loss: 0.002688973235109726\n",
      "Iteration:50, Price of Hedge: 0.2855427785529457, Loss: 0.002978353905424624\n",
      "Iteration:60, Price of Hedge: 0.26683834679252527, Loss: 0.002709637769127271\n",
      "Iteration:70, Price of Hedge: 0.2941787353346683, Loss: 0.0027203804777981675\n",
      "Iteration:80, Price of Hedge: 0.2568686547564084, Loss: 0.0031267893466643934\n",
      "Iteration:90, Price of Hedge: 0.29478072811107264, Loss: 0.0033375056792249056\n",
      "Iteration:100, Price of Hedge: 0.29492820220761473, Loss: 0.0022654903512159485\n",
      "Iteration:110, Price of Hedge: 0.295963143890134, Loss: 0.002903576129894958\n",
      "Iteration:120, Price of Hedge: 0.2627903088995652, Loss: 0.00316442722509338\n",
      "Iteration:130, Price of Hedge: 0.3151845117040352, Loss: 0.0027433938602224204\n",
      "Iteration:140, Price of Hedge: 0.2898840074791451, Loss: 0.0031972651444625464\n",
      "Iteration:150, Price of Hedge: 0.2857573303166077, Loss: 0.002848921137221438\n",
      "Iteration:160, Price of Hedge: 0.2827833500122779, Loss: 0.0027237738335854633\n",
      "Iteration:170, Price of Hedge: 0.28792714259803914, Loss: 0.0031563359735388816\n",
      "Iteration:180, Price of Hedge: 0.27407387264400423, Loss: 0.0025342874617045206\n",
      "Iteration:190, Price of Hedge: 0.2685653547930599, Loss: 0.002662157248958774\n",
      "Iteration:200, Price of Hedge: 0.27938528299931137, Loss: 0.0034990265099748893\n",
      "Iteration:210, Price of Hedge: 0.26400061004138137, Loss: 0.00293443306640917\n",
      "Iteration:220, Price of Hedge: 0.31179624913368115, Loss: 0.0029602582627019647\n",
      "Iteration:230, Price of Hedge: 0.28494631191692293, Loss: 0.003576704434854427\n",
      "Iteration:240, Price of Hedge: 0.2963479618961514, Loss: 0.002429150929942736\n",
      "Iteration:250, Price of Hedge: 0.3074925062841714, Loss: 0.002745326497307188\n",
      "Iteration:260, Price of Hedge: 0.262606341903637, Loss: 0.002958753575212558\n",
      "Iteration:270, Price of Hedge: 0.26186072040948144, Loss: 0.0034114625714303237\n",
      "Iteration:280, Price of Hedge: 0.26659804881722377, Loss: 0.002820724212836456\n",
      "Iteration:290, Price of Hedge: 0.28204289813331795, Loss: 0.003013056021775906\n",
      "Iteration:300, Price of Hedge: 0.29923938115385906, Loss: 0.003209899306784347\n",
      "Iteration:310, Price of Hedge: 0.3051816118934596, Loss: 0.002817384176664017\n",
      "Iteration:320, Price of Hedge: 0.2855297653836601, Loss: 0.0026670286324280475\n",
      "Iteration:330, Price of Hedge: 0.3091602037734219, Loss: 0.0026845823250355224\n",
      "Iteration:340, Price of Hedge: 0.276689315941735, Loss: 0.0027434073890799213\n",
      "Iteration:350, Price of Hedge: 0.3032169798565178, Loss: 0.0029902002107507816\n",
      "Iteration:360, Price of Hedge: 0.27715631300310406, Loss: 0.002889679008934687\n",
      "Iteration:370, Price of Hedge: 0.3074615395251669, Loss: 0.003246527892653006\n",
      "Iteration:380, Price of Hedge: 0.32632997287110466, Loss: 0.0029559668295211505\n",
      "Iteration:390, Price of Hedge: 0.29443650304407926, Loss: 0.002614899557031469\n",
      "Iteration:400, Price of Hedge: 0.3079704537619648, Loss: 0.0032635463995740466\n",
      "Iteration:410, Price of Hedge: 0.2727301546844046, Loss: 0.0025112573671621785\n",
      "Iteration:420, Price of Hedge: 0.2646517778273562, Loss: 0.0029007458133242458\n",
      "Iteration:430, Price of Hedge: 0.31700164417835025, Loss: 0.003022472106596563\n",
      "Iteration:440, Price of Hedge: 0.325176944953796, Loss: 0.0027336063286818478\n",
      "Iteration:450, Price of Hedge: 0.3118212568288641, Loss: 0.0027409326029261827\n",
      "Iteration:460, Price of Hedge: 0.284670514219539, Loss: 0.003480091282272024\n",
      "Iteration:470, Price of Hedge: 0.3204707361015664, Loss: 0.0031070732253484223\n",
      "Iteration:480, Price of Hedge: 0.3168036199036635, Loss: 0.0030920480364171163\n",
      "Iteration:490, Price of Hedge: 0.2943551389034383, Loss: 0.0024116338448320284\n",
      "Iteration:500, Price of Hedge: 0.3107158759560434, Loss: 0.003139521792156863\n",
      "Iteration:510, Price of Hedge: 0.2826924106237868, Loss: 0.0031656866025636886\n",
      "Iteration:520, Price of Hedge: 0.29578345519643673, Loss: 0.0032248936578787024\n",
      "Iteration:530, Price of Hedge: 0.2788468026381679, Loss: 0.0026131167321481463\n",
      "Iteration:540, Price of Hedge: 0.2950371461179941, Loss: 0.003329717633241458\n",
      "Iteration:550, Price of Hedge: 0.2901770202497914, Loss: 0.0027147295933922953\n",
      "Iteration:560, Price of Hedge: 0.2856738015587666, Loss: 0.0026791039335627874\n",
      "Iteration:570, Price of Hedge: 0.32399351053134634, Loss: 0.003205089201081401\n",
      "Iteration:580, Price of Hedge: 0.2696289203547906, Loss: 0.0033277768390514327\n",
      "Iteration:590, Price of Hedge: 0.26705208364147665, Loss: 0.0033048502004782154\n",
      "Iteration:600, Price of Hedge: 0.2841074845527373, Loss: 0.0033898808604557293\n",
      "Iteration:610, Price of Hedge: 0.3042689838157912, Loss: 0.0031994003165022543\n",
      "Iteration:620, Price of Hedge: 0.2854346240911923, Loss: 0.0028774407646485756\n",
      "Iteration:630, Price of Hedge: 0.26837015725377567, Loss: 0.0026916802003326356\n",
      "Iteration:640, Price of Hedge: 0.31032665231737155, Loss: 0.003060615327643967\n",
      "Iteration:650, Price of Hedge: 0.2976946593876619, Loss: 0.0027961733155479783\n",
      "Iteration:660, Price of Hedge: 0.2804574306315885, Loss: 0.002352096526230962\n",
      "Iteration:670, Price of Hedge: 0.3205237819560125, Loss: 0.0032998614342747423\n",
      "Iteration:680, Price of Hedge: 0.3060062037162936, Loss: 0.0025926561257620493\n",
      "Iteration:690, Price of Hedge: 0.2766258035264741, Loss: 0.002671804319125881\n",
      "Iteration:700, Price of Hedge: 0.30845619386167866, Loss: 0.0024127613159417027\n",
      "Iteration:710, Price of Hedge: 0.27538853380095246, Loss: 0.00341215572642346\n",
      "Iteration:720, Price of Hedge: 0.30363574415345057, Loss: 0.0023368037444564393\n",
      "Iteration:730, Price of Hedge: 0.29234619587910515, Loss: 0.001956437528371957\n",
      "Iteration:740, Price of Hedge: 0.24508307808412721, Loss: 0.0034638232290347126\n",
      "Iteration:750, Price of Hedge: 0.2623470462291436, Loss: 0.0030195367424264317\n",
      "Iteration:760, Price of Hedge: 0.30076571640689737, Loss: 0.003491481784472672\n",
      "Iteration:770, Price of Hedge: 0.3160305459701931, Loss: 0.002814724562442361\n",
      "Iteration:780, Price of Hedge: 0.289120050404, Loss: 0.0046353622045728566\n",
      "Iteration:790, Price of Hedge: 0.25760981968574015, Loss: 0.0025607113099417322\n",
      "Iteration:800, Price of Hedge: 0.2711769272459151, Loss: 0.002669939923189979\n",
      "Iteration:810, Price of Hedge: 0.29032334837252166, Loss: 0.0027907406834462023\n",
      "Iteration:820, Price of Hedge: 0.3056534475109231, Loss: 0.0023274700265035085\n",
      "Iteration:830, Price of Hedge: 0.3026857063973466, Loss: 0.002103281538271284\n",
      "Iteration:840, Price of Hedge: 0.2903151992254152, Loss: 0.00263671304916766\n",
      "Iteration:850, Price of Hedge: 0.2950049569869236, Loss: 0.0016360743817033895\n",
      "Iteration:860, Price of Hedge: 0.28639808247393717, Loss: 0.002147761039520013\n",
      "Iteration:870, Price of Hedge: 0.279961376767568, Loss: 0.001980434538318043\n",
      "Iteration:880, Price of Hedge: 0.28859580558420816, Loss: 0.002217296183814277\n",
      "Iteration:890, Price of Hedge: 0.29633013563685606, Loss: 0.001698655693242168\n",
      "Iteration:900, Price of Hedge: 0.2525831710896341, Loss: 0.00219291320352184\n",
      "Iteration:910, Price of Hedge: 0.2724634993114307, Loss: 0.0023792517285883717\n",
      "Iteration:920, Price of Hedge: 0.29066983992105405, Loss: 0.0017480228921706864\n",
      "Iteration:930, Price of Hedge: 0.28480983916897457, Loss: 0.0020015055349219767\n",
      "Iteration:940, Price of Hedge: 0.3016799233818176, Loss: 0.00199790287975099\n",
      "Iteration:950, Price of Hedge: 0.3065719837202437, Loss: 0.0018240236366276806\n",
      "Iteration:960, Price of Hedge: 0.2679469873241885, Loss: 0.0014785956950393864\n",
      "Iteration:970, Price of Hedge: 0.29725208430152744, Loss: 0.002112271066173088\n",
      "Iteration:980, Price of Hedge: 0.317567627910978, Loss: 0.0023206220371625895\n",
      "Iteration:990, Price of Hedge: 0.3104550523164676, Loss: 0.0017219513910898597\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 10 \n",
      "\n",
      "tf.Tensor(1.3856134, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_63 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 1.251134127425803, Loss: 0.0645332911920292\n",
      "Iteration:20, Price of Hedge: 1.4306148473469422, Loss: 0.06321927713157437\n",
      "Iteration:30, Price of Hedge: 1.2525762169977952, Loss: 0.07920395473199307\n",
      "Iteration:40, Price of Hedge: 1.4408653685127093, Loss: 0.06438910623613055\n",
      "Iteration:50, Price of Hedge: 1.2196548444951079, Loss: 0.08773509701440219\n",
      "Iteration:60, Price of Hedge: 1.3793407546394976, Loss: 0.06373009338292661\n",
      "Iteration:70, Price of Hedge: 1.238637724561022, Loss: 0.06070495802943015\n",
      "Iteration:80, Price of Hedge: 1.3517851586098233, Loss: 0.07466416015984123\n",
      "Iteration:90, Price of Hedge: 1.3131854898422717, Loss: 0.08424852522818611\n",
      "Iteration:100, Price of Hedge: 1.2653339368798697, Loss: 0.06612597749593051\n",
      "Iteration:110, Price of Hedge: 1.424141445140026, Loss: 0.08281419607671268\n",
      "Iteration:120, Price of Hedge: 1.2843520188532922, Loss: 0.08803422179469465\n",
      "Iteration:130, Price of Hedge: 1.4151855312688213, Loss: 0.07125594690540282\n",
      "Iteration:140, Price of Hedge: 1.1946571013551421, Loss: 0.07641457501067919\n",
      "Iteration:150, Price of Hedge: 1.3450963390156632, Loss: 0.06926967355966554\n",
      "Iteration:160, Price of Hedge: 1.3166315280034953, Loss: 0.07050116886290994\n",
      "Iteration:170, Price of Hedge: 1.3647593930814539, Loss: 0.07093483236210858\n",
      "Iteration:180, Price of Hedge: 1.3552171160080435, Loss: 0.06964424814268995\n",
      "Iteration:190, Price of Hedge: 1.2695597201507782, Loss: 0.09015628535572517\n",
      "Iteration:200, Price of Hedge: 1.2572341151125557, Loss: 0.07076338307167732\n",
      "Iteration:210, Price of Hedge: 1.3055339666529109, Loss: 0.07242646747599935\n",
      "Iteration:220, Price of Hedge: 1.2361094961337358, Loss: 0.07506967927681957\n",
      "Iteration:230, Price of Hedge: 1.3333344216651994, Loss: 0.06867636140948434\n",
      "Iteration:240, Price of Hedge: 1.2393859251042387, Loss: 0.08569275777344387\n",
      "Iteration:250, Price of Hedge: 1.3507197751649302, Loss: 0.08525012235950698\n",
      "Iteration:260, Price of Hedge: 1.287737345153255, Loss: 0.07134422026015556\n",
      "Iteration:270, Price of Hedge: 1.317757531876123, Loss: 0.07069491650449322\n",
      "Iteration:280, Price of Hedge: 1.3111099488021865, Loss: 0.06962659575757756\n",
      "Iteration:290, Price of Hedge: 1.2924131642391103, Loss: 0.07394260106026139\n",
      "Iteration:300, Price of Hedge: 1.4075488203106716, Loss: 0.08973598829510793\n",
      "Iteration:310, Price of Hedge: 1.311282575299265, Loss: 0.08278138287007125\n",
      "Iteration:320, Price of Hedge: 1.3638623387579174, Loss: 0.0684239820193568\n",
      "Iteration:330, Price of Hedge: 1.3376441409129711, Loss: 0.090315648276939\n",
      "Iteration:340, Price of Hedge: 1.3687043839940316, Loss: 0.06993316665564323\n",
      "Iteration:350, Price of Hedge: 1.2659973785444891, Loss: 0.08524072185011562\n",
      "Iteration:360, Price of Hedge: 1.3101531883861754, Loss: 0.061544123501820994\n",
      "Iteration:370, Price of Hedge: 1.2470241904323303, Loss: 0.08969503750465294\n",
      "Iteration:380, Price of Hedge: 1.3876100027304803, Loss: 0.08375137828897011\n",
      "Iteration:390, Price of Hedge: 1.3824450142805518, Loss: 0.0776901298442624\n",
      "Iteration:400, Price of Hedge: 1.2820821815704677, Loss: 0.06602390910794327\n",
      "Iteration:410, Price of Hedge: 1.3572792163198075, Loss: 0.07656626894490018\n",
      "Iteration:420, Price of Hedge: 1.2724872387860842, Loss: 0.06771860093928268\n",
      "Iteration:430, Price of Hedge: 1.3296261521514225, Loss: 0.07202949167910618\n",
      "Iteration:440, Price of Hedge: 1.2834198540557737, Loss: 0.07282456333358596\n",
      "Iteration:450, Price of Hedge: 1.384795221632726, Loss: 0.08498199925912218\n",
      "Iteration:460, Price of Hedge: 1.3794678472406305, Loss: 0.05414128235938023\n",
      "Iteration:470, Price of Hedge: 1.3134369320387578, Loss: 0.0827400834892984\n",
      "Iteration:480, Price of Hedge: 1.3283616264869125, Loss: 0.05723246129162192\n",
      "Iteration:490, Price of Hedge: 1.269488767734606, Loss: 0.07346418085008821\n",
      "Iteration:500, Price of Hedge: 1.3701867957509877, Loss: 0.08018461930045646\n",
      "Iteration:510, Price of Hedge: 1.2512155032639385, Loss: 0.06261374146188672\n",
      "Iteration:520, Price of Hedge: 1.380724326754853, Loss: 0.05246973463930829\n",
      "Iteration:530, Price of Hedge: 1.3694964726297258, Loss: 0.059022546863550934\n",
      "Iteration:540, Price of Hedge: 1.3239164027536163, Loss: 0.05160582496894506\n",
      "Iteration:550, Price of Hedge: 1.3304954106830564, Loss: 0.06113888440001603\n",
      "Iteration:560, Price of Hedge: 1.3347827287169594, Loss: 0.05012597906531227\n",
      "Iteration:570, Price of Hedge: 1.2748104732480898, Loss: 0.04436565264114237\n",
      "Iteration:580, Price of Hedge: 1.4017507461267542, Loss: 0.07158045591834963\n",
      "Iteration:590, Price of Hedge: 1.3507175807603062, Loss: 0.05205090622970232\n",
      "Iteration:600, Price of Hedge: 1.3392016195947691, Loss: 0.04373829007442112\n",
      "Iteration:610, Price of Hedge: 1.2146021364151012, Loss: 0.03678011874187064\n",
      "Iteration:620, Price of Hedge: 1.4674290936523904, Loss: 0.04414353774811915\n",
      "Iteration:630, Price of Hedge: 1.2368625426538302, Loss: 0.05431797193377008\n",
      "Iteration:640, Price of Hedge: 1.3869338518057477, Loss: 0.05505875493219037\n",
      "Iteration:650, Price of Hedge: 1.3006080768734591, Loss: 0.04841103470796498\n",
      "Iteration:660, Price of Hedge: 1.260899776603219, Loss: 0.039978809214193944\n",
      "Iteration:670, Price of Hedge: 1.403131209502226, Loss: 0.04485253616706544\n",
      "Iteration:680, Price of Hedge: 1.220498410205937, Loss: 0.045925028568604635\n",
      "Iteration:690, Price of Hedge: 1.4425567058765638, Loss: 0.0464994082643095\n",
      "Iteration:700, Price of Hedge: 1.2343801224230675, Loss: 0.04887942580325558\n",
      "Iteration:710, Price of Hedge: 1.4204478964239344, Loss: 0.047361469263069014\n",
      "Iteration:720, Price of Hedge: 1.210425178647074, Loss: 0.043523804166223104\n",
      "Iteration:730, Price of Hedge: 1.4391643391950995, Loss: 0.04889668388128712\n",
      "Iteration:740, Price of Hedge: 1.2184181146225002, Loss: 0.041802676616680405\n",
      "Iteration:750, Price of Hedge: 1.4178775171411644, Loss: 0.05001987617299051\n",
      "Iteration:760, Price of Hedge: 1.2715741835954988, Loss: 0.04563726726121473\n",
      "Iteration:770, Price of Hedge: 1.318550626280603, Loss: 0.047732917962423474\n",
      "Iteration:780, Price of Hedge: 1.3350561149596842, Loss: 0.05507400147265003\n",
      "Iteration:790, Price of Hedge: 1.2859707579975066, Loss: 0.046584352867256484\n",
      "Iteration:800, Price of Hedge: 1.369676230941832, Loss: 0.04084312747812646\n",
      "Iteration:810, Price of Hedge: 1.355186120042731, Loss: 0.050475780877387424\n",
      "Iteration:820, Price of Hedge: 1.320432968280261, Loss: 0.054660579070268514\n",
      "Iteration:830, Price of Hedge: 1.2920165256033442, Loss: 0.047038434615728875\n",
      "Iteration:840, Price of Hedge: 1.3625958015558355, Loss: 0.045228605116780334\n",
      "Iteration:850, Price of Hedge: 1.3159423020845453, Loss: 0.07355820880238327\n",
      "Iteration:860, Price of Hedge: 1.3459356987842968, Loss: 0.06917412552500082\n",
      "Iteration:870, Price of Hedge: 1.3043429535433007, Loss: 0.056035705013660224\n",
      "Iteration:880, Price of Hedge: 1.355277096401096, Loss: 0.04874401275125706\n",
      "Iteration:890, Price of Hedge: 1.2910787833607402, Loss: 0.046050112489463405\n",
      "Iteration:900, Price of Hedge: 1.3512018127139755, Loss: 0.04656182878958717\n",
      "Iteration:910, Price of Hedge: 1.3631691811973496, Loss: 0.05285003524689813\n",
      "Iteration:920, Price of Hedge: 1.3019219766420065, Loss: 0.04547650712143181\n",
      "Iteration:930, Price of Hedge: 1.2965136835794056, Loss: 0.03426501102556472\n",
      "Iteration:940, Price of Hedge: 1.2575605328003576, Loss: 0.05156083967415555\n",
      "Iteration:950, Price of Hedge: 1.393330998451984, Loss: 0.04582607177779892\n",
      "Iteration:960, Price of Hedge: 1.2654355195272502, Loss: 0.05087164804277791\n",
      "Iteration:970, Price of Hedge: 1.2425955161672393, Loss: 0.04741367209181675\n",
      "Iteration:980, Price of Hedge: 1.3826681120839794, Loss: 0.04501691078842285\n",
      "Iteration:990, Price of Hedge: 1.2473159548137802, Loss: 0.042959073564808395\n",
      "tf.Tensor(0.44547585, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_64 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.3183836753149706, Loss: 0.013346018903463276\n",
      "Iteration:20, Price of Hedge: 0.5314237680248084, Loss: 0.007685742900788917\n",
      "Iteration:30, Price of Hedge: 0.39494565259874437, Loss: 0.008573691016595752\n",
      "Iteration:40, Price of Hedge: 0.4839413322068481, Loss: 0.008350724648861708\n",
      "Iteration:50, Price of Hedge: 0.45196273079069443, Loss: 0.008419747674770406\n",
      "Iteration:60, Price of Hedge: 0.456817165269581, Loss: 0.0061106782660498744\n",
      "Iteration:70, Price of Hedge: 0.4255608887087874, Loss: 0.007541170066729209\n",
      "Iteration:80, Price of Hedge: 0.49277422226882667, Loss: 0.0073778819328174094\n",
      "Iteration:90, Price of Hedge: 0.5007572834234452, Loss: 0.008964215749635329\n",
      "Iteration:100, Price of Hedge: 0.44431326485566847, Loss: 0.007491013777450029\n",
      "Iteration:110, Price of Hedge: 0.4516687720046207, Loss: 0.008209134119263162\n",
      "Iteration:120, Price of Hedge: 0.44276639246288596, Loss: 0.007327514203509367\n",
      "Iteration:130, Price of Hedge: 0.4544460653567171, Loss: 0.0069727556942710935\n",
      "Iteration:140, Price of Hedge: 0.4769231690520542, Loss: 0.008450122177835695\n",
      "Iteration:150, Price of Hedge: 0.4617703936733051, Loss: 0.0076566284660037455\n",
      "Iteration:160, Price of Hedge: 0.4765412969307363, Loss: 0.007024054188300788\n",
      "Iteration:170, Price of Hedge: 0.46533209524491215, Loss: 0.00773014459252579\n",
      "Iteration:180, Price of Hedge: 0.4568232455990597, Loss: 0.008642138297020452\n",
      "Iteration:190, Price of Hedge: 0.45463364123529576, Loss: 0.00752581780625512\n",
      "Iteration:200, Price of Hedge: 0.4261212847896104, Loss: 0.00994789762445656\n",
      "Iteration:210, Price of Hedge: 0.37564558963115363, Loss: 0.007924382260662456\n",
      "Iteration:220, Price of Hedge: 0.3902520954088459, Loss: 0.00723392341776048\n",
      "Iteration:230, Price of Hedge: 0.5027534601629668, Loss: 0.008917676084903903\n",
      "Iteration:240, Price of Hedge: 0.5588579860487244, Loss: 0.007144168554156849\n",
      "Iteration:250, Price of Hedge: 0.4579012011537771, Loss: 0.008100948256927332\n",
      "Iteration:260, Price of Hedge: 0.4448487453006578, Loss: 0.009270539491451048\n",
      "Iteration:270, Price of Hedge: 0.467559324504623, Loss: 0.006816179352626861\n",
      "Iteration:280, Price of Hedge: 0.41170916668818336, Loss: 0.007949725776824757\n",
      "Iteration:290, Price of Hedge: 0.4630213871759679, Loss: 0.008623420854195096\n",
      "Iteration:300, Price of Hedge: 0.4077127444172334, Loss: 0.006173533100576023\n",
      "Iteration:310, Price of Hedge: 0.44036342796621286, Loss: 0.00665273049572015\n",
      "Iteration:320, Price of Hedge: 0.48781198766279205, Loss: 0.007244971159268587\n",
      "Iteration:330, Price of Hedge: 0.4673802519439619, Loss: 0.006277137286070201\n",
      "Iteration:340, Price of Hedge: 0.4459029738553795, Loss: 0.0073213452978023955\n",
      "Iteration:350, Price of Hedge: 0.44208347545722976, Loss: 0.005600693845486848\n",
      "Iteration:360, Price of Hedge: 0.4989733238977579, Loss: 0.004748676248098338\n",
      "Iteration:370, Price of Hedge: 0.47546992458989057, Loss: 0.004632242081663573\n",
      "Iteration:380, Price of Hedge: 0.4866526562699392, Loss: 0.00801574221124195\n",
      "Iteration:390, Price of Hedge: 0.44019546457896014, Loss: 0.005454198050083559\n",
      "Iteration:400, Price of Hedge: 0.48904277435621, Loss: 0.007408648599990287\n",
      "Iteration:410, Price of Hedge: 0.46493390223920417, Loss: 0.0049807677531591215\n",
      "Iteration:420, Price of Hedge: 0.48837060078985817, Loss: 0.005298775699542802\n",
      "Iteration:430, Price of Hedge: 0.4290318425058445, Loss: 0.005828330823453066\n",
      "Iteration:440, Price of Hedge: 0.46955495264298863, Loss: 0.005264623848934846\n",
      "Iteration:450, Price of Hedge: 0.49739440405411417, Loss: 0.006080567348696242\n",
      "Iteration:460, Price of Hedge: 0.4749309239541504, Loss: 0.006211454441158004\n",
      "Iteration:470, Price of Hedge: 0.45197105124156, Loss: 0.0058794010908299835\n",
      "Iteration:480, Price of Hedge: 0.473507943989091, Loss: 0.005521615989016394\n",
      "Iteration:490, Price of Hedge: 0.4867076535358251, Loss: 0.004461916066385641\n",
      "Iteration:500, Price of Hedge: 0.45890011242527184, Loss: 0.006085506902073235\n",
      "Iteration:510, Price of Hedge: 0.4426410828155099, Loss: 0.005469661388005243\n",
      "Iteration:520, Price of Hedge: 0.42310283551270234, Loss: 0.004818078580275032\n",
      "Iteration:530, Price of Hedge: 0.4204482916692541, Loss: 0.005228510463464531\n",
      "Iteration:540, Price of Hedge: 0.49779703158583294, Loss: 0.0055744263506849025\n",
      "Iteration:550, Price of Hedge: 0.5173822757210019, Loss: 0.004607159293915242\n",
      "Iteration:560, Price of Hedge: 0.4465215216587353, Loss: 0.0061559342897952625\n",
      "Iteration:570, Price of Hedge: 0.45278714117782787, Loss: 0.0057206814187580335\n",
      "Iteration:580, Price of Hedge: 0.46177487391607885, Loss: 0.00471738776693531\n",
      "Iteration:590, Price of Hedge: 0.4790625764100469, Loss: 0.006148230300905767\n",
      "Iteration:600, Price of Hedge: 0.494232861309024, Loss: 0.006831270170362558\n",
      "Iteration:610, Price of Hedge: 0.4660271729095257, Loss: 0.00587363613558356\n",
      "Iteration:620, Price of Hedge: 0.40822340065991514, Loss: 0.004839259728031298\n",
      "Iteration:630, Price of Hedge: 0.42038597972128855, Loss: 0.006343916618969914\n",
      "Iteration:640, Price of Hedge: 0.45466129987690923, Loss: 0.0050047669107595285\n",
      "Iteration:650, Price of Hedge: 0.45277456906800356, Loss: 0.0042256814796782114\n",
      "Iteration:660, Price of Hedge: 0.49262733430931577, Loss: 0.006771404069217369\n",
      "Iteration:670, Price of Hedge: 0.43557692859714053, Loss: 0.0051251498625982\n",
      "Iteration:680, Price of Hedge: 0.448878037924203, Loss: 0.004970822928558327\n",
      "Iteration:690, Price of Hedge: 0.46508207026807896, Loss: 0.005479076183885035\n",
      "Iteration:700, Price of Hedge: 0.5081881775145803, Loss: 0.005153542829717317\n",
      "Iteration:710, Price of Hedge: 0.5237130873441288, Loss: 0.005236910204340895\n",
      "Iteration:720, Price of Hedge: 0.4637659760949078, Loss: 0.005399957610922535\n",
      "Iteration:730, Price of Hedge: 0.4767040028902443, Loss: 0.006054233064560855\n",
      "Iteration:740, Price of Hedge: 0.4306015275633627, Loss: 0.0050615667743239895\n",
      "Iteration:750, Price of Hedge: 0.4270892000957929, Loss: 0.004924475774258585\n",
      "Iteration:760, Price of Hedge: 0.4185168041493739, Loss: 0.004181596590822423\n",
      "Iteration:770, Price of Hedge: 0.42810895821121453, Loss: 0.007466046710258034\n",
      "Iteration:780, Price of Hedge: 0.4851292822933374, Loss: 0.005977044239023944\n",
      "Iteration:790, Price of Hedge: 0.5160471633744237, Loss: 0.005500251974208137\n",
      "Iteration:800, Price of Hedge: 0.45497765987685174, Loss: 0.005835831587044549\n",
      "Iteration:810, Price of Hedge: 0.4413971754111117, Loss: 0.005040435629277251\n",
      "Iteration:820, Price of Hedge: 0.44240541290225793, Loss: 0.00407022198426752\n",
      "Iteration:830, Price of Hedge: 0.4655659364876442, Loss: 0.006506411138449054\n",
      "Iteration:840, Price of Hedge: 0.4528636253223226, Loss: 0.0045552254083123245\n",
      "Iteration:850, Price of Hedge: 0.4518745431548723, Loss: 0.005838838178536055\n",
      "Iteration:860, Price of Hedge: 0.437394809960972, Loss: 0.005182286530127556\n",
      "Iteration:870, Price of Hedge: 0.4797357557451847, Loss: 0.005135644002679385\n",
      "Iteration:880, Price of Hedge: 0.4724165019892894, Loss: 0.005931562131599045\n",
      "Iteration:890, Price of Hedge: 0.5107564538262522, Loss: 0.005623868315542247\n",
      "Iteration:900, Price of Hedge: 0.4857051763568166, Loss: 0.004621486141681785\n",
      "Iteration:910, Price of Hedge: 0.43992029538247834, Loss: 0.005406822982940796\n",
      "Iteration:920, Price of Hedge: 0.44804196976250527, Loss: 0.005157065163441388\n",
      "Iteration:930, Price of Hedge: 0.45507992827567706, Loss: 0.006892766359838376\n",
      "Iteration:940, Price of Hedge: 0.4518950242646952, Loss: 0.005876455574076545\n",
      "Iteration:950, Price of Hedge: 0.4449230807572917, Loss: 0.005225022060150498\n",
      "Iteration:960, Price of Hedge: 0.4516186207156125, Loss: 0.00473180640539006\n",
      "Iteration:970, Price of Hedge: 0.44773804472209805, Loss: 0.005740791437043757\n",
      "Iteration:980, Price of Hedge: 0.4811897773923193, Loss: 0.004941856001766266\n",
      "Iteration:990, Price of Hedge: 0.48457574372696405, Loss: 0.004670592731223078\n",
      "tf.Tensor(1.2502776, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_65 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 1.2613022669846488, Loss: 0.08751852527889242\n",
      "Iteration:20, Price of Hedge: 1.375624804709537, Loss: 0.07786690513758288\n",
      "Iteration:30, Price of Hedge: 1.2617211239672317, Loss: 0.07729688567814891\n",
      "Iteration:40, Price of Hedge: 1.309996288455568, Loss: 0.06825953882285489\n",
      "Iteration:50, Price of Hedge: 1.3170362127895487, Loss: 0.08285342677395989\n",
      "Iteration:60, Price of Hedge: 1.3088822623748457, Loss: 0.0607344053393959\n",
      "Iteration:70, Price of Hedge: 1.3777810815530758, Loss: 0.08319599962288607\n",
      "Iteration:80, Price of Hedge: 1.261987378394929, Loss: 0.0582445275616692\n",
      "Iteration:90, Price of Hedge: 1.339564976427073, Loss: 0.0788015386403032\n",
      "Iteration:100, Price of Hedge: 1.3061160324793946, Loss: 0.08175249854583627\n",
      "Iteration:110, Price of Hedge: 1.3315650000701453, Loss: 0.1242862204904185\n",
      "Iteration:120, Price of Hedge: 1.3679300334623805, Loss: 0.08845165012843381\n",
      "Iteration:130, Price of Hedge: 1.3648691133126478, Loss: 0.08250298492720276\n",
      "Iteration:140, Price of Hedge: 1.3725868343748289, Loss: 0.07599982110757537\n",
      "Iteration:150, Price of Hedge: 1.2485529589869657, Loss: 0.06895577083573415\n",
      "Iteration:160, Price of Hedge: 1.3639739790931573, Loss: 0.0676231329089532\n",
      "Iteration:170, Price of Hedge: 1.2424294728840324, Loss: 0.0769222196615985\n",
      "Iteration:180, Price of Hedge: 1.3672117316821641, Loss: 0.08075757606191303\n",
      "Iteration:190, Price of Hedge: 1.1809629192998274, Loss: 0.08795749192259877\n",
      "Iteration:200, Price of Hedge: 1.4482763300951775, Loss: 0.08168511775177337\n",
      "Iteration:210, Price of Hedge: 1.158456008275016, Loss: 0.07146889558744506\n",
      "Iteration:220, Price of Hedge: 1.4070674227963083, Loss: 0.07079592769233614\n",
      "Iteration:230, Price of Hedge: 1.1544343046341283, Loss: 0.06940488088623056\n",
      "Iteration:240, Price of Hedge: 1.498394794467572, Loss: 0.07029921506236861\n",
      "Iteration:250, Price of Hedge: 1.16315422857474, Loss: 0.06830950724481114\n",
      "Iteration:260, Price of Hedge: 1.3214372741297895, Loss: 0.0730834002164869\n",
      "Iteration:270, Price of Hedge: 1.2687381899197137, Loss: 0.06540596133710182\n",
      "Iteration:280, Price of Hedge: 1.2617422451117364, Loss: 0.07310123546865128\n",
      "Iteration:290, Price of Hedge: 1.2723639863930432, Loss: 0.06366660422831387\n",
      "Iteration:300, Price of Hedge: 1.1924444100260645, Loss: 0.06671195782024597\n",
      "Iteration:310, Price of Hedge: 1.4888812275213241, Loss: 0.07350792036308605\n",
      "Iteration:320, Price of Hedge: 1.2595244335052032, Loss: 0.08343698982443187\n",
      "Iteration:330, Price of Hedge: 1.282078981397058, Loss: 0.05589749752452349\n",
      "Iteration:340, Price of Hedge: 1.2663570780357531, Loss: 0.06911860823093577\n",
      "Iteration:350, Price of Hedge: 1.39169991578176, Loss: 0.08033019290303117\n",
      "Iteration:360, Price of Hedge: 1.219343970506725, Loss: 0.08354880731212831\n",
      "Iteration:370, Price of Hedge: 1.351894513106913, Loss: 0.06976346031680124\n",
      "Iteration:380, Price of Hedge: 1.2893898232685617, Loss: 0.0823929789662401\n",
      "Iteration:390, Price of Hedge: 1.3624686175211764, Loss: 0.051790349253593604\n",
      "Iteration:400, Price of Hedge: 1.275420060565898, Loss: 0.05997210117479455\n",
      "Iteration:410, Price of Hedge: 1.3187547973441498, Loss: 0.07379087283846815\n",
      "Iteration:420, Price of Hedge: 1.3779008594721291, Loss: 0.06830464983874265\n",
      "Iteration:430, Price of Hedge: 1.3301659756888968, Loss: 0.07158994214667161\n",
      "Iteration:440, Price of Hedge: 1.3839020075172812, Loss: 0.0640392358489109\n",
      "Iteration:450, Price of Hedge: 1.322366055886846, Loss: 0.06534385511456975\n",
      "Iteration:460, Price of Hedge: 1.3697558695429735, Loss: 0.0736773866889223\n",
      "Iteration:470, Price of Hedge: 1.2796672392818893, Loss: 0.0640874270317056\n",
      "Iteration:480, Price of Hedge: 1.4324970064795481, Loss: 0.07197207142478135\n",
      "Iteration:490, Price of Hedge: 1.270522423745979, Loss: 0.07399626682542504\n",
      "Iteration:500, Price of Hedge: 1.3336920181853658, Loss: 0.06780565708522061\n",
      "Iteration:510, Price of Hedge: 1.2506850059461159, Loss: 0.06016254006565589\n",
      "Iteration:520, Price of Hedge: 1.3360126925086435, Loss: 0.05853322891999824\n",
      "Iteration:530, Price of Hedge: 1.2616889393660813, Loss: 0.04956227994836269\n",
      "Iteration:540, Price of Hedge: 1.4066635609119886, Loss: 0.051057932422801856\n",
      "Iteration:550, Price of Hedge: 1.2475275319929324, Loss: 0.05112903341845368\n",
      "Iteration:560, Price of Hedge: 1.3929143358740248, Loss: 0.0489186736442889\n",
      "Iteration:570, Price of Hedge: 1.2954997772096477, Loss: 0.06014792213068745\n",
      "Iteration:580, Price of Hedge: 1.2672704075269168, Loss: 0.04423944580229247\n",
      "Iteration:590, Price of Hedge: 1.3982694146244967, Loss: 0.043911839478652584\n",
      "Iteration:600, Price of Hedge: 1.187210572131062, Loss: 0.055651055598990244\n",
      "Iteration:610, Price of Hedge: 1.377414707414414, Loss: 0.0794985249797719\n",
      "Iteration:620, Price of Hedge: 1.3462677853507103, Loss: 0.04725484634256816\n",
      "Iteration:630, Price of Hedge: 1.3739624517734228, Loss: 0.060839508177527084\n",
      "Iteration:640, Price of Hedge: 1.3341668324858575, Loss: 0.06302175214244841\n",
      "Iteration:650, Price of Hedge: 1.3549043219156147, Loss: 0.04755859423051874\n",
      "Iteration:660, Price of Hedge: 1.2479906428020968, Loss: 0.05180710444723218\n",
      "Iteration:670, Price of Hedge: 1.358173253336986, Loss: 0.056092490947898456\n",
      "Iteration:680, Price of Hedge: 1.2930110480655914, Loss: 0.04874386988637269\n",
      "Iteration:690, Price of Hedge: 1.3366577560345378, Loss: 0.056355865219526895\n",
      "Iteration:700, Price of Hedge: 1.308805732513588, Loss: 0.04495312161755294\n",
      "Iteration:710, Price of Hedge: 1.313688191368192, Loss: 0.056106605998473925\n",
      "Iteration:720, Price of Hedge: 1.3161889897376797, Loss: 0.04099649007419686\n",
      "Iteration:730, Price of Hedge: 1.344972080853836, Loss: 0.05572611680923672\n",
      "Iteration:740, Price of Hedge: 1.3257202947879705, Loss: 0.05752594005168419\n",
      "Iteration:750, Price of Hedge: 1.285313350945603, Loss: 0.04794915253680614\n",
      "Iteration:760, Price of Hedge: 1.278550195894809, Loss: 0.05166526247543715\n",
      "Iteration:770, Price of Hedge: 1.3955486271914652, Loss: 0.04241917859489206\n",
      "Iteration:780, Price of Hedge: 1.347232957651113, Loss: 0.05691051241740297\n",
      "Iteration:790, Price of Hedge: 1.3596248519956817, Loss: 0.046644927578228135\n",
      "Iteration:800, Price of Hedge: 1.2687325210411018, Loss: 0.04339785448416507\n",
      "Iteration:810, Price of Hedge: 1.3960297504052506, Loss: 0.04364178770232883\n",
      "Iteration:820, Price of Hedge: 1.3489441360901084, Loss: 0.05368226891509949\n",
      "Iteration:830, Price of Hedge: 1.3422018278832413, Loss: 0.0463870164597779\n",
      "Iteration:840, Price of Hedge: 1.300198088942898, Loss: 0.0507266859019083\n",
      "Iteration:850, Price of Hedge: 1.23701322510467, Loss: 0.06096433779889168\n",
      "Iteration:860, Price of Hedge: 1.3731366241666365, Loss: 0.05332619247730293\n",
      "Iteration:870, Price of Hedge: 1.2396853699018722, Loss: 0.033838445053821435\n",
      "Iteration:880, Price of Hedge: 1.3053654546645022, Loss: 0.04740348296826369\n",
      "Iteration:890, Price of Hedge: 1.3742627194727903, Loss: 0.05273321748824884\n",
      "Iteration:900, Price of Hedge: 1.2467269400393208, Loss: 0.05544179283096469\n",
      "Iteration:910, Price of Hedge: 1.3457580434432885, Loss: 0.04735658899861903\n",
      "Iteration:920, Price of Hedge: 1.2949242031635095, Loss: 0.04556867783023009\n",
      "Iteration:930, Price of Hedge: 1.3654011650004123, Loss: 0.05098308836717962\n",
      "Iteration:940, Price of Hedge: 1.2966736922498967, Loss: 0.0351840093953399\n",
      "Iteration:950, Price of Hedge: 1.4004913407397, Loss: 0.05345031920343644\n",
      "Iteration:960, Price of Hedge: 1.2307019345393428, Loss: 0.04820481210467875\n",
      "Iteration:970, Price of Hedge: 1.316490811806989, Loss: 0.059672056344646764\n",
      "Iteration:980, Price of Hedge: 1.3604919161226918, Loss: 0.04873236640588346\n",
      "Iteration:990, Price of Hedge: 1.277031667895085, Loss: 0.0458539761470135\n",
      "tf.Tensor(0.99439913, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_66 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 1.0096516934928104, Loss: 0.044478510185196996\n",
      "Iteration:20, Price of Hedge: 0.884466029977989, Loss: 0.047142125948802516\n",
      "Iteration:30, Price of Hedge: 1.050439640837999, Loss: 0.04294449277470989\n",
      "Iteration:40, Price of Hedge: 0.9259338770224759, Loss: 0.04144041984398612\n",
      "Iteration:50, Price of Hedge: 0.984053049220006, Loss: 0.030368605602862433\n",
      "Iteration:60, Price of Hedge: 0.9860580950115492, Loss: 0.04794927254330901\n",
      "Iteration:70, Price of Hedge: 0.9843037599482841, Loss: 0.038000636307400276\n",
      "Iteration:80, Price of Hedge: 0.9687932508990799, Loss: 0.04055440326141593\n",
      "Iteration:90, Price of Hedge: 1.0465760257635566, Loss: 0.038243118018338865\n",
      "Iteration:100, Price of Hedge: 0.8411656722055114, Loss: 0.044444039745896904\n",
      "Iteration:110, Price of Hedge: 1.0403334932097779, Loss: 0.036443806232177425\n",
      "Iteration:120, Price of Hedge: 0.9509103161508847, Loss: 0.039823700809236584\n",
      "Iteration:130, Price of Hedge: 0.9236658684101713, Loss: 0.03889028451533108\n",
      "Iteration:140, Price of Hedge: 1.029299203859182, Loss: 0.055521991462453006\n",
      "Iteration:150, Price of Hedge: 0.9219618217862036, Loss: 0.036880789911288764\n",
      "Iteration:160, Price of Hedge: 1.0448346742609829, Loss: 0.03558771412828676\n",
      "Iteration:170, Price of Hedge: 0.9992692337490326, Loss: 0.034446738015777356\n",
      "Iteration:180, Price of Hedge: 1.0014176473093357, Loss: 0.041632538825887626\n",
      "Iteration:190, Price of Hedge: 0.968085006806723, Loss: 0.04279694477943324\n",
      "Iteration:200, Price of Hedge: 0.9666721759630491, Loss: 0.04437028146339586\n",
      "Iteration:210, Price of Hedge: 0.9902540709529831, Loss: 0.044171833567116896\n",
      "Iteration:220, Price of Hedge: 1.0015536089624903, Loss: 0.03504780487188199\n",
      "Iteration:230, Price of Hedge: 0.9687798101707586, Loss: 0.03473321925380333\n",
      "Iteration:240, Price of Hedge: 1.0077460359440238, Loss: 0.04039805478926226\n",
      "Iteration:250, Price of Hedge: 1.0017511053786394, Loss: 0.03593476150539132\n",
      "Iteration:260, Price of Hedge: 0.9565150084273228, Loss: 0.03738425433569148\n",
      "Iteration:270, Price of Hedge: 0.9939914163280265, Loss: 0.03323644671867072\n",
      "Iteration:280, Price of Hedge: 1.0504558245721, Loss: 0.044825283261723574\n",
      "Iteration:290, Price of Hedge: 0.9942797062354886, Loss: 0.03499526202470946\n",
      "Iteration:300, Price of Hedge: 0.9376944228700496, Loss: 0.035072849086111545\n",
      "Iteration:310, Price of Hedge: 1.048126372630327, Loss: 0.03899064995389665\n",
      "Iteration:320, Price of Hedge: 0.9035501269571796, Loss: 0.03217417201366146\n",
      "Iteration:330, Price of Hedge: 1.0066174719326682, Loss: 0.030861386591212184\n",
      "Iteration:340, Price of Hedge: 0.9334667194950953, Loss: 0.03256435601395182\n",
      "Iteration:350, Price of Hedge: 1.0081348112965542, Loss: 0.042310498420056325\n",
      "Iteration:360, Price of Hedge: 0.9476700948566759, Loss: 0.03406699172393886\n",
      "Iteration:370, Price of Hedge: 1.0411429542154111, Loss: 0.034344686771576254\n",
      "Iteration:380, Price of Hedge: 0.9060628116850467, Loss: 0.03330384465651975\n",
      "Iteration:390, Price of Hedge: 1.0472627829773047, Loss: 0.032142627447193206\n",
      "Iteration:400, Price of Hedge: 0.9981349094255393, Loss: 0.03480390594129048\n",
      "Iteration:410, Price of Hedge: 0.959404399282289, Loss: 0.0368875302765332\n",
      "Iteration:420, Price of Hedge: 0.9762848568514756, Loss: 0.02705514605433166\n",
      "Iteration:430, Price of Hedge: 0.9938138524205443, Loss: 0.030486506277335224\n",
      "Iteration:440, Price of Hedge: 0.9484388679432414, Loss: 0.029268783148943812\n",
      "Iteration:450, Price of Hedge: 1.0411852879379466, Loss: 0.02417597575319306\n",
      "Iteration:460, Price of Hedge: 0.9702816058352256, Loss: 0.029117592099115797\n",
      "Iteration:470, Price of Hedge: 1.0216749278605677, Loss: 0.020917937779254814\n",
      "Iteration:480, Price of Hedge: 0.9343496930556285, Loss: 0.01906774323587719\n",
      "Iteration:490, Price of Hedge: 1.0186038585894495, Loss: 0.024087585249235134\n",
      "Iteration:500, Price of Hedge: 1.0156409551795833, Loss: 0.02691969014286784\n",
      "Iteration:510, Price of Hedge: 0.8900741052948888, Loss: 0.02325354862619307\n",
      "Iteration:520, Price of Hedge: 1.0278049971773726, Loss: 0.02466504796914464\n",
      "Iteration:530, Price of Hedge: 0.9167865927813637, Loss: 0.021629790638590763\n",
      "Iteration:540, Price of Hedge: 1.0253972781373477, Loss: 0.02071410816278174\n",
      "Iteration:550, Price of Hedge: 1.0161431081043475, Loss: 0.022595214381189877\n",
      "Iteration:560, Price of Hedge: 0.9625214596169827, Loss: 0.02473815764507066\n",
      "Iteration:570, Price of Hedge: 0.9692908321475443, Loss: 0.02428277582615053\n",
      "Iteration:580, Price of Hedge: 0.9656016722407004, Loss: 0.02835160202049778\n",
      "Iteration:590, Price of Hedge: 0.9970426445240037, Loss: 0.02483068837337754\n",
      "Iteration:600, Price of Hedge: 0.8900827914798584, Loss: 0.030182875538589827\n",
      "Iteration:610, Price of Hedge: 0.9479315947410214, Loss: 0.02314575992823578\n",
      "Iteration:620, Price of Hedge: 0.9608582837791346, Loss: 0.025653710113834906\n",
      "Iteration:630, Price of Hedge: 1.0340679194074482, Loss: 0.023346625098358234\n",
      "Iteration:640, Price of Hedge: 0.9924707853572046, Loss: 0.020357973150382593\n",
      "Iteration:650, Price of Hedge: 1.0160490230060988, Loss: 0.027421085883744922\n",
      "Iteration:660, Price of Hedge: 0.9383397606965218, Loss: 0.019228446229706365\n",
      "Iteration:670, Price of Hedge: 1.0121129925790684, Loss: 0.02656339940774473\n",
      "Iteration:680, Price of Hedge: 0.963129492564849, Loss: 0.03374236556178687\n",
      "Iteration:690, Price of Hedge: 0.9398387219216829, Loss: 0.030871409991499378\n",
      "Iteration:700, Price of Hedge: 0.9728278466671327, Loss: 0.02859740676864675\n",
      "Iteration:710, Price of Hedge: 0.9165914736368905, Loss: 0.02617549267371118\n",
      "Iteration:720, Price of Hedge: 1.0300127510960466, Loss: 0.030205711061707066\n",
      "Iteration:730, Price of Hedge: 0.9330685264893873, Loss: 0.02802833307474728\n",
      "Iteration:740, Price of Hedge: 0.9585303862073034, Loss: 0.026237918913584225\n",
      "Iteration:750, Price of Hedge: 1.0597259954721494, Loss: 0.022031793850764814\n",
      "Iteration:760, Price of Hedge: 0.9329908994258176, Loss: 0.02372638139073864\n",
      "Iteration:770, Price of Hedge: 0.9478679570069289, Loss: 0.02288113987481566\n",
      "Iteration:780, Price of Hedge: 1.0230501795250575, Loss: 0.023065024124782244\n",
      "Iteration:790, Price of Hedge: 0.9341321726972865, Loss: 0.024329601220650688\n",
      "Iteration:800, Price of Hedge: 0.952803538740136, Loss: 0.02825432817802991\n",
      "Iteration:810, Price of Hedge: 1.0059234000368407, Loss: 0.02155595949499869\n",
      "Iteration:820, Price of Hedge: 0.9461575100361416, Loss: 0.020702118941685655\n",
      "Iteration:830, Price of Hedge: 1.001650711367097, Loss: 0.0195913230359988\n",
      "Iteration:840, Price of Hedge: 0.9634047074780938, Loss: 0.020152934896987773\n",
      "Iteration:850, Price of Hedge: 0.9883079083521807, Loss: 0.022984918355468766\n",
      "Iteration:860, Price of Hedge: 0.9188345208965985, Loss: 0.024345844958003227\n",
      "Iteration:870, Price of Hedge: 1.0244311000681592, Loss: 0.023856784171242398\n",
      "Iteration:880, Price of Hedge: 1.0049667310543555, Loss: 0.02810553725825926\n",
      "Iteration:890, Price of Hedge: 0.8627926269761474, Loss: 0.028500641525167226\n",
      "Iteration:900, Price of Hedge: 0.9160674680994134, Loss: 0.02298530837660309\n",
      "Iteration:910, Price of Hedge: 1.0477238822488972, Loss: 0.028167074878551548\n",
      "Iteration:920, Price of Hedge: 0.9342891640614198, Loss: 0.018923453988612948\n",
      "Iteration:930, Price of Hedge: 1.0262540102759203, Loss: 0.03094363676244001\n",
      "Iteration:940, Price of Hedge: 1.0138974092723856, Loss: 0.028083504635792168\n",
      "Iteration:950, Price of Hedge: 0.9832050032664029, Loss: 0.025791148989893743\n",
      "Iteration:960, Price of Hedge: 0.9853930075434619, Loss: 0.021664368226554133\n",
      "Iteration:970, Price of Hedge: 0.9845476131621127, Loss: 0.026746360750558296\n",
      "Iteration:980, Price of Hedge: 1.0173209547862143, Loss: 0.026846431887462077\n",
      "Iteration:990, Price of Hedge: 0.9549148302888852, Loss: 0.018156943881815837\n",
      "tf.Tensor(1.2728194, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_67 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.9942462415649743, Loss: 0.08778490542768794\n",
      "Iteration:20, Price of Hedge: 1.1981403529614454, Loss: 0.08715575133531672\n",
      "Iteration:30, Price of Hedge: 1.4269212071973243, Loss: 0.07860652235854673\n",
      "Iteration:40, Price of Hedge: 1.4236866547817273, Loss: 0.07242967336400455\n",
      "Iteration:50, Price of Hedge: 1.3009453751508546, Loss: 0.06550695538115861\n",
      "Iteration:60, Price of Hedge: 1.291191520898292, Loss: 0.07936424341765758\n",
      "Iteration:70, Price of Hedge: 1.3751819007096175, Loss: 0.07043983982534884\n",
      "Iteration:80, Price of Hedge: 1.2716361755261234, Loss: 0.07555322547904382\n",
      "Iteration:90, Price of Hedge: 1.3065728343752654, Loss: 0.08580776971995477\n",
      "Iteration:100, Price of Hedge: 1.4592905955035804, Loss: 0.08003266820944362\n",
      "Iteration:110, Price of Hedge: 1.3095031874498773, Loss: 0.0692176307395883\n",
      "Iteration:120, Price of Hedge: 1.299346202781203, Loss: 0.08018766517979117\n",
      "Iteration:130, Price of Hedge: 1.3014724894282155, Loss: 0.08440695095575848\n",
      "Iteration:140, Price of Hedge: 1.2896482144130232, Loss: 0.07653718736903842\n",
      "Iteration:150, Price of Hedge: 1.404630445027965, Loss: 0.07796470472282523\n",
      "Iteration:160, Price of Hedge: 1.3172628765004903, Loss: 0.06667595586938546\n",
      "Iteration:170, Price of Hedge: 1.2402360740289398, Loss: 0.10218177698865533\n",
      "Iteration:180, Price of Hedge: 1.352801899418887, Loss: 0.07595861316032854\n",
      "Iteration:190, Price of Hedge: 1.268818011387907, Loss: 0.07732889884143788\n",
      "Iteration:200, Price of Hedge: 1.396473843041008, Loss: 0.07706439307992526\n",
      "Iteration:210, Price of Hedge: 1.3491626622172364, Loss: 0.08945713318460946\n",
      "Iteration:220, Price of Hedge: 1.2566758220028307, Loss: 0.06919939546574767\n",
      "Iteration:230, Price of Hedge: 1.3402229320801327, Loss: 0.07038727126249711\n",
      "Iteration:240, Price of Hedge: 1.398336801133155, Loss: 0.06542480235805215\n",
      "Iteration:250, Price of Hedge: 1.3115930835535439, Loss: 0.06590747422718408\n",
      "Iteration:260, Price of Hedge: 1.2959029990592854, Loss: 0.08062615751208142\n",
      "Iteration:270, Price of Hedge: 1.2680533528100115, Loss: 0.08640192763025141\n",
      "Iteration:280, Price of Hedge: 1.3465502235125086, Loss: 0.06809079253603585\n",
      "Iteration:290, Price of Hedge: 1.2818137327381465, Loss: 0.06867480703954243\n",
      "Iteration:300, Price of Hedge: 1.3213603785344277, Loss: 0.06724083790757761\n",
      "Iteration:310, Price of Hedge: 1.3910538464870799, Loss: 0.08991659808192481\n",
      "Iteration:320, Price of Hedge: 1.3363044568900933, Loss: 0.07819832881093305\n",
      "Iteration:330, Price of Hedge: 1.4103369942523614, Loss: 0.08473603164500504\n",
      "Iteration:340, Price of Hedge: 1.2165074282297839, Loss: 0.061429197274240725\n",
      "Iteration:350, Price of Hedge: 1.399424037190761, Loss: 0.07042450756595856\n",
      "Iteration:360, Price of Hedge: 1.2937181035221101, Loss: 0.0833536653092736\n",
      "Iteration:370, Price of Hedge: 1.344934227374074, Loss: 0.06804056124269238\n",
      "Iteration:380, Price of Hedge: 1.2759759764039473, Loss: 0.08134423070848272\n",
      "Iteration:390, Price of Hedge: 1.2757233455716233, Loss: 0.08290984697409415\n",
      "Iteration:400, Price of Hedge: 1.3661971852777244, Loss: 0.087819787317855\n",
      "Iteration:410, Price of Hedge: 1.340053780057042, Loss: 0.06924139202715622\n",
      "Iteration:420, Price of Hedge: 1.2985820013709373, Loss: 0.06536023885950897\n",
      "Iteration:430, Price of Hedge: 1.363872487879303, Loss: 0.07182256618058887\n",
      "Iteration:440, Price of Hedge: 1.2965065517643781, Loss: 0.0804943160821921\n",
      "Iteration:450, Price of Hedge: 1.3316943785094282, Loss: 0.09513693238805701\n",
      "Iteration:460, Price of Hedge: 1.3068281167798432, Loss: 0.09357900796781991\n",
      "Iteration:470, Price of Hedge: 1.3468946536049318, Loss: 0.062054996899126996\n",
      "Iteration:480, Price of Hedge: 1.2621885321521178, Loss: 0.07137224463587302\n",
      "Iteration:490, Price of Hedge: 1.297793478642757, Loss: 0.08795961775207815\n",
      "Iteration:500, Price of Hedge: 1.3752005531489204, Loss: 0.0766779778552845\n",
      "Iteration:510, Price of Hedge: 1.305857458467881, Loss: 0.05643356657283647\n",
      "Iteration:520, Price of Hedge: 1.3102768065133206, Loss: 0.07496057622192609\n",
      "Iteration:530, Price of Hedge: 1.2803325096170284, Loss: 0.077494062076957\n",
      "Iteration:540, Price of Hedge: 1.309887665426686, Loss: 0.0726556398943103\n",
      "Iteration:550, Price of Hedge: 1.3342952965898804, Loss: 0.0571446108169269\n",
      "Iteration:560, Price of Hedge: 1.3783657989518134, Loss: 0.07550779444581508\n",
      "Iteration:570, Price of Hedge: 1.270121487734491, Loss: 0.05856183618444391\n",
      "Iteration:580, Price of Hedge: 1.3868511958982481, Loss: 0.05825976838753349\n",
      "Iteration:590, Price of Hedge: 1.4021154744619482, Loss: 0.062068540490165\n",
      "Iteration:600, Price of Hedge: 1.24062804955488, Loss: 0.0786267748845546\n",
      "Iteration:610, Price of Hedge: 1.3412881326579738, Loss: 0.06108857310233731\n",
      "Iteration:620, Price of Hedge: 1.32938467620927, Loss: 0.08931589124532878\n",
      "Iteration:630, Price of Hedge: 1.3611916568971312, Loss: 0.050392107771911304\n",
      "Iteration:640, Price of Hedge: 1.300050880966046, Loss: 0.06038670078382325\n",
      "Iteration:650, Price of Hedge: 1.3565680463546188, Loss: 0.055751849632208916\n",
      "Iteration:660, Price of Hedge: 1.2909675087596044, Loss: 0.04738088745815219\n",
      "Iteration:670, Price of Hedge: 1.3211627906847525, Loss: 0.05001627597790446\n",
      "Iteration:680, Price of Hedge: 1.339621756646716, Loss: 0.044579178497317434\n",
      "Iteration:690, Price of Hedge: 1.3554240300773701, Loss: 0.06454473181196932\n",
      "Iteration:700, Price of Hedge: 1.3616506531976258, Loss: 0.047899395554878765\n",
      "Iteration:710, Price of Hedge: 1.2399646078902606, Loss: 0.05389221171997463\n",
      "Iteration:720, Price of Hedge: 1.2838761073504885, Loss: 0.048015201830146736\n",
      "Iteration:730, Price of Hedge: 1.3434446838020904, Loss: 0.05860554712446486\n",
      "Iteration:740, Price of Hedge: 1.31462904235068, Loss: 0.04602839131244423\n",
      "Iteration:750, Price of Hedge: 1.3203215108120732, Loss: 0.05262798321442404\n",
      "Iteration:760, Price of Hedge: 1.349781392887644, Loss: 0.04103087479456633\n",
      "Iteration:770, Price of Hedge: 1.3127173501891776, Loss: 0.045101109636673443\n",
      "Iteration:780, Price of Hedge: 1.30739345027107, Loss: 0.03944558603437756\n",
      "Iteration:790, Price of Hedge: 1.2981514408970272, Loss: 0.058387592456874415\n",
      "Iteration:800, Price of Hedge: 1.3702575653001077, Loss: 0.04570547667160696\n",
      "Iteration:810, Price of Hedge: 1.3146528150674386, Loss: 0.03607146034134914\n",
      "Iteration:820, Price of Hedge: 1.3345944670869359, Loss: 0.06446053296371872\n",
      "Iteration:830, Price of Hedge: 1.3054154688032213, Loss: 0.035168557129446755\n",
      "Iteration:840, Price of Hedge: 1.363436807127937, Loss: 0.04706487604852754\n",
      "Iteration:850, Price of Hedge: 1.2651614932498434, Loss: 0.05501752412656202\n",
      "Iteration:860, Price of Hedge: 1.3270101475391813, Loss: 0.04577164597145043\n",
      "Iteration:870, Price of Hedge: 1.3481033133850588, Loss: 0.05010248636372694\n",
      "Iteration:880, Price of Hedge: 1.2456321149990572, Loss: 0.04810625247825158\n",
      "Iteration:890, Price of Hedge: 1.3761243060620474, Loss: 0.043880606357632246\n",
      "Iteration:900, Price of Hedge: 1.3243497062333063, Loss: 0.05568325734392659\n",
      "Iteration:910, Price of Hedge: 1.3047667479362872, Loss: 0.0376033004909985\n",
      "Iteration:920, Price of Hedge: 1.3871912371814235, Loss: 0.03954602861998069\n",
      "Iteration:930, Price of Hedge: 1.3022621093587077, Loss: 0.04648874482934034\n",
      "Iteration:940, Price of Hedge: 1.3366129536068003, Loss: 0.051731991805627334\n",
      "Iteration:950, Price of Hedge: 1.353419350019931, Loss: 0.067990941411054\n",
      "Iteration:960, Price of Hedge: 1.2355300818795059, Loss: 0.060861909391395845\n",
      "Iteration:970, Price of Hedge: 1.3896550964064092, Loss: 0.04344653426486431\n",
      "Iteration:980, Price of Hedge: 1.3088644328372767, Loss: 0.04255878044530022\n",
      "Iteration:990, Price of Hedge: 1.2437825062017056, Loss: 0.06004248213142916\n",
      "tf.Tensor(1.3813447, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_68 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 1.3123791375765224, Loss: 0.13116772481142222\n",
      "Iteration:20, Price of Hedge: 1.2274529356266386, Loss: 0.07989258061842862\n",
      "Iteration:30, Price of Hedge: 1.3456101954317548, Loss: 0.09710319322079215\n",
      "Iteration:40, Price of Hedge: 1.3180410672402332, Loss: 0.0812569231203483\n",
      "Iteration:50, Price of Hedge: 1.4069806523801391, Loss: 0.08282729964390684\n",
      "Iteration:60, Price of Hedge: 1.3082567656235142, Loss: 0.062451784114372806\n",
      "Iteration:70, Price of Hedge: 1.3007371810121642, Loss: 0.07763004658849298\n",
      "Iteration:80, Price of Hedge: 1.2852684570843396, Loss: 0.08104072854813325\n",
      "Iteration:90, Price of Hedge: 1.3608379005850566, Loss: 0.07146840984683821\n",
      "Iteration:100, Price of Hedge: 1.2800101150043703, Loss: 0.0736710663464379\n",
      "Iteration:110, Price of Hedge: 1.3833086953671, Loss: 0.06387679847538551\n",
      "Iteration:120, Price of Hedge: 1.308659256004944, Loss: 0.0860567660696205\n",
      "Iteration:130, Price of Hedge: 1.3333632232258879, Loss: 0.08481051568111866\n",
      "Iteration:140, Price of Hedge: 1.2752811730399118, Loss: 0.06146827367741282\n",
      "Iteration:150, Price of Hedge: 1.3922476026024697, Loss: 0.06943603114561796\n",
      "Iteration:160, Price of Hedge: 1.238259738364559, Loss: 0.08344139006287038\n",
      "Iteration:170, Price of Hedge: 1.3942084860009574, Loss: 0.07420001500891403\n",
      "Iteration:180, Price of Hedge: 1.1791839886180697, Loss: 0.08176785937820341\n",
      "Iteration:190, Price of Hedge: 1.4226729312790214, Loss: 0.07992387945729576\n",
      "Iteration:200, Price of Hedge: 1.3123517989522497, Loss: 0.058498221308732924\n",
      "Iteration:210, Price of Hedge: 1.2371281570468455, Loss: 0.06596225433844581\n",
      "Iteration:220, Price of Hedge: 1.4720380748307436, Loss: 0.07072803258468952\n",
      "Iteration:230, Price of Hedge: 1.3266137832039933, Loss: 0.07918554230569584\n",
      "Iteration:240, Price of Hedge: 1.2976866842843948, Loss: 0.07993549151509712\n",
      "Iteration:250, Price of Hedge: 1.2520102434718865, Loss: 0.07675278762333448\n",
      "Iteration:260, Price of Hedge: 1.3897754229266184, Loss: 0.09612868327154729\n",
      "Iteration:270, Price of Hedge: 1.318225854396269, Loss: 0.07212628549556258\n",
      "Iteration:280, Price of Hedge: 1.3135303771023246, Loss: 0.07955381940461735\n",
      "Iteration:290, Price of Hedge: 1.3199494677947996, Loss: 0.07344123674965886\n",
      "Iteration:300, Price of Hedge: 1.2669432583709068, Loss: 0.0610702463949707\n",
      "Iteration:310, Price of Hedge: 1.3540624934417793, Loss: 0.09394263338610642\n",
      "Iteration:320, Price of Hedge: 1.1702727857410764, Loss: 0.08263876371330525\n",
      "Iteration:330, Price of Hedge: 1.4796493672686666, Loss: 0.06282696444450693\n",
      "Iteration:340, Price of Hedge: 1.172016057347696, Loss: 0.09502701786062034\n",
      "Iteration:350, Price of Hedge: 1.3995796570520043, Loss: 0.0781024493297366\n",
      "Iteration:360, Price of Hedge: 1.1822818479123045, Loss: 0.07342448155602029\n",
      "Iteration:370, Price of Hedge: 1.3996158647282984, Loss: 0.07007259706819013\n",
      "Iteration:380, Price of Hedge: 1.2414505855547304, Loss: 0.07921128655785879\n",
      "Iteration:390, Price of Hedge: 1.3042966881791473, Loss: 0.08125399153292108\n",
      "Iteration:400, Price of Hedge: 1.333761599098648, Loss: 0.0750155392002398\n",
      "Iteration:410, Price of Hedge: 1.327916528082369, Loss: 0.06953758522002147\n",
      "Iteration:420, Price of Hedge: 1.3450538224260755, Loss: 0.07293575221579118\n",
      "Iteration:430, Price of Hedge: 1.3295935103826424, Loss: 0.08682504770098376\n",
      "Iteration:440, Price of Hedge: 1.3350686413527457, Loss: 0.06197283244682979\n",
      "Iteration:450, Price of Hedge: 1.3195720301994927, Loss: 0.07362681251985635\n",
      "Iteration:460, Price of Hedge: 1.3318128763591177, Loss: 0.08935623628867405\n",
      "Iteration:470, Price of Hedge: 1.210915719514037, Loss: 0.09254911787479898\n",
      "Iteration:480, Price of Hedge: 1.4667345645889327, Loss: 0.0775116458869249\n",
      "Iteration:490, Price of Hedge: 1.247665505183659, Loss: 0.058016698073271304\n",
      "Iteration:500, Price of Hedge: 1.2938897242504028, Loss: 0.0686436624947504\n",
      "Iteration:510, Price of Hedge: 1.3381522370169252, Loss: 0.07549338223628013\n",
      "Iteration:520, Price of Hedge: 1.3143659880963925, Loss: 0.04858527272093909\n",
      "Iteration:530, Price of Hedge: 1.3935230088565733, Loss: 0.06483854201856332\n",
      "Iteration:540, Price of Hedge: 1.3204966974478793, Loss: 0.06601170273222294\n",
      "Iteration:550, Price of Hedge: 1.4094183616166902, Loss: 0.07099678429056554\n",
      "Iteration:560, Price of Hedge: 1.361029453822016, Loss: 0.07342225286382416\n",
      "Iteration:570, Price of Hedge: 1.2677851782782683, Loss: 0.08843630072525742\n",
      "Iteration:580, Price of Hedge: 1.4236788829320177, Loss: 0.07834897697420047\n",
      "Iteration:590, Price of Hedge: 1.1822566122591298, Loss: 0.07826103506597946\n",
      "Iteration:600, Price of Hedge: 1.3872539605802559, Loss: 0.07470408232312878\n",
      "Iteration:610, Price of Hedge: 1.2888511883669254, Loss: 0.07583270348043812\n",
      "Iteration:620, Price of Hedge: 1.2655080263133642, Loss: 0.08009504301795829\n",
      "Iteration:630, Price of Hedge: 1.399167566150345, Loss: 0.07954371028539953\n",
      "Iteration:640, Price of Hedge: 1.3445700476400362, Loss: 0.07497142252394724\n",
      "Iteration:650, Price of Hedge: 1.2254601419275788, Loss: 0.07835968041133726\n",
      "Iteration:660, Price of Hedge: 1.3962266067867177, Loss: 0.07363983036811989\n",
      "Iteration:670, Price of Hedge: 1.269182373988997, Loss: 0.10530766065860747\n",
      "Iteration:680, Price of Hedge: 1.3968084897461495, Loss: 0.06448623721371405\n",
      "Iteration:690, Price of Hedge: 1.3417485004613583, Loss: 0.07523524824861028\n",
      "Iteration:700, Price of Hedge: 1.3502571215233958, Loss: 0.09210870543846283\n",
      "Iteration:710, Price of Hedge: 1.2955230927587764, Loss: 0.07026876769821229\n",
      "Iteration:720, Price of Hedge: 1.3319507581163181, Loss: 0.07799539209998728\n",
      "Iteration:730, Price of Hedge: 1.216775785628579, Loss: 0.07235300635245778\n",
      "Iteration:740, Price of Hedge: 1.3658309025725885, Loss: 0.06089967143763176\n",
      "Iteration:750, Price of Hedge: 1.4154708953034516, Loss: 0.0751467348808518\n",
      "Iteration:760, Price of Hedge: 1.2523677485585267, Loss: 0.09718630629592157\n",
      "Iteration:770, Price of Hedge: 1.4210539178342287, Loss: 0.0663731966064347\n",
      "Iteration:780, Price of Hedge: 1.2617574230770516, Loss: 0.09581298616466825\n",
      "Iteration:790, Price of Hedge: 1.367432543647442, Loss: 0.06705074189243874\n",
      "Iteration:800, Price of Hedge: 1.2842866438822058, Loss: 0.06869789400485615\n",
      "Iteration:810, Price of Hedge: 1.3156381027435602, Loss: 0.0725798415012605\n",
      "Iteration:820, Price of Hedge: 1.4475293181877988, Loss: 0.0820763903824826\n",
      "Iteration:830, Price of Hedge: 1.2317870676258509, Loss: 0.09079714293942374\n",
      "Iteration:840, Price of Hedge: 1.3462420925299057, Loss: 0.08026388073830333\n",
      "Iteration:850, Price of Hedge: 1.3776022375762296, Loss: 0.06655442356955206\n",
      "Iteration:860, Price of Hedge: 1.2533171942924584, Loss: 0.06071975311685521\n",
      "Iteration:870, Price of Hedge: 1.3529771774882193, Loss: 0.07670952813634813\n",
      "Iteration:880, Price of Hedge: 1.3121742350447676, Loss: 0.07797737969536628\n",
      "Iteration:890, Price of Hedge: 1.3625262206425532, Loss: 0.04687770304892283\n",
      "Iteration:900, Price of Hedge: 1.330649019006728, Loss: 0.0720186053749174\n",
      "Iteration:910, Price of Hedge: 1.3925452187295833, Loss: 0.05591060109171764\n",
      "Iteration:920, Price of Hedge: 1.237374570399402, Loss: 0.055994314199361385\n",
      "Iteration:930, Price of Hedge: 1.4210006120885739, Loss: 0.06185719189482768\n",
      "Iteration:940, Price of Hedge: 1.2997828893013548, Loss: 0.03979641933091785\n",
      "Iteration:950, Price of Hedge: 1.3069534721439824, Loss: 0.06646815032318046\n",
      "Iteration:960, Price of Hedge: 1.2498779222121585, Loss: 0.04464845367974704\n",
      "Iteration:970, Price of Hedge: 1.4311626256011778, Loss: 0.040425719145471106\n",
      "Iteration:980, Price of Hedge: 1.3139685265588925, Loss: 0.050509342696022946\n",
      "Iteration:990, Price of Hedge: 1.3219387870198718, Loss: 0.063388474871428\n",
      "tf.Tensor(0.59710526, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_69 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.3085733380017246, Loss: 0.014736862841433052\n",
      "Iteration:20, Price of Hedge: 0.5903608131123633, Loss: 0.011787795181293427\n",
      "Iteration:30, Price of Hedge: 0.6071252872538253, Loss: 0.010052370428447688\n",
      "Iteration:40, Price of Hedge: 0.4880038152003295, Loss: 0.01066424644170354\n",
      "Iteration:50, Price of Hedge: 0.5167349720737207, Loss: 0.012649845465186616\n",
      "Iteration:60, Price of Hedge: 0.5606671355108234, Loss: 0.010917037282698062\n",
      "Iteration:70, Price of Hedge: 0.5114814759706292, Loss: 0.009136385793408232\n",
      "Iteration:80, Price of Hedge: 0.5486310090159009, Loss: 0.013701059570848174\n",
      "Iteration:90, Price of Hedge: 0.5179103500503857, Loss: 0.010906937449697729\n",
      "Iteration:100, Price of Hedge: 0.5552590710320374, Loss: 0.01350024583208409\n",
      "Iteration:110, Price of Hedge: 0.5543924640726573, Loss: 0.010301232485122115\n",
      "Iteration:120, Price of Hedge: 0.5091102389074763, Loss: 0.01268723463407433\n",
      "Iteration:130, Price of Hedge: 0.5401628472891161, Loss: 0.00928491669908933\n",
      "Iteration:140, Price of Hedge: 0.5419580531385009, Loss: 0.0126447251877309\n",
      "Iteration:150, Price of Hedge: 0.5260201380720332, Loss: 0.011543375508198395\n",
      "Iteration:160, Price of Hedge: 0.5393677413470641, Loss: 0.00958756809905239\n",
      "Iteration:170, Price of Hedge: 0.5492720951834145, Loss: 0.012219852164867363\n",
      "Iteration:180, Price of Hedge: 0.5118985499994552, Loss: 0.011495639350060394\n",
      "Iteration:190, Price of Hedge: 0.555988161968321, Loss: 0.009637765104823615\n",
      "Iteration:200, Price of Hedge: 0.5196911551194262, Loss: 0.01360752878835072\n",
      "Iteration:210, Price of Hedge: 0.53324073505338, Loss: 0.012795891950528571\n",
      "Iteration:220, Price of Hedge: 0.5433968053867944, Loss: 0.010352719560799174\n",
      "Iteration:230, Price of Hedge: 0.5263412526153275, Loss: 0.010434652571983706\n",
      "Iteration:240, Price of Hedge: 0.511394111236541, Loss: 0.010612208621897247\n",
      "Iteration:250, Price of Hedge: 0.5536146847837813, Loss: 0.010215113532825627\n",
      "Iteration:260, Price of Hedge: 0.5049712260527371, Loss: 0.011619790363224247\n",
      "Iteration:270, Price of Hedge: 0.5689487271278154, Loss: 0.013447190099976681\n",
      "Iteration:280, Price of Hedge: 0.5420450978552481, Loss: 0.01219097488579024\n",
      "Iteration:290, Price of Hedge: 0.5260293271413957, Loss: 0.008964413617500179\n",
      "Iteration:300, Price of Hedge: 0.5134698351436783, Loss: 0.012494594195344889\n",
      "Iteration:310, Price of Hedge: 0.5670262000934827, Loss: 0.01118899344793043\n",
      "Iteration:320, Price of Hedge: 0.5293760227766257, Loss: 0.01073133936302444\n",
      "Iteration:330, Price of Hedge: 0.5406209292543508, Loss: 0.010101412371628805\n",
      "Iteration:340, Price of Hedge: 0.4732658280122564, Loss: 0.013584356104106377\n",
      "Iteration:350, Price of Hedge: 0.5899790324245715, Loss: 0.013554327334061256\n",
      "Iteration:360, Price of Hedge: 0.5070934439078428, Loss: 0.0106903049966121\n",
      "Iteration:370, Price of Hedge: 0.5274468668116583, Loss: 0.011541181103574516\n",
      "Iteration:380, Price of Hedge: 0.5283158967594773, Loss: 0.00962000557104794\n",
      "Iteration:390, Price of Hedge: 0.5424776241499671, Loss: 0.013592476544133803\n",
      "Iteration:400, Price of Hedge: 0.5189419030906607, Loss: 0.009562493883197121\n",
      "Iteration:410, Price of Hedge: 0.5438801687219667, Loss: 0.011607822571860816\n",
      "Iteration:420, Price of Hedge: 0.5255458266559344, Loss: 0.010627339441800566\n",
      "Iteration:430, Price of Hedge: 0.5120946291959513, Loss: 0.0133115556074074\n",
      "Iteration:440, Price of Hedge: 0.5615731503199072, Loss: 0.010236806136867928\n",
      "Iteration:450, Price of Hedge: 0.5265194565574917, Loss: 0.010306855646970804\n",
      "Iteration:460, Price of Hedge: 0.5314554497415657, Loss: 0.01032429659205434\n",
      "Iteration:470, Price of Hedge: 0.5325768819378937, Loss: 0.012445510107022884\n",
      "Iteration:480, Price of Hedge: 0.5050171713995496, Loss: 0.010509323761095857\n",
      "Iteration:490, Price of Hedge: 0.5551810782343637, Loss: 0.010044520717376139\n",
      "Iteration:500, Price of Hedge: 0.5292487015916777, Loss: 0.01114415387532297\n",
      "Iteration:510, Price of Hedge: 0.5314837941346241, Loss: 0.012244792087731327\n",
      "Iteration:520, Price of Hedge: 0.5698027162606082, Loss: 0.010544874258921767\n",
      "Iteration:530, Price of Hedge: 0.4507681974903335, Loss: 0.009777428387132048\n",
      "Iteration:540, Price of Hedge: 0.5415709235894383, Loss: 0.010027309784756433\n",
      "Iteration:550, Price of Hedge: 0.526586065881179, Loss: 0.010166170880739145\n",
      "Iteration:560, Price of Hedge: 0.5192235183507251, Loss: 0.010794976382792499\n",
      "Iteration:570, Price of Hedge: 0.5581726003378663, Loss: 0.009350639546169149\n",
      "Iteration:580, Price of Hedge: 0.49509599379441627, Loss: 0.010533715797128274\n",
      "Iteration:590, Price of Hedge: 0.5824441784143801, Loss: 0.009194789672461923\n",
      "Iteration:600, Price of Hedge: 0.48024824065838634, Loss: 0.008644360560296783\n",
      "Iteration:610, Price of Hedge: 0.5588568431296494, Loss: 0.008766669330776721\n",
      "Iteration:620, Price of Hedge: 0.5239650781417708, Loss: 0.009794437880264795\n",
      "Iteration:630, Price of Hedge: 0.5411885485837274, Loss: 0.012835181222378367\n",
      "Iteration:640, Price of Hedge: 0.544433158687184, Loss: 0.009292936419373277\n",
      "Iteration:650, Price of Hedge: 0.5289657605454864, Loss: 0.014855917864171531\n",
      "Iteration:660, Price of Hedge: 0.5388249919367581, Loss: 0.00937569876121156\n",
      "Iteration:670, Price of Hedge: 0.5373158815902116, Loss: 0.02701940126026301\n",
      "Iteration:680, Price of Hedge: 0.5123803589646855, Loss: 0.01055140246981292\n",
      "Iteration:690, Price of Hedge: 0.5571180060490406, Loss: 0.009026889860082755\n",
      "Iteration:700, Price of Hedge: 0.5360837691106667, Loss: 0.012498271537468499\n",
      "Iteration:710, Price of Hedge: 0.5460895227273455, Loss: 0.0074809403744533045\n",
      "Iteration:720, Price of Hedge: 0.5310474733485763, Loss: 0.0096232200309462\n",
      "Iteration:730, Price of Hedge: 0.5336056005388627, Loss: 0.009128603228832334\n",
      "Iteration:740, Price of Hedge: 0.5430916459937862, Loss: 0.008625163091459954\n",
      "Iteration:750, Price of Hedge: 0.5541050885004551, Loss: 0.0068572408633672316\n",
      "Iteration:760, Price of Hedge: 0.5518648299632901, Loss: 0.006606440844536366\n",
      "Iteration:770, Price of Hedge: 0.5433727126526947, Loss: 0.007233889130188232\n",
      "Iteration:780, Price of Hedge: 0.5609868328344646, Loss: 0.006188256041234475\n",
      "Iteration:790, Price of Hedge: 0.5176248488654664, Loss: 0.006020486950224502\n",
      "Iteration:800, Price of Hedge: 0.5212520168416859, Loss: 0.0087069460945159\n",
      "Iteration:810, Price of Hedge: 0.5234712456678722, Loss: 0.00630964476185909\n",
      "Iteration:820, Price of Hedge: 0.5872937669163889, Loss: 0.010829502539397497\n",
      "Iteration:830, Price of Hedge: 0.48409279184265874, Loss: 0.00806230687732814\n",
      "Iteration:840, Price of Hedge: 0.5317841532675175, Loss: 0.007130282801720789\n",
      "Iteration:850, Price of Hedge: 0.5390607990002991, Loss: 0.006047418409576544\n",
      "Iteration:860, Price of Hedge: 0.5169307312528758, Loss: 0.006076294974329244\n",
      "Iteration:870, Price of Hedge: 0.5345640524751047, Loss: 0.006938426691206524\n",
      "Iteration:880, Price of Hedge: 0.5710275140580734, Loss: 0.007113611184039571\n",
      "Iteration:890, Price of Hedge: 0.49351213654036885, Loss: 0.007228329543213086\n",
      "Iteration:900, Price of Hedge: 0.538954233225752, Loss: 0.00595388726991688\n",
      "Iteration:910, Price of Hedge: 0.4831582497734644, Loss: 0.006527769438661935\n",
      "Iteration:920, Price of Hedge: 0.5551097600840876, Loss: 0.009283043026130856\n",
      "Iteration:930, Price of Hedge: 0.5445626742767559, Loss: 0.006916359066842759\n",
      "Iteration:940, Price of Hedge: 0.4962167402392993, Loss: 0.006450916702765497\n",
      "Iteration:950, Price of Hedge: 0.5943343312850516, Loss: 0.00769274899471828\n",
      "Iteration:960, Price of Hedge: 0.5426724689938623, Loss: 0.00596825519133768\n",
      "Iteration:970, Price of Hedge: 0.4671126717301377, Loss: 0.005879758253040901\n",
      "Iteration:980, Price of Hedge: 0.5535458353387072, Loss: 0.006674758832240713\n",
      "Iteration:990, Price of Hedge: 0.5234736686563111, Loss: 0.007221760615829887\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 11 \n",
      "\n",
      "tf.Tensor(0.14600474, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_70 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.202087227783602, Loss: 0.002177473049324519\n",
      "Iteration:20, Price of Hedge: 0.08983343523455574, Loss: 0.0016247008442499046\n",
      "Iteration:30, Price of Hedge: 0.1455233967444599, Loss: 0.0013549406999859848\n",
      "Iteration:40, Price of Hedge: 0.1273214619925227, Loss: 0.0013755097551855222\n",
      "Iteration:50, Price of Hedge: 0.13030571016743125, Loss: 0.001198166634334097\n",
      "Iteration:60, Price of Hedge: 0.13511146834515558, Loss: 0.0010946927515258942\n",
      "Iteration:70, Price of Hedge: 0.14004730118136877, Loss: 0.0012111776299740475\n",
      "Iteration:80, Price of Hedge: 0.13318580349696846, Loss: 0.0011377857581720719\n",
      "Iteration:90, Price of Hedge: 0.11547285391001197, Loss: 0.0016134997532001984\n",
      "Iteration:100, Price of Hedge: 0.14032444213563622, Loss: 0.001416494936120083\n",
      "Iteration:110, Price of Hedge: 0.12972366011882172, Loss: 0.001605280068928039\n",
      "Iteration:120, Price of Hedge: 0.12344443947055198, Loss: 0.001295188599524\n",
      "Iteration:130, Price of Hedge: 0.1350661140766647, Loss: 0.0014477272536782772\n",
      "Iteration:140, Price of Hedge: 0.13068389299535285, Loss: 0.0015198001827379849\n",
      "Iteration:150, Price of Hedge: 0.1323821487742407, Loss: 0.0012472839303223184\n",
      "Iteration:160, Price of Hedge: 0.13991063307584, Loss: 0.0016930345592352403\n",
      "Iteration:170, Price of Hedge: 0.12987742795093596, Loss: 0.0015537025592351483\n",
      "Iteration:180, Price of Hedge: 0.12147760340961895, Loss: 0.001318439282594941\n",
      "Iteration:190, Price of Hedge: 0.13445930077040202, Loss: 0.0015291933114269796\n",
      "Iteration:200, Price of Hedge: 0.1397480019214754, Loss: 0.001377120116802466\n",
      "Iteration:210, Price of Hedge: 0.12472912398609425, Loss: 0.0015409132310962193\n",
      "Iteration:220, Price of Hedge: 0.12599711951437484, Loss: 0.0013101270468633076\n",
      "Iteration:230, Price of Hedge: 0.13796737129030703, Loss: 0.0016508996628620488\n",
      "Iteration:240, Price of Hedge: 0.14284363611564005, Loss: 0.0014216324710132789\n",
      "Iteration:250, Price of Hedge: 0.1369991614237506, Loss: 0.0014712478222095094\n",
      "Iteration:260, Price of Hedge: 0.13205283311692143, Loss: 0.0013051355169641178\n",
      "Iteration:270, Price of Hedge: 0.12958208475926655, Loss: 0.0011710222032737861\n",
      "Iteration:280, Price of Hedge: 0.12505851530592055, Loss: 0.0014127848554887025\n",
      "Iteration:290, Price of Hedge: 0.13871427913277332, Loss: 0.00173265097501778\n",
      "Iteration:300, Price of Hedge: 0.13396207920108624, Loss: 0.0012546491180448261\n",
      "Iteration:310, Price of Hedge: 0.12963869112344356, Loss: 0.001520203153143651\n",
      "Iteration:320, Price of Hedge: 0.1287381559649475, Loss: 0.001312571216063141\n",
      "Iteration:330, Price of Hedge: 0.13987694164235906, Loss: 0.0012498434510674452\n",
      "Iteration:340, Price of Hedge: 0.12291528832327572, Loss: 0.0012832571457252141\n",
      "Iteration:350, Price of Hedge: 0.12111407749019919, Loss: 0.0012845970307685307\n",
      "Iteration:360, Price of Hedge: 0.12002641814292475, Loss: 0.0016465137707980305\n",
      "Iteration:370, Price of Hedge: 0.11698844958803535, Loss: 0.0015504510981077858\n",
      "Iteration:380, Price of Hedge: 0.1287342755592306, Loss: 0.0015531572149602548\n",
      "Iteration:390, Price of Hedge: 0.12724980959837923, Loss: 0.001454116851062004\n",
      "Iteration:400, Price of Hedge: 0.1382869913377988, Loss: 0.001233285015408292\n",
      "Iteration:410, Price of Hedge: 0.13840462491834843, Loss: 0.0017232146106104908\n",
      "Iteration:420, Price of Hedge: 0.12336562075610119, Loss: 0.0012449905794679418\n",
      "Iteration:430, Price of Hedge: 0.12138610582077831, Loss: 0.0013317388259876497\n",
      "Iteration:440, Price of Hedge: 0.1322610563362275, Loss: 0.001357539403100816\n",
      "Iteration:450, Price of Hedge: 0.13232500196358501, Loss: 0.0015617438961693431\n",
      "Iteration:460, Price of Hedge: 0.12748005060722675, Loss: 0.001308438320506955\n",
      "Iteration:470, Price of Hedge: 0.11860829739179622, Loss: 0.0012878270429262707\n",
      "Iteration:480, Price of Hedge: 0.13933470088136915, Loss: 0.0011668962321881083\n",
      "Iteration:490, Price of Hedge: 0.13040561710348017, Loss: 0.0016682312747647644\n",
      "Iteration:500, Price of Hedge: 0.12373551313503982, Loss: 0.001228503752967214\n",
      "Iteration:510, Price of Hedge: 0.1393776879942834, Loss: 0.0011538523875356255\n",
      "Iteration:520, Price of Hedge: 0.14157003075291075, Loss: 0.0010505119274518472\n",
      "Iteration:530, Price of Hedge: 0.14504074561220934, Loss: 0.0023239328628203108\n",
      "Iteration:540, Price of Hedge: 0.14261885361622717, Loss: 0.0015967035210904257\n",
      "Iteration:550, Price of Hedge: 0.130373730761238, Loss: 0.0011979412512635346\n",
      "Iteration:560, Price of Hedge: 0.12575518324372867, Loss: 0.001114893796451355\n",
      "Iteration:570, Price of Hedge: 0.13189875182584956, Loss: 0.0013531249687071423\n",
      "Iteration:580, Price of Hedge: 0.13356676421979047, Loss: 0.001436261850522591\n",
      "Iteration:590, Price of Hedge: 0.12484164494295556, Loss: 0.001183311111751362\n",
      "Iteration:600, Price of Hedge: 0.13510243208003203, Loss: 0.0010506359768076567\n",
      "Iteration:610, Price of Hedge: 0.12619428519872714, Loss: 0.0010686589379792723\n",
      "Iteration:620, Price of Hedge: 0.12765426893409426, Loss: 0.0008080938149920059\n",
      "Iteration:630, Price of Hedge: 0.11727713447908741, Loss: 0.000721556173709459\n",
      "Iteration:640, Price of Hedge: 0.1297699547641855, Loss: 0.0011910309674755038\n",
      "Iteration:650, Price of Hedge: 0.12275719691933205, Loss: 0.0009275715847053778\n",
      "Iteration:660, Price of Hedge: 0.12379021712761187, Loss: 0.0011046943047272164\n",
      "Iteration:670, Price of Hedge: 0.12323365453493694, Loss: 0.00104398721844845\n",
      "Iteration:680, Price of Hedge: 0.12552246699000877, Loss: 0.0008861445887744957\n",
      "Iteration:690, Price of Hedge: 0.1340335694612861, Loss: 0.0010498085025819393\n",
      "Iteration:700, Price of Hedge: 0.14113800864678297, Loss: 0.0010553382833959901\n",
      "Iteration:710, Price of Hedge: 0.13477331098344508, Loss: 0.0008820596578432927\n",
      "Iteration:720, Price of Hedge: 0.11491269194378902, Loss: 0.0009694564401374173\n",
      "Iteration:730, Price of Hedge: 0.1292635672225913, Loss: 0.000924073207093068\n",
      "Iteration:740, Price of Hedge: 0.12515539574168885, Loss: 0.0008970592431905012\n",
      "Iteration:750, Price of Hedge: 0.12974705064241904, Loss: 0.0008197193254170011\n",
      "Iteration:760, Price of Hedge: 0.1261359710236775, Loss: 0.0009727768081908118\n",
      "Iteration:770, Price of Hedge: 0.1299060391875173, Loss: 0.0010550101310497163\n",
      "Iteration:780, Price of Hedge: 0.13343183635192304, Loss: 0.0009506391070869037\n",
      "Iteration:790, Price of Hedge: 0.12894678992357742, Loss: 0.000844652485931885\n",
      "Iteration:800, Price of Hedge: 0.12302423152444818, Loss: 0.00086488865987846\n",
      "Iteration:810, Price of Hedge: 0.12824574436929198, Loss: 0.0008590150199923486\n",
      "Iteration:820, Price of Hedge: 0.12532068589272854, Loss: 0.0009514165900133432\n",
      "Iteration:830, Price of Hedge: 0.12733163319525148, Loss: 0.0009821500079159051\n",
      "Iteration:840, Price of Hedge: 0.12980605658896138, Loss: 0.000936977464553479\n",
      "Iteration:850, Price of Hedge: 0.11608011038238715, Loss: 0.0009146033181151481\n",
      "Iteration:860, Price of Hedge: 0.12925419588065098, Loss: 0.000694500240760032\n",
      "Iteration:870, Price of Hedge: 0.12471166756483286, Loss: 0.0009536927141362118\n",
      "Iteration:880, Price of Hedge: 0.13325236488528278, Loss: 0.0008282640375792294\n",
      "Iteration:890, Price of Hedge: 0.1304392653012428, Loss: 0.0008720027088779059\n",
      "Iteration:900, Price of Hedge: 0.13119211805497458, Loss: 0.000890351457942451\n",
      "Iteration:910, Price of Hedge: 0.12506621126377696, Loss: 0.0008150353433420854\n",
      "Iteration:920, Price of Hedge: 0.13084040629557878, Loss: 0.0009802733075186866\n",
      "Iteration:930, Price of Hedge: 0.11949137612903088, Loss: 0.0010206577484142888\n",
      "Iteration:940, Price of Hedge: 0.12560316645820535, Loss: 0.0012841483757464634\n",
      "Iteration:950, Price of Hedge: 0.1380670188120462, Loss: 0.0008232273297322124\n",
      "Iteration:960, Price of Hedge: 0.1421156438999276, Loss: 0.0007660526523049605\n",
      "Iteration:970, Price of Hedge: 0.12249205387689131, Loss: 0.0009656830259343164\n",
      "Iteration:980, Price of Hedge: 0.11890531596754955, Loss: 0.000974588739455351\n",
      "Iteration:990, Price of Hedge: 0.13200490632319203, Loss: 0.0008343513227139443\n",
      "tf.Tensor(0.12782086, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_71 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.13112925332057443, Loss: 0.0013460226575296554\n",
      "Iteration:20, Price of Hedge: 0.08383193381828563, Loss: 0.0017335097782503084\n",
      "Iteration:30, Price of Hedge: 0.09901616135381915, Loss: 0.0010608847842729751\n",
      "Iteration:40, Price of Hedge: 0.13032562021570585, Loss: 0.0012149116929179194\n",
      "Iteration:50, Price of Hedge: 0.11023554921906112, Loss: 0.0011839702031210654\n",
      "Iteration:60, Price of Hedge: 0.11619564703059951, Loss: 0.0011794447238649753\n",
      "Iteration:70, Price of Hedge: 0.10748159609764799, Loss: 0.0009680197813965119\n",
      "Iteration:80, Price of Hedge: 0.10781309515874114, Loss: 0.0012196803730894158\n",
      "Iteration:90, Price of Hedge: 0.10564367813973946, Loss: 0.0011478139114735166\n",
      "Iteration:100, Price of Hedge: 0.09967362530406376, Loss: 0.0009733997572022535\n",
      "Iteration:110, Price of Hedge: 0.12234750606170337, Loss: 0.0010203714806701126\n",
      "Iteration:120, Price of Hedge: 0.13324188022359637, Loss: 0.0010522074938339454\n",
      "Iteration:130, Price of Hedge: 0.12882454093009985, Loss: 0.0010071218441319197\n",
      "Iteration:140, Price of Hedge: 0.11719855356108724, Loss: 0.0011505623351518947\n",
      "Iteration:150, Price of Hedge: 0.10001516586073081, Loss: 0.0011328188861434718\n",
      "Iteration:160, Price of Hedge: 0.09494872872847965, Loss: 0.001046764606680295\n",
      "Iteration:170, Price of Hedge: 0.0898009706145814, Loss: 0.0008688538481367303\n",
      "Iteration:180, Price of Hedge: 0.10617985509123856, Loss: 0.0011321914615596285\n",
      "Iteration:190, Price of Hedge: 0.09842702064740934, Loss: 0.0009690124295772762\n",
      "Iteration:200, Price of Hedge: 0.09315478149607657, Loss: 0.001339665740268936\n",
      "Iteration:210, Price of Hedge: 0.09342901484828872, Loss: 0.0011082700337417873\n",
      "Iteration:220, Price of Hedge: 0.09472703758292483, Loss: 0.001129675092088034\n",
      "Iteration:230, Price of Hedge: 0.10147847874640661, Loss: 0.0011606840532499608\n",
      "Iteration:240, Price of Hedge: 0.11960247030718847, Loss: 0.000986081756048307\n",
      "Iteration:250, Price of Hedge: 0.11576908343390642, Loss: 0.0010859956165677255\n",
      "Iteration:260, Price of Hedge: 0.11328818549138192, Loss: 0.0010481147095398491\n",
      "Iteration:270, Price of Hedge: 0.10695875736524273, Loss: 0.001019781380671203\n",
      "Iteration:280, Price of Hedge: 0.09561593152427009, Loss: 0.001035863294536732\n",
      "Iteration:290, Price of Hedge: 0.10771332873877669, Loss: 0.001104781282832379\n",
      "Iteration:300, Price of Hedge: 0.12305226988776213, Loss: 0.0011198086505063822\n",
      "Iteration:310, Price of Hedge: 0.10934331531847762, Loss: 0.0012104356138477714\n",
      "Iteration:320, Price of Hedge: 0.10968784994863655, Loss: 0.0009287012022905828\n",
      "Iteration:330, Price of Hedge: 0.1082344704692389, Loss: 0.0009295840722803651\n",
      "Iteration:340, Price of Hedge: 0.11694407893213567, Loss: 0.0009721293701983048\n",
      "Iteration:350, Price of Hedge: 0.11832026103651856, Loss: 0.0011105876202429422\n",
      "Iteration:360, Price of Hedge: 0.1084968031899905, Loss: 0.0011425772384293877\n",
      "Iteration:370, Price of Hedge: 0.12259345244522138, Loss: 0.0012187622051889947\n",
      "Iteration:380, Price of Hedge: 0.1156229358971416, Loss: 0.0011297766791370735\n",
      "Iteration:390, Price of Hedge: 0.12559932928820672, Loss: 0.001062329634155823\n",
      "Iteration:400, Price of Hedge: 0.11632345181387792, Loss: 0.0010160133709328889\n",
      "Iteration:410, Price of Hedge: 0.10950627074072941, Loss: 0.0010309279204044675\n",
      "Iteration:420, Price of Hedge: 0.09867656640447536, Loss: 0.0011084082698176623\n",
      "Iteration:430, Price of Hedge: 0.09751058555351051, Loss: 0.0009464753891924804\n",
      "Iteration:440, Price of Hedge: 0.09698023461505159, Loss: 0.0010252204678105504\n",
      "Iteration:450, Price of Hedge: 0.10828622362403735, Loss: 0.0011442346357789291\n",
      "Iteration:460, Price of Hedge: 0.12087679986819923, Loss: 0.0009414114056872426\n",
      "Iteration:470, Price of Hedge: 0.11736815647502681, Loss: 0.0008486785588637691\n",
      "Iteration:480, Price of Hedge: 0.12048374395318434, Loss: 0.0010973042057998317\n",
      "Iteration:490, Price of Hedge: 0.1232885638971709, Loss: 0.0012374326043531171\n",
      "Iteration:500, Price of Hedge: 0.11299756580193616, Loss: 0.0008767164155091489\n",
      "Iteration:510, Price of Hedge: 0.10146703208998815, Loss: 0.0012100233545182526\n",
      "Iteration:520, Price of Hedge: 0.08778992062722751, Loss: 0.0008601475931442337\n",
      "Iteration:530, Price of Hedge: 0.09702584829785224, Loss: 0.0009941181107415264\n",
      "Iteration:540, Price of Hedge: 0.1119125005977594, Loss: 0.0011588672241892085\n",
      "Iteration:550, Price of Hedge: 0.10993682283243517, Loss: 0.0010209232427469406\n",
      "Iteration:560, Price of Hedge: 0.126640931786568, Loss: 0.0010268512650599693\n",
      "Iteration:570, Price of Hedge: 0.13270723814009672, Loss: 0.0009061079216940994\n",
      "Iteration:580, Price of Hedge: 0.12535943590524995, Loss: 0.0008601810332701022\n",
      "Iteration:590, Price of Hedge: 0.11271934395471135, Loss: 0.0008610814677704415\n",
      "Iteration:600, Price of Hedge: 0.10391758936719953, Loss: 0.0007412013187647394\n",
      "Iteration:610, Price of Hedge: 0.0927621687471742, Loss: 0.0006928291633589989\n",
      "Iteration:620, Price of Hedge: 0.11007981416176449, Loss: 0.0009685349788912668\n",
      "Iteration:630, Price of Hedge: 0.11790741397145439, Loss: 0.0005853259142731826\n",
      "Iteration:640, Price of Hedge: 0.10852023694930608, Loss: 0.000994335471559671\n",
      "Iteration:650, Price of Hedge: 0.11379448656153955, Loss: 0.0008132391188033328\n",
      "Iteration:660, Price of Hedge: 0.11238651539528065, Loss: 0.0008776148233351933\n",
      "Iteration:670, Price of Hedge: 0.13147460942938097, Loss: 0.0008474410208723527\n",
      "Iteration:680, Price of Hedge: 0.11950900549316544, Loss: 0.0005081249925784182\n",
      "Iteration:690, Price of Hedge: 0.11910530278252054, Loss: 0.0007943231542704599\n",
      "Iteration:700, Price of Hedge: 0.11795404369363496, Loss: 0.000550367429356391\n",
      "Iteration:710, Price of Hedge: 0.11631871750272467, Loss: 0.0005992265354838989\n",
      "Iteration:720, Price of Hedge: 0.10443419134724082, Loss: 0.0008167968610835353\n",
      "Iteration:730, Price of Hedge: 0.09609812868147856, Loss: 0.0005839661002659647\n",
      "Iteration:740, Price of Hedge: 0.10446495356080732, Loss: 0.0006685105496017085\n",
      "Iteration:750, Price of Hedge: 0.11306016031309696, Loss: 0.0006110564866784074\n",
      "Iteration:760, Price of Hedge: 0.1082393020607583, Loss: 0.0005869129691357333\n",
      "Iteration:770, Price of Hedge: 0.09668684783963499, Loss: 0.0006709118630846778\n",
      "Iteration:780, Price of Hedge: 0.10567735876429084, Loss: 0.0007953651181924038\n",
      "Iteration:790, Price of Hedge: 0.10295461102255672, Loss: 0.0006011683850152272\n",
      "Iteration:800, Price of Hedge: 0.11614964422633421, Loss: 0.0008949516708131711\n",
      "Iteration:810, Price of Hedge: 0.11357119569440784, Loss: 0.000728221989910649\n",
      "Iteration:820, Price of Hedge: 0.10158920542095871, Loss: 0.0006469416684166118\n",
      "Iteration:830, Price of Hedge: 0.11153490145203478, Loss: 0.0006381440019689322\n",
      "Iteration:840, Price of Hedge: 0.10166400321360812, Loss: 0.0006121459930015227\n",
      "Iteration:850, Price of Hedge: 0.10289578882781712, Loss: 0.0006034873648549599\n",
      "Iteration:860, Price of Hedge: 0.10075228081300339, Loss: 0.00072553132644968\n",
      "Iteration:870, Price of Hedge: 0.09930865098808113, Loss: 0.0006101618788666663\n",
      "Iteration:880, Price of Hedge: 0.09924809936460975, Loss: 0.000699355603480023\n",
      "Iteration:890, Price of Hedge: 0.10867660973344756, Loss: 0.0006072460434470406\n",
      "Iteration:900, Price of Hedge: 0.12358384223526288, Loss: 0.0009334697135725546\n",
      "Iteration:910, Price of Hedge: 0.11939025859286972, Loss: 0.0007045644519749761\n",
      "Iteration:920, Price of Hedge: 0.1168702863699366, Loss: 0.0006275988778327246\n",
      "Iteration:930, Price of Hedge: 0.1223601957450228, Loss: 0.0006887085545157269\n",
      "Iteration:940, Price of Hedge: 0.11073119268465917, Loss: 0.000552017522233994\n",
      "Iteration:950, Price of Hedge: 0.0975225942742668, Loss: 0.0005984818171252293\n",
      "Iteration:960, Price of Hedge: 0.10821163120104985, Loss: 0.0005361471847203925\n",
      "Iteration:970, Price of Hedge: 0.10594455550335057, Loss: 0.0006400110756632493\n",
      "Iteration:980, Price of Hedge: 0.09590063872923907, Loss: 0.0007067277578954201\n",
      "Iteration:990, Price of Hedge: 0.09860423304776873, Loss: 0.0007491410686498945\n",
      "tf.Tensor(0.1233394, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_72 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.08825674208211752, Loss: 0.0017138192863576764\n",
      "Iteration:20, Price of Hedge: 0.16918858605115475, Loss: 0.0020603018882932034\n",
      "Iteration:30, Price of Hedge: 0.10335710313308938, Loss: 0.001356538817112396\n",
      "Iteration:40, Price of Hedge: 0.15041446980330875, Loss: 0.001711997306166424\n",
      "Iteration:50, Price of Hedge: 0.11838702779449478, Loss: 0.0015783136474266436\n",
      "Iteration:60, Price of Hedge: 0.13182171658477843, Loss: 0.0011076750359466647\n",
      "Iteration:70, Price of Hedge: 0.12919688693605166, Loss: 0.0013356091827778638\n",
      "Iteration:80, Price of Hedge: 0.1280250260273988, Loss: 0.001647233746841348\n",
      "Iteration:90, Price of Hedge: 0.13392339404214226, Loss: 0.0012922643618505259\n",
      "Iteration:100, Price of Hedge: 0.12054574397321859, Loss: 0.001261917194290696\n",
      "Iteration:110, Price of Hedge: 0.1348581394627388, Loss: 0.0012355358061024724\n",
      "Iteration:120, Price of Hedge: 0.1261957011685013, Loss: 0.001572100032927537\n",
      "Iteration:130, Price of Hedge: 0.13259077192394103, Loss: 0.001182809172084287\n",
      "Iteration:140, Price of Hedge: 0.12383615507829973, Loss: 0.0015345077580971812\n",
      "Iteration:150, Price of Hedge: 0.13056501638790224, Loss: 0.0013311252503448224\n",
      "Iteration:160, Price of Hedge: 0.12393479736958853, Loss: 0.0013352188790865416\n",
      "Iteration:170, Price of Hedge: 0.13052387760194506, Loss: 0.0009658288620387978\n",
      "Iteration:180, Price of Hedge: 0.1299436866892222, Loss: 0.0013763992118667634\n",
      "Iteration:190, Price of Hedge: 0.12667632022199202, Loss: 0.0011933426428432981\n",
      "Iteration:200, Price of Hedge: 0.11690996595040133, Loss: 0.0011203360924916695\n",
      "Iteration:210, Price of Hedge: 0.15014547878193982, Loss: 0.0013599258965280026\n",
      "Iteration:220, Price of Hedge: 0.12537110954918945, Loss: 0.001149461259896345\n",
      "Iteration:230, Price of Hedge: 0.1181353742961619, Loss: 0.0013106583733076605\n",
      "Iteration:240, Price of Hedge: 0.1394520426208203, Loss: 0.001107646071393198\n",
      "Iteration:250, Price of Hedge: 0.12385668123556003, Loss: 0.0013040124860703717\n",
      "Iteration:260, Price of Hedge: 0.1237525588169774, Loss: 0.0012761078832598917\n",
      "Iteration:270, Price of Hedge: 0.1421602091165596, Loss: 0.0014718186688026159\n",
      "Iteration:280, Price of Hedge: 0.1315611132927586, Loss: 0.0014335893426855153\n",
      "Iteration:290, Price of Hedge: 0.134776456381951, Loss: 0.001380974851311656\n",
      "Iteration:300, Price of Hedge: 0.1302292045639092, Loss: 0.0016227763481172276\n",
      "Iteration:310, Price of Hedge: 0.12123432683170564, Loss: 0.0014070360249612613\n",
      "Iteration:320, Price of Hedge: 0.1319429387299465, Loss: 0.001429885426521782\n",
      "Iteration:330, Price of Hedge: 0.13398825842851353, Loss: 0.0013394982018605452\n",
      "Iteration:340, Price of Hedge: 0.1459770691365236, Loss: 0.0014516757218736133\n",
      "Iteration:350, Price of Hedge: 0.12966813464760207, Loss: 0.0013629127922150986\n",
      "Iteration:360, Price of Hedge: 0.130249363217564, Loss: 0.0015798944533767846\n",
      "Iteration:370, Price of Hedge: 0.13172407952393997, Loss: 0.0014059884032402437\n",
      "Iteration:380, Price of Hedge: 0.13603451850395346, Loss: 0.0013370580860093018\n",
      "Iteration:390, Price of Hedge: 0.13432521599904135, Loss: 0.0012486478821228887\n",
      "Iteration:400, Price of Hedge: 0.12261664840808635, Loss: 0.001414550848802554\n",
      "Iteration:410, Price of Hedge: 0.1260640375973651, Loss: 0.0013792531914980088\n",
      "Iteration:420, Price of Hedge: 0.12512397418341833, Loss: 0.0011731508868416897\n",
      "Iteration:430, Price of Hedge: 0.1373147929762297, Loss: 0.001346028906442065\n",
      "Iteration:440, Price of Hedge: 0.13762000472059982, Loss: 0.0015262416292057602\n",
      "Iteration:450, Price of Hedge: 0.12322201331778616, Loss: 0.00142509960406354\n",
      "Iteration:460, Price of Hedge: 0.1283710847166276, Loss: 0.001496399863548259\n",
      "Iteration:470, Price of Hedge: 0.13089326196119375, Loss: 0.0011856796184441798\n",
      "Iteration:480, Price of Hedge: 0.12688698625938175, Loss: 0.0015499299050349081\n",
      "Iteration:490, Price of Hedge: 0.11844613102140329, Loss: 0.0016098061392974651\n",
      "Iteration:500, Price of Hedge: 0.12748283931105675, Loss: 0.0014793904928584569\n",
      "Iteration:510, Price of Hedge: 0.12718977680352736, Loss: 0.0012954054536735704\n",
      "Iteration:520, Price of Hedge: 0.12634973922385484, Loss: 0.0011478948940005563\n",
      "Iteration:530, Price of Hedge: 0.1286194090646518, Loss: 0.001156695473792535\n",
      "Iteration:540, Price of Hedge: 0.119800846591653, Loss: 0.00185765252996708\n",
      "Iteration:550, Price of Hedge: 0.12532706316117698, Loss: 0.0013458706569575265\n",
      "Iteration:560, Price of Hedge: 0.12581534574573539, Loss: 0.0012524960299406197\n",
      "Iteration:570, Price of Hedge: 0.1260847583153577, Loss: 0.0012242238390798744\n",
      "Iteration:580, Price of Hedge: 0.1258272679950551, Loss: 0.0012474100907971853\n",
      "Iteration:590, Price of Hedge: 0.13125993327911942, Loss: 0.00169947837015636\n",
      "Iteration:600, Price of Hedge: 0.12889463683838473, Loss: 0.0013947439920274807\n",
      "Iteration:610, Price of Hedge: 0.12659803114509033, Loss: 0.0013426163247082458\n",
      "Iteration:620, Price of Hedge: 0.12518693619818463, Loss: 0.001342017780233107\n",
      "Iteration:630, Price of Hedge: 0.13837484631737312, Loss: 0.0009021723735473942\n",
      "Iteration:640, Price of Hedge: 0.13610489544440726, Loss: 0.0012576016447136684\n",
      "Iteration:650, Price of Hedge: 0.12856589405433283, Loss: 0.00119723351971075\n",
      "Iteration:660, Price of Hedge: 0.12141501970738773, Loss: 0.0007519839015725172\n",
      "Iteration:670, Price of Hedge: 0.13204566679661411, Loss: 0.0009111506251192393\n",
      "Iteration:680, Price of Hedge: 0.1413628019551254, Loss: 0.0008592360119352715\n",
      "Iteration:690, Price of Hedge: 0.12122941957767921, Loss: 0.0009366045564831893\n",
      "Iteration:700, Price of Hedge: 0.12901153541172336, Loss: 0.001088200131532169\n",
      "Iteration:710, Price of Hedge: 0.12965144566034043, Loss: 0.0008920796200027948\n",
      "Iteration:720, Price of Hedge: 0.12287636536788114, Loss: 0.0009357859489575127\n",
      "Iteration:730, Price of Hedge: 0.12907700509815073, Loss: 0.0010634671051039215\n",
      "Iteration:740, Price of Hedge: 0.1285924083585769, Loss: 0.0009346836070305288\n",
      "Iteration:750, Price of Hedge: 0.14010334548120795, Loss: 0.0008014171054164798\n",
      "Iteration:760, Price of Hedge: 0.13600388599754185, Loss: 0.0009242637989215652\n",
      "Iteration:770, Price of Hedge: 0.12179361327463313, Loss: 0.0008534322923123395\n",
      "Iteration:780, Price of Hedge: 0.12075802054111479, Loss: 0.0007281030916853394\n",
      "Iteration:790, Price of Hedge: 0.12533871518725734, Loss: 0.0009335159048575293\n",
      "Iteration:800, Price of Hedge: 0.1278276117376663, Loss: 0.0009288242383092449\n",
      "Iteration:810, Price of Hedge: 0.11996795264286107, Loss: 0.0009995718068247506\n",
      "Iteration:820, Price of Hedge: 0.11832803265688199, Loss: 0.0008371187464638386\n",
      "Iteration:830, Price of Hedge: 0.1124169317231008, Loss: 0.0008611953837547759\n",
      "Iteration:840, Price of Hedge: 0.1037101227729636, Loss: 0.0007616213289588281\n",
      "Iteration:850, Price of Hedge: 0.11577729822038237, Loss: 0.0011463202525180628\n",
      "Iteration:860, Price of Hedge: 0.13426589659354135, Loss: 0.0009905314039078573\n",
      "Iteration:870, Price of Hedge: 0.12662403742964443, Loss: 0.000814817982523941\n",
      "Iteration:880, Price of Hedge: 0.12684051867114476, Loss: 0.0008722046163045505\n",
      "Iteration:890, Price of Hedge: 0.1324766512455028, Loss: 0.0006891306516600527\n",
      "Iteration:900, Price of Hedge: 0.12872331530464295, Loss: 0.0009787096438552913\n",
      "Iteration:910, Price of Hedge: 0.13814294073337124, Loss: 0.0008655093288813198\n",
      "Iteration:920, Price of Hedge: 0.1255422257132693, Loss: 0.0008096820520812287\n",
      "Iteration:930, Price of Hedge: 0.1380967109415849, Loss: 0.000758575490827651\n",
      "Iteration:940, Price of Hedge: 0.13478017465372433, Loss: 0.000929949295877286\n",
      "Iteration:950, Price of Hedge: 0.12191584065025154, Loss: 0.0007804093596768258\n",
      "Iteration:960, Price of Hedge: 0.1293636038657951, Loss: 0.0009129825697924422\n",
      "Iteration:970, Price of Hedge: 0.12083426673032706, Loss: 0.0007771166050607015\n",
      "Iteration:980, Price of Hedge: 0.12558340773494478, Loss: 0.0010643095260525648\n",
      "Iteration:990, Price of Hedge: 0.1413397789351336, Loss: 0.000851680063494742\n",
      "tf.Tensor(0.16047032, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_73 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.17828447323022376, Loss: 0.0023940316422271127\n",
      "Iteration:20, Price of Hedge: 0.14792301153659082, Loss: 0.0021934250027008774\n",
      "Iteration:30, Price of Hedge: 0.13430674353840005, Loss: 0.002101254557994281\n",
      "Iteration:40, Price of Hedge: 0.15077939007464353, Loss: 0.0018170006525092932\n",
      "Iteration:50, Price of Hedge: 0.16615083367485683, Loss: 0.0020070537234230914\n",
      "Iteration:60, Price of Hedge: 0.14711289307397807, Loss: 0.0018086774389585614\n",
      "Iteration:70, Price of Hedge: 0.15366960056226164, Loss: 0.0015548584391414267\n",
      "Iteration:80, Price of Hedge: 0.1652941719615001, Loss: 0.0017806137422159197\n",
      "Iteration:90, Price of Hedge: 0.16122626374325932, Loss: 0.0022681106527059573\n",
      "Iteration:100, Price of Hedge: 0.15645122454338323, Loss: 0.001919094370122565\n",
      "Iteration:110, Price of Hedge: 0.16532503145543276, Loss: 0.0023246435499397755\n",
      "Iteration:120, Price of Hedge: 0.1492826127430078, Loss: 0.0020068865227937495\n",
      "Iteration:130, Price of Hedge: 0.1510546394662356, Loss: 0.0017492487619361619\n",
      "Iteration:140, Price of Hedge: 0.1617326837116423, Loss: 0.0016623446303852597\n",
      "Iteration:150, Price of Hedge: 0.16663432790361413, Loss: 0.0023594324275515\n",
      "Iteration:160, Price of Hedge: 0.13473514465312064, Loss: 0.0017300228851256706\n",
      "Iteration:170, Price of Hedge: 0.1414658759075394, Loss: 0.0017916895172383819\n",
      "Iteration:180, Price of Hedge: 0.14104298734690135, Loss: 0.00203269571327267\n",
      "Iteration:190, Price of Hedge: 0.14531330358033756, Loss: 0.0017518508428414849\n",
      "Iteration:200, Price of Hedge: 0.15918591615229616, Loss: 0.0018705349162340568\n",
      "Iteration:210, Price of Hedge: 0.1691364545838212, Loss: 0.0022935413617602763\n",
      "Iteration:220, Price of Hedge: 0.17648907760125782, Loss: 0.0021583049327314366\n",
      "Iteration:230, Price of Hedge: 0.1583600706971538, Loss: 0.001924145686913459\n",
      "Iteration:240, Price of Hedge: 0.1457035167468746, Loss: 0.0017990132425826034\n",
      "Iteration:250, Price of Hedge: 0.14595657540605203, Loss: 0.0019398046169646578\n",
      "Iteration:260, Price of Hedge: 0.15986828387627838, Loss: 0.0017513789655097868\n",
      "Iteration:270, Price of Hedge: 0.16197526851806288, Loss: 0.001999706691324477\n",
      "Iteration:280, Price of Hedge: 0.14937531012303112, Loss: 0.0019092921910050188\n",
      "Iteration:290, Price of Hedge: 0.1506812125673264, Loss: 0.001909947989028993\n",
      "Iteration:300, Price of Hedge: 0.1409672707952382, Loss: 0.0018653883457512956\n",
      "Iteration:310, Price of Hedge: 0.1519722311155988, Loss: 0.001848925501563059\n",
      "Iteration:320, Price of Hedge: 0.16289401672289047, Loss: 0.0022249901170672717\n",
      "Iteration:330, Price of Hedge: 0.14317033601200252, Loss: 0.002178366474909588\n",
      "Iteration:340, Price of Hedge: 0.13680112021610286, Loss: 0.0020506392119229665\n",
      "Iteration:350, Price of Hedge: 0.13398529678181034, Loss: 0.0016851119516368307\n",
      "Iteration:360, Price of Hedge: 0.14583004607646333, Loss: 0.001854207859223589\n",
      "Iteration:370, Price of Hedge: 0.15647087517734803, Loss: 0.0017957046967959302\n",
      "Iteration:380, Price of Hedge: 0.15279083458792686, Loss: 0.0016499793838425703\n",
      "Iteration:390, Price of Hedge: 0.15165735618818987, Loss: 0.0021336360843225324\n",
      "Iteration:400, Price of Hedge: 0.1677533547645112, Loss: 0.0017954608203224255\n",
      "Iteration:410, Price of Hedge: 0.16799984159450787, Loss: 0.0017662949505423244\n",
      "Iteration:420, Price of Hedge: 0.1591528840635192, Loss: 0.00196926908342423\n",
      "Iteration:430, Price of Hedge: 0.14901446481814562, Loss: 0.0016674435740220872\n",
      "Iteration:440, Price of Hedge: 0.15145269991564306, Loss: 0.0017843619074350949\n",
      "Iteration:450, Price of Hedge: 0.12951700419430381, Loss: 0.0017399083267788384\n",
      "Iteration:460, Price of Hedge: 0.13805289154109346, Loss: 0.001839731155844504\n",
      "Iteration:470, Price of Hedge: 0.1556764728983353, Loss: 0.0019063421976790453\n",
      "Iteration:480, Price of Hedge: 0.1510711879374128, Loss: 0.002087096549148093\n",
      "Iteration:490, Price of Hedge: 0.1582170253231766, Loss: 0.001546867937954133\n",
      "Iteration:500, Price of Hedge: 0.15570694327080334, Loss: 0.001638436291505574\n",
      "Iteration:510, Price of Hedge: 0.1457862699116902, Loss: 0.0016910067027135157\n",
      "Iteration:520, Price of Hedge: 0.15047617798224452, Loss: 0.0017948038400717793\n",
      "Iteration:530, Price of Hedge: 0.13524722850060017, Loss: 0.001641826410932623\n",
      "Iteration:540, Price of Hedge: 0.15540805475023378, Loss: 0.001553229161897729\n",
      "Iteration:550, Price of Hedge: 0.15843955956523814, Loss: 0.0014415850794480712\n",
      "Iteration:560, Price of Hedge: 0.15778288466685242, Loss: 0.001319393339519337\n",
      "Iteration:570, Price of Hedge: 0.15094802018492148, Loss: 0.0014411229977087992\n",
      "Iteration:580, Price of Hedge: 0.15331205198089606, Loss: 0.0011573782941404433\n",
      "Iteration:590, Price of Hedge: 0.1441221487323958, Loss: 0.0015722344689891089\n",
      "Iteration:600, Price of Hedge: 0.13489736506816144, Loss: 0.0010734468715565715\n",
      "Iteration:610, Price of Hedge: 0.14489134458764286, Loss: 0.0014350532770846414\n",
      "Iteration:620, Price of Hedge: 0.12953047212055255, Loss: 0.0013645218027158457\n",
      "Iteration:630, Price of Hedge: 0.12346808940845905, Loss: 0.0010761529039642781\n",
      "Iteration:640, Price of Hedge: 0.14668840479176312, Loss: 0.0010638286131313013\n",
      "Iteration:650, Price of Hedge: 0.14056325462563565, Loss: 0.0012559504962765368\n",
      "Iteration:660, Price of Hedge: 0.14824825222746085, Loss: 0.0013261207159522394\n",
      "Iteration:670, Price of Hedge: 0.1614999566489928, Loss: 0.0012993583974413082\n",
      "Iteration:680, Price of Hedge: 0.16035807971097712, Loss: 0.0009941345774701737\n",
      "Iteration:690, Price of Hedge: 0.15263886103812185, Loss: 0.001167540714613935\n",
      "Iteration:700, Price of Hedge: 0.1555244993485303, Loss: 0.0012324909813084429\n",
      "Iteration:710, Price of Hedge: 0.14101761878919206, Loss: 0.001419834979803092\n",
      "Iteration:720, Price of Hedge: 0.13679358639219005, Loss: 0.0011319560295623534\n",
      "Iteration:730, Price of Hedge: 0.14814133029611867, Loss: 0.0014790717983255597\n",
      "Iteration:740, Price of Hedge: 0.15903803918679957, Loss: 0.001311587012358606\n",
      "Iteration:750, Price of Hedge: 0.13471205677955142, Loss: 0.0012987238794974322\n",
      "Iteration:760, Price of Hedge: 0.13400016986890365, Loss: 0.0010699517872899912\n",
      "Iteration:770, Price of Hedge: 0.13436540359919605, Loss: 0.0012773536123932506\n",
      "Iteration:780, Price of Hedge: 0.14570657567394393, Loss: 0.001689444981279653\n",
      "Iteration:790, Price of Hedge: 0.13773855706016322, Loss: 0.0013632904291920767\n",
      "Iteration:800, Price of Hedge: 0.16353163547843794, Loss: 0.0014524159646598811\n",
      "Iteration:810, Price of Hedge: 0.1687422637312011, Loss: 0.0014302378989595967\n",
      "Iteration:820, Price of Hedge: 0.15874422005420002, Loss: 0.0008913525505994447\n",
      "Iteration:830, Price of Hedge: 0.1632483874789614, Loss: 0.0013357518099813782\n",
      "Iteration:840, Price of Hedge: 0.17107330667411702, Loss: 0.0011399051528161231\n",
      "Iteration:850, Price of Hedge: 0.17680920566843952, Loss: 0.0014371691250486764\n",
      "Iteration:860, Price of Hedge: 0.15515326666232454, Loss: 0.0010559592057331369\n",
      "Iteration:870, Price of Hedge: 0.15444109871950787, Loss: 0.0012157101181454078\n",
      "Iteration:880, Price of Hedge: 0.14934970376887124, Loss: 0.0012489447054623516\n",
      "Iteration:890, Price of Hedge: 0.14352659833074882, Loss: 0.0011073625058814153\n",
      "Iteration:900, Price of Hedge: 0.1501096363714737, Loss: 0.0010877781610549864\n",
      "Iteration:910, Price of Hedge: 0.14793195052134822, Loss: 0.0013277314153482323\n",
      "Iteration:920, Price of Hedge: 0.1686545276498521, Loss: 0.0012110856696279093\n",
      "Iteration:930, Price of Hedge: 0.1512733797740168, Loss: 0.0014129797540000768\n",
      "Iteration:940, Price of Hedge: 0.15114621271758324, Loss: 0.0013586823629584634\n",
      "Iteration:950, Price of Hedge: 0.14802537209965294, Loss: 0.0018401148728443674\n",
      "Iteration:960, Price of Hedge: 0.15378642347309324, Loss: 0.0014553796380373464\n",
      "Iteration:970, Price of Hedge: 0.15603658319600983, Loss: 0.0010423180832769498\n",
      "Iteration:980, Price of Hedge: 0.16524322947641965, Loss: 0.0011259897537720055\n",
      "Iteration:990, Price of Hedge: 0.14693797216668827, Loss: 0.0011952627478483359\n",
      "tf.Tensor(0.1159416, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_74 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.07962141798771541, Loss: 0.002254864647292543\n",
      "Iteration:20, Price of Hedge: 0.1568151503931972, Loss: 0.0015542730680492057\n",
      "Iteration:30, Price of Hedge: 0.11063918707612858, Loss: 0.0023186582740779118\n",
      "Iteration:40, Price of Hedge: 0.12518485007477695, Loss: 0.0015061659003075434\n",
      "Iteration:50, Price of Hedge: 0.13779051558462357, Loss: 0.0012288241363953567\n",
      "Iteration:60, Price of Hedge: 0.1171846857044443, Loss: 0.0014039105554192412\n",
      "Iteration:70, Price of Hedge: 0.12479848488716812, Loss: 0.001197517169667295\n",
      "Iteration:80, Price of Hedge: 0.14915968278696712, Loss: 0.0013250813698179266\n",
      "Iteration:90, Price of Hedge: 0.12941043895763757, Loss: 0.001142584247344658\n",
      "Iteration:100, Price of Hedge: 0.12204142960296736, Loss: 0.001344786892878247\n",
      "Iteration:110, Price of Hedge: 0.14060135610238264, Loss: 0.0014674272033842863\n",
      "Iteration:120, Price of Hedge: 0.1358532743728631, Loss: 0.0016658803325825034\n",
      "Iteration:130, Price of Hedge: 0.13809598674330348, Loss: 0.001543981615978929\n",
      "Iteration:140, Price of Hedge: 0.12063363137958164, Loss: 0.001407385119608584\n",
      "Iteration:150, Price of Hedge: 0.1289813568803538, Loss: 0.0014418336848282644\n",
      "Iteration:160, Price of Hedge: 0.14987488803899396, Loss: 0.0017327957133403517\n",
      "Iteration:170, Price of Hedge: 0.12239099038537803, Loss: 0.0012884195073785245\n",
      "Iteration:180, Price of Hedge: 0.12354254131536209, Loss: 0.0012010429918273503\n",
      "Iteration:190, Price of Hedge: 0.12173435872271057, Loss: 0.0010705991408377358\n",
      "Iteration:200, Price of Hedge: 0.13603726397206517, Loss: 0.0015427308201598324\n",
      "Iteration:210, Price of Hedge: 0.13372109411624253, Loss: 0.0014185774284030117\n",
      "Iteration:220, Price of Hedge: 0.1528073614412449, Loss: 0.0015795142830569377\n",
      "Iteration:230, Price of Hedge: 0.14981480119949425, Loss: 0.0015256533869916211\n",
      "Iteration:240, Price of Hedge: 0.14846653856019998, Loss: 0.001635282448523423\n",
      "Iteration:250, Price of Hedge: 0.14766529422876717, Loss: 0.0015204833408649422\n",
      "Iteration:260, Price of Hedge: 0.13800878029950356, Loss: 0.0012274989447406794\n",
      "Iteration:270, Price of Hedge: 0.12798850265436953, Loss: 0.0016879852691186416\n",
      "Iteration:280, Price of Hedge: 0.12485651803004885, Loss: 0.0013709000845014254\n",
      "Iteration:290, Price of Hedge: 0.12539802378382775, Loss: 0.0017373947439843997\n",
      "Iteration:300, Price of Hedge: 0.12877149070375254, Loss: 0.0015068184894305504\n",
      "Iteration:310, Price of Hedge: 0.13088010749390264, Loss: 0.001492606604826019\n",
      "Iteration:320, Price of Hedge: 0.14503827036733696, Loss: 0.00145539044696692\n",
      "Iteration:330, Price of Hedge: 0.14651215438613577, Loss: 0.0015706504541380007\n",
      "Iteration:340, Price of Hedge: 0.13573123074904744, Loss: 0.001595062759359056\n",
      "Iteration:350, Price of Hedge: 0.12170054839100432, Loss: 0.0015299281497484609\n",
      "Iteration:360, Price of Hedge: 0.11830642560666434, Loss: 0.0011907716376104993\n",
      "Iteration:370, Price of Hedge: 0.10642859017858655, Loss: 0.001366337787328975\n",
      "Iteration:380, Price of Hedge: 0.11358600392792369, Loss: 0.0014068904421910668\n",
      "Iteration:390, Price of Hedge: 0.11758776149717393, Loss: 0.0012949571364305524\n",
      "Iteration:400, Price of Hedge: 0.11941166027342548, Loss: 0.0013407333753986173\n",
      "Iteration:410, Price of Hedge: 0.12012530903959374, Loss: 0.0013042557714305404\n",
      "Iteration:420, Price of Hedge: 0.12617015966791884, Loss: 0.0016892754161969671\n",
      "Iteration:430, Price of Hedge: 0.12807259612645225, Loss: 0.0014781098035935082\n",
      "Iteration:440, Price of Hedge: 0.1478391774788179, Loss: 0.0015844877417769965\n",
      "Iteration:450, Price of Hedge: 0.12735974722107243, Loss: 0.0011973127288977814\n",
      "Iteration:460, Price of Hedge: 0.12089870956844494, Loss: 0.0012335782076229763\n",
      "Iteration:470, Price of Hedge: 0.11880699794414797, Loss: 0.0013124386377863396\n",
      "Iteration:480, Price of Hedge: 0.13084963712143463, Loss: 0.0012725715055045496\n",
      "Iteration:490, Price of Hedge: 0.12899482480660254, Loss: 0.0009899327749879562\n",
      "Iteration:500, Price of Hedge: 0.12476440433222252, Loss: 0.0009078027280733371\n",
      "Iteration:510, Price of Hedge: 0.13910042814179066, Loss: 0.0013426886938695316\n",
      "Iteration:520, Price of Hedge: 0.133746203259642, Loss: 0.001120049149189395\n",
      "Iteration:530, Price of Hedge: 0.13661462294523974, Loss: 0.003170692752240001\n",
      "Iteration:540, Price of Hedge: 0.1354506849819643, Loss: 0.0011241235245253113\n",
      "Iteration:550, Price of Hedge: 0.11841286113617572, Loss: 0.0008497031271646805\n",
      "Iteration:560, Price of Hedge: 0.12158190958000432, Loss: 0.0011217752001306813\n",
      "Iteration:570, Price of Hedge: 0.12269188936684829, Loss: 0.0007561721084480056\n",
      "Iteration:580, Price of Hedge: 0.13959327209462913, Loss: 0.0010448895107335598\n",
      "Iteration:590, Price of Hedge: 0.13064653733474643, Loss: 0.000889001946196233\n",
      "Iteration:600, Price of Hedge: 0.14634822616022236, Loss: 0.0008337206047843715\n",
      "Iteration:610, Price of Hedge: 0.13110892172404648, Loss: 0.0008383078976064607\n",
      "Iteration:620, Price of Hedge: 0.12804074221099881, Loss: 0.0008891178044101001\n",
      "Iteration:630, Price of Hedge: 0.12925707105591755, Loss: 0.0011446263750312102\n",
      "Iteration:640, Price of Hedge: 0.1356405978745727, Loss: 0.0010458436521027183\n",
      "Iteration:650, Price of Hedge: 0.12758791291544186, Loss: 0.0008934657807758485\n",
      "Iteration:660, Price of Hedge: 0.12531978875157393, Loss: 0.0011030156272975767\n",
      "Iteration:670, Price of Hedge: 0.12254951414650464, Loss: 0.0011542441267879068\n",
      "Iteration:680, Price of Hedge: 0.12595852082686748, Loss: 0.0009864664019405556\n",
      "Iteration:690, Price of Hedge: 0.13485235668541692, Loss: 0.001054018073982288\n",
      "Iteration:700, Price of Hedge: 0.13225034468702007, Loss: 0.0008927008801189907\n",
      "Iteration:710, Price of Hedge: 0.13584870219565345, Loss: 0.0011242235915686295\n",
      "Iteration:720, Price of Hedge: 0.1337292872848593, Loss: 0.0010322153652503995\n",
      "Iteration:730, Price of Hedge: 0.1316986244947941, Loss: 0.0008401709179521877\n",
      "Iteration:740, Price of Hedge: 0.12242697331192859, Loss: 0.0009477696740641584\n",
      "Iteration:750, Price of Hedge: 0.12185767780021593, Loss: 0.001064765612213714\n",
      "Iteration:760, Price of Hedge: 0.13119729553224033, Loss: 0.0008969900829301825\n",
      "Iteration:770, Price of Hedge: 0.12318015033354755, Loss: 0.0011461937542641466\n",
      "Iteration:780, Price of Hedge: 0.13738124627524828, Loss: 0.0008208322229392717\n",
      "Iteration:790, Price of Hedge: 0.13748529303132387, Loss: 0.0010709725555765994\n",
      "Iteration:800, Price of Hedge: 0.1300858781577631, Loss: 0.0009123292206665746\n",
      "Iteration:810, Price of Hedge: 0.13749235126233544, Loss: 0.000904512675689606\n",
      "Iteration:820, Price of Hedge: 0.12530474272160746, Loss: 0.0009207278433900347\n",
      "Iteration:830, Price of Hedge: 0.10947969158290789, Loss: 0.0008549505246936207\n",
      "Iteration:840, Price of Hedge: 0.10984448214708778, Loss: 0.0012378941794238152\n",
      "Iteration:850, Price of Hedge: 0.11498448485401697, Loss: 0.0009270166137275827\n",
      "Iteration:860, Price of Hedge: 0.12248029376151522, Loss: 0.0008777472327224701\n",
      "Iteration:870, Price of Hedge: 0.13853453744289368, Loss: 0.0010177183951283642\n",
      "Iteration:880, Price of Hedge: 0.1320533843723297, Loss: 0.0008963926362369535\n",
      "Iteration:890, Price of Hedge: 0.14001697132498522, Loss: 0.000998568687493462\n",
      "Iteration:900, Price of Hedge: 0.1402505090573527, Loss: 0.0008802691755483761\n",
      "Iteration:910, Price of Hedge: 0.14255278943867325, Loss: 0.0010753980522341334\n",
      "Iteration:920, Price of Hedge: 0.14365795925185695, Loss: 0.0009538148212624887\n",
      "Iteration:930, Price of Hedge: 0.1322980985378763, Loss: 0.001118822082348503\n",
      "Iteration:940, Price of Hedge: 0.12586723941661832, Loss: 0.0010839950357042216\n",
      "Iteration:950, Price of Hedge: 0.1362247340465899, Loss: 0.0010172232954870353\n",
      "Iteration:960, Price of Hedge: 0.13224564280265555, Loss: 0.000836871154420793\n",
      "Iteration:970, Price of Hedge: 0.13685622413906914, Loss: 0.0010238207114307673\n",
      "Iteration:980, Price of Hedge: 0.13812020955447793, Loss: 0.0009825262093319242\n",
      "Iteration:990, Price of Hedge: 0.13818621968738398, Loss: 0.0010468736248684164\n",
      "tf.Tensor(0.11958239, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_75 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.13593429810894692, Loss: 0.0019525000425279161\n",
      "Iteration:20, Price of Hedge: 0.11031757818559527, Loss: 0.00136737316455946\n",
      "Iteration:30, Price of Hedge: 0.14974561324129354, Loss: 0.001492401404053645\n",
      "Iteration:40, Price of Hedge: 0.122100403122721, Loss: 0.0016359446643493315\n",
      "Iteration:50, Price of Hedge: 0.12630606033944788, Loss: 0.001691977817479895\n",
      "Iteration:60, Price of Hedge: 0.14002105710036405, Loss: 0.0016309556677930105\n",
      "Iteration:70, Price of Hedge: 0.1254631800112975, Loss: 0.0014661054739648627\n",
      "Iteration:80, Price of Hedge: 0.1314995888656256, Loss: 0.0018391467980894305\n",
      "Iteration:90, Price of Hedge: 0.1357419856339732, Loss: 0.001323387492331074\n",
      "Iteration:100, Price of Hedge: 0.12995132860243075, Loss: 0.0014163626956223308\n",
      "Iteration:110, Price of Hedge: 0.13204564517875497, Loss: 0.0015387727252615946\n",
      "Iteration:120, Price of Hedge: 0.13128889040144714, Loss: 0.001449702923336904\n",
      "Iteration:130, Price of Hedge: 0.13317104930810048, Loss: 0.00146959675821714\n",
      "Iteration:140, Price of Hedge: 0.1329299128982427, Loss: 0.0015333138780478706\n",
      "Iteration:150, Price of Hedge: 0.12360890814294408, Loss: 0.001440495910904005\n",
      "Iteration:160, Price of Hedge: 0.12619697662219095, Loss: 0.0014179245015009557\n",
      "Iteration:170, Price of Hedge: 0.13224569684730342, Loss: 0.001355122678448728\n",
      "Iteration:180, Price of Hedge: 0.13960870724606025, Loss: 0.001515043747057021\n",
      "Iteration:190, Price of Hedge: 0.13798751913503227, Loss: 0.0016282850177407049\n",
      "Iteration:200, Price of Hedge: 0.15293514460666416, Loss: 0.001648959966672159\n",
      "Iteration:210, Price of Hedge: 0.14988649682935604, Loss: 0.00157285665799769\n",
      "Iteration:220, Price of Hedge: 0.1528730364973342, Loss: 0.0018920244193425973\n",
      "Iteration:230, Price of Hedge: 0.1326044560287812, Loss: 0.0012284305393583052\n",
      "Iteration:240, Price of Hedge: 0.14581853456646743, Loss: 0.0015427463579960944\n",
      "Iteration:250, Price of Hedge: 0.1298635709032226, Loss: 0.0014081117667881227\n",
      "Iteration:260, Price of Hedge: 0.10192808698095064, Loss: 0.0013796337840416674\n",
      "Iteration:270, Price of Hedge: 0.1020504224458648, Loss: 0.0014012091674734607\n",
      "Iteration:280, Price of Hedge: 0.1107619008535778, Loss: 0.001402215664595241\n",
      "Iteration:290, Price of Hedge: 0.11062608665348535, Loss: 0.0010696602839705529\n",
      "Iteration:300, Price of Hedge: 0.1131930344843454, Loss: 0.0013079818965667568\n",
      "Iteration:310, Price of Hedge: 0.125230301623634, Loss: 0.0015613782503486108\n",
      "Iteration:320, Price of Hedge: 0.1186124047850342, Loss: 0.0016716943544664354\n",
      "Iteration:330, Price of Hedge: 0.1340659746321478, Loss: 0.0014288114580349289\n",
      "Iteration:340, Price of Hedge: 0.13097068632372952, Loss: 0.0012826777702111159\n",
      "Iteration:350, Price of Hedge: 0.12953333648688956, Loss: 0.0014959911508987567\n",
      "Iteration:360, Price of Hedge: 0.11880519285290916, Loss: 0.0013163165946051603\n",
      "Iteration:370, Price of Hedge: 0.1307537511071871, Loss: 0.0009695193514853263\n",
      "Iteration:380, Price of Hedge: 0.13418266783582453, Loss: 0.0012633119684295037\n",
      "Iteration:390, Price of Hedge: 0.13482155123613213, Loss: 0.001287334898851622\n",
      "Iteration:400, Price of Hedge: 0.12919095283371576, Loss: 0.001006390045821881\n",
      "Iteration:410, Price of Hedge: 0.12710065717919292, Loss: 0.0008030892805994228\n",
      "Iteration:420, Price of Hedge: 0.11850080258718663, Loss: 0.0013952473672555145\n",
      "Iteration:430, Price of Hedge: 0.12191181972845017, Loss: 0.001027179332961481\n",
      "Iteration:440, Price of Hedge: 0.14271497742692532, Loss: 0.0015971767495383206\n",
      "Iteration:450, Price of Hedge: 0.1190134809257927, Loss: 0.0011671376597635064\n",
      "Iteration:460, Price of Hedge: 0.11554047457342449, Loss: 0.000696325598741776\n",
      "Iteration:470, Price of Hedge: 0.11786285956375196, Loss: 0.000994850500164901\n",
      "Iteration:480, Price of Hedge: 0.11585568457765022, Loss: 0.0010644891400619638\n",
      "Iteration:490, Price of Hedge: 0.1428463167301743, Loss: 0.0010428093829039752\n",
      "Iteration:500, Price of Hedge: 0.1374712630407373, Loss: 0.001650105713206962\n",
      "Iteration:510, Price of Hedge: 0.13266409970216841, Loss: 0.0014530031935368727\n",
      "Iteration:520, Price of Hedge: 0.12901951240174866, Loss: 0.0009025148815032581\n",
      "Iteration:530, Price of Hedge: 0.11755082738482088, Loss: 0.000781753129179208\n",
      "Iteration:540, Price of Hedge: 0.12442316642558354, Loss: 0.000942056394781643\n",
      "Iteration:550, Price of Hedge: 0.13400435292464863, Loss: 0.0007776382203573906\n",
      "Iteration:560, Price of Hedge: 0.13175100456750785, Loss: 0.000916853939919804\n",
      "Iteration:570, Price of Hedge: 0.11564768834586517, Loss: 0.0009658825689076168\n",
      "Iteration:580, Price of Hedge: 0.10823912911788512, Loss: 0.0009275604379967551\n",
      "Iteration:590, Price of Hedge: 0.12359188407886564, Loss: 0.0009675910553383461\n",
      "Iteration:600, Price of Hedge: 0.12433346311905212, Loss: 0.00086424552856883\n",
      "Iteration:610, Price of Hedge: 0.13435549181077705, Loss: 0.0006157828600239946\n",
      "Iteration:620, Price of Hedge: 0.1267506316128106, Loss: 0.0009264866383994264\n",
      "Iteration:630, Price of Hedge: 0.11898107575493101, Loss: 0.0008071443180847738\n",
      "Iteration:640, Price of Hedge: 0.13160013352851935, Loss: 0.0007071627328659958\n",
      "Iteration:650, Price of Hedge: 0.12239359533740526, Loss: 0.0008284242292933008\n",
      "Iteration:660, Price of Hedge: 0.14083065673435727, Loss: 0.0010363991809982486\n",
      "Iteration:670, Price of Hedge: 0.12747579188897476, Loss: 0.0008550168138320214\n",
      "Iteration:680, Price of Hedge: 0.1279767209211343, Loss: 0.0010748541435201986\n",
      "Iteration:690, Price of Hedge: 0.1219977831453491, Loss: 0.0008944517578203915\n",
      "Iteration:700, Price of Hedge: 0.12301637343264817, Loss: 0.0009601386361763887\n",
      "Iteration:710, Price of Hedge: 0.1292932701610596, Loss: 0.0009038905711257873\n",
      "Iteration:720, Price of Hedge: 0.13444901066944795, Loss: 0.0007683879722061971\n",
      "Iteration:730, Price of Hedge: 0.11822829866370627, Loss: 0.0010248061818067366\n",
      "Iteration:740, Price of Hedge: 0.13909518581094746, Loss: 0.0008008767433825615\n",
      "Iteration:750, Price of Hedge: 0.14753454941664473, Loss: 0.0009299287758000486\n",
      "Iteration:760, Price of Hedge: 0.15315316071616394, Loss: 0.0008392155099115951\n",
      "Iteration:770, Price of Hedge: 0.13374537097206485, Loss: 0.0009188725919624386\n",
      "Iteration:780, Price of Hedge: 0.12086215376862698, Loss: 0.00088931548959863\n",
      "Iteration:790, Price of Hedge: 0.12559189274466007, Loss: 0.000820744062607437\n",
      "Iteration:800, Price of Hedge: 0.13871341441840743, Loss: 0.0009071999613600835\n",
      "Iteration:810, Price of Hedge: 0.12927555432548843, Loss: 0.0008415483809147251\n",
      "Iteration:820, Price of Hedge: 0.13005807759089977, Loss: 0.000876629352959224\n",
      "Iteration:830, Price of Hedge: 0.1282827649530816, Loss: 0.0008492349654025234\n",
      "Iteration:840, Price of Hedge: 0.14305999845891507, Loss: 0.0008210292325697033\n",
      "Iteration:850, Price of Hedge: 0.133666173945079, Loss: 0.0009127054220825937\n",
      "Iteration:860, Price of Hedge: 0.13065448189798304, Loss: 0.0007896818168005026\n",
      "Iteration:870, Price of Hedge: 0.1499388552842106, Loss: 0.0008958256741029125\n",
      "Iteration:880, Price of Hedge: 0.13310487704125082, Loss: 0.0008139293702903228\n",
      "Iteration:890, Price of Hedge: 0.14461731660509258, Loss: 0.0009908505206645656\n",
      "Iteration:900, Price of Hedge: 0.12885056883251308, Loss: 0.000744786421147925\n",
      "Iteration:910, Price of Hedge: 0.13554024777241125, Loss: 0.0008431953071137421\n",
      "Iteration:920, Price of Hedge: 0.13804127194180182, Loss: 0.0010191564049854662\n",
      "Iteration:930, Price of Hedge: 0.13505798576162534, Loss: 0.0011015834441290729\n",
      "Iteration:940, Price of Hedge: 0.11731509543974995, Loss: 0.000750024023084439\n",
      "Iteration:950, Price of Hedge: 0.13223537431956062, Loss: 0.0009317850405647922\n",
      "Iteration:960, Price of Hedge: 0.12850398050573517, Loss: 0.0011357829817447485\n",
      "Iteration:970, Price of Hedge: 0.12381448317450464, Loss: 0.000729097597650874\n",
      "Iteration:980, Price of Hedge: 0.12899991581243173, Loss: 0.0009686180725373639\n",
      "Iteration:990, Price of Hedge: 0.1344088446871524, Loss: 0.0009074207844134819\n",
      "tf.Tensor(0.0973559, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_76 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.12825107317157178, Loss: 0.001057613647515998\n",
      "Iteration:20, Price of Hedge: 0.08972633495587559, Loss: 0.0009738014609364854\n",
      "Iteration:30, Price of Hedge: 0.10956563338194769, Loss: 0.0010816118356227645\n",
      "Iteration:40, Price of Hedge: 0.09668672894140969, Loss: 0.0006990779491016009\n",
      "Iteration:50, Price of Hedge: 0.10820356773958793, Loss: 0.0009740709241729651\n",
      "Iteration:60, Price of Hedge: 0.10146815621866381, Loss: 0.0008539397208889633\n",
      "Iteration:70, Price of Hedge: 0.10135535422963358, Loss: 0.0008753425836713902\n",
      "Iteration:80, Price of Hedge: 0.10495848928513851, Loss: 0.0009158330027436713\n",
      "Iteration:90, Price of Hedge: 0.10495207958990137, Loss: 0.000865067682774523\n",
      "Iteration:100, Price of Hedge: 0.09922893513247573, Loss: 0.0009250717664071929\n",
      "Iteration:110, Price of Hedge: 0.09694612163331727, Loss: 0.0008520823583423099\n",
      "Iteration:120, Price of Hedge: 0.10381630969709477, Loss: 0.0006880937966462276\n",
      "Iteration:130, Price of Hedge: 0.10366282289714945, Loss: 0.000889353151962613\n",
      "Iteration:140, Price of Hedge: 0.11456906526371427, Loss: 0.0009071094365749045\n",
      "Iteration:150, Price of Hedge: 0.11099619521101545, Loss: 0.000977688875568683\n",
      "Iteration:160, Price of Hedge: 0.10420261003112614, Loss: 0.0009220580172856874\n",
      "Iteration:170, Price of Hedge: 0.10800725596067196, Loss: 0.0006989636531158361\n",
      "Iteration:180, Price of Hedge: 0.11257004021051104, Loss: 0.0009152989740669249\n",
      "Iteration:190, Price of Hedge: 0.10028683749663402, Loss: 0.0006520225830966898\n",
      "Iteration:200, Price of Hedge: 0.09293291740764859, Loss: 0.0008419669736014157\n",
      "Iteration:210, Price of Hedge: 0.10765198806344643, Loss: 0.0009783825892909271\n",
      "Iteration:220, Price of Hedge: 0.11567996380957198, Loss: 0.0008938033909354992\n",
      "Iteration:230, Price of Hedge: 0.10712500951101447, Loss: 0.000847738857548963\n",
      "Iteration:240, Price of Hedge: 0.10206108005042439, Loss: 0.0008932137976051636\n",
      "Iteration:250, Price of Hedge: 0.10209801416277742, Loss: 0.0007750602062093215\n",
      "Iteration:260, Price of Hedge: 0.11009870817065917, Loss: 0.0008133091235112745\n",
      "Iteration:270, Price of Hedge: 0.10976706859348156, Loss: 0.0009108071038262278\n",
      "Iteration:280, Price of Hedge: 0.0996006974562306, Loss: 0.0009329201470595461\n",
      "Iteration:290, Price of Hedge: 0.0994172591124368, Loss: 0.000996047082446605\n",
      "Iteration:300, Price of Hedge: 0.09784598663817974, Loss: 0.0008793358920355044\n",
      "Iteration:310, Price of Hedge: 0.09743962493085974, Loss: 0.0008699612567494519\n",
      "Iteration:320, Price of Hedge: 0.08660871539895823, Loss: 0.0008289094488974414\n",
      "Iteration:330, Price of Hedge: 0.10148025141085669, Loss: 0.001000388894344706\n",
      "Iteration:340, Price of Hedge: 0.1034580261085182, Loss: 0.00083123269319767\n",
      "Iteration:350, Price of Hedge: 0.10274625809609575, Loss: 0.0007894509448203913\n",
      "Iteration:360, Price of Hedge: 0.10494319464979185, Loss: 0.0007358173740551699\n",
      "Iteration:370, Price of Hedge: 0.1061873781062218, Loss: 0.0008108106563292861\n",
      "Iteration:380, Price of Hedge: 0.11030371032895232, Loss: 0.0010881528424652844\n",
      "Iteration:390, Price of Hedge: 0.10258154081832345, Loss: 0.0007357873117197933\n",
      "Iteration:400, Price of Hedge: 0.10481527096828813, Loss: 0.0008338391652306321\n",
      "Iteration:410, Price of Hedge: 0.10553853968177691, Loss: 0.0009325622701569447\n",
      "Iteration:420, Price of Hedge: 0.08771686307223946, Loss: 0.0007362650157400896\n",
      "Iteration:430, Price of Hedge: 0.09863066088057622, Loss: 0.0007117307722822819\n",
      "Iteration:440, Price of Hedge: 0.08992260349907327, Loss: 0.0006475134016797224\n",
      "Iteration:450, Price of Hedge: 0.09933226849919947, Loss: 0.0007501351523916179\n",
      "Iteration:460, Price of Hedge: 0.09853576928784946, Loss: 0.0007724781387126623\n",
      "Iteration:470, Price of Hedge: 0.10168546974774131, Loss: 0.0007504218423596055\n",
      "Iteration:480, Price of Hedge: 0.11062214139419098, Loss: 0.00078095656173649\n",
      "Iteration:490, Price of Hedge: 0.10092273763237927, Loss: 0.0006895540154758129\n",
      "Iteration:500, Price of Hedge: 0.09784501383451812, Loss: 0.0007277161657845088\n",
      "Iteration:510, Price of Hedge: 0.11188993155280968, Loss: 0.0006115960042647029\n",
      "Iteration:520, Price of Hedge: 0.11654340272177138, Loss: 0.000781601719720415\n",
      "Iteration:530, Price of Hedge: 0.10976859265255144, Loss: 0.0006417424466245603\n",
      "Iteration:540, Price of Hedge: 0.10023710561166582, Loss: 0.0005241085282958746\n",
      "Iteration:550, Price of Hedge: 0.10366432533836019, Loss: 0.0005674399647283891\n",
      "Iteration:560, Price of Hedge: 0.10636982202849482, Loss: 0.0004831485963452398\n",
      "Iteration:570, Price of Hedge: 0.10251522803538933, Loss: 0.00046228064890956326\n",
      "Iteration:580, Price of Hedge: 0.0984510813246402, Loss: 0.0005697444200690072\n",
      "Iteration:590, Price of Hedge: 0.09695076947303392, Loss: 0.0006134837669257821\n",
      "Iteration:600, Price of Hedge: 0.09676392631642444, Loss: 0.0004901787072509656\n",
      "Iteration:610, Price of Hedge: 0.10620819610458057, Loss: 0.0006128389889432873\n",
      "Iteration:620, Price of Hedge: 0.10135648916723881, Loss: 0.0005603202579298694\n",
      "Iteration:630, Price of Hedge: 0.10219979104364257, Loss: 0.0005811219162271453\n",
      "Iteration:640, Price of Hedge: 0.10595188395760147, Loss: 0.0005325496689571497\n",
      "Iteration:650, Price of Hedge: 0.10297849875691441, Loss: 0.0005864479318297811\n",
      "Iteration:660, Price of Hedge: 0.10785148847658661, Loss: 0.0006275071285984923\n",
      "Iteration:670, Price of Hedge: 0.10603460469562834, Loss: 0.0005536984796722156\n",
      "Iteration:680, Price of Hedge: 0.1086738426474767, Loss: 0.000559074993242703\n",
      "Iteration:690, Price of Hedge: 0.10046381210054278, Loss: 0.0005347352260724581\n",
      "Iteration:700, Price of Hedge: 0.10485885257232895, Loss: 0.0006249654679205907\n",
      "Iteration:710, Price of Hedge: 0.10754975720753919, Loss: 0.0005866653770926878\n",
      "Iteration:720, Price of Hedge: 0.10555740126388287, Loss: 0.0005699482697251846\n",
      "Iteration:730, Price of Hedge: 0.10521418532313193, Loss: 0.0005143301626012953\n",
      "Iteration:740, Price of Hedge: 0.11209170184116034, Loss: 0.0006311383378218905\n",
      "Iteration:750, Price of Hedge: 0.10389778740822067, Loss: 0.0005459727550370941\n",
      "Iteration:760, Price of Hedge: 0.10455405156728262, Loss: 0.0004971861869603966\n",
      "Iteration:770, Price of Hedge: 0.09406743346462464, Loss: 0.0006095646010629619\n",
      "Iteration:780, Price of Hedge: 0.10949694263450738, Loss: 0.0007247513946251338\n",
      "Iteration:790, Price of Hedge: 0.12556823199782344, Loss: 0.0006234023531481504\n",
      "Iteration:800, Price of Hedge: 0.11139715245354864, Loss: 0.0005309515096083572\n",
      "Iteration:810, Price of Hedge: 0.10970813830944622, Loss: 0.000647161815911912\n",
      "Iteration:820, Price of Hedge: 0.09853329404297712, Loss: 0.000570858204261282\n",
      "Iteration:830, Price of Hedge: 0.09484568720285438, Loss: 0.00046760451117076055\n",
      "Iteration:840, Price of Hedge: 0.0836823436374516, Loss: 0.0004767518211567179\n",
      "Iteration:850, Price of Hedge: 0.09626161374127946, Loss: 0.0005268633275538059\n",
      "Iteration:860, Price of Hedge: 0.10411769508039584, Loss: 0.0005280817388065628\n",
      "Iteration:870, Price of Hedge: 0.08871573787199623, Loss: 0.0005880651334724707\n",
      "Iteration:880, Price of Hedge: 0.09620607746113025, Loss: 0.0005831041303548502\n",
      "Iteration:890, Price of Hedge: 0.1072571919107702, Loss: 0.0004943043405575943\n",
      "Iteration:900, Price of Hedge: 0.10853508841854023, Loss: 0.0006736903913208137\n",
      "Iteration:910, Price of Hedge: 0.1049857385965936, Loss: 0.0006038520817833071\n",
      "Iteration:920, Price of Hedge: 0.10288432055353952, Loss: 0.0005203897498539779\n",
      "Iteration:930, Price of Hedge: 0.09599023394647475, Loss: 0.00039079904429781823\n",
      "Iteration:940, Price of Hedge: 0.09501941912789108, Loss: 0.0005092331611940004\n",
      "Iteration:950, Price of Hedge: 0.09989218186004223, Loss: 0.0004298079222380347\n",
      "Iteration:960, Price of Hedge: 0.10791953068825251, Loss: 0.0005607111527345277\n",
      "Iteration:970, Price of Hedge: 0.09795892914329443, Loss: 0.00047965266763103645\n",
      "Iteration:980, Price of Hedge: 0.10081135161312318, Loss: 0.0005513751509272247\n",
      "Iteration:990, Price of Hedge: 0.10829383311045718, Loss: 0.0005788209653441623\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 12 \n",
      "\n",
      "tf.Tensor(0.20195244, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_77 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.18407961196949998, Loss: 0.003171902990543329\n",
      "Iteration:20, Price of Hedge: 0.20614716097082067, Loss: 0.001786792724291919\n",
      "Iteration:30, Price of Hedge: 0.20612999083161582, Loss: 0.001769162736271157\n",
      "Iteration:40, Price of Hedge: 0.20203463822264495, Loss: 0.0016705645961808569\n",
      "Iteration:50, Price of Hedge: 0.21586418572074847, Loss: 0.0020884155713466247\n",
      "Iteration:60, Price of Hedge: 0.20085628841817424, Loss: 0.00210287071904085\n",
      "Iteration:70, Price of Hedge: 0.18692618976239855, Loss: 0.002944452854031576\n",
      "Iteration:80, Price of Hedge: 0.22704821854006665, Loss: 0.0019293355975317115\n",
      "Iteration:90, Price of Hedge: 0.19467858601584423, Loss: 0.001991664483010469\n",
      "Iteration:100, Price of Hedge: 0.1639366278065168, Loss: 0.001928870848561903\n",
      "Iteration:110, Price of Hedge: 0.21972164565902402, Loss: 0.0021041743131034463\n",
      "Iteration:120, Price of Hedge: 0.2378476872826738, Loss: 0.0019843274213500405\n",
      "Iteration:130, Price of Hedge: 0.19769555195955063, Loss: 0.0020366212510665393\n",
      "Iteration:140, Price of Hedge: 0.20318987890140505, Loss: 0.0021265893013906246\n",
      "Iteration:150, Price of Hedge: 0.19356219375706588, Loss: 0.0020972931188839136\n",
      "Iteration:160, Price of Hedge: 0.19758639613166054, Loss: 0.0021854753693773877\n",
      "Iteration:170, Price of Hedge: 0.20336781328919215, Loss: 0.0018632116960006439\n",
      "Iteration:180, Price of Hedge: 0.18566114643543585, Loss: 0.0019009234334113943\n",
      "Iteration:190, Price of Hedge: 0.20695031579280396, Loss: 0.002080183925342993\n",
      "Iteration:200, Price of Hedge: 0.2020851490088674, Loss: 0.001901986154284696\n",
      "Iteration:210, Price of Hedge: 0.2217719092447595, Loss: 0.002131483023821312\n",
      "Iteration:220, Price of Hedge: 0.19086577627974746, Loss: 0.0018828449281805602\n",
      "Iteration:230, Price of Hedge: 0.20625439593838876, Loss: 0.0021617374926717003\n",
      "Iteration:240, Price of Hedge: 0.20381147322172807, Loss: 0.002049398249185763\n",
      "Iteration:250, Price of Hedge: 0.2089061828141439, Loss: 0.00220214998052084\n",
      "Iteration:260, Price of Hedge: 0.20977995865388407, Loss: 0.0016118465115943835\n",
      "Iteration:270, Price of Hedge: 0.19941184065725961, Loss: 0.0020727310975470867\n",
      "Iteration:280, Price of Hedge: 0.2088129622866802, Loss: 0.00204069174764494\n",
      "Iteration:290, Price of Hedge: 0.21315336179101507, Loss: 0.0018176278613774022\n",
      "Iteration:300, Price of Hedge: 0.21411808448681738, Loss: 0.0024353048149308608\n",
      "Iteration:310, Price of Hedge: 0.24020593534024215, Loss: 0.001984927690200666\n",
      "Iteration:320, Price of Hedge: 0.21578950737557676, Loss: 0.002146816830358622\n",
      "Iteration:330, Price of Hedge: 0.2250540715165954, Loss: 0.0017480096907385723\n",
      "Iteration:340, Price of Hedge: 0.2251176755139923, Loss: 0.0017912993345658766\n",
      "Iteration:350, Price of Hedge: 0.21134110847966808, Loss: 0.00218735549717024\n",
      "Iteration:360, Price of Hedge: 0.20576461575750926, Loss: 0.0018908187035861167\n",
      "Iteration:370, Price of Hedge: 0.21312243201970774, Loss: 0.002136571221109218\n",
      "Iteration:380, Price of Hedge: 0.2064783525714418, Loss: 0.0015461936373552863\n",
      "Iteration:390, Price of Hedge: 0.20465625975109844, Loss: 0.0019797385803687396\n",
      "Iteration:400, Price of Hedge: 0.19390024557312271, Loss: 0.0019234076363721653\n",
      "Iteration:410, Price of Hedge: 0.1779810176514516, Loss: 0.0017992611658463442\n",
      "Iteration:420, Price of Hedge: 0.16522009571207832, Loss: 0.002058921851386519\n",
      "Iteration:430, Price of Hedge: 0.18748909983982287, Loss: 0.0024199604424367414\n",
      "Iteration:440, Price of Hedge: 0.201830262604507, Loss: 0.001647269264622697\n",
      "Iteration:450, Price of Hedge: 0.1986773859927112, Loss: 0.0017735843595012124\n",
      "Iteration:460, Price of Hedge: 0.20438308597244798, Loss: 0.002206518620837039\n",
      "Iteration:470, Price of Hedge: 0.20425723042012578, Loss: 0.001672289909736979\n",
      "Iteration:480, Price of Hedge: 0.22133655997320859, Loss: 0.0018790070357817767\n",
      "Iteration:490, Price of Hedge: 0.21750420842342777, Loss: 0.002366327033152571\n",
      "Iteration:500, Price of Hedge: 0.20565998767180674, Loss: 0.0021151537203967785\n",
      "Iteration:510, Price of Hedge: 0.22012051818507244, Loss: 0.001907486117628554\n",
      "Iteration:520, Price of Hedge: 0.21970943447554844, Loss: 0.0020861532315509246\n",
      "Iteration:530, Price of Hedge: 0.21962070248904125, Loss: 0.0016326326581050043\n",
      "Iteration:540, Price of Hedge: 0.21082316221427105, Loss: 0.0021564026032617643\n",
      "Iteration:550, Price of Hedge: 0.21622505265328298, Loss: 0.002091286755262245\n",
      "Iteration:560, Price of Hedge: 0.2044455335335286, Loss: 0.0017618736042408934\n",
      "Iteration:570, Price of Hedge: 0.21762971116467042, Loss: 0.0020409739658826197\n",
      "Iteration:580, Price of Hedge: 0.22042607218057952, Loss: 0.0017413689103189078\n",
      "Iteration:590, Price of Hedge: 0.2235437852881134, Loss: 0.0017762293706891862\n",
      "Iteration:600, Price of Hedge: 0.22643021113238573, Loss: 0.0016511779029931616\n",
      "Iteration:610, Price of Hedge: 0.2099404484938489, Loss: 0.002010273429899101\n",
      "Iteration:620, Price of Hedge: 0.18428655526827242, Loss: 0.002181463827775387\n",
      "Iteration:630, Price of Hedge: 0.17183518584997443, Loss: 0.0024017623428252088\n",
      "Iteration:640, Price of Hedge: 0.18360259178933092, Loss: 0.0017949850159346803\n",
      "Iteration:650, Price of Hedge: 0.17734540889102418, Loss: 0.0015095660589910741\n",
      "Iteration:660, Price of Hedge: 0.19901420296998965, Loss: 0.002263541711569539\n",
      "Iteration:670, Price of Hedge: 0.1843239728433204, Loss: 0.001715601144867329\n",
      "Iteration:680, Price of Hedge: 0.21081771324315354, Loss: 0.0019746479330038924\n",
      "Iteration:690, Price of Hedge: 0.22115484266662405, Loss: 0.0017871152156693215\n",
      "Iteration:700, Price of Hedge: 0.1986928704789804, Loss: 0.001990272839307794\n",
      "Iteration:710, Price of Hedge: 0.19657690562998623, Loss: 0.002049944156954253\n",
      "Iteration:720, Price of Hedge: 0.19863914519181095, Loss: 0.0017676459855146653\n",
      "Iteration:730, Price of Hedge: 0.22690713330947715, Loss: 0.0023455395084736705\n",
      "Iteration:740, Price of Hedge: 0.22688794430687267, Loss: 0.0019260501974831979\n",
      "Iteration:750, Price of Hedge: 0.20657484640169912, Loss: 0.0016265336509489914\n",
      "Iteration:760, Price of Hedge: 0.21962323096844472, Loss: 0.0017169953917767543\n",
      "Iteration:770, Price of Hedge: 0.21347467468140877, Loss: 0.002427128601918027\n",
      "Iteration:780, Price of Hedge: 0.22314316830728273, Loss: 0.0021651703567261205\n",
      "Iteration:790, Price of Hedge: 0.19614137995289552, Loss: 0.0018921241352064188\n",
      "Iteration:800, Price of Hedge: 0.2091968599424632, Loss: 0.0015869936967505827\n",
      "Iteration:810, Price of Hedge: 0.1989084184479708, Loss: 0.0018450249279949647\n",
      "Iteration:820, Price of Hedge: 0.17581828573380134, Loss: 0.0017367786911693273\n",
      "Iteration:830, Price of Hedge: 0.16451984412163084, Loss: 0.0010262816446022672\n",
      "Iteration:840, Price of Hedge: 0.1791659336621251, Loss: 0.0023221262669627096\n",
      "Iteration:850, Price of Hedge: 0.21773851418148096, Loss: 0.00126084626859731\n",
      "Iteration:860, Price of Hedge: 0.20353537895136356, Loss: 0.001210933301148548\n",
      "Iteration:870, Price of Hedge: 0.20790218048481818, Loss: 0.0013650367858710987\n",
      "Iteration:880, Price of Hedge: 0.2005311730083676, Loss: 0.001578993429888098\n",
      "Iteration:890, Price of Hedge: 0.24093954717832275, Loss: 0.0018581530527658429\n",
      "Iteration:900, Price of Hedge: 0.23444613766164082, Loss: 0.0013111444340801915\n",
      "Iteration:910, Price of Hedge: 0.22099290238110994, Loss: 0.0013552585287982533\n",
      "Iteration:920, Price of Hedge: 0.2015152611123142, Loss: 0.0010480821995315025\n",
      "Iteration:930, Price of Hedge: 0.22464089054120961, Loss: 0.001193488064242143\n",
      "Iteration:940, Price of Hedge: 0.2209839056985814, Loss: 0.0013181544104689524\n",
      "Iteration:950, Price of Hedge: 0.22532348197706398, Loss: 0.001392237080684311\n",
      "Iteration:960, Price of Hedge: 0.21209124363664103, Loss: 0.001072876442223425\n",
      "Iteration:970, Price of Hedge: 0.2244260481943783, Loss: 0.0012807163160265865\n",
      "Iteration:980, Price of Hedge: 0.2197656490408903, Loss: 0.0012155415130506663\n",
      "Iteration:990, Price of Hedge: 0.2059057793905609, Loss: 0.0012724489142125928\n",
      "tf.Tensor(0.18159139, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_78 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.21557537065090457, Loss: 0.0024134778451096015\n",
      "Iteration:20, Price of Hedge: 0.25539609876663577, Loss: 0.0017217318498937706\n",
      "Iteration:30, Price of Hedge: 0.2008625998163751, Loss: 0.001955932254638504\n",
      "Iteration:40, Price of Hedge: 0.2251637369604893, Loss: 0.0019868845360277443\n",
      "Iteration:50, Price of Hedge: 0.2161240898826847, Loss: 0.0023202608396315047\n",
      "Iteration:60, Price of Hedge: 0.21224910699412475, Loss: 0.0020730765583958145\n",
      "Iteration:70, Price of Hedge: 0.20369635880671666, Loss: 0.0019847615443580823\n",
      "Iteration:80, Price of Hedge: 0.23517026280180459, Loss: 0.0021031145016965126\n",
      "Iteration:90, Price of Hedge: 0.209030372314146, Loss: 0.0019285727048241053\n",
      "Iteration:100, Price of Hedge: 0.19730322603908945, Loss: 0.002302304838247737\n",
      "Iteration:110, Price of Hedge: 0.21068876079357748, Loss: 0.0024521798729940755\n",
      "Iteration:120, Price of Hedge: 0.20350889851978166, Loss: 0.0024137649635011635\n",
      "Iteration:130, Price of Hedge: 0.19850686063759468, Loss: 0.0019401712159345496\n",
      "Iteration:140, Price of Hedge: 0.2246725651359071, Loss: 0.0025943981110391422\n",
      "Iteration:150, Price of Hedge: 0.253407733924746, Loss: 0.002277925653902657\n",
      "Iteration:160, Price of Hedge: 0.24528976659103846, Loss: 0.0023641101729100942\n",
      "Iteration:170, Price of Hedge: 0.20963113118015997, Loss: 0.0023215777559874693\n",
      "Iteration:180, Price of Hedge: 0.20878060167043913, Loss: 0.00218529130734717\n",
      "Iteration:190, Price of Hedge: 0.21666340081901012, Loss: 0.002027102395889857\n",
      "Iteration:200, Price of Hedge: 0.24175850009642375, Loss: 0.0020449141489937038\n",
      "Iteration:210, Price of Hedge: 0.22813781675741465, Loss: 0.002013752079766362\n",
      "Iteration:220, Price of Hedge: 0.21177671255922093, Loss: 0.0021151292196273652\n",
      "Iteration:230, Price of Hedge: 0.20007871239945843, Loss: 0.0019927085220470928\n",
      "Iteration:240, Price of Hedge: 0.2114929348475684, Loss: 0.002520124181692551\n",
      "Iteration:250, Price of Hedge: 0.23398785566991903, Loss: 0.0019027859512762313\n",
      "Iteration:260, Price of Hedge: 0.21780011891609377, Loss: 0.002480530325801433\n",
      "Iteration:270, Price of Hedge: 0.20720643703594277, Loss: 0.002176855539308364\n",
      "Iteration:280, Price of Hedge: 0.19406675280205546, Loss: 0.0019615345086946624\n",
      "Iteration:290, Price of Hedge: 0.20250654264216053, Loss: 0.002143697423022883\n",
      "Iteration:300, Price of Hedge: 0.20999687866596162, Loss: 0.0023778172814881704\n",
      "Iteration:310, Price of Hedge: 0.21739746347124791, Loss: 0.0024084009794275497\n",
      "Iteration:320, Price of Hedge: 0.20431944277382, Loss: 0.0026052029503504047\n",
      "Iteration:330, Price of Hedge: 0.2115259030828909, Loss: 0.00203991492012473\n",
      "Iteration:340, Price of Hedge: 0.20055438013715587, Loss: 0.0022863173205565188\n",
      "Iteration:350, Price of Hedge: 0.21364696409192305, Loss: 0.0022671370463511306\n",
      "Iteration:360, Price of Hedge: 0.19789767350690254, Loss: 0.002041476384785401\n",
      "Iteration:370, Price of Hedge: 0.20810102872937647, Loss: 0.0022662640533109733\n",
      "Iteration:380, Price of Hedge: 0.20150250111160375, Loss: 0.0017232995928766037\n",
      "Iteration:390, Price of Hedge: 0.2309988794051904, Loss: 0.002054107297066998\n",
      "Iteration:400, Price of Hedge: 0.22491876846758743, Loss: 0.0018538528614741921\n",
      "Iteration:410, Price of Hedge: 0.21820824293267263, Loss: 0.0018769160482421609\n",
      "Iteration:420, Price of Hedge: 0.23787418731487123, Loss: 0.0019161002818946504\n",
      "Iteration:430, Price of Hedge: 0.23830763532671567, Loss: 0.0020761241478512104\n",
      "Iteration:440, Price of Hedge: 0.229876724565446, Loss: 0.0024149292094377216\n",
      "Iteration:450, Price of Hedge: 0.2579048403502483, Loss: 0.0021677547285097964\n",
      "Iteration:460, Price of Hedge: 0.25208700524906075, Loss: 0.0020088379910710996\n",
      "Iteration:470, Price of Hedge: 0.21687851757445883, Loss: 0.0017722184416064212\n",
      "Iteration:480, Price of Hedge: 0.2378591928439903, Loss: 0.002048898280359923\n",
      "Iteration:490, Price of Hedge: 0.24840097229421615, Loss: 0.002535677423245919\n",
      "Iteration:500, Price of Hedge: 0.2264954419808717, Loss: 0.0023313308997716664\n",
      "Iteration:510, Price of Hedge: 0.2606133318067336, Loss: 0.0022971798898057116\n",
      "Iteration:520, Price of Hedge: 0.22677602479219275, Loss: 0.0018772157232780473\n",
      "Iteration:530, Price of Hedge: 0.25968969200108344, Loss: 0.0020081415567005266\n",
      "Iteration:540, Price of Hedge: 0.2558432868099672, Loss: 0.002194969417525039\n",
      "Iteration:550, Price of Hedge: 0.2276565236430599, Loss: 0.0017467456041666551\n",
      "Iteration:560, Price of Hedge: 0.18679909937129793, Loss: 0.0018952113852823028\n",
      "Iteration:570, Price of Hedge: 0.1853427344361407, Loss: 0.001991475520826369\n",
      "Iteration:580, Price of Hedge: 0.19602922523082925, Loss: 0.0016752142296962646\n",
      "Iteration:590, Price of Hedge: 0.22263086701915852, Loss: 0.0026812910085422413\n",
      "Iteration:600, Price of Hedge: 0.21661563411896195, Loss: 0.0020477479692359688\n",
      "Iteration:610, Price of Hedge: 0.19235448223053025, Loss: 0.0020323379040538604\n",
      "Iteration:620, Price of Hedge: 0.21166551826731564, Loss: 0.002792119932723658\n",
      "Iteration:630, Price of Hedge: 0.2443750450654548, Loss: 0.0018133866250621522\n",
      "Iteration:640, Price of Hedge: 0.2015108509738198, Loss: 0.0020517962619920893\n",
      "Iteration:650, Price of Hedge: 0.2098466987497659, Loss: 0.00231237480760641\n",
      "Iteration:660, Price of Hedge: 0.20617248496608623, Loss: 0.0021863909325044004\n",
      "Iteration:670, Price of Hedge: 0.2229978493437386, Loss: 0.0021186299201870983\n",
      "Iteration:680, Price of Hedge: 0.2126216950947466, Loss: 0.0018960180731152354\n",
      "Iteration:690, Price of Hedge: 0.226224659477316, Loss: 0.0020762146475682306\n",
      "Iteration:700, Price of Hedge: 0.2125499176406734, Loss: 0.0021080831046037195\n",
      "Iteration:710, Price of Hedge: 0.21295774764801934, Loss: 0.0016424779860341188\n",
      "Iteration:720, Price of Hedge: 0.2369123459095519, Loss: 0.0018781017323519554\n",
      "Iteration:730, Price of Hedge: 0.23895030030873413, Loss: 0.0021942356194811106\n",
      "Iteration:740, Price of Hedge: 0.25194421476492007, Loss: 0.0022970166534294957\n",
      "Iteration:750, Price of Hedge: 0.22710221823585355, Loss: 0.0021487542286999783\n",
      "Iteration:760, Price of Hedge: 0.19105888154395528, Loss: 0.0019450278809514997\n",
      "Iteration:770, Price of Hedge: 0.17543503489833084, Loss: 0.0018760161043556488\n",
      "Iteration:780, Price of Hedge: 0.21488391973683035, Loss: 0.0017821305341321869\n",
      "Iteration:790, Price of Hedge: 0.2194393575941518, Loss: 0.001833312028917322\n",
      "Iteration:800, Price of Hedge: 0.2447627060394197, Loss: 0.0019249911517253081\n",
      "Iteration:810, Price of Hedge: 0.2476392531734646, Loss: 0.0015803647073261984\n",
      "Iteration:820, Price of Hedge: 0.2144941026951571, Loss: 0.002150219374710893\n",
      "Iteration:830, Price of Hedge: 0.16476069648527128, Loss: 0.001533987660293201\n",
      "Iteration:840, Price of Hedge: 0.19308150826179257, Loss: 0.0018226532754436863\n",
      "Iteration:850, Price of Hedge: 0.19649085892780674, Loss: 0.0029806775478687484\n",
      "Iteration:860, Price of Hedge: 0.2004527901468606, Loss: 0.0018692793115458461\n",
      "Iteration:870, Price of Hedge: 0.18924443296366888, Loss: 0.0016826261718332124\n",
      "Iteration:880, Price of Hedge: 0.20341612880647517, Loss: 0.0016250773864669888\n",
      "Iteration:890, Price of Hedge: 0.20938263457646258, Loss: 0.001449586491039434\n",
      "Iteration:900, Price of Hedge: 0.19240450300136444, Loss: 0.0014036870558801872\n",
      "Iteration:910, Price of Hedge: 0.19943620422236422, Loss: 0.0015582812450751437\n",
      "Iteration:920, Price of Hedge: 0.20393258542509188, Loss: 0.0016244535356258027\n",
      "Iteration:930, Price of Hedge: 0.24980755166592558, Loss: 0.0015711234764929304\n",
      "Iteration:940, Price of Hedge: 0.23605062444836306, Loss: 0.002012900831159059\n",
      "Iteration:950, Price of Hedge: 0.22611618967096944, Loss: 0.0016559524904325772\n",
      "Iteration:960, Price of Hedge: 0.23118067511423704, Loss: 0.0012354465506412614\n",
      "Iteration:970, Price of Hedge: 0.23083731153137135, Loss: 0.0019016621316092052\n",
      "Iteration:980, Price of Hedge: 0.2039072810304418, Loss: 0.0013561120743526887\n",
      "Iteration:990, Price of Hedge: 0.20544449850466293, Loss: 0.001462417390851367\n",
      "tf.Tensor(0.18195228, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_79 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.19453375706768838, Loss: 0.0033780898280601377\n",
      "Iteration:20, Price of Hedge: 0.1733873389932299, Loss: 0.002085148546875171\n",
      "Iteration:30, Price of Hedge: 0.22323211590056075, Loss: 0.0016612588976980703\n",
      "Iteration:40, Price of Hedge: 0.20459171492415607, Loss: 0.0019445176524284678\n",
      "Iteration:50, Price of Hedge: 0.18502947739873007, Loss: 0.0018722662615969442\n",
      "Iteration:60, Price of Hedge: 0.2035382798424621, Loss: 0.002068899177210848\n",
      "Iteration:70, Price of Hedge: 0.20309571754439587, Loss: 0.001665035231913703\n",
      "Iteration:80, Price of Hedge: 0.1799259083280944, Loss: 0.0021780868561011913\n",
      "Iteration:90, Price of Hedge: 0.1994541191849592, Loss: 0.0016270731272655103\n",
      "Iteration:100, Price of Hedge: 0.22674711388428506, Loss: 0.0020599098449131104\n",
      "Iteration:110, Price of Hedge: 0.21677845643217494, Loss: 0.0017869469260094139\n",
      "Iteration:120, Price of Hedge: 0.19728360582294327, Loss: 0.00210147968785741\n",
      "Iteration:130, Price of Hedge: 0.1899265539847505, Loss: 0.002110485405044693\n",
      "Iteration:140, Price of Hedge: 0.17896898667727326, Loss: 0.001826869245340479\n",
      "Iteration:150, Price of Hedge: 0.18918921802971908, Loss: 0.002028436309654602\n",
      "Iteration:160, Price of Hedge: 0.1965739263364256, Loss: 0.0020575201011164613\n",
      "Iteration:170, Price of Hedge: 0.20060683138431584, Loss: 0.0015339833726585538\n",
      "Iteration:180, Price of Hedge: 0.20019904057820098, Loss: 0.0018538490332289713\n",
      "Iteration:190, Price of Hedge: 0.1954799767824298, Loss: 0.0019415374400889585\n",
      "Iteration:200, Price of Hedge: 0.17661503115450614, Loss: 0.0015785894734523965\n",
      "Iteration:210, Price of Hedge: 0.18946599832162717, Loss: 0.0018642470066381645\n",
      "Iteration:220, Price of Hedge: 0.18976737738602623, Loss: 0.002190722515406862\n",
      "Iteration:230, Price of Hedge: 0.19479963941736145, Loss: 0.0021325973494401907\n",
      "Iteration:240, Price of Hedge: 0.19954704570318996, Loss: 0.0017138692467294268\n",
      "Iteration:250, Price of Hedge: 0.20131521723020854, Loss: 0.0019058111837795377\n",
      "Iteration:260, Price of Hedge: 0.20452985538154136, Loss: 0.0019073738734786793\n",
      "Iteration:270, Price of Hedge: 0.21193555594748117, Loss: 0.0021964057751318934\n",
      "Iteration:280, Price of Hedge: 0.23197101113366328, Loss: 0.0015692626430559907\n",
      "Iteration:290, Price of Hedge: 0.21824667973972822, Loss: 0.0017598460124421344\n",
      "Iteration:300, Price of Hedge: 0.22601461928128969, Loss: 0.00151019649441404\n",
      "Iteration:310, Price of Hedge: 0.2023297450900742, Loss: 0.001919373890947884\n",
      "Iteration:320, Price of Hedge: 0.2275962517503032, Loss: 0.0018193312773708613\n",
      "Iteration:330, Price of Hedge: 0.20985063847348753, Loss: 0.0018461447662869613\n",
      "Iteration:340, Price of Hedge: 0.20884947823341377, Loss: 0.0019269506007591362\n",
      "Iteration:350, Price of Hedge: 0.23192659613887087, Loss: 0.0024231521270422496\n",
      "Iteration:360, Price of Hedge: 0.24319432358650486, Loss: 0.002065039387249401\n",
      "Iteration:370, Price of Hedge: 0.2353558218290331, Loss: 0.0017399818605104977\n",
      "Iteration:380, Price of Hedge: 0.218532201906163, Loss: 0.002097085781122754\n",
      "Iteration:390, Price of Hedge: 0.19419399999808035, Loss: 0.0015538312928304542\n",
      "Iteration:400, Price of Hedge: 0.19354386718154473, Loss: 0.0018736533114053543\n",
      "Iteration:410, Price of Hedge: 0.19497502572512956, Loss: 0.0015695999880248502\n",
      "Iteration:420, Price of Hedge: 0.2077998848723638, Loss: 0.0018822108176421825\n",
      "Iteration:430, Price of Hedge: 0.19813090123110158, Loss: 0.0015487969972352578\n",
      "Iteration:440, Price of Hedge: 0.1696897416752222, Loss: 0.001595887629177417\n",
      "Iteration:450, Price of Hedge: 0.2000440193099692, Loss: 0.0012692084577629714\n",
      "Iteration:460, Price of Hedge: 0.21679829225509195, Loss: 0.001498772704415474\n",
      "Iteration:470, Price of Hedge: 0.19783810723630493, Loss: 0.001885085523543406\n",
      "Iteration:480, Price of Hedge: 0.18909444905362846, Loss: 0.0014263282168950119\n",
      "Iteration:490, Price of Hedge: 0.19425534992469123, Loss: 0.0013609416353934755\n",
      "Iteration:500, Price of Hedge: 0.20604735463653867, Loss: 0.0018404432841146788\n",
      "Iteration:510, Price of Hedge: 0.2030680218746511, Loss: 0.0014018897713139133\n",
      "Iteration:520, Price of Hedge: 0.19807429465344908, Loss: 0.0012821632395902504\n",
      "Iteration:530, Price of Hedge: 0.201681807542478, Loss: 0.0015741343147942066\n",
      "Iteration:540, Price of Hedge: 0.20656982864412327, Loss: 0.0013907953635341475\n",
      "Iteration:550, Price of Hedge: 0.16964761995244684, Loss: 0.0011863926414200532\n",
      "Iteration:560, Price of Hedge: 0.1897996792004207, Loss: 0.0009964165848557415\n",
      "Iteration:570, Price of Hedge: 0.19383960126867095, Loss: 0.0013029334606007525\n",
      "Iteration:580, Price of Hedge: 0.19527087741594898, Loss: 0.0012998806647318562\n",
      "Iteration:590, Price of Hedge: 0.19011820880340904, Loss: 0.0009032807381763264\n",
      "Iteration:600, Price of Hedge: 0.1827497102057464, Loss: 0.0012502652285016568\n",
      "Iteration:610, Price of Hedge: 0.17162855616105047, Loss: 0.0012690292958866367\n",
      "Iteration:620, Price of Hedge: 0.1850064074742505, Loss: 0.0014837604704767138\n",
      "Iteration:630, Price of Hedge: 0.1947823908756945, Loss: 0.0013567690012325827\n",
      "Iteration:640, Price of Hedge: 0.20251418688221748, Loss: 0.0013868587024086665\n",
      "Iteration:650, Price of Hedge: 0.2262115662661415, Loss: 0.001329988588355191\n",
      "Iteration:660, Price of Hedge: 0.2219668569668272, Loss: 0.001258485083510008\n",
      "Iteration:670, Price of Hedge: 0.20530300166114726, Loss: 0.0009714731937300158\n",
      "Iteration:680, Price of Hedge: 0.20328382465164338, Loss: 0.0012081036919760256\n",
      "Iteration:690, Price of Hedge: 0.20559618766825452, Loss: 0.0015178470127931497\n",
      "Iteration:700, Price of Hedge: 0.1996726268468947, Loss: 0.001329544511909575\n",
      "Iteration:710, Price of Hedge: 0.20534357493529568, Loss: 0.0011288563361332492\n",
      "Iteration:720, Price of Hedge: 0.19999170526711793, Loss: 0.0012343559601427523\n",
      "Iteration:730, Price of Hedge: 0.17245315405642428, Loss: 0.0012853197043397268\n",
      "Iteration:740, Price of Hedge: 0.17551245732967685, Loss: 0.0010164604346180439\n",
      "Iteration:750, Price of Hedge: 0.18760721314901047, Loss: 0.0013150875266576434\n",
      "Iteration:760, Price of Hedge: 0.2071436366637826, Loss: 0.0013917427776613978\n",
      "Iteration:770, Price of Hedge: 0.19126004266114618, Loss: 0.001320494233947922\n",
      "Iteration:780, Price of Hedge: 0.18240168167638443, Loss: 0.0014252348700599436\n",
      "Iteration:790, Price of Hedge: 0.19450080843298137, Loss: 0.0011383274913744801\n",
      "Iteration:800, Price of Hedge: 0.2158028553947531, Loss: 0.0012866337112293236\n",
      "Iteration:810, Price of Hedge: 0.2005057706106399, Loss: 0.0012276660250544523\n",
      "Iteration:820, Price of Hedge: 0.21004529218632229, Loss: 0.001215559122978682\n",
      "Iteration:830, Price of Hedge: 0.20565681237209077, Loss: 0.0011483435590404433\n",
      "Iteration:840, Price of Hedge: 0.1827126062405469, Loss: 0.0009766799134899584\n",
      "Iteration:850, Price of Hedge: 0.1978612947644777, Loss: 0.0010923855626932821\n",
      "Iteration:860, Price of Hedge: 0.21726386567579112, Loss: 0.0013254914721293808\n",
      "Iteration:870, Price of Hedge: 0.23317989869713074, Loss: 0.0017758903412924299\n",
      "Iteration:880, Price of Hedge: 0.2161456701603839, Loss: 0.0015086198699022946\n",
      "Iteration:890, Price of Hedge: 0.203742322250136, Loss: 0.0011411199665683602\n",
      "Iteration:900, Price of Hedge: 0.2082489741754017, Loss: 0.0011288817556815156\n",
      "Iteration:910, Price of Hedge: 0.21413670507157148, Loss: 0.0010643936633333072\n",
      "Iteration:920, Price of Hedge: 0.21624708374513943, Loss: 0.001388316957578184\n",
      "Iteration:930, Price of Hedge: 0.20679149200515923, Loss: 0.0014044749087466335\n",
      "Iteration:940, Price of Hedge: 0.22046635144549498, Loss: 0.0011135618073919052\n",
      "Iteration:950, Price of Hedge: 0.21079264405588985, Loss: 0.0011154598513723913\n",
      "Iteration:960, Price of Hedge: 0.19889848093589677, Loss: 0.0010839059229642456\n",
      "Iteration:970, Price of Hedge: 0.19399593577814328, Loss: 0.0012397780569788186\n",
      "Iteration:980, Price of Hedge: 0.19733829154027374, Loss: 0.00095570120624473\n",
      "Iteration:990, Price of Hedge: 0.18331461954595482, Loss: 0.00114162651997598\n",
      "tf.Tensor(0.26177266, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_80 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.32398839401424623, Loss: 0.0035208873561720197\n",
      "Iteration:20, Price of Hedge: 0.17962535248954764, Loss: 0.002642479339714643\n",
      "Iteration:30, Price of Hedge: 0.23762886601088978, Loss: 0.0025097796505866407\n",
      "Iteration:40, Price of Hedge: 0.24028698388546132, Loss: 0.0023733031678535798\n",
      "Iteration:50, Price of Hedge: 0.23433790306268065, Loss: 0.0025818050218203267\n",
      "Iteration:60, Price of Hedge: 0.2260785368885351, Loss: 0.0019960289888218295\n",
      "Iteration:70, Price of Hedge: 0.2344786942840372, Loss: 0.0027208214686925023\n",
      "Iteration:80, Price of Hedge: 0.2210733629078632, Loss: 0.002435285520574948\n",
      "Iteration:90, Price of Hedge: 0.23204968800440326, Loss: 0.0028815388595532674\n",
      "Iteration:100, Price of Hedge: 0.2573729776478245, Loss: 0.002434917549644322\n",
      "Iteration:110, Price of Hedge: 0.26131250536332684, Loss: 0.002616010852257844\n",
      "Iteration:120, Price of Hedge: 0.23906911924008084, Loss: 0.0026646111909852887\n",
      "Iteration:130, Price of Hedge: 0.22615933062575236, Loss: 0.0022608460144148412\n",
      "Iteration:140, Price of Hedge: 0.24669189662302243, Loss: 0.0026724027419183336\n",
      "Iteration:150, Price of Hedge: 0.22728052503533575, Loss: 0.002807911291129761\n",
      "Iteration:160, Price of Hedge: 0.23642229132005496, Loss: 0.0026424116563391387\n",
      "Iteration:170, Price of Hedge: 0.25940777634790635, Loss: 0.0023364169532422486\n",
      "Iteration:180, Price of Hedge: 0.24088574348869116, Loss: 0.0023042440741467994\n",
      "Iteration:190, Price of Hedge: 0.22198447792018924, Loss: 0.0023532786890120947\n",
      "Iteration:200, Price of Hedge: 0.2209071496881634, Loss: 0.0024866633277750073\n",
      "Iteration:210, Price of Hedge: 0.22489432650002072, Loss: 0.0024930986079912177\n",
      "Iteration:220, Price of Hedge: 0.2201508795385294, Loss: 0.002453351009772031\n",
      "Iteration:230, Price of Hedge: 0.23510038660743787, Loss: 0.0023250832035712765\n",
      "Iteration:240, Price of Hedge: 0.227839887401349, Loss: 0.0024813996437261787\n",
      "Iteration:250, Price of Hedge: 0.22863136025647604, Loss: 0.0030680953743565274\n",
      "Iteration:260, Price of Hedge: 0.24092884524224303, Loss: 0.0026876841780610226\n",
      "Iteration:270, Price of Hedge: 0.20898278201963763, Loss: 0.002388075906771325\n",
      "Iteration:280, Price of Hedge: 0.22351275751372837, Loss: 0.00255003609916058\n",
      "Iteration:290, Price of Hedge: 0.22117038595473984, Loss: 0.0027346429652377767\n",
      "Iteration:300, Price of Hedge: 0.24354999635592378, Loss: 0.00244872021122311\n",
      "Iteration:310, Price of Hedge: 0.2573635497517543, Loss: 0.0028495843435652145\n",
      "Iteration:320, Price of Hedge: 0.2372707039632985, Loss: 0.002623418966149571\n",
      "Iteration:330, Price of Hedge: 0.24434776100863614, Loss: 0.002207938899813966\n",
      "Iteration:340, Price of Hedge: 0.2241947413305013, Loss: 0.0029899290383992084\n",
      "Iteration:350, Price of Hedge: 0.23172404337797728, Loss: 0.002210409496149679\n",
      "Iteration:360, Price of Hedge: 0.24187053721479684, Loss: 0.0033068186211349547\n",
      "Iteration:370, Price of Hedge: 0.27678148754564375, Loss: 0.002513973876050579\n",
      "Iteration:380, Price of Hedge: 0.2520572123134542, Loss: 0.0025119272961555248\n",
      "Iteration:390, Price of Hedge: 0.2524540267748719, Loss: 0.002584370252377899\n",
      "Iteration:400, Price of Hedge: 0.24573473976481494, Loss: 0.0023260528215208074\n",
      "Iteration:410, Price of Hedge: 0.20880275036598875, Loss: 0.002404197872434699\n",
      "Iteration:420, Price of Hedge: 0.22074395496325536, Loss: 0.002283534798800213\n",
      "Iteration:430, Price of Hedge: 0.2112988299519685, Loss: 0.0021911560258956685\n",
      "Iteration:440, Price of Hedge: 0.22019909705273477, Loss: 0.0027434218971781775\n",
      "Iteration:450, Price of Hedge: 0.23215819701198084, Loss: 0.002384715779376101\n",
      "Iteration:460, Price of Hedge: 0.2593289622728577, Loss: 0.009032871390023355\n",
      "Iteration:470, Price of Hedge: 0.22474179450996132, Loss: 0.002423533420266244\n",
      "Iteration:480, Price of Hedge: 0.2234896091867867, Loss: 0.003147790864584854\n",
      "Iteration:490, Price of Hedge: 0.244629186646425, Loss: 0.0025702333084264284\n",
      "Iteration:500, Price of Hedge: 0.24282297032466146, Loss: 0.0025945062206841783\n",
      "Iteration:510, Price of Hedge: 0.26879562836061266, Loss: 0.0022086949016801747\n",
      "Iteration:520, Price of Hedge: 0.2379908893797406, Loss: 0.002204253371574971\n",
      "Iteration:530, Price of Hedge: 0.2521256576628872, Loss: 0.002275653513799192\n",
      "Iteration:540, Price of Hedge: 0.2757039633074626, Loss: 0.0023709723790333315\n",
      "Iteration:550, Price of Hedge: 0.22598182745150694, Loss: 0.0019218633222500836\n",
      "Iteration:560, Price of Hedge: 0.22277793043748487, Loss: 0.002440976130530803\n",
      "Iteration:570, Price of Hedge: 0.21046004121095052, Loss: 0.0026479390299187777\n",
      "Iteration:580, Price of Hedge: 0.1974943712417442, Loss: 0.001700540062519551\n",
      "Iteration:590, Price of Hedge: 0.1808322603908465, Loss: 0.0016645488916408491\n",
      "Iteration:600, Price of Hedge: 0.21598812041274867, Loss: 0.0016265971998196572\n",
      "Iteration:610, Price of Hedge: 0.21718830530292052, Loss: 0.0029777659376835964\n",
      "Iteration:620, Price of Hedge: 0.228047183511201, Loss: 0.0021032426713465057\n",
      "Iteration:630, Price of Hedge: 0.22571382823535657, Loss: 0.0018314697241872512\n",
      "Iteration:640, Price of Hedge: 0.22215133796020153, Loss: 0.0016427317221273552\n",
      "Iteration:650, Price of Hedge: 0.2173806853443537, Loss: 0.0019575234264820884\n",
      "Iteration:660, Price of Hedge: 0.22884049882418792, Loss: 0.0013618951747130792\n",
      "Iteration:670, Price of Hedge: 0.23698322173531067, Loss: 0.0016361505092033267\n",
      "Iteration:680, Price of Hedge: 0.237459771500707, Loss: 0.0016905938220464155\n",
      "Iteration:690, Price of Hedge: 0.22804592907180704, Loss: 0.001363311931704403\n",
      "Iteration:700, Price of Hedge: 0.2456111578838943, Loss: 0.001450633439542426\n",
      "Iteration:710, Price of Hedge: 0.2415622979349621, Loss: 0.0017364047481761569\n",
      "Iteration:720, Price of Hedge: 0.2577116958848094, Loss: 0.0019252012458230272\n",
      "Iteration:730, Price of Hedge: 0.27378845395350027, Loss: 0.0017685056562614543\n",
      "Iteration:740, Price of Hedge: 0.2789669953785406, Loss: 0.0016559803600577848\n",
      "Iteration:750, Price of Hedge: 0.2521946322289395, Loss: 0.0016971228177056318\n",
      "Iteration:760, Price of Hedge: 0.2411912190817361, Loss: 0.0015354780727225737\n",
      "Iteration:770, Price of Hedge: 0.22769372561133708, Loss: 0.0014386158121452053\n",
      "Iteration:780, Price of Hedge: 0.24184848652232488, Loss: 0.0011245720703417172\n",
      "Iteration:790, Price of Hedge: 0.23802552366738325, Loss: 0.0014967970236219096\n",
      "Iteration:800, Price of Hedge: 0.25160328165838025, Loss: 0.0013799421352032935\n",
      "Iteration:810, Price of Hedge: 0.22129833877292385, Loss: 0.0013098161861183732\n",
      "Iteration:820, Price of Hedge: 0.22324011295169724, Loss: 0.0017509765807847133\n",
      "Iteration:830, Price of Hedge: 0.21594513626289, Loss: 0.0019228424342477622\n",
      "Iteration:840, Price of Hedge: 0.2027794028109625, Loss: 0.0017778355492540365\n",
      "Iteration:850, Price of Hedge: 0.22788804611370778, Loss: 0.0016119590620038758\n",
      "Iteration:860, Price of Hedge: 0.2525526766728376, Loss: 0.0018548068601832223\n",
      "Iteration:870, Price of Hedge: 0.23824697142164836, Loss: 0.0015740661720292759\n",
      "Iteration:880, Price of Hedge: 0.22677367271832907, Loss: 0.0015970091518973106\n",
      "Iteration:890, Price of Hedge: 0.22908013594966548, Loss: 0.0017415451627288746\n",
      "Iteration:900, Price of Hedge: 0.24563705029701025, Loss: 0.0018065136998522968\n",
      "Iteration:910, Price of Hedge: 0.23907739069983477, Loss: 0.0016018295251495672\n",
      "Iteration:920, Price of Hedge: 0.2289212141589431, Loss: 0.0020546894966001817\n",
      "Iteration:930, Price of Hedge: 0.21969716449022628, Loss: 0.001423404356325153\n",
      "Iteration:940, Price of Hedge: 0.2348238807241472, Loss: 0.0013619427980836262\n",
      "Iteration:950, Price of Hedge: 0.25317652506394667, Loss: 0.0017522285701017325\n",
      "Iteration:960, Price of Hedge: 0.2418534846792852, Loss: 0.0015511184451371673\n",
      "Iteration:970, Price of Hedge: 0.23650143860556766, Loss: 0.0018987581779144945\n",
      "Iteration:980, Price of Hedge: 0.2123657698577631, Loss: 0.0018319871498112983\n",
      "Iteration:990, Price of Hedge: 0.19994640824462664, Loss: 0.0014833477856419086\n",
      "tf.Tensor(0.20062697, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_81 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.10820324777562504, Loss: 0.0027433967838895288\n",
      "Iteration:20, Price of Hedge: 0.2202172864239472, Loss: 0.0020717161531741413\n",
      "Iteration:30, Price of Hedge: 0.22106916837613966, Loss: 0.0020253680476750133\n",
      "Iteration:40, Price of Hedge: 0.18414094229549532, Loss: 0.0015864883683814335\n",
      "Iteration:50, Price of Hedge: 0.20785010164935327, Loss: 0.0016297029786024096\n",
      "Iteration:60, Price of Hedge: 0.2208442905141567, Loss: 0.0022558979309020176\n",
      "Iteration:70, Price of Hedge: 0.19858885001235932, Loss: 0.0017738338079598015\n",
      "Iteration:80, Price of Hedge: 0.1846603782076727, Loss: 0.0018920729898502687\n",
      "Iteration:90, Price of Hedge: 0.21628736301005488, Loss: 0.0019757815529786835\n",
      "Iteration:100, Price of Hedge: 0.21340081956208934, Loss: 0.0021252651879336447\n",
      "Iteration:110, Price of Hedge: 0.2131265089477381, Loss: 0.0019134431734517787\n",
      "Iteration:120, Price of Hedge: 0.18705984635970196, Loss: 0.0017266427228630477\n",
      "Iteration:130, Price of Hedge: 0.2072460106786991, Loss: 0.0020526098406664192\n",
      "Iteration:140, Price of Hedge: 0.1973606558425942, Loss: 0.002290142962570596\n",
      "Iteration:150, Price of Hedge: 0.1861984973102082, Loss: 0.0022017754250084343\n",
      "Iteration:160, Price of Hedge: 0.19919923278059884, Loss: 0.0018029183650707047\n",
      "Iteration:170, Price of Hedge: 0.1983710479725829, Loss: 0.0019062322907538287\n",
      "Iteration:180, Price of Hedge: 0.2148649463409967, Loss: 0.0021433714096598775\n",
      "Iteration:190, Price of Hedge: 0.2409212794046482, Loss: 0.002364467424754102\n",
      "Iteration:200, Price of Hedge: 0.2301778096206121, Loss: 0.002319874493123819\n",
      "Iteration:210, Price of Hedge: 0.20963087637215808, Loss: 0.0017773893289910968\n",
      "Iteration:220, Price of Hedge: 0.2137027866449543, Loss: 0.0018745359516234683\n",
      "Iteration:230, Price of Hedge: 0.1889137901802826, Loss: 0.00153630788315664\n",
      "Iteration:240, Price of Hedge: 0.1752333445645206, Loss: 0.0021243490122873966\n",
      "Iteration:250, Price of Hedge: 0.17074086388428356, Loss: 0.002319688134146469\n",
      "Iteration:260, Price of Hedge: 0.1880930340055528, Loss: 0.001990090002316047\n",
      "Iteration:270, Price of Hedge: 0.17829064857498905, Loss: 0.00169720703910049\n",
      "Iteration:280, Price of Hedge: 0.19799126644606133, Loss: 0.0021449584469986236\n",
      "Iteration:290, Price of Hedge: 0.17893609684441286, Loss: 0.001823740803346019\n",
      "Iteration:300, Price of Hedge: 0.20719473546847098, Loss: 0.0019616551749840226\n",
      "Iteration:310, Price of Hedge: 0.19819217275525033, Loss: 0.001949961417132484\n",
      "Iteration:320, Price of Hedge: 0.2020529647981661, Loss: 0.0017143735031899144\n",
      "Iteration:330, Price of Hedge: 0.1925419033162342, Loss: 0.0020867300715407986\n",
      "Iteration:340, Price of Hedge: 0.18000137069788735, Loss: 0.001646867605134128\n",
      "Iteration:350, Price of Hedge: 0.17941889920616347, Loss: 0.0021852397026015935\n",
      "Iteration:360, Price of Hedge: 0.19860551053556036, Loss: 0.0019204608063309813\n",
      "Iteration:370, Price of Hedge: 0.2125454879015635, Loss: 0.001813479421726305\n",
      "Iteration:380, Price of Hedge: 0.22554712500026852, Loss: 0.0018979932945193732\n",
      "Iteration:390, Price of Hedge: 0.22174045025683284, Loss: 0.002002088029097737\n",
      "Iteration:400, Price of Hedge: 0.2185607600029911, Loss: 0.0018465180967608963\n",
      "Iteration:410, Price of Hedge: 0.24067288080402846, Loss: 0.0020051409780964423\n",
      "Iteration:420, Price of Hedge: 0.2271574527704189, Loss: 0.0022986808681918934\n",
      "Iteration:430, Price of Hedge: 0.20624030309582222, Loss: 0.0019036153023208712\n",
      "Iteration:440, Price of Hedge: 0.19539404768394347, Loss: 0.002100353264983634\n",
      "Iteration:450, Price of Hedge: 0.1875055643568686, Loss: 0.001731465239932628\n",
      "Iteration:460, Price of Hedge: 0.18481763394607498, Loss: 0.0021435465901611826\n",
      "Iteration:470, Price of Hedge: 0.17974526905536406, Loss: 0.0017401957828534376\n",
      "Iteration:480, Price of Hedge: 0.1712245286731175, Loss: 0.0014897823002090749\n",
      "Iteration:490, Price of Hedge: 0.18551900277160768, Loss: 0.0015942159110543862\n",
      "Iteration:500, Price of Hedge: 0.18640863550931214, Loss: 0.0022413071101971657\n",
      "Iteration:510, Price of Hedge: 0.19647484522491823, Loss: 0.001774347864728054\n",
      "Iteration:520, Price of Hedge: 0.1958665009206939, Loss: 0.0018697942870929518\n",
      "Iteration:530, Price of Hedge: 0.20476484716113816, Loss: 0.001540420796692088\n",
      "Iteration:540, Price of Hedge: 0.22225800450991925, Loss: 0.0018326696493692672\n",
      "Iteration:550, Price of Hedge: 0.1917313394615803, Loss: 0.0012393456949635784\n",
      "Iteration:560, Price of Hedge: 0.18659744823871874, Loss: 0.004401372731616026\n",
      "Iteration:570, Price of Hedge: 0.1854534387126577, Loss: 0.0014665378077474477\n",
      "Iteration:580, Price of Hedge: 0.23017132181687144, Loss: 0.0016491630209685359\n",
      "Iteration:590, Price of Hedge: 0.2086688781619145, Loss: 0.0017459131905258384\n",
      "Iteration:600, Price of Hedge: 0.19429378673174683, Loss: 0.0018256762109998602\n",
      "Iteration:610, Price of Hedge: 0.18885796762725135, Loss: 0.0016455543638935755\n",
      "Iteration:620, Price of Hedge: 0.201096376357809, Loss: 0.001238077167627205\n",
      "Iteration:630, Price of Hedge: 0.19774373027252493, Loss: 0.0012680956634421813\n",
      "Iteration:640, Price of Hedge: 0.18685458871386515, Loss: 0.0010971986622796191\n",
      "Iteration:650, Price of Hedge: 0.19107256277359566, Loss: 0.00126266568042096\n",
      "Iteration:660, Price of Hedge: 0.1881506990164439, Loss: 0.0014348835793145164\n",
      "Iteration:670, Price of Hedge: 0.19504717559089782, Loss: 0.001356783395434613\n",
      "Iteration:680, Price of Hedge: 0.21170897283194703, Loss: 0.0014685967911570175\n",
      "Iteration:690, Price of Hedge: 0.22779570761394297, Loss: 0.0015882985158516493\n",
      "Iteration:700, Price of Hedge: 0.2432363081049715, Loss: 0.0018009042486951232\n",
      "Iteration:710, Price of Hedge: 0.22009088205439012, Loss: 0.0013008067938156786\n",
      "Iteration:720, Price of Hedge: 0.19970929959855255, Loss: 0.0018310559674437842\n",
      "Iteration:730, Price of Hedge: 0.2035773830704457, Loss: 0.0013495383647892933\n",
      "Iteration:740, Price of Hedge: 0.20451231283064145, Loss: 0.00134883412079847\n",
      "Iteration:750, Price of Hedge: 0.19212946716423857, Loss: 0.0009959031406067242\n",
      "Iteration:760, Price of Hedge: 0.2053797380709497, Loss: 0.0009485229401960616\n",
      "Iteration:770, Price of Hedge: 0.23062976061351748, Loss: 0.0012505627597202194\n",
      "Iteration:780, Price of Hedge: 0.22154026917041847, Loss: 0.0013291250893631811\n",
      "Iteration:790, Price of Hedge: 0.23637107491167342, Loss: 0.0013696303738764736\n",
      "Iteration:800, Price of Hedge: 0.20412859158039823, Loss: 0.0012110377356781721\n",
      "Iteration:810, Price of Hedge: 0.1862362480957202, Loss: 0.0012482417712077365\n",
      "Iteration:820, Price of Hedge: 0.2099394096612258, Loss: 0.0012511867636912143\n",
      "Iteration:830, Price of Hedge: 0.21192783330496212, Loss: 0.0013592003963372346\n",
      "Iteration:840, Price of Hedge: 0.21674172487867052, Loss: 0.001377826340634647\n",
      "Iteration:850, Price of Hedge: 0.22130594381174973, Loss: 0.0011687356259880322\n",
      "Iteration:860, Price of Hedge: 0.22420509045550147, Loss: 0.0012035739591009342\n",
      "Iteration:870, Price of Hedge: 0.1937911289464637, Loss: 0.0010516773811832857\n",
      "Iteration:880, Price of Hedge: 0.21609265049537354, Loss: 0.0014190739984611621\n",
      "Iteration:890, Price of Hedge: 0.20449145777571687, Loss: 0.0012167879896945676\n",
      "Iteration:900, Price of Hedge: 0.16202590100274392, Loss: 0.0013255462926009432\n",
      "Iteration:910, Price of Hedge: 0.18942097570775332, Loss: 0.001129815770950493\n",
      "Iteration:920, Price of Hedge: 0.1575163383860719, Loss: 0.0010496208478506573\n",
      "Iteration:930, Price of Hedge: 0.18033497317421876, Loss: 0.0012707852354045257\n",
      "Iteration:940, Price of Hedge: 0.22804677189827485, Loss: 0.0012387391477907904\n",
      "Iteration:950, Price of Hedge: 0.2074022471850938, Loss: 0.001212835403068968\n",
      "Iteration:960, Price of Hedge: 0.207674930948356, Loss: 0.0011386591705404125\n",
      "Iteration:970, Price of Hedge: 0.21427588904245454, Loss: 0.0010277568206156606\n",
      "Iteration:980, Price of Hedge: 0.2015534627119834, Loss: 0.0013808287567964371\n",
      "Iteration:990, Price of Hedge: 0.1914519326871911, Loss: 0.0010926214591637895\n",
      "tf.Tensor(0.18920562, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_82 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.17234162655405497, Loss: 0.004920789655697089\n",
      "Iteration:20, Price of Hedge: 0.23578703537070708, Loss: 0.0019071368285346058\n",
      "Iteration:30, Price of Hedge: 0.18617844588052038, Loss: 0.0017174886228910058\n",
      "Iteration:40, Price of Hedge: 0.17265413876807542, Loss: 0.0018308962530531713\n",
      "Iteration:50, Price of Hedge: 0.22498239206559986, Loss: 0.0026354751822586175\n",
      "Iteration:60, Price of Hedge: 0.1999265528210941, Loss: 0.0019360183355189963\n",
      "Iteration:70, Price of Hedge: 0.17594202441964626, Loss: 0.0015189498536763656\n",
      "Iteration:80, Price of Hedge: 0.20219214876904915, Loss: 0.0018723745243717893\n",
      "Iteration:90, Price of Hedge: 0.2205368744601742, Loss: 0.001924721643261762\n",
      "Iteration:100, Price of Hedge: 0.21305482949674256, Loss: 0.0018031223339760704\n",
      "Iteration:110, Price of Hedge: 0.19208689462730602, Loss: 0.0015736263832183072\n",
      "Iteration:120, Price of Hedge: 0.1992317698023797, Loss: 0.0018457689857360848\n",
      "Iteration:130, Price of Hedge: 0.19696801631228453, Loss: 0.0020480675511470037\n",
      "Iteration:140, Price of Hedge: 0.23256261651222446, Loss: 0.001952727553999245\n",
      "Iteration:150, Price of Hedge: 0.1822118301143547, Loss: 0.0017031176965916384\n",
      "Iteration:160, Price of Hedge: 0.17123801389660256, Loss: 0.0024791445010314936\n",
      "Iteration:170, Price of Hedge: 0.16898802003860994, Loss: 0.0018967654997121496\n",
      "Iteration:180, Price of Hedge: 0.18314099729358446, Loss: 0.0016819626603715387\n",
      "Iteration:190, Price of Hedge: 0.1928330312587107, Loss: 0.0015317055667521617\n",
      "Iteration:200, Price of Hedge: 0.1968393382713259, Loss: 0.0021289690917496995\n",
      "Iteration:210, Price of Hedge: 0.22008623670850938, Loss: 0.0018483135437694642\n",
      "Iteration:220, Price of Hedge: 0.2210100137184682, Loss: 0.0015942865038962584\n",
      "Iteration:230, Price of Hedge: 0.23676696814416118, Loss: 0.002128678604502343\n",
      "Iteration:240, Price of Hedge: 0.22194537469220563, Loss: 0.0016516605681506035\n",
      "Iteration:250, Price of Hedge: 0.23389651680154627, Loss: 0.0017054356225079447\n",
      "Iteration:260, Price of Hedge: 0.210209545344469, Loss: 0.001804332825114896\n",
      "Iteration:270, Price of Hedge: 0.22149156164082484, Loss: 0.0018936713587948684\n",
      "Iteration:280, Price of Hedge: 0.23084268210002676, Loss: 0.0023767345006099117\n",
      "Iteration:290, Price of Hedge: 0.21523045861941198, Loss: 0.001365952961517347\n",
      "Iteration:300, Price of Hedge: 0.20670142717679596, Loss: 0.0017698962280554675\n",
      "Iteration:310, Price of Hedge: 0.20132586036444167, Loss: 0.0018292216254637728\n",
      "Iteration:320, Price of Hedge: 0.21279545455142568, Loss: 0.0016696269823613717\n",
      "Iteration:330, Price of Hedge: 0.2040697113313442, Loss: 0.0020452288307508558\n",
      "Iteration:340, Price of Hedge: 0.20669560579398336, Loss: 0.0016950872631568137\n",
      "Iteration:350, Price of Hedge: 0.2199467195271623, Loss: 0.001614770984683478\n",
      "Iteration:360, Price of Hedge: 0.22088911712187523, Loss: 0.0015358792728217164\n",
      "Iteration:370, Price of Hedge: 0.20030335505405503, Loss: 0.0015009499040374628\n",
      "Iteration:380, Price of Hedge: 0.2134906295824507, Loss: 0.00163735211881324\n",
      "Iteration:390, Price of Hedge: 0.21706495862938624, Loss: 0.0017368048763666377\n",
      "Iteration:400, Price of Hedge: 0.1933279664014748, Loss: 0.0015441429229553938\n",
      "Iteration:410, Price of Hedge: 0.2147414624631537, Loss: 0.001970149132350185\n",
      "Iteration:420, Price of Hedge: 0.22249556397015055, Loss: 0.001743025621720673\n",
      "Iteration:430, Price of Hedge: 0.21470067358223446, Loss: 0.0017102212352935963\n",
      "Iteration:440, Price of Hedge: 0.19112636646322725, Loss: 0.0020964190539350946\n",
      "Iteration:450, Price of Hedge: 0.1579960046493376, Loss: 0.0016402704667099809\n",
      "Iteration:460, Price of Hedge: 0.20291090334055753, Loss: 0.0015303641496267838\n",
      "Iteration:470, Price of Hedge: 0.21389371624083822, Loss: 0.0017308472080241777\n",
      "Iteration:480, Price of Hedge: 0.20231429980503604, Loss: 0.0013620469263536327\n",
      "Iteration:490, Price of Hedge: 0.162062269944861, Loss: 0.0016921820844236323\n",
      "Iteration:500, Price of Hedge: 0.21113583123321575, Loss: 0.0016987371121503503\n",
      "Iteration:510, Price of Hedge: 0.19640692909210458, Loss: 0.001896957830752044\n",
      "Iteration:520, Price of Hedge: 0.19992255429552586, Loss: 0.0013281603715675327\n",
      "Iteration:530, Price of Hedge: 0.19615625682008328, Loss: 0.0016131113638153448\n",
      "Iteration:540, Price of Hedge: 0.21348961035044312, Loss: 0.0020676663291199324\n",
      "Iteration:550, Price of Hedge: 0.19872462347614003, Loss: 0.0016527989351494687\n",
      "Iteration:560, Price of Hedge: 0.20949735697916338, Loss: 0.0017158927040233473\n",
      "Iteration:570, Price of Hedge: 0.22210792259680118, Loss: 0.0014533147424950932\n",
      "Iteration:580, Price of Hedge: 0.20388348588318764, Loss: 0.001319028322287963\n",
      "Iteration:590, Price of Hedge: 0.19673276972468584, Loss: 0.0013174054525739497\n",
      "Iteration:600, Price of Hedge: 0.20532681640901698, Loss: 0.0010827496397777469\n",
      "Iteration:610, Price of Hedge: 0.20876505838232332, Loss: 0.001307297200763069\n",
      "Iteration:620, Price of Hedge: 0.22669668150052472, Loss: 0.002128243715845257\n",
      "Iteration:630, Price of Hedge: 0.19921358043116724, Loss: 0.0017599397278851403\n",
      "Iteration:640, Price of Hedge: 0.21312615613665856, Loss: 0.0013713941230146132\n",
      "Iteration:650, Price of Hedge: 0.2168543696161251, Loss: 0.0012203513203461135\n",
      "Iteration:660, Price of Hedge: 0.2266552065980619, Loss: 0.001564799368517933\n",
      "Iteration:670, Price of Hedge: 0.22166438026795846, Loss: 0.0015188183151705781\n",
      "Iteration:680, Price of Hedge: 0.223488844762781, Loss: 0.0012635856843124292\n",
      "Iteration:690, Price of Hedge: 0.20212830956426586, Loss: 0.0011470100281002205\n",
      "Iteration:700, Price of Hedge: 0.1737933069421004, Loss: 0.0011873902821246008\n",
      "Iteration:710, Price of Hedge: 0.18927667597621678, Loss: 0.0009435701862240686\n",
      "Iteration:720, Price of Hedge: 0.1998109483906944, Loss: 0.0011879002809529193\n",
      "Iteration:730, Price of Hedge: 0.20032152482465193, Loss: 0.0011306089833602484\n",
      "Iteration:740, Price of Hedge: 0.21784968887277073, Loss: 0.0010587335262094099\n",
      "Iteration:750, Price of Hedge: 0.22178049431436192, Loss: 0.0011266196455805289\n",
      "Iteration:760, Price of Hedge: 0.21337496635020442, Loss: 0.0012478848256233465\n",
      "Iteration:770, Price of Hedge: 0.21491692717338395, Loss: 0.0013696432367804156\n",
      "Iteration:780, Price of Hedge: 0.2155380902801653, Loss: 0.0012080637250959203\n",
      "Iteration:790, Price of Hedge: 0.20192118985995364, Loss: 0.0012898687315707313\n",
      "Iteration:800, Price of Hedge: 0.18286384458998128, Loss: 0.0013869710996883499\n",
      "Iteration:810, Price of Hedge: 0.19864224208906478, Loss: 0.0017263395258415581\n",
      "Iteration:820, Price of Hedge: 0.2209891586635436, Loss: 0.0013643250385196426\n",
      "Iteration:830, Price of Hedge: 0.24080212726283748, Loss: 0.0013601854803974578\n",
      "Iteration:840, Price of Hedge: 0.2083332176209524, Loss: 0.0010182080285613515\n",
      "Iteration:850, Price of Hedge: 0.18328433659496, Loss: 0.001304233073288319\n",
      "Iteration:860, Price of Hedge: 0.20325963749207857, Loss: 0.0011544021399269243\n",
      "Iteration:870, Price of Hedge: 0.2068032523744776, Loss: 0.0012908525905924839\n",
      "Iteration:880, Price of Hedge: 0.20240312979462088, Loss: 0.0012304453310847728\n",
      "Iteration:890, Price of Hedge: 0.21092692787289025, Loss: 0.001287948024378538\n",
      "Iteration:900, Price of Hedge: 0.22687685035848232, Loss: 0.001490601391556523\n",
      "Iteration:910, Price of Hedge: 0.23695274277816053, Loss: 0.001534176928736919\n",
      "Iteration:920, Price of Hedge: 0.21196413364492486, Loss: 0.0010513063476564831\n",
      "Iteration:930, Price of Hedge: 0.19133807271157366, Loss: 0.0010151408384904248\n",
      "Iteration:940, Price of Hedge: 0.2073462678271383, Loss: 0.0011879578577610405\n",
      "Iteration:950, Price of Hedge: 0.21145177355495406, Loss: 0.0013657307701647303\n",
      "Iteration:960, Price of Hedge: 0.21035802000711357, Loss: 0.001128651907838457\n",
      "Iteration:970, Price of Hedge: 0.22689825423064178, Loss: 0.0014739534249998076\n",
      "Iteration:980, Price of Hedge: 0.21247900261368358, Loss: 0.0012673223579075742\n",
      "Iteration:990, Price of Hedge: 0.22228034921162418, Loss: 0.0013107825883419187\n",
      "tf.Tensor(0.18876679, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_83 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.16054228141169133, Loss: 0.0016264777585687674\n",
      "Iteration:20, Price of Hedge: 0.23876638773321018, Loss: 0.002173841179021485\n",
      "Iteration:30, Price of Hedge: 0.19007885076742354, Loss: 0.001939975516038861\n",
      "Iteration:40, Price of Hedge: 0.18579154933056116, Loss: 0.00167811098628996\n",
      "Iteration:50, Price of Hedge: 0.21044463512714343, Loss: 0.001427689540895538\n",
      "Iteration:60, Price of Hedge: 0.20129471498636348, Loss: 0.0019018883043368517\n",
      "Iteration:70, Price of Hedge: 0.1959059765603726, Loss: 0.0016527242078027582\n",
      "Iteration:80, Price of Hedge: 0.19616137258073676, Loss: 0.0019015988889981572\n",
      "Iteration:90, Price of Hedge: 0.18610082744301906, Loss: 0.0017775338835306354\n",
      "Iteration:100, Price of Hedge: 0.19436078163563053, Loss: 0.00198613971263758\n",
      "Iteration:110, Price of Hedge: 0.18800853575200022, Loss: 0.0016322735687032907\n",
      "Iteration:120, Price of Hedge: 0.21144287487550315, Loss: 0.0019120150848546014\n",
      "Iteration:130, Price of Hedge: 0.1998925065519174, Loss: 0.002633022655240347\n",
      "Iteration:140, Price of Hedge: 0.20332722041442822, Loss: 0.0018767338237696495\n",
      "Iteration:150, Price of Hedge: 0.21279461172495787, Loss: 0.0017003636569797754\n",
      "Iteration:160, Price of Hedge: 0.16842654080611935, Loss: 0.0021797221293297195\n",
      "Iteration:170, Price of Hedge: 0.18271507591810376, Loss: 0.0019601647625546504\n",
      "Iteration:180, Price of Hedge: 0.1628351320155417, Loss: 0.0019553472987687615\n",
      "Iteration:190, Price of Hedge: 0.17997686992847406, Loss: 0.0017933702621005354\n",
      "Iteration:200, Price of Hedge: 0.1874062088367438, Loss: 0.0018729415640538981\n",
      "Iteration:210, Price of Hedge: 0.1981117318291126, Loss: 0.0018390199425415753\n",
      "Iteration:220, Price of Hedge: 0.18647000503653857, Loss: 0.0019057704512503882\n",
      "Iteration:230, Price of Hedge: 0.18587389151640535, Loss: 0.0016282292573222001\n",
      "Iteration:240, Price of Hedge: 0.23039890456379766, Loss: 0.00204974508820277\n",
      "Iteration:250, Price of Hedge: 0.22356616919104935, Loss: 0.0016248107874698102\n",
      "Iteration:260, Price of Hedge: 0.20511291489173117, Loss: 0.0019930858338960576\n",
      "Iteration:270, Price of Hedge: 0.19130079234083439, Loss: 0.0016443884335291203\n",
      "Iteration:280, Price of Hedge: 0.19615853049148482, Loss: 0.0018762917380115483\n",
      "Iteration:290, Price of Hedge: 0.1755831175486648, Loss: 0.001687220066098205\n",
      "Iteration:300, Price of Hedge: 0.19611354707884202, Loss: 0.0016857053060292282\n",
      "Iteration:310, Price of Hedge: 0.18803926951715225, Loss: 0.0021100016679785893\n",
      "Iteration:320, Price of Hedge: 0.17434184976834075, Loss: 0.0016993186991642983\n",
      "Iteration:330, Price of Hedge: 0.18623358241200805, Loss: 0.0016893491829602203\n",
      "Iteration:340, Price of Hedge: 0.20338114170775298, Loss: 0.001557640703084795\n",
      "Iteration:350, Price of Hedge: 0.1887337585266337, Loss: 0.0014698423490220657\n",
      "Iteration:360, Price of Hedge: 0.18981269400913306, Loss: 0.0014872117101081938\n",
      "Iteration:370, Price of Hedge: 0.17423843692080113, Loss: 0.002224405254417405\n",
      "Iteration:380, Price of Hedge: 0.16727416181722674, Loss: 0.001670040432845221\n",
      "Iteration:390, Price of Hedge: 0.16967472760372573, Loss: 0.0018111487860358654\n",
      "Iteration:400, Price of Hedge: 0.19323082575090494, Loss: 0.001818534236715885\n",
      "Iteration:410, Price of Hedge: 0.18808025440422682, Loss: 0.0016812141618659626\n",
      "Iteration:420, Price of Hedge: 0.19741302868729207, Loss: 0.0018652556726889479\n",
      "Iteration:430, Price of Hedge: 0.17634319021771175, Loss: 0.001546148157802063\n",
      "Iteration:440, Price of Hedge: 0.18459453974010528, Loss: 0.0019524511546943012\n",
      "Iteration:450, Price of Hedge: 0.19835707273370956, Loss: 0.0017959993477883907\n",
      "Iteration:460, Price of Hedge: 0.18111815496897635, Loss: 0.0019251249871782283\n",
      "Iteration:470, Price of Hedge: 0.20480267634911228, Loss: 0.0015382027114111407\n",
      "Iteration:480, Price of Hedge: 0.19666971454452378, Loss: 0.0015271424515787447\n",
      "Iteration:490, Price of Hedge: 0.18004245358803955, Loss: 0.0013589148092437609\n",
      "Iteration:500, Price of Hedge: 0.15967229829105634, Loss: 0.0017226578258477843\n",
      "Iteration:510, Price of Hedge: 0.17273867622285904, Loss: 0.0016818773670680186\n",
      "Iteration:520, Price of Hedge: 0.213020234410331, Loss: 0.0015716718343383618\n",
      "Iteration:530, Price of Hedge: 0.18426097646500494, Loss: 0.0012849404018032472\n",
      "Iteration:540, Price of Hedge: 0.19851330924010427, Loss: 0.0014680429206384682\n",
      "Iteration:550, Price of Hedge: 0.17962531328831657, Loss: 0.00966767530017556\n",
      "Iteration:560, Price of Hedge: 0.16602397575683625, Loss: 0.0014629440042639441\n",
      "Iteration:570, Price of Hedge: 0.19198816632687823, Loss: 0.0016927854158704347\n",
      "Iteration:580, Price of Hedge: 0.1472609239287486, Loss: 0.0016395461627142004\n",
      "Iteration:590, Price of Hedge: 0.1772817656923962, Loss: 0.0017225538507075866\n",
      "Iteration:600, Price of Hedge: 0.16783228934446157, Loss: 0.001545928722786005\n",
      "Iteration:610, Price of Hedge: 0.19463373980751014, Loss: 0.0015376421031810027\n",
      "Iteration:620, Price of Hedge: 0.20720579021563026, Loss: 0.001992246835673461\n",
      "Iteration:630, Price of Hedge: 0.22862867497214837, Loss: 0.001892662539614276\n",
      "Iteration:640, Price of Hedge: 0.20966290377793512, Loss: 0.001623643325807267\n",
      "Iteration:650, Price of Hedge: 0.22107606779280645, Loss: 0.0017394580034344796\n",
      "Iteration:660, Price of Hedge: 0.19041200242959774, Loss: 0.0017179463278896078\n",
      "Iteration:670, Price of Hedge: 0.1941803383690555, Loss: 0.00185756947506438\n",
      "Iteration:680, Price of Hedge: 0.1988847409044098, Loss: 0.001395229696538336\n",
      "Iteration:690, Price of Hedge: 0.20819873779779668, Loss: 0.001302740210782005\n",
      "Iteration:700, Price of Hedge: 0.20568801655201555, Loss: 0.001406377087231958\n",
      "Iteration:710, Price of Hedge: 0.19179462984912873, Loss: 0.0015955141455736733\n",
      "Iteration:720, Price of Hedge: 0.1845252515642045, Loss: 0.0017513018284986746\n",
      "Iteration:730, Price of Hedge: 0.20029167308719878, Loss: 0.0015834689548108627\n",
      "Iteration:740, Price of Hedge: 0.19714026652156774, Loss: 0.0011789349134702642\n",
      "Iteration:750, Price of Hedge: 0.213405719715972, Loss: 0.0016158951106101215\n",
      "Iteration:760, Price of Hedge: 0.18706549133697478, Loss: 0.0021486366250067944\n",
      "Iteration:770, Price of Hedge: 0.20671352075657837, Loss: 0.0018778551933597341\n",
      "Iteration:780, Price of Hedge: 0.2058346291561847, Loss: 0.0016399005050918402\n",
      "Iteration:790, Price of Hedge: 0.2084264577490316, Loss: 0.0015360026954476357\n",
      "Iteration:800, Price of Hedge: 0.1858716766468504, Loss: 0.001838387363301286\n",
      "Iteration:810, Price of Hedge: 0.1815961355793064, Loss: 0.0015139371493842146\n",
      "Iteration:820, Price of Hedge: 0.2006847242304346, Loss: 0.0020344759024447877\n",
      "Iteration:830, Price of Hedge: 0.19305788952007816, Loss: 0.001882061669208379\n",
      "Iteration:840, Price of Hedge: 0.18412843710278678, Loss: 0.0014937849602821628\n",
      "Iteration:850, Price of Hedge: 0.17085313621004303, Loss: 0.002632490376024843\n",
      "Iteration:860, Price of Hedge: 0.1962718220492519, Loss: 0.001489259974431145\n",
      "Iteration:870, Price of Hedge: 0.2191011489731707, Loss: 0.0014340971046163497\n",
      "Iteration:880, Price of Hedge: 0.21496128336632978, Loss: 0.002020205429300015\n",
      "Iteration:890, Price of Hedge: 0.18810791087274054, Loss: 0.0017190337026621316\n",
      "Iteration:900, Price of Hedge: 0.17880551754374777, Loss: 0.0019387642592509913\n",
      "Iteration:910, Price of Hedge: 0.17114202968234907, Loss: 0.001565555217254333\n",
      "Iteration:920, Price of Hedge: 0.1769558270567373, Loss: 0.001723831412702681\n",
      "Iteration:930, Price of Hedge: 0.17085540988144457, Loss: 0.0016841914647391042\n",
      "Iteration:940, Price of Hedge: 0.2360477627584956, Loss: 0.0011887655409377306\n",
      "Iteration:950, Price of Hedge: 0.2346803650172319, Loss: 0.0017713823528501926\n",
      "Iteration:960, Price of Hedge: 0.23014846749916273, Loss: 0.001699371375818537\n",
      "Iteration:970, Price of Hedge: 0.18645238408317652, Loss: 0.0016864011278805656\n",
      "Iteration:980, Price of Hedge: 0.17877325493058435, Loss: 0.0014368604851465515\n",
      "Iteration:990, Price of Hedge: 0.18082904588989948, Loss: 0.0017367342835247657\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 13 \n",
      "\n",
      "tf.Tensor(0.25809798, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_84 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.32558003366725646, Loss: 0.0031430316890004306\n",
      "Iteration:20, Price of Hedge: 0.311347785580233, Loss: 0.003080206952237674\n",
      "Iteration:30, Price of Hedge: 0.2839169892943346, Loss: 0.003044522686293405\n",
      "Iteration:40, Price of Hedge: 0.2345434105000777, Loss: 0.003420631539881214\n",
      "Iteration:50, Price of Hedge: 0.22714958423341614, Loss: 0.0031333915383450874\n",
      "Iteration:60, Price of Hedge: 0.2956898749662969, Loss: 0.003514831947331132\n",
      "Iteration:70, Price of Hedge: 0.3476902842444588, Loss: 0.003810619175465746\n",
      "Iteration:80, Price of Hedge: 0.33329234940420066, Loss: 0.0030062308823673336\n",
      "Iteration:90, Price of Hedge: 0.27594621198297775, Loss: 0.0035559840743950135\n",
      "Iteration:100, Price of Hedge: 0.29864910382318616, Loss: 0.003687688190872862\n",
      "Iteration:110, Price of Hedge: 0.27600931447839233, Loss: 0.0029553838917221855\n",
      "Iteration:120, Price of Hedge: 0.2996034497611845, Loss: 0.003241372930819608\n",
      "Iteration:130, Price of Hedge: 0.2989439725604598, Loss: 0.0031914011563518585\n",
      "Iteration:140, Price of Hedge: 0.2794561357805151, Loss: 0.00358220510116567\n",
      "Iteration:150, Price of Hedge: 0.26403108947970394, Loss: 0.003144457847184512\n",
      "Iteration:160, Price of Hedge: 0.29331125739165603, Loss: 0.0030338229731214027\n",
      "Iteration:170, Price of Hedge: 0.29675644378767174, Loss: 0.0030398892449534642\n",
      "Iteration:180, Price of Hedge: 0.3259931280774936, Loss: 0.003576775367520568\n",
      "Iteration:190, Price of Hedge: 0.33691325160434643, Loss: 0.003337275730006439\n",
      "Iteration:200, Price of Hedge: 0.28174959182808834, Loss: 0.0028932629881389007\n",
      "Iteration:210, Price of Hedge: 0.24686625906517748, Loss: 0.002703441924813532\n",
      "Iteration:220, Price of Hedge: 0.25379811454947687, Loss: 0.0031171705855891573\n",
      "Iteration:230, Price of Hedge: 0.28649325969684014, Loss: 0.0030954486008107907\n",
      "Iteration:240, Price of Hedge: 0.2762780003163698, Loss: 0.0026158249883874163\n",
      "Iteration:250, Price of Hedge: 0.26635419345145694, Loss: 0.0028967440265617486\n",
      "Iteration:260, Price of Hedge: 0.27579194517090855, Loss: 0.002834935386994708\n",
      "Iteration:270, Price of Hedge: 0.26676658021576716, Loss: 0.003377695428284966\n",
      "Iteration:280, Price of Hedge: 0.3014089229381853, Loss: 0.0031279974538886536\n",
      "Iteration:290, Price of Hedge: 0.29504769848840623, Loss: 0.003996755218379633\n",
      "Iteration:300, Price of Hedge: 0.2952151665572501, Loss: 0.0034141971472827493\n",
      "Iteration:310, Price of Hedge: 0.29386348963207637, Loss: 0.0028540469742306842\n",
      "Iteration:320, Price of Hedge: 0.28410261214144156, Loss: 0.0028756187367594776\n",
      "Iteration:330, Price of Hedge: 0.2562491804260844, Loss: 0.0027341349230695757\n",
      "Iteration:340, Price of Hedge: 0.26320289972936733, Loss: 0.003058423010313227\n",
      "Iteration:350, Price of Hedge: 0.24777758501113567, Loss: 0.002747323407140279\n",
      "Iteration:360, Price of Hedge: 0.25289266938518723, Loss: 0.0028712218763988773\n",
      "Iteration:370, Price of Hedge: 0.23763933702878148, Loss: 0.0035482609731580794\n",
      "Iteration:380, Price of Hedge: 0.24830975914976536, Loss: 0.0037464960075585195\n",
      "Iteration:390, Price of Hedge: 0.279345987031752, Loss: 0.0027162369333472826\n",
      "Iteration:400, Price of Hedge: 0.3129580704893215, Loss: 0.0031818040897427127\n",
      "Iteration:410, Price of Hedge: 0.31795053690534586, Loss: 0.002969269346026948\n",
      "Iteration:420, Price of Hedge: 0.29978106888884215, Loss: 0.003220242684445651\n",
      "Iteration:430, Price of Hedge: 0.31702576568677615, Loss: 0.00344997482553957\n",
      "Iteration:440, Price of Hedge: 0.3094342621906662, Loss: 0.003811554823690244\n",
      "Iteration:450, Price of Hedge: 0.2913732836152349, Loss: 0.0023484595048522297\n",
      "Iteration:460, Price of Hedge: 0.29401024075637, Loss: 0.0032637430826646606\n",
      "Iteration:470, Price of Hedge: 0.2594816094139333, Loss: 0.0032359283274594475\n",
      "Iteration:480, Price of Hedge: 0.2514660307949271, Loss: 0.0026892251427552694\n",
      "Iteration:490, Price of Hedge: 0.26095885688876025, Loss: 0.003438353190033894\n",
      "Iteration:500, Price of Hedge: 0.29838559112095026, Loss: 0.002483003546269025\n",
      "Iteration:510, Price of Hedge: 0.2868597958854025, Loss: 0.003319612414889761\n",
      "Iteration:520, Price of Hedge: 0.3053751563506694, Loss: 0.002387234193242982\n",
      "Iteration:530, Price of Hedge: 0.3031639092385376, Loss: 0.0025511482095502912\n",
      "Iteration:540, Price of Hedge: 0.29748385499738106, Loss: 0.0027732466583350046\n",
      "Iteration:550, Price of Hedge: 0.3064865264796936, Loss: 0.0069624604080892995\n",
      "Iteration:560, Price of Hedge: 0.30005914933653915, Loss: 0.0029362517156499737\n",
      "Iteration:570, Price of Hedge: 0.2990692014879414, Loss: 0.0028517696201781463\n",
      "Iteration:580, Price of Hedge: 0.28284236795034307, Loss: 0.003245980254839509\n",
      "Iteration:590, Price of Hedge: 0.2940901315413612, Loss: 0.0019116566684147073\n",
      "Iteration:600, Price of Hedge: 0.2634369353185093, Loss: 0.0018470957971000958\n",
      "Iteration:610, Price of Hedge: 0.31082844667462267, Loss: 0.003122236773764797\n",
      "Iteration:620, Price of Hedge: 0.31015552420128645, Loss: 0.002111492103557744\n",
      "Iteration:630, Price of Hedge: 0.27732248570450796, Loss: 0.0019133009157529912\n",
      "Iteration:640, Price of Hedge: 0.3037703129947431, Loss: 0.002350033788274786\n",
      "Iteration:650, Price of Hedge: 0.30402992144358904, Loss: 0.0021885132241799\n",
      "Iteration:660, Price of Hedge: 0.29566559539052834, Loss: 0.0016729130987201302\n",
      "Iteration:670, Price of Hedge: 0.2760470881299398, Loss: 0.0019403340577307305\n",
      "Iteration:680, Price of Hedge: 0.28699783564431985, Loss: 0.0017250468916300222\n",
      "Iteration:690, Price of Hedge: 0.3053952632556275, Loss: 0.0018334351042575748\n",
      "Iteration:700, Price of Hedge: 0.2765879004291946, Loss: 0.002011528728335499\n",
      "Iteration:710, Price of Hedge: 0.270972559187976, Loss: 0.0016360005561844916\n",
      "Iteration:720, Price of Hedge: 0.26078682572376694, Loss: 0.0023213070238792713\n",
      "Iteration:730, Price of Hedge: 0.2791812031371137, Loss: 0.002170844189942045\n",
      "Iteration:740, Price of Hedge: 0.2993664859820001, Loss: 0.0023988462968800306\n",
      "Iteration:750, Price of Hedge: 0.2733787749537669, Loss: 0.0016959291299833978\n",
      "Iteration:760, Price of Hedge: 0.28465167217598264, Loss: 0.0017953007668012333\n",
      "Iteration:770, Price of Hedge: 0.2676276877024975, Loss: 0.0021248420574830006\n",
      "Iteration:780, Price of Hedge: 0.2862925566710146, Loss: 0.0017499794003995818\n",
      "Iteration:790, Price of Hedge: 0.30620139397431106, Loss: 0.0024329587576875865\n",
      "Iteration:800, Price of Hedge: 0.3082086926499869, Loss: 0.0024834740393044896\n",
      "Iteration:810, Price of Hedge: 0.3147422654853472, Loss: 0.002320593468193799\n",
      "Iteration:820, Price of Hedge: 0.2513617140246652, Loss: 0.0022863536616213767\n",
      "Iteration:830, Price of Hedge: 0.24688639037171925, Loss: 0.0019264323992493006\n",
      "Iteration:840, Price of Hedge: 0.2763768267303021, Loss: 0.0019120286019285615\n",
      "Iteration:850, Price of Hedge: 0.2889329300338659, Loss: 0.0021506164208897616\n",
      "Iteration:860, Price of Hedge: 0.29581844691074366, Loss: 0.0018905494891628294\n",
      "Iteration:870, Price of Hedge: 0.31369348541848013, Loss: 0.0021810505335938756\n",
      "Iteration:880, Price of Hedge: 0.287508219168717, Loss: 0.0021271344718879702\n",
      "Iteration:890, Price of Hedge: 0.26948535586700473, Loss: 0.002236159985251973\n",
      "Iteration:900, Price of Hedge: 0.25819449907919534, Loss: 0.001585687540819869\n",
      "Iteration:910, Price of Hedge: 0.2743427595173216, Loss: 0.0018735555018611905\n",
      "Iteration:920, Price of Hedge: 0.30897329187323525, Loss: 0.001672369972845722\n",
      "Iteration:930, Price of Hedge: 0.27664109588163227, Loss: 0.001955484581639766\n",
      "Iteration:940, Price of Hedge: 0.26470828223018544, Loss: 0.002134340183295791\n",
      "Iteration:950, Price of Hedge: 0.26004069849936967, Loss: 0.0025452498892434504\n",
      "Iteration:960, Price of Hedge: 0.2995670425983235, Loss: 0.0018114145813537875\n",
      "Iteration:970, Price of Hedge: 0.3105376286002411, Loss: 0.0020313916174567125\n",
      "Iteration:980, Price of Hedge: 0.3190761087560759, Loss: 0.0020841979790169776\n",
      "Iteration:990, Price of Hedge: 0.30692333922927445, Loss: 0.0020857560582628666\n",
      "tf.Tensor(0.37625173, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_85 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.4605915560490303, Loss: 0.004614931594889882\n",
      "Iteration:20, Price of Hedge: 0.2789799632764471, Loss: 0.004013106567098391\n",
      "Iteration:30, Price of Hedge: 0.3613790114564381, Loss: 0.003676765813249716\n",
      "Iteration:40, Price of Hedge: 0.3395958397069762, Loss: 0.005162511139595693\n",
      "Iteration:50, Price of Hedge: 0.35226140851495985, Loss: 0.003994310103439247\n",
      "Iteration:60, Price of Hedge: 0.34324394967293304, Loss: 0.004445693267404494\n",
      "Iteration:70, Price of Hedge: 0.34152029500603476, Loss: 0.0037890546571571096\n",
      "Iteration:80, Price of Hedge: 0.34668745235967435, Loss: 0.004899932941760099\n",
      "Iteration:90, Price of Hedge: 0.32668986649650833, Loss: 0.004730311051881131\n",
      "Iteration:100, Price of Hedge: 0.3136807477917955, Loss: 0.0033807940481384692\n",
      "Iteration:110, Price of Hedge: 0.354470288673474, Loss: 0.004694031234785001\n",
      "Iteration:120, Price of Hedge: 0.326882297385464, Loss: 0.003600921115853595\n",
      "Iteration:130, Price of Hedge: 0.31050051379145316, Loss: 0.003451576179469029\n",
      "Iteration:140, Price of Hedge: 0.343172306623228, Loss: 0.0034354974421930253\n",
      "Iteration:150, Price of Hedge: 0.33041467063999336, Loss: 0.005474917371320132\n",
      "Iteration:160, Price of Hedge: 0.32607560543035563, Loss: 0.003975776719354229\n",
      "Iteration:170, Price of Hedge: 0.34291294219021895, Loss: 0.004069163867772829\n",
      "Iteration:180, Price of Hedge: 0.36014133873025006, Loss: 0.004527649036415227\n",
      "Iteration:190, Price of Hedge: 0.31906158981378213, Loss: 0.004462871982320138\n",
      "Iteration:200, Price of Hedge: 0.3435791298264576, Loss: 0.0040902872512013745\n",
      "Iteration:210, Price of Hedge: 0.32868076730794654, Loss: 0.003851498309812129\n",
      "Iteration:220, Price of Hedge: 0.3361065840508218, Loss: 0.004243304244656088\n",
      "Iteration:230, Price of Hedge: 0.34060735855555324, Loss: 0.00404212920069611\n",
      "Iteration:240, Price of Hedge: 0.33248412014932, Loss: 0.0038462935282666424\n",
      "Iteration:250, Price of Hedge: 0.32226908038310287, Loss: 0.0031532508053562225\n",
      "Iteration:260, Price of Hedge: 0.33193427926410096, Loss: 0.003577443360874\n",
      "Iteration:270, Price of Hedge: 0.2985090387328228, Loss: 0.003340280937547391\n",
      "Iteration:280, Price of Hedge: 0.31967882787314467, Loss: 0.004832318441011907\n",
      "Iteration:290, Price of Hedge: 0.34569042805180744, Loss: 0.0035453030436855214\n",
      "Iteration:300, Price of Hedge: 0.3629451294990531, Loss: 0.004105137139973891\n",
      "Iteration:310, Price of Hedge: 0.33395477919655153, Loss: 0.003782609588865782\n",
      "Iteration:320, Price of Hedge: 0.338364804211551, Loss: 0.004018205735539482\n",
      "Iteration:330, Price of Hedge: 0.360957962129919, Loss: 0.004471221517963287\n",
      "Iteration:340, Price of Hedge: 0.36297497263590234, Loss: 0.004036069219897342\n",
      "Iteration:350, Price of Hedge: 0.32876949146623247, Loss: 0.0034332471586473903\n",
      "Iteration:360, Price of Hedge: 0.3616356917152416, Loss: 0.004221425174682736\n",
      "Iteration:370, Price of Hedge: 0.3462268724675823, Loss: 0.004620260672002274\n",
      "Iteration:380, Price of Hedge: 0.34332232755973563, Loss: 0.003265968964626609\n",
      "Iteration:390, Price of Hedge: 0.30235519195198324, Loss: 0.0038215083821860675\n",
      "Iteration:400, Price of Hedge: 0.31802523015301176, Loss: 0.004052424762638296\n",
      "Iteration:410, Price of Hedge: 0.3254622960259667, Loss: 0.004357169659634508\n",
      "Iteration:420, Price of Hedge: 0.32782522338229686, Loss: 0.004108159886153118\n",
      "Iteration:430, Price of Hedge: 0.33865093718186473, Loss: 0.003660103725613695\n",
      "Iteration:440, Price of Hedge: 0.3127587827553498, Loss: 0.002235225671489083\n",
      "Iteration:450, Price of Hedge: 0.31454136724685217, Loss: 0.00417056045476194\n",
      "Iteration:460, Price of Hedge: 0.3432486347770009, Loss: 0.004522383632185267\n",
      "Iteration:470, Price of Hedge: 0.35510180165929345, Loss: 0.004131699788916166\n",
      "Iteration:480, Price of Hedge: 0.3718180089577345, Loss: 0.002936280501893229\n",
      "Iteration:490, Price of Hedge: 0.32973120668250433, Loss: 0.003649893187939668\n",
      "Iteration:500, Price of Hedge: 0.3574269309624924, Loss: 0.002877063386768697\n",
      "Iteration:510, Price of Hedge: 0.36566563766273247, Loss: 0.0025332839626429405\n",
      "Iteration:520, Price of Hedge: 0.36182795179311145, Loss: 0.004115036557455909\n",
      "Iteration:530, Price of Hedge: 0.37297998797132553, Loss: 0.0027966603591574215\n",
      "Iteration:540, Price of Hedge: 0.3632981472102529, Loss: 0.0023451933147482507\n",
      "Iteration:550, Price of Hedge: 0.32735800625944195, Loss: 0.0025553367032626895\n",
      "Iteration:560, Price of Hedge: 0.3431199408246357, Loss: 0.003035345593815997\n",
      "Iteration:570, Price of Hedge: 0.33309008467701917, Loss: 0.002635275719509167\n",
      "Iteration:580, Price of Hedge: 0.30696667644190256, Loss: 0.0023174189746660192\n",
      "Iteration:590, Price of Hedge: 0.31866430762977416, Loss: 0.002410155096457345\n",
      "Iteration:600, Price of Hedge: 0.33446125846755875, Loss: 0.0030201218651559002\n",
      "Iteration:610, Price of Hedge: 0.3341933046770919, Loss: 0.0031812901313863053\n",
      "Iteration:620, Price of Hedge: 0.3723968633259574, Loss: 0.0031653444589963445\n",
      "Iteration:630, Price of Hedge: 0.36655658828631205, Loss: 0.0026331613604101633\n",
      "Iteration:640, Price of Hedge: 0.3698019257119313, Loss: 0.0023284871898791694\n",
      "Iteration:650, Price of Hedge: 0.35092041948344105, Loss: 0.00256611686540591\n",
      "Iteration:660, Price of Hedge: 0.328610881172267, Loss: 0.0024832092439940113\n",
      "Iteration:670, Price of Hedge: 0.3257719765245383, Loss: 0.002507435822573001\n",
      "Iteration:680, Price of Hedge: 0.3161440388618303, Loss: 0.0023916125617784445\n",
      "Iteration:690, Price of Hedge: 0.3231581276831548, Loss: 0.002773179363342493\n",
      "Iteration:700, Price of Hedge: 0.3219645242171055, Loss: 0.0025561808455483617\n",
      "Iteration:710, Price of Hedge: 0.2968697403407305, Loss: 0.002219276567626416\n",
      "Iteration:720, Price of Hedge: 0.31307934636024587, Loss: 0.0027904941933421415\n",
      "Iteration:730, Price of Hedge: 0.3267822508923473, Loss: 0.002814498488744732\n",
      "Iteration:740, Price of Hedge: 0.28639943560756365, Loss: 0.002295726538680398\n",
      "Iteration:750, Price of Hedge: 0.31357323441407065, Loss: 0.0028133626712790517\n",
      "Iteration:760, Price of Hedge: 0.2907420878500034, Loss: 0.002368064461608377\n",
      "Iteration:770, Price of Hedge: 0.289899379157373, Loss: 0.0023840555056930056\n",
      "Iteration:780, Price of Hedge: 0.33335991738942994, Loss: 0.0028408685939407263\n",
      "Iteration:790, Price of Hedge: 0.3146718425148265, Loss: 0.003055512358909063\n",
      "Iteration:800, Price of Hedge: 0.3210359951546479, Loss: 0.002517198553058897\n",
      "Iteration:810, Price of Hedge: 0.33997970101995634, Loss: 0.0027033976969430998\n",
      "Iteration:820, Price of Hedge: 0.3280170930348277, Loss: 0.002512297647485262\n",
      "Iteration:830, Price of Hedge: 0.3458578717190676, Loss: 0.0028032135188389875\n",
      "Iteration:840, Price of Hedge: 0.323324009649059, Loss: 0.0021056090342407075\n",
      "Iteration:850, Price of Hedge: 0.30703258511944115, Loss: 0.0031289929622481337\n",
      "Iteration:860, Price of Hedge: 0.31927022335430594, Loss: 0.003383165958327794\n",
      "Iteration:870, Price of Hedge: 0.3042349679513109, Loss: 0.0028592542340620144\n",
      "Iteration:880, Price of Hedge: 0.31488972425556766, Loss: 0.0025464528110642703\n",
      "Iteration:890, Price of Hedge: 0.3038917596767533, Loss: 0.0027101035571600817\n",
      "Iteration:900, Price of Hedge: 0.3365150177585747, Loss: 0.002345315132029313\n",
      "Iteration:910, Price of Hedge: 0.3432008808777255, Loss: 0.0026697130263995564\n",
      "Iteration:920, Price of Hedge: 0.3318189085764289, Loss: 0.002702055037928197\n",
      "Iteration:930, Price of Hedge: 0.33539981658091167, Loss: 0.002243964107372243\n",
      "Iteration:940, Price of Hedge: 0.32088407089461274, Loss: 0.0031883555336879254\n",
      "Iteration:950, Price of Hedge: 0.3139819609408278, Loss: 0.0032885766506378644\n",
      "Iteration:960, Price of Hedge: 0.31562958027295734, Loss: 0.0026827650141115103\n",
      "Iteration:970, Price of Hedge: 0.3352688044780962, Loss: 0.0028071825889355753\n",
      "Iteration:980, Price of Hedge: 0.3451136966213653, Loss: 0.0024848018286043327\n",
      "Iteration:990, Price of Hedge: 0.3591738159370607, Loss: 0.0026244044327018655\n",
      "tf.Tensor(0.25809965, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_86 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.20722415385321255, Loss: 0.0070938255713187464\n",
      "Iteration:20, Price of Hedge: 0.34113545762970715, Loss: 0.003502234629752721\n",
      "Iteration:30, Price of Hedge: 0.2328147779101073, Loss: 0.003171954237977559\n",
      "Iteration:40, Price of Hedge: 0.32120329241240597, Loss: 0.0030159255553112276\n",
      "Iteration:50, Price of Hedge: 0.26331646469984665, Loss: 0.0031791698625287523\n",
      "Iteration:60, Price of Hedge: 0.300530343917535, Loss: 0.0034360453340017473\n",
      "Iteration:70, Price of Hedge: 0.26636810235415853, Loss: 0.0033308161732747976\n",
      "Iteration:80, Price of Hedge: 0.3087211503089975, Loss: 0.0034644201818075262\n",
      "Iteration:90, Price of Hedge: 0.26342563738526226, Loss: 0.0028175896737407057\n",
      "Iteration:100, Price of Hedge: 0.2865569478302632, Loss: 0.002689528446815004\n",
      "Iteration:110, Price of Hedge: 0.293230024519562, Loss: 0.003028568625859052\n",
      "Iteration:120, Price of Hedge: 0.2564930742550359, Loss: 0.003178614345225128\n",
      "Iteration:130, Price of Hedge: 0.3111707032874165, Loss: 0.002865971913796095\n",
      "Iteration:140, Price of Hedge: 0.2847446666114138, Loss: 0.00357819332829763\n",
      "Iteration:150, Price of Hedge: 0.245041118211725, Loss: 0.0029488486519536395\n",
      "Iteration:160, Price of Hedge: 0.2955257011112508, Loss: 0.0029845535067341447\n",
      "Iteration:170, Price of Hedge: 0.2748831325880701, Loss: 0.0034269481185834395\n",
      "Iteration:180, Price of Hedge: 0.2817006910543796, Loss: 0.0033473497713217173\n",
      "Iteration:190, Price of Hedge: 0.29605560590259755, Loss: 0.0032952192192471585\n",
      "Iteration:200, Price of Hedge: 0.28271028217784533, Loss: 0.003296835824166422\n",
      "Iteration:210, Price of Hedge: 0.2627474441698496, Loss: 0.0036328890968572837\n",
      "Iteration:220, Price of Hedge: 0.2707952572809063, Loss: 0.003874470113204964\n",
      "Iteration:230, Price of Hedge: 0.2858961529440194, Loss: 0.00292178863010637\n",
      "Iteration:240, Price of Hedge: 0.28963542722663077, Loss: 0.0030610473243838144\n",
      "Iteration:250, Price of Hedge: 0.27674023951615256, Loss: 0.003029444223311195\n",
      "Iteration:260, Price of Hedge: 0.2870474684655392, Loss: 0.0033817891752232045\n",
      "Iteration:270, Price of Hedge: 0.31566584102631623, Loss: 0.0030708529482785353\n",
      "Iteration:280, Price of Hedge: 0.30324333639343876, Loss: 0.003265670426501188\n",
      "Iteration:290, Price of Hedge: 0.2622124882506796, Loss: 0.00243085984021576\n",
      "Iteration:300, Price of Hedge: 0.24566006438194563, Loss: 0.0030186863657405637\n",
      "Iteration:310, Price of Hedge: 0.3176374645866417, Loss: 0.0032245350755260916\n",
      "Iteration:320, Price of Hedge: 0.3249288042018179, Loss: 0.0038467087364640663\n",
      "Iteration:330, Price of Hedge: 0.2635593092606996, Loss: 0.002788019720246382\n",
      "Iteration:340, Price of Hedge: 0.2739561652269686, Loss: 0.0030777099839319534\n",
      "Iteration:350, Price of Hedge: 0.291153815771554, Loss: 0.0031618026072516513\n",
      "Iteration:360, Price of Hedge: 0.2686529446426903, Loss: 0.0031359550390938295\n",
      "Iteration:370, Price of Hedge: 0.23970607796231888, Loss: 0.00347859750192967\n",
      "Iteration:380, Price of Hedge: 0.2936443146073998, Loss: 0.003272429665182486\n",
      "Iteration:390, Price of Hedge: 0.2879708731954224, Loss: 0.0034871765649693745\n",
      "Iteration:400, Price of Hedge: 0.2646484495469849, Loss: 0.0023753245046673754\n",
      "Iteration:410, Price of Hedge: 0.2952489871522403, Loss: 0.004142462793695856\n",
      "Iteration:420, Price of Hedge: 0.30700537735363015, Loss: 0.0028824900702158376\n",
      "Iteration:430, Price of Hedge: 0.2773510599590054, Loss: 0.0026839164638417404\n",
      "Iteration:440, Price of Hedge: 0.26462307189995043, Loss: 0.002854961271069456\n",
      "Iteration:450, Price of Hedge: 0.24745655777614958, Loss: 0.002156676401688529\n",
      "Iteration:460, Price of Hedge: 0.2596200151966059, Loss: 0.002520037906085726\n",
      "Iteration:470, Price of Hedge: 0.297681410218911, Loss: 0.0027772016212660234\n",
      "Iteration:480, Price of Hedge: 0.31228070692775417, Loss: 0.0034581280046889875\n",
      "Iteration:490, Price of Hedge: 0.30703788026310125, Loss: 0.0022934295489784873\n",
      "Iteration:500, Price of Hedge: 0.26586447806844266, Loss: 0.0031902895498324923\n",
      "Iteration:510, Price of Hedge: 0.31533690767821554, Loss: 0.0028777561629805604\n",
      "Iteration:520, Price of Hedge: 0.2645444988004783, Loss: 0.0024718232362808124\n",
      "Iteration:530, Price of Hedge: 0.2593525006346454, Loss: 0.0019272248788070102\n",
      "Iteration:540, Price of Hedge: 0.26099135979823135, Loss: 0.002753216389600688\n",
      "Iteration:550, Price of Hedge: 0.26625063313028935, Loss: 0.0018250428658429742\n",
      "Iteration:560, Price of Hedge: 0.26621429917217937, Loss: 0.0015641413236989977\n",
      "Iteration:570, Price of Hedge: 0.2738058026682893, Loss: 0.001818794916594868\n",
      "Iteration:580, Price of Hedge: 0.3077179035972904, Loss: 0.0018446495383354744\n",
      "Iteration:590, Price of Hedge: 0.32850014678549544, Loss: 0.0022470009607170383\n",
      "Iteration:600, Price of Hedge: 0.3001903810536078, Loss: 0.0022436855861709404\n",
      "Iteration:610, Price of Hedge: 0.2780535571517703, Loss: 0.0020761115229479543\n",
      "Iteration:620, Price of Hedge: 0.281457822091943, Loss: 0.00188063501132838\n",
      "Iteration:630, Price of Hedge: 0.255691653042004, Loss: 0.0018719652048993396\n",
      "Iteration:640, Price of Hedge: 0.26605834865083583, Loss: 0.0017793930312484108\n",
      "Iteration:650, Price of Hedge: 0.2973186318742364, Loss: 0.0016680575648411633\n",
      "Iteration:660, Price of Hedge: 0.30921152453477135, Loss: 0.002173895531727155\n",
      "Iteration:670, Price of Hedge: 0.30410329700573585, Loss: 0.002540042438774748\n",
      "Iteration:680, Price of Hedge: 0.27814672239828725, Loss: 0.0020411894252191586\n",
      "Iteration:690, Price of Hedge: 0.2772898363855347, Loss: 0.002106810812237292\n",
      "Iteration:700, Price of Hedge: 0.29022884934031484, Loss: 0.0022488017213381896\n",
      "Iteration:710, Price of Hedge: 0.29325166872429237, Loss: 0.0019150847096479852\n",
      "Iteration:720, Price of Hedge: 0.29504713725198145, Loss: 0.0019279822810881698\n",
      "Iteration:730, Price of Hedge: 0.27594374742302535, Loss: 0.0020923524926280026\n",
      "Iteration:740, Price of Hedge: 0.2848517895637997, Loss: 0.0016822836881306813\n",
      "Iteration:750, Price of Hedge: 0.3127285735947453, Loss: 0.0015450314521993746\n",
      "Iteration:760, Price of Hedge: 0.27811290180329706, Loss: 0.0023479762391128037\n",
      "Iteration:770, Price of Hedge: 0.29746269882432447, Loss: 0.002724514598700978\n",
      "Iteration:780, Price of Hedge: 0.28214343338879644, Loss: 0.0017354023137071907\n",
      "Iteration:790, Price of Hedge: 0.2769105137671204, Loss: 0.0019496200041478674\n",
      "Iteration:800, Price of Hedge: 0.2917342806443003, Loss: 0.0018387580809740456\n",
      "Iteration:810, Price of Hedge: 0.2903192816094588, Loss: 0.0018738670033279449\n",
      "Iteration:820, Price of Hedge: 0.2784974463606204, Loss: 0.0017565163559044806\n",
      "Iteration:830, Price of Hedge: 0.2997965638944834, Loss: 0.0019474389219684696\n",
      "Iteration:840, Price of Hedge: 0.3099069208666833, Loss: 0.0021283530259733397\n",
      "Iteration:850, Price of Hedge: 0.2931131409337013, Loss: 0.0016809313066097787\n",
      "Iteration:860, Price of Hedge: 0.2759530200248264, Loss: 0.0014394353145302575\n",
      "Iteration:870, Price of Hedge: 0.2669386601839278, Loss: 0.0018210978160553282\n",
      "Iteration:880, Price of Hedge: 0.2713953410269369, Loss: 0.0021253420993112117\n",
      "Iteration:890, Price of Hedge: 0.2806653074569567, Loss: 0.0019548676791021793\n",
      "Iteration:900, Price of Hedge: 0.264450040270026, Loss: 0.001839120482619272\n",
      "Iteration:910, Price of Hedge: 0.29266964215019015, Loss: 0.001911964166496638\n",
      "Iteration:920, Price of Hedge: 0.2680452476025494, Loss: 0.00164282403966034\n",
      "Iteration:930, Price of Hedge: 0.3009050546366325, Loss: 0.0025024624747977953\n",
      "Iteration:940, Price of Hedge: 0.2841575157047373, Loss: 0.0018454704228616948\n",
      "Iteration:950, Price of Hedge: 0.26697404248027395, Loss: 0.001931661773015847\n",
      "Iteration:960, Price of Hedge: 0.2646170447087798, Loss: 0.0020320628516454775\n",
      "Iteration:970, Price of Hedge: 0.2831405797045818, Loss: 0.002200440642031154\n",
      "Iteration:980, Price of Hedge: 0.277757492736896, Loss: 0.0015965684548144843\n",
      "Iteration:990, Price of Hedge: 0.2667160689375351, Loss: 0.001852882594543992\n",
      "tf.Tensor(0.31673655, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_87 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.16368967882258403, Loss: 0.005111084039425862\n",
      "Iteration:20, Price of Hedge: 0.4422940285213372, Loss: 0.005173319134795307\n",
      "Iteration:30, Price of Hedge: 0.25192631786801484, Loss: 0.003545884487671813\n",
      "Iteration:40, Price of Hedge: 0.28320121764004397, Loss: 0.0031224296987858225\n",
      "Iteration:50, Price of Hedge: 0.32886863510075276, Loss: 0.00419326994113014\n",
      "Iteration:60, Price of Hedge: 0.2775649398400219, Loss: 0.003024510146834736\n",
      "Iteration:70, Price of Hedge: 0.31667770149706487, Loss: 0.0033465346059166736\n",
      "Iteration:80, Price of Hedge: 0.28266184503422664, Loss: 0.002845067572708615\n",
      "Iteration:90, Price of Hedge: 0.29559095094602983, Loss: 0.0034244656387180327\n",
      "Iteration:100, Price of Hedge: 0.29510357811504945, Loss: 0.003919410586136251\n",
      "Iteration:110, Price of Hedge: 0.31621653596696436, Loss: 0.0031561892898167797\n",
      "Iteration:120, Price of Hedge: 0.27969910234928647, Loss: 0.0035340752649915433\n",
      "Iteration:130, Price of Hedge: 0.3174022821230665, Loss: 0.003194626740695483\n",
      "Iteration:140, Price of Hedge: 0.27912032118581465, Loss: 0.0032676419982081485\n",
      "Iteration:150, Price of Hedge: 0.3125072756322879, Loss: 0.0033169309096074072\n",
      "Iteration:160, Price of Hedge: 0.2743273865195988, Loss: 0.0034690236930799757\n",
      "Iteration:170, Price of Hedge: 0.3078927897475751, Loss: 0.003946435340069598\n",
      "Iteration:180, Price of Hedge: 0.30258327355470555, Loss: 0.003708004796940756\n",
      "Iteration:190, Price of Hedge: 0.30088060424977814, Loss: 0.0028551641092338545\n",
      "Iteration:200, Price of Hedge: 0.3150431370122078, Loss: 0.0031612024808028495\n",
      "Iteration:210, Price of Hedge: 0.2811930405073554, Loss: 0.0030482342052996713\n",
      "Iteration:220, Price of Hedge: 0.31623378788663103, Loss: 0.0026966651474939598\n",
      "Iteration:230, Price of Hedge: 0.2893556630696594, Loss: 0.004079907427540519\n",
      "Iteration:240, Price of Hedge: 0.2861899968147782, Loss: 0.003364286376774217\n",
      "Iteration:250, Price of Hedge: 0.31175014329364786, Loss: 0.0035517206601952014\n",
      "Iteration:260, Price of Hedge: 0.27425527983980375, Loss: 0.0030048285538548216\n",
      "Iteration:270, Price of Hedge: 0.2899888841663369, Loss: 0.0032194980548684526\n",
      "Iteration:280, Price of Hedge: 0.320264197464212, Loss: 0.0033979350168543477\n",
      "Iteration:290, Price of Hedge: 0.2731178732209855, Loss: 0.0033615827575566473\n",
      "Iteration:300, Price of Hedge: 0.3110233665251144, Loss: 0.0036293928074446315\n",
      "Iteration:310, Price of Hedge: 0.3100250001301447, Loss: 0.0030726348357998034\n",
      "Iteration:320, Price of Hedge: 0.27937492731000474, Loss: 0.0029168661825096365\n",
      "Iteration:330, Price of Hedge: 0.3345613781654265, Loss: 0.003437809110972623\n",
      "Iteration:340, Price of Hedge: 0.2983774409919988, Loss: 0.003160031204785874\n",
      "Iteration:350, Price of Hedge: 0.29900914919048777, Loss: 0.003550847922303646\n",
      "Iteration:360, Price of Hedge: 0.3383665611255765, Loss: 0.003394552728590483\n",
      "Iteration:370, Price of Hedge: 0.2861101304313706, Loss: 0.003914858546954392\n",
      "Iteration:380, Price of Hedge: 0.3023912574926726, Loss: 0.0037305812184229127\n",
      "Iteration:390, Price of Hedge: 0.2927196897983322, Loss: 0.0034030208406793604\n",
      "Iteration:400, Price of Hedge: 0.3021355776988003, Loss: 0.003496388162811215\n",
      "Iteration:410, Price of Hedge: 0.28009152861814074, Loss: 0.00344500185903911\n",
      "Iteration:420, Price of Hedge: 0.30058134322744084, Loss: 0.0031026678474720625\n",
      "Iteration:430, Price of Hedge: 0.2556540257999586, Loss: 0.002786360221918294\n",
      "Iteration:440, Price of Hedge: 0.31490309632342817, Loss: 0.0029667170928831866\n",
      "Iteration:450, Price of Hedge: 0.28934163215903935, Loss: 0.0033549287507049995\n",
      "Iteration:460, Price of Hedge: 0.2911447383824225, Loss: 0.0037483478589955157\n",
      "Iteration:470, Price of Hedge: 0.300294673422286, Loss: 0.003930682592700663\n",
      "Iteration:480, Price of Hedge: 0.3087647071358788, Loss: 0.003046369390521342\n",
      "Iteration:490, Price of Hedge: 0.3048837816599644, Loss: 0.0039034672013947614\n",
      "Iteration:500, Price of Hedge: 0.2863620279797715, Loss: 0.002958959295644448\n",
      "Iteration:510, Price of Hedge: 0.2868754373005459, Loss: 0.0039967567434786135\n",
      "Iteration:520, Price of Hedge: 0.29128126524315123, Loss: 0.0037511399339539508\n",
      "Iteration:530, Price of Hedge: 0.302526173848878, Loss: 0.005001795827762479\n",
      "Iteration:540, Price of Hedge: 0.2799207907370828, Loss: 0.003272433859204682\n",
      "Iteration:550, Price of Hedge: 0.3342713165401392, Loss: 0.003008046893978289\n",
      "Iteration:560, Price of Hedge: 0.3056216367474917, Loss: 0.003551722947843672\n",
      "Iteration:570, Price of Hedge: 0.2874848180499612, Loss: 0.0030635031150170636\n",
      "Iteration:580, Price of Hedge: 0.3060294848172362, Loss: 0.003199365604502447\n",
      "Iteration:590, Price of Hedge: 0.2908572877265897, Loss: 0.002525916972017939\n",
      "Iteration:600, Price of Hedge: 0.3308969679415668, Loss: 0.002822160395385076\n",
      "Iteration:610, Price of Hedge: 0.29461593686664855, Loss: 0.0034635360056736175\n",
      "Iteration:620, Price of Hedge: 0.31223126931920436, Loss: 0.0028159479046882653\n",
      "Iteration:630, Price of Hedge: 0.30060813616632914, Loss: 0.0022283009595684077\n",
      "Iteration:640, Price of Hedge: 0.2884676162345386, Loss: 0.0023880121843603773\n",
      "Iteration:650, Price of Hedge: 0.288970264456907, Loss: 0.002361451632429201\n",
      "Iteration:660, Price of Hedge: 0.2938392344578915, Loss: 0.002760715682562243\n",
      "Iteration:670, Price of Hedge: 0.2951218793028147, Loss: 0.0023662715171195005\n",
      "Iteration:680, Price of Hedge: 0.28865401993232354, Loss: 0.002256567334709203\n",
      "Iteration:690, Price of Hedge: 0.29594152849886085, Loss: 0.0018289032726372058\n",
      "Iteration:700, Price of Hedge: 0.3008674761977545, Loss: 0.0021992514461011583\n",
      "Iteration:710, Price of Hedge: 0.31328724785325907, Loss: 0.002807907392226028\n",
      "Iteration:720, Price of Hedge: 0.2916924075266934, Loss: 0.003770055355333568\n",
      "Iteration:730, Price of Hedge: 0.29743776040579634, Loss: 0.0029382720905243077\n",
      "Iteration:740, Price of Hedge: 0.2847966663862508, Loss: 0.002168021613004001\n",
      "Iteration:750, Price of Hedge: 0.2953985688602416, Loss: 0.0024853131180375245\n",
      "Iteration:760, Price of Hedge: 0.30466485065112464, Loss: 0.0021023184425530417\n",
      "Iteration:770, Price of Hedge: 0.30215624584018314, Loss: 0.001878643613334674\n",
      "Iteration:780, Price of Hedge: 0.27663087161806743, Loss: 0.0022699010844577927\n",
      "Iteration:790, Price of Hedge: 0.3004755135589903, Loss: 0.0020464315716896666\n",
      "Iteration:800, Price of Hedge: 0.295162239522233, Loss: 0.0017474065584195842\n",
      "Iteration:810, Price of Hedge: 0.27412939206956255, Loss: 0.0022660448716857575\n",
      "Iteration:820, Price of Hedge: 0.29653534103788387, Loss: 0.002154424783681286\n",
      "Iteration:830, Price of Hedge: 0.300651180559953, Loss: 0.002026439239792488\n",
      "Iteration:840, Price of Hedge: 0.29985254112746135, Loss: 0.0019378008683242243\n",
      "Iteration:850, Price of Hedge: 0.2717021421386335, Loss: 0.0022404230181770402\n",
      "Iteration:860, Price of Hedge: 0.2863247179583141, Loss: 0.0020846902047129134\n",
      "Iteration:870, Price of Hedge: 0.2771736116424336, Loss: 0.0028175990149719612\n",
      "Iteration:880, Price of Hedge: 0.3238260722334189, Loss: 0.0025144703416202677\n",
      "Iteration:890, Price of Hedge: 0.3385117017453467, Loss: 0.0023786976423373573\n",
      "Iteration:900, Price of Hedge: 0.27588330470023265, Loss: 0.0023239603148304867\n",
      "Iteration:910, Price of Hedge: 0.2910310514040248, Loss: 0.002113339570335171\n",
      "Iteration:920, Price of Hedge: 0.29424159217130635, Loss: 0.001986487174988838\n",
      "Iteration:930, Price of Hedge: 0.30497472636236583, Loss: 0.0023463596341935402\n",
      "Iteration:940, Price of Hedge: 0.29201358117118165, Loss: 0.0023968867353275415\n",
      "Iteration:950, Price of Hedge: 0.31058843269747743, Loss: 0.0024738573370459704\n",
      "Iteration:960, Price of Hedge: 0.31331875029779893, Loss: 0.001837663822455582\n",
      "Iteration:970, Price of Hedge: 0.30822943399612085, Loss: 0.001722808236964113\n",
      "Iteration:980, Price of Hedge: 0.2985141386638134, Loss: 0.001959751427312284\n",
      "Iteration:990, Price of Hedge: 0.29061534602433314, Loss: 0.002493509381233139\n",
      "tf.Tensor(0.30653942, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_88 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.39227314891661536, Loss: 0.0061242934602226745\n",
      "Iteration:20, Price of Hedge: 0.2551227301183417, Loss: 0.00404277622393856\n",
      "Iteration:30, Price of Hedge: 0.2710164576370289, Loss: 0.003116881769969737\n",
      "Iteration:40, Price of Hedge: 0.32369225394847945, Loss: 0.0034695753976361488\n",
      "Iteration:50, Price of Hedge: 0.2810800123717172, Loss: 0.002874755149461805\n",
      "Iteration:60, Price of Hedge: 0.2802957210704335, Loss: 0.0036721554390318546\n",
      "Iteration:70, Price of Hedge: 0.2873146414053281, Loss: 0.0034070471019877146\n",
      "Iteration:80, Price of Hedge: 0.30394668764163274, Loss: 0.0037659006044361122\n",
      "Iteration:90, Price of Hedge: 0.2832627096309352, Loss: 0.0031517710780704536\n",
      "Iteration:100, Price of Hedge: 0.28037727116311545, Loss: 0.0031447024349334995\n",
      "Iteration:110, Price of Hedge: 0.2601447956553784, Loss: 0.0025159996346229008\n",
      "Iteration:120, Price of Hedge: 0.25465726990951226, Loss: 0.002592698387448067\n",
      "Iteration:130, Price of Hedge: 0.2397703761353341, Loss: 0.00373236825315324\n",
      "Iteration:140, Price of Hedge: 0.2974760708921849, Loss: 0.0030273573159938397\n",
      "Iteration:150, Price of Hedge: 0.2760660481604646, Loss: 0.003008326368366454\n",
      "Iteration:160, Price of Hedge: 0.28398914477729703, Loss: 0.0028463040467070046\n",
      "Iteration:170, Price of Hedge: 0.2943248991780138, Loss: 0.0031669379967935287\n",
      "Iteration:180, Price of Hedge: 0.30461080114325795, Loss: 0.0030416471121657907\n",
      "Iteration:190, Price of Hedge: 0.340368198633837, Loss: 0.0031151096049544694\n",
      "Iteration:200, Price of Hedge: 0.3333226805727236, Loss: 0.002557686499516798\n",
      "Iteration:210, Price of Hedge: 0.31790463752643067, Loss: 0.003019722289223026\n",
      "Iteration:220, Price of Hedge: 0.32446290476448214, Loss: 0.0030947634500938293\n",
      "Iteration:230, Price of Hedge: 0.2865060949298595, Loss: 0.0039488148757538255\n",
      "Iteration:240, Price of Hedge: 0.29025259208124227, Loss: 0.003123871489234453\n",
      "Iteration:250, Price of Hedge: 0.2586944387257745, Loss: 0.0031431746670298466\n",
      "Iteration:260, Price of Hedge: 0.3047803189451315, Loss: 0.0030602950693117137\n",
      "Iteration:270, Price of Hedge: 0.2952570152732733, Loss: 0.003055698992896794\n",
      "Iteration:280, Price of Hedge: 0.2655736355924773, Loss: 0.0036300013219378257\n",
      "Iteration:290, Price of Hedge: 0.30140104122665434, Loss: 0.003145393304771638\n",
      "Iteration:300, Price of Hedge: 0.2658011315571912, Loss: 0.002878332078483048\n",
      "Iteration:310, Price of Hedge: 0.24590015156384198, Loss: 0.0028592208725218174\n",
      "Iteration:320, Price of Hedge: 0.2709644090590246, Loss: 0.003011123781171321\n",
      "Iteration:330, Price of Hedge: 0.25358418586529297, Loss: 0.0031813538042687385\n",
      "Iteration:340, Price of Hedge: 0.2727724932054798, Loss: 0.0028691755748418758\n",
      "Iteration:350, Price of Hedge: 0.2870875846691206, Loss: 0.003136657728449066\n",
      "Iteration:360, Price of Hedge: 0.2566487075557916, Loss: 0.0034978232809518063\n",
      "Iteration:370, Price of Hedge: 0.25238023612776034, Loss: 0.003736603834296659\n",
      "Iteration:380, Price of Hedge: 0.28395744712008764, Loss: 0.003001735653122495\n",
      "Iteration:390, Price of Hedge: 0.2871709160774117, Loss: 0.00318038307876769\n",
      "Iteration:400, Price of Hedge: 0.29078703556715485, Loss: 0.002505449571788354\n",
      "Iteration:410, Price of Hedge: 0.27366161371028286, Loss: 0.002574529502019374\n",
      "Iteration:420, Price of Hedge: 0.290231875136692, Loss: 0.0034402809151451662\n",
      "Iteration:430, Price of Hedge: 0.3138877220246286, Loss: 0.0027518739212231583\n",
      "Iteration:440, Price of Hedge: 0.28093904442275747, Loss: 0.004771552015960623\n",
      "Iteration:450, Price of Hedge: 0.32828677933773637, Loss: 0.002799497233898407\n",
      "Iteration:460, Price of Hedge: 0.2771089962488304, Loss: 0.0025202380753269085\n",
      "Iteration:470, Price of Hedge: 0.27962209095117035, Loss: 0.002327666305352949\n",
      "Iteration:480, Price of Hedge: 0.2739938412721813, Loss: 0.0019733793305267257\n",
      "Iteration:490, Price of Hedge: 0.2729312255073637, Loss: 0.0020326938613486334\n",
      "Iteration:500, Price of Hedge: 0.31941880459737604, Loss: 0.002947305251785437\n",
      "Iteration:510, Price of Hedge: 0.3237717543081317, Loss: 0.0024564062013249454\n",
      "Iteration:520, Price of Hedge: 0.32730671413053186, Loss: 0.002177628020844402\n",
      "Iteration:530, Price of Hedge: 0.31808037773214437, Loss: 0.0017936698640790283\n",
      "Iteration:540, Price of Hedge: 0.26859599134636486, Loss: 0.0020172718698210803\n",
      "Iteration:550, Price of Hedge: 0.27090979831473305, Loss: 0.0019660394104086265\n",
      "Iteration:560, Price of Hedge: 0.26567077829713526, Loss: 0.0016858888314830623\n",
      "Iteration:570, Price of Hedge: 0.2794080890622354, Loss: 0.0014954928058420692\n",
      "Iteration:580, Price of Hedge: 0.271529110508709, Loss: 0.0017152544217140075\n",
      "Iteration:590, Price of Hedge: 0.27905465652411293, Loss: 0.0017432531419837361\n",
      "Iteration:600, Price of Hedge: 0.289242342115017, Loss: 0.0020545094490769245\n",
      "Iteration:610, Price of Hedge: 0.3058329544622211, Loss: 0.0018417011407315443\n",
      "Iteration:620, Price of Hedge: 0.2891560337135161, Loss: 0.0019006286776871663\n",
      "Iteration:630, Price of Hedge: 0.2817429057941581, Loss: 0.0017846675860722528\n",
      "Iteration:640, Price of Hedge: 0.2852330155057416, Loss: 0.0018713147501841832\n",
      "Iteration:650, Price of Hedge: 0.30242846990779526, Loss: 0.0022638035480966323\n",
      "Iteration:660, Price of Hedge: 0.27132006214126253, Loss: 0.0019451310659363231\n",
      "Iteration:670, Price of Hedge: 0.2718896927108517, Loss: 0.0015845843223448953\n",
      "Iteration:680, Price of Hedge: 0.27047903715790655, Loss: 0.0019430521653886147\n",
      "Iteration:690, Price of Hedge: 0.2690554243640236, Loss: 0.002183440173058848\n",
      "Iteration:700, Price of Hedge: 0.2548540930835316, Loss: 0.0018945004487090245\n",
      "Iteration:710, Price of Hedge: 0.2654557027385181, Loss: 0.0019706272894165267\n",
      "Iteration:720, Price of Hedge: 0.30329440890809567, Loss: 0.0022466027192457718\n",
      "Iteration:730, Price of Hedge: 0.30837533106498544, Loss: 0.0018580187466353594\n",
      "Iteration:740, Price of Hedge: 0.3354278784021517, Loss: 0.0022791780709184198\n",
      "Iteration:750, Price of Hedge: 0.3453700840611646, Loss: 0.002288059866105741\n",
      "Iteration:760, Price of Hedge: 0.3297955780602706, Loss: 0.0020237354299375457\n",
      "Iteration:770, Price of Hedge: 0.2766750140829572, Loss: 0.0017908768359337303\n",
      "Iteration:780, Price of Hedge: 0.2585750173752103, Loss: 0.0021441181647714916\n",
      "Iteration:790, Price of Hedge: 0.2521498851777551, Loss: 0.002418697366484146\n",
      "Iteration:800, Price of Hedge: 0.25522543638408024, Loss: 0.0018141851142891242\n",
      "Iteration:810, Price of Hedge: 0.27795758572312934, Loss: 0.0017806182576418194\n",
      "Iteration:820, Price of Hedge: 0.28451224152679516, Loss: 0.0021308555227628648\n",
      "Iteration:830, Price of Hedge: 0.27059574993268143, Loss: 0.0017008075403470713\n",
      "Iteration:840, Price of Hedge: 0.24963605842790457, Loss: 0.0017495586637183535\n",
      "Iteration:850, Price of Hedge: 0.24491283908628247, Loss: 0.0020959648802005406\n",
      "Iteration:860, Price of Hedge: 0.26540831486299793, Loss: 0.0019619220244361914\n",
      "Iteration:870, Price of Hedge: 0.2535493892069553, Loss: 0.001586405862439655\n",
      "Iteration:880, Price of Hedge: 0.25274909046677296, Loss: 0.0016885857783925928\n",
      "Iteration:890, Price of Hedge: 0.24613591966542572, Loss: 0.0020084057068983086\n",
      "Iteration:900, Price of Hedge: 0.25693452330551736, Loss: 0.0022068574959913435\n",
      "Iteration:910, Price of Hedge: 0.24559005623834765, Loss: 0.0018033147806686856\n",
      "Iteration:920, Price of Hedge: 0.2656489388797354, Loss: 0.0020681979749758383\n",
      "Iteration:930, Price of Hedge: 0.2915329675788826, Loss: 0.001823770742655917\n",
      "Iteration:940, Price of Hedge: 0.3127646635370184, Loss: 0.0018121277557645143\n",
      "Iteration:950, Price of Hedge: 0.2900536215678585, Loss: 0.0019228318311938608\n",
      "Iteration:960, Price of Hedge: 0.23584745553389438, Loss: 0.002134820017562511\n",
      "Iteration:970, Price of Hedge: 0.252705118812969, Loss: 0.0017087369112211094\n",
      "Iteration:980, Price of Hedge: 0.27564824424457585, Loss: 0.0019306115517304435\n",
      "Iteration:990, Price of Hedge: 0.25841682190816756, Loss: 0.0020784088939246105\n",
      "tf.Tensor(0.28545576, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_89 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.24485264037932666, Loss: 0.003390383870527458\n",
      "Iteration:20, Price of Hedge: 0.2511310702556557, Loss: 0.0031480040835887737\n",
      "Iteration:30, Price of Hedge: 0.3035780529168733, Loss: 0.003436152853479868\n",
      "Iteration:40, Price of Hedge: 0.2841174239027396, Loss: 0.002491779537714578\n",
      "Iteration:50, Price of Hedge: 0.29619408489002125, Loss: 0.003763524881499336\n",
      "Iteration:60, Price of Hedge: 0.3039987606212208, Loss: 0.002613315438015107\n",
      "Iteration:70, Price of Hedge: 0.2648376106237265, Loss: 0.002574431514409881\n",
      "Iteration:80, Price of Hedge: 0.2589616116655634, Loss: 0.0026628840144399036\n",
      "Iteration:90, Price of Hedge: 0.316143282412736, Loss: 0.0031965687636096975\n",
      "Iteration:100, Price of Hedge: 0.3058451796556483, Loss: 0.002718754109214494\n",
      "Iteration:110, Price of Hedge: 0.27147005867618645, Loss: 0.00360856224302033\n",
      "Iteration:120, Price of Hedge: 0.28766785432919734, Loss: 0.0030566550393201553\n",
      "Iteration:130, Price of Hedge: 0.29533180612727394, Loss: 0.0028023394464858245\n",
      "Iteration:140, Price of Hedge: 0.2870763599406246, Loss: 0.0029058172216711144\n",
      "Iteration:150, Price of Hedge: 0.29047123027107774, Loss: 0.002679901259500994\n",
      "Iteration:160, Price of Hedge: 0.2653137831277945, Loss: 0.0028045712382063215\n",
      "Iteration:170, Price of Hedge: 0.2873813309335446, Loss: 0.0029396749909489372\n",
      "Iteration:180, Price of Hedge: 0.31787669771310906, Loss: 0.002924546199700373\n",
      "Iteration:190, Price of Hedge: 0.3190965572832056, Loss: 0.003419747363747305\n",
      "Iteration:200, Price of Hedge: 0.28486686974251824, Loss: 0.0034332593594392337\n",
      "Iteration:210, Price of Hedge: 0.30767688453511255, Loss: 0.0030523178484571645\n",
      "Iteration:220, Price of Hedge: 0.2729274432618922, Loss: 0.002406460544177236\n",
      "Iteration:230, Price of Hedge: 0.28070786381890683, Loss: 0.0026925759758526626\n",
      "Iteration:240, Price of Hedge: 0.26512913634403507, Loss: 0.0030949779171379533\n",
      "Iteration:250, Price of Hedge: 0.28291793965502166, Loss: 0.0030509113259224565\n",
      "Iteration:260, Price of Hedge: 0.34898879011877854, Loss: 0.0029187098365396126\n",
      "Iteration:270, Price of Hedge: 0.26243032118825343, Loss: 0.002430459311096023\n",
      "Iteration:280, Price of Hedge: 0.2710951771460032, Loss: 0.0030590618361486578\n",
      "Iteration:290, Price of Hedge: 0.26091312832093083, Loss: 0.002437455512031406\n",
      "Iteration:300, Price of Hedge: 0.2861819442921615, Loss: 0.002859335636220095\n",
      "Iteration:310, Price of Hedge: 0.29960093639806473, Loss: 0.0029659873330210476\n",
      "Iteration:320, Price of Hedge: 0.31919560331139113, Loss: 0.0032156769193729673\n",
      "Iteration:330, Price of Hedge: 0.3312720446844196, Loss: 0.0030610181568658137\n",
      "Iteration:340, Price of Hedge: 0.29700880496616267, Loss: 0.002794529605244378\n",
      "Iteration:350, Price of Hedge: 0.2508437416077413, Loss: 0.002890093832457552\n",
      "Iteration:360, Price of Hedge: 0.2812824723115682, Loss: 0.0028539055213002485\n",
      "Iteration:370, Price of Hedge: 0.24644642981784273, Loss: 0.003171867688610419\n",
      "Iteration:380, Price of Hedge: 0.2950789325155256, Loss: 0.003102242344856521\n",
      "Iteration:390, Price of Hedge: 0.26528733181107783, Loss: 0.002822896255643137\n",
      "Iteration:400, Price of Hedge: 0.26932679437620666, Loss: 0.0021366360291734665\n",
      "Iteration:410, Price of Hedge: 0.2863995332138984, Loss: 0.003007358121151249\n",
      "Iteration:420, Price of Hedge: 0.2698393252399683, Loss: 0.0025664636347865867\n",
      "Iteration:430, Price of Hedge: 0.30034999181250444, Loss: 0.0022490508843841183\n",
      "Iteration:440, Price of Hedge: 0.2718281519167931, Loss: 0.001956990998157693\n",
      "Iteration:450, Price of Hedge: 0.240969006327623, Loss: 0.002007525915423969\n",
      "Iteration:460, Price of Hedge: 0.2392167042014762, Loss: 0.0020282064482360696\n",
      "Iteration:470, Price of Hedge: 0.24485981444493063, Loss: 0.0026070573849862554\n",
      "Iteration:480, Price of Hedge: 0.25423719664634065, Loss: 0.002211318029234377\n",
      "Iteration:490, Price of Hedge: 0.2379776161834343, Loss: 0.0025427510145640043\n",
      "Iteration:500, Price of Hedge: 0.23395450267937576, Loss: 0.002521981644736293\n",
      "Iteration:510, Price of Hedge: 0.2601802755580593, Loss: 0.0018716434090144674\n",
      "Iteration:520, Price of Hedge: 0.27157156926432435, Loss: 0.0016514951805509882\n",
      "Iteration:530, Price of Hedge: 0.26150135289728954, Loss: 0.002103065741053456\n",
      "Iteration:540, Price of Hedge: 0.29400467719528933, Loss: 0.002162568621599448\n",
      "Iteration:550, Price of Hedge: 0.2756885068576594, Loss: 0.002466143577040292\n",
      "Iteration:560, Price of Hedge: 0.25692581194014114, Loss: 0.00252118668689274\n",
      "Iteration:570, Price of Hedge: 0.2692016142518924, Loss: 0.0027896815062229408\n",
      "Iteration:580, Price of Hedge: 0.2912510804841304, Loss: 0.0017038916717602604\n",
      "Iteration:590, Price of Hedge: 0.3040685735521493, Loss: 0.0022840057717409936\n",
      "Iteration:600, Price of Hedge: 0.2650729882999713, Loss: 0.0018255045895593015\n",
      "Iteration:610, Price of Hedge: 0.2612907428284871, Loss: 0.0016542100473735388\n",
      "Iteration:620, Price of Hedge: 0.2764810458942293, Loss: 0.0016664346688886056\n",
      "Iteration:630, Price of Hedge: 0.29973953739340686, Loss: 0.0019943071200110296\n",
      "Iteration:640, Price of Hedge: 0.2863525845668846, Loss: 0.0019973519801254726\n",
      "Iteration:650, Price of Hedge: 0.2926316732859732, Loss: 0.0019766460925428222\n",
      "Iteration:660, Price of Hedge: 0.2786095472360785, Loss: 0.0020273075930244745\n",
      "Iteration:670, Price of Hedge: 0.25565641715515997, Loss: 0.0018031390130111903\n",
      "Iteration:680, Price of Hedge: 0.29554109851055727, Loss: 0.0019306020198618158\n",
      "Iteration:690, Price of Hedge: 0.29152652556078923, Loss: 0.0019335239188709608\n",
      "Iteration:700, Price of Hedge: 0.28042822166985387, Loss: 0.0020188055474832825\n",
      "Iteration:710, Price of Hedge: 0.28095944414671975, Loss: 0.0015852096129268746\n",
      "Iteration:720, Price of Hedge: 0.2852393843190839, Loss: 0.0020875261262670365\n",
      "Iteration:730, Price of Hedge: 0.2848811690705588, Loss: 0.001621400974282139\n",
      "Iteration:740, Price of Hedge: 0.28585345017256714, Loss: 0.001725271271817519\n",
      "Iteration:750, Price of Hedge: 0.27083644715416993, Loss: 0.002328857979568788\n",
      "Iteration:760, Price of Hedge: 0.2900016217930215, Loss: 0.00152017281541168\n",
      "Iteration:770, Price of Hedge: 0.2682078109530721, Loss: 0.0024032504014607882\n",
      "Iteration:780, Price of Hedge: 0.2793538199401155, Loss: 0.0018074967927104169\n",
      "Iteration:790, Price of Hedge: 0.2918864489201724, Loss: 0.002212751241001243\n",
      "Iteration:800, Price of Hedge: 0.3027905406065429, Loss: 0.002418403403655667\n",
      "Iteration:810, Price of Hedge: 0.3311250251427055, Loss: 0.0018241068363437308\n",
      "Iteration:820, Price of Hedge: 0.320981262402438, Loss: 0.001804367670877305\n",
      "Iteration:830, Price of Hedge: 0.2797935120765715, Loss: 0.00216483510932175\n",
      "Iteration:840, Price of Hedge: 0.2813671214053784, Loss: 0.001940576167193875\n",
      "Iteration:850, Price of Hedge: 0.26974369543349896, Loss: 0.0021198685190704225\n",
      "Iteration:860, Price of Hedge: 0.2722905131244943, Loss: 0.0016450243762143658\n",
      "Iteration:870, Price of Hedge: 0.26604551341781646, Loss: 0.002105817782163655\n",
      "Iteration:880, Price of Hedge: 0.3272413666894181, Loss: 0.0024925912716469156\n",
      "Iteration:890, Price of Hedge: 0.2903175002938497, Loss: 0.001955110551114814\n",
      "Iteration:900, Price of Hedge: 0.27956374676457474, Loss: 0.0016651924757690396\n",
      "Iteration:910, Price of Hedge: 0.2696111948340786, Loss: 0.0021132263317358737\n",
      "Iteration:920, Price of Hedge: 0.30113591801989514, Loss: 0.001931420807376938\n",
      "Iteration:930, Price of Hedge: 0.2893405096861898, Loss: 0.0021818557858555468\n",
      "Iteration:940, Price of Hedge: 0.31033380217170364, Loss: 0.0017809097421844556\n",
      "Iteration:950, Price of Hedge: 0.30253283548122456, Loss: 0.002018523976084019\n",
      "Iteration:960, Price of Hedge: 0.27788755317794767, Loss: 0.0017944913205173664\n",
      "Iteration:970, Price of Hedge: 0.24326680585709257, Loss: 0.002062702280799833\n",
      "Iteration:980, Price of Hedge: 0.28828194458426426, Loss: 0.0025531727784468216\n",
      "Iteration:990, Price of Hedge: 0.27798164568464473, Loss: 0.001770878022365885\n",
      "tf.Tensor(0.3661643, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_90 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.35726922352712337, Loss: 0.00525782181910337\n",
      "Iteration:20, Price of Hedge: 0.33951816946610053, Loss: 0.004275581820752806\n",
      "Iteration:30, Price of Hedge: 0.2952343218004444, Loss: 0.005055154465791034\n",
      "Iteration:40, Price of Hedge: 0.34604918013517366, Loss: 0.004820718919441447\n",
      "Iteration:50, Price of Hedge: 0.30289800518110044, Loss: 0.004926278645372407\n",
      "Iteration:60, Price of Hedge: 0.3363930830448908, Loss: 0.004525835693727487\n",
      "Iteration:70, Price of Hedge: 0.3293225289589145, Loss: 0.003723354918178856\n",
      "Iteration:80, Price of Hedge: 0.3213519956633945, Loss: 0.003330394483406707\n",
      "Iteration:90, Price of Hedge: 0.3265908448699065, Loss: 0.004040842017156621\n",
      "Iteration:100, Price of Hedge: 0.33770630307417376, Loss: 0.0031248995965846406\n",
      "Iteration:110, Price of Hedge: 0.31801476187361005, Loss: 0.004482242264470671\n",
      "Iteration:120, Price of Hedge: 0.33274050758911927, Loss: 0.004233393388931717\n",
      "Iteration:130, Price of Hedge: 0.3461845357198854, Loss: 0.004342954593312598\n",
      "Iteration:140, Price of Hedge: 0.28504695343012826, Loss: 0.003948088166089647\n",
      "Iteration:150, Price of Hedge: 0.349694752336427, Loss: 0.0033122744011453878\n",
      "Iteration:160, Price of Hedge: 0.3074746930126821, Loss: 0.004391230838988847\n",
      "Iteration:170, Price of Hedge: 0.2929032385108258, Loss: 0.0036386554961023165\n",
      "Iteration:180, Price of Hedge: 0.3594370846234597, Loss: 0.003781241956355075\n",
      "Iteration:190, Price of Hedge: 0.3469493545573869, Loss: 0.005023838464601482\n",
      "Iteration:200, Price of Hedge: 0.2926178863911901, Loss: 0.00396029010175738\n",
      "Iteration:210, Price of Hedge: 0.3292610369680233, Loss: 0.003796372463339992\n",
      "Iteration:220, Price of Hedge: 0.3486550496586915, Loss: 0.004604106442326739\n",
      "Iteration:230, Price of Hedge: 0.32142581045404767, Loss: 0.003335285094562224\n",
      "Iteration:240, Price of Hedge: 0.30965587737371153, Loss: 0.004807347614130464\n",
      "Iteration:250, Price of Hedge: 0.3278217095542459, Loss: 0.00410309083841689\n",
      "Iteration:260, Price of Hedge: 0.31836924367983105, Loss: 0.0033333569881762062\n",
      "Iteration:270, Price of Hedge: 0.3002658063487843, Loss: 0.004007587615162934\n",
      "Iteration:280, Price of Hedge: 0.36504852161128837, Loss: 0.004842048191232351\n",
      "Iteration:290, Price of Hedge: 0.3210289430969624, Loss: 0.0041981727530775005\n",
      "Iteration:300, Price of Hedge: 0.2875679786471665, Loss: 0.003390299227534044\n",
      "Iteration:310, Price of Hedge: 0.335990017685549, Loss: 0.004021034794148193\n",
      "Iteration:320, Price of Hedge: 0.373948901654785, Loss: 0.004142339260678441\n",
      "Iteration:330, Price of Hedge: 0.28077072229848454, Loss: 0.003922570591223718\n",
      "Iteration:340, Price of Hedge: 0.313876228878712, Loss: 0.004073363609090208\n",
      "Iteration:350, Price of Hedge: 0.3340665872530053, Loss: 0.004415509652207917\n",
      "Iteration:360, Price of Hedge: 0.319737269666075, Loss: 0.0037978906993750175\n",
      "Iteration:370, Price of Hedge: 0.31186463552430727, Loss: 0.0034548818315091267\n",
      "Iteration:380, Price of Hedge: 0.29550927884542944, Loss: 0.004159775336047034\n",
      "Iteration:390, Price of Hedge: 0.3421486357859749, Loss: 0.0031458149946397285\n",
      "Iteration:400, Price of Hedge: 0.32804905910945764, Loss: 0.003398596147262367\n",
      "Iteration:410, Price of Hedge: 0.36003450859686836, Loss: 0.00298230551083698\n",
      "Iteration:420, Price of Hedge: 0.3463122536089031, Loss: 0.0029666558982865965\n",
      "Iteration:430, Price of Hedge: 0.3294118875583763, Loss: 0.0030933941018467695\n",
      "Iteration:440, Price of Hedge: 0.29513793554488077, Loss: 0.003226224885196416\n",
      "Iteration:450, Price of Hedge: 0.32726474340659023, Loss: 0.0030796365652189907\n",
      "Iteration:460, Price of Hedge: 0.3439246806530491, Loss: 0.0021686078229246064\n",
      "Iteration:470, Price of Hedge: 0.3370739360329253, Loss: 0.0021723814897143257\n",
      "Iteration:480, Price of Hedge: 0.33380868691501747, Loss: 0.002532871042093987\n",
      "Iteration:490, Price of Hedge: 0.3188170127404874, Loss: 0.00232804472053747\n",
      "Iteration:500, Price of Hedge: 0.29032413752461256, Loss: 0.002684755458918353\n",
      "Iteration:510, Price of Hedge: 0.3095800860547797, Loss: 0.0028197861975472805\n",
      "Iteration:520, Price of Hedge: 0.3085491679471716, Loss: 0.002599933075736516\n",
      "Iteration:530, Price of Hedge: 0.3386282925122032, Loss: 0.0021448788078879846\n",
      "Iteration:540, Price of Hedge: 0.3225251017991468, Loss: 0.0019875200482733393\n",
      "Iteration:550, Price of Hedge: 0.31002582978399007, Loss: 0.002206004203111789\n",
      "Iteration:560, Price of Hedge: 0.32332732826444044, Loss: 0.002651257803637286\n",
      "Iteration:570, Price of Hedge: 0.36271331445402666, Loss: 0.0029286818868605735\n",
      "Iteration:580, Price of Hedge: 0.35903399486253423, Loss: 0.0029216843514635825\n",
      "Iteration:590, Price of Hedge: 0.3624699574599163, Loss: 0.0026003309359330373\n",
      "Iteration:600, Price of Hedge: 0.33155185764455836, Loss: 0.002399064004759488\n",
      "Iteration:610, Price of Hedge: 0.3165979327199921, Loss: 0.002603635634786272\n",
      "Iteration:620, Price of Hedge: 0.29210679522086597, Loss: 0.002553281060474433\n",
      "Iteration:630, Price of Hedge: 0.31605660798747975, Loss: 0.0035787438890295675\n",
      "Iteration:640, Price of Hedge: 0.3123935642523065, Loss: 0.002107451163171703\n",
      "Iteration:650, Price of Hedge: 0.3376451527054542, Loss: 0.0026262162502906253\n",
      "Iteration:660, Price of Hedge: 0.35759115362070587, Loss: 0.003404250070457593\n",
      "Iteration:670, Price of Hedge: 0.33962980671146853, Loss: 0.002438513549449084\n",
      "Iteration:680, Price of Hedge: 0.3031106161797652, Loss: 0.002618233882227017\n",
      "Iteration:690, Price of Hedge: 0.3069734844837512, Loss: 0.002268509050363399\n",
      "Iteration:700, Price of Hedge: 0.3220057140903691, Loss: 0.0022061738703733624\n",
      "Iteration:710, Price of Hedge: 0.3224990897109365, Loss: 0.0021916789483885425\n",
      "Iteration:720, Price of Hedge: 0.3207377834004092, Loss: 0.002453270979095912\n",
      "Iteration:730, Price of Hedge: 0.3337101289185057, Loss: 0.002760742181157028\n",
      "Iteration:740, Price of Hedge: 0.2931011109529436, Loss: 0.002306789987959235\n",
      "Iteration:750, Price of Hedge: 0.30747254567331767, Loss: 0.0019382294211377272\n",
      "Iteration:760, Price of Hedge: 0.30658959876918745, Loss: 0.0024442107473278797\n",
      "Iteration:770, Price of Hedge: 0.3447822499101449, Loss: 0.0027389275466155995\n",
      "Iteration:780, Price of Hedge: 0.337088772195807, Loss: 0.002080534309991222\n",
      "Iteration:790, Price of Hedge: 0.31032831181537407, Loss: 0.0024638622196029303\n",
      "Iteration:800, Price of Hedge: 0.29748258611502937, Loss: 0.0019067691074571515\n",
      "Iteration:810, Price of Hedge: 0.33687013400597154, Loss: 0.0025909111620803674\n",
      "Iteration:820, Price of Hedge: 0.3332402764246126, Loss: 0.002225344173920085\n",
      "Iteration:830, Price of Hedge: 0.3248495234564189, Loss: 0.002839377809687349\n",
      "Iteration:840, Price of Hedge: 0.3082970995876849, Loss: 0.0028909719081955387\n",
      "Iteration:850, Price of Hedge: 0.3235836669010723, Loss: 0.0023768924970566374\n",
      "Iteration:860, Price of Hedge: 0.30518331109972224, Loss: 0.0024273372428456953\n",
      "Iteration:870, Price of Hedge: 0.28680079285604737, Loss: 0.002142257162740613\n",
      "Iteration:880, Price of Hedge: 0.3116976066839698, Loss: 0.002557566969884206\n",
      "Iteration:890, Price of Hedge: 0.32254320777424256, Loss: 0.0024628993102341567\n",
      "Iteration:900, Price of Hedge: 0.2820131777350753, Loss: 0.0026756386078506723\n",
      "Iteration:910, Price of Hedge: 0.3223997752653304, Loss: 0.0030267823536782148\n",
      "Iteration:920, Price of Hedge: 0.3290466202521657, Loss: 0.0024920279382110166\n",
      "Iteration:930, Price of Hedge: 0.3567997370569856, Loss: 0.0026059371997851247\n",
      "Iteration:940, Price of Hedge: 0.3308301808070155, Loss: 0.002029630890683798\n",
      "Iteration:950, Price of Hedge: 0.3156379256145783, Loss: 0.0023532927341586075\n",
      "Iteration:960, Price of Hedge: 0.32664081931329747, Loss: 0.003716122517538878\n",
      "Iteration:970, Price of Hedge: 0.338661283453348, Loss: 0.003192973342763317\n",
      "Iteration:980, Price of Hedge: 0.32504244237704827, Loss: 0.002337789149835601\n",
      "Iteration:990, Price of Hedge: 0.3020389230258161, Loss: 0.0019696159581551243\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 14 \n",
      "\n",
      "tf.Tensor(0.05476952, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_91 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.035813013996110504, Loss: 0.0032888444670403417\n",
      "Iteration:20, Price of Hedge: 0.05359497194068581, Loss: 0.0012272973037565915\n",
      "Iteration:30, Price of Hedge: 0.047390504328639345, Loss: 0.0013187085724359006\n",
      "Iteration:40, Price of Hedge: 0.04881659528000455, Loss: 0.001100132075779392\n",
      "Iteration:50, Price of Hedge: 0.04856163142771664, Loss: 0.0008855202419045583\n",
      "Iteration:60, Price of Hedge: 0.04910429865095836, Loss: 0.0008006379848469081\n",
      "Iteration:70, Price of Hedge: 0.048073120229237536, Loss: 0.0012367353176040653\n",
      "Iteration:80, Price of Hedge: 0.051624040662656516, Loss: 0.0011653139453029482\n",
      "Iteration:90, Price of Hedge: 0.04901590399295089, Loss: 0.0010118200069351158\n",
      "Iteration:100, Price of Hedge: 0.05046516382140567, Loss: 0.001005665391009991\n",
      "Iteration:110, Price of Hedge: 0.04632114954491585, Loss: 0.0011341999141241566\n",
      "Iteration:120, Price of Hedge: 0.05245365965717213, Loss: 0.0011071658131371898\n",
      "Iteration:130, Price of Hedge: 0.04669550337244602, Loss: 0.0012264084809693544\n",
      "Iteration:140, Price of Hedge: 0.05208707099807413, Loss: 0.0009646300015224486\n",
      "Iteration:150, Price of Hedge: 0.04721739948496833, Loss: 0.0011314088599459371\n",
      "Iteration:160, Price of Hedge: 0.049193342789124024, Loss: 0.0008853215556100969\n",
      "Iteration:170, Price of Hedge: 0.05152076923272376, Loss: 0.001187019321996763\n",
      "Iteration:180, Price of Hedge: 0.047535648847261316, Loss: 0.0011119967047619195\n",
      "Iteration:190, Price of Hedge: 0.05191851251551043, Loss: 0.0011607774131995987\n",
      "Iteration:200, Price of Hedge: 0.04900487099982343, Loss: 0.0011004568158584861\n",
      "Iteration:210, Price of Hedge: 0.0487296793126717, Loss: 0.001061084634256382\n",
      "Iteration:220, Price of Hedge: 0.05030257320369174, Loss: 0.0013234124529054815\n",
      "Iteration:230, Price of Hedge: 0.05038761017182481, Loss: 0.001254916549603058\n",
      "Iteration:240, Price of Hedge: 0.04861171084117189, Loss: 0.0010494073945962246\n",
      "Iteration:250, Price of Hedge: 0.05249688889310989, Loss: 0.0009956257017054383\n",
      "Iteration:260, Price of Hedge: 0.04815794478876541, Loss: 0.001020504123413435\n",
      "Iteration:270, Price of Hedge: 0.048171081444040455, Loss: 0.000957819586793729\n",
      "Iteration:280, Price of Hedge: 0.046575484340949914, Loss: 0.0008067509232422277\n",
      "Iteration:290, Price of Hedge: 0.054201749799668165, Loss: 0.00088591991218272\n",
      "Iteration:300, Price of Hedge: 0.044530402035803725, Loss: 0.001001762765837766\n",
      "Iteration:310, Price of Hedge: 0.050926147681607865, Loss: 0.0008958942449933672\n",
      "Iteration:320, Price of Hedge: 0.04760167933001043, Loss: 0.0011526876323377346\n",
      "Iteration:330, Price of Hedge: 0.04999827745284762, Loss: 0.0013000217211549536\n",
      "Iteration:340, Price of Hedge: 0.048207378806843344, Loss: 0.0010935711518071933\n",
      "Iteration:350, Price of Hedge: 0.05034812259516315, Loss: 0.0012803856689195482\n",
      "Iteration:360, Price of Hedge: 0.04970080737083578, Loss: 0.0010328641597257438\n",
      "Iteration:370, Price of Hedge: 0.04880933662440015, Loss: 0.0011488681069263152\n",
      "Iteration:380, Price of Hedge: 0.046862509638279454, Loss: 0.0010789256805986192\n",
      "Iteration:390, Price of Hedge: 0.050391376339786124, Loss: 0.0009147465937242139\n",
      "Iteration:400, Price of Hedge: 0.04897775213963343, Loss: 0.0009622255973833706\n",
      "Iteration:410, Price of Hedge: 0.04726296113078235, Loss: 0.0011130971702579375\n",
      "Iteration:420, Price of Hedge: 0.04977309573787637, Loss: 0.0011357036240815966\n",
      "Iteration:430, Price of Hedge: 0.05009710055641393, Loss: 0.001080933095096981\n",
      "Iteration:440, Price of Hedge: 0.04702111759464601, Loss: 0.0009982918509436446\n",
      "Iteration:450, Price of Hedge: 0.04995220929420583, Loss: 0.0011728561102295476\n",
      "Iteration:460, Price of Hedge: 0.05226723025830609, Loss: 0.0010180965280393028\n",
      "Iteration:470, Price of Hedge: 0.04897441895844424, Loss: 0.0009473442939043065\n",
      "Iteration:480, Price of Hedge: 0.04663017138722552, Loss: 0.0009330252222170544\n",
      "Iteration:490, Price of Hedge: 0.05689444960292605, Loss: 0.001379504280851851\n",
      "Iteration:500, Price of Hedge: 0.05002058444117381, Loss: 0.0010613633567259973\n",
      "Iteration:510, Price of Hedge: 0.046645231974289915, Loss: 0.0008179524135805361\n",
      "Iteration:520, Price of Hedge: 0.04817610163972859, Loss: 0.0008070433680225753\n",
      "Iteration:530, Price of Hedge: 0.04920180645508481, Loss: 0.0009597045855154197\n",
      "Iteration:540, Price of Hedge: 0.04591005719824893, Loss: 0.0007169278045998873\n",
      "Iteration:550, Price of Hedge: 0.049709409919346116, Loss: 0.0008854912654902681\n",
      "Iteration:560, Price of Hedge: 0.050894850090588764, Loss: 0.0008259689875102617\n",
      "Iteration:570, Price of Hedge: 0.051896511885749425, Loss: 0.000983273260532558\n",
      "Iteration:580, Price of Hedge: 0.045241795217624774, Loss: 0.000634600195027657\n",
      "Iteration:590, Price of Hedge: 0.04171345545285021, Loss: 0.0005908656589314499\n",
      "Iteration:600, Price of Hedge: 0.05394701469510892, Loss: 0.0006470174182721333\n",
      "Iteration:610, Price of Hedge: 0.05221116255609673, Loss: 0.0008300672353912964\n",
      "Iteration:620, Price of Hedge: 0.04663889647916193, Loss: 0.0006138429342683827\n",
      "Iteration:630, Price of Hedge: 0.04851325128310294, Loss: 0.000737435829901445\n",
      "Iteration:640, Price of Hedge: 0.048966000225073004, Loss: 0.0005879592096936781\n",
      "Iteration:650, Price of Hedge: 0.048874296894561554, Loss: 0.0006257284977528644\n",
      "Iteration:660, Price of Hedge: 0.04767880816238091, Loss: 0.0007112057286739804\n",
      "Iteration:670, Price of Hedge: 0.04952398129179301, Loss: 0.000731425713099565\n",
      "Iteration:680, Price of Hedge: 0.045291323185662695, Loss: 0.0007419039419252372\n",
      "Iteration:690, Price of Hedge: 0.04735187047117933, Loss: 0.0006841068456154176\n",
      "Iteration:700, Price of Hedge: 0.05392839626390753, Loss: 0.000944520370005031\n",
      "Iteration:710, Price of Hedge: 0.05122581946050815, Loss: 0.0006684665387911127\n",
      "Iteration:720, Price of Hedge: 0.04780534241936323, Loss: 0.000733909323692683\n",
      "Iteration:730, Price of Hedge: 0.047401884528140675, Loss: 0.0006932240126905632\n",
      "Iteration:740, Price of Hedge: 0.04719328293871712, Loss: 0.0006411900954141459\n",
      "Iteration:750, Price of Hedge: 0.04778610310146974, Loss: 0.000674524013521194\n",
      "Iteration:760, Price of Hedge: 0.04768061363552505, Loss: 0.0006713001002202513\n",
      "Iteration:770, Price of Hedge: 0.05222577381726552, Loss: 0.0008238835154024793\n",
      "Iteration:780, Price of Hedge: 0.0539452990871439, Loss: 0.000688867083296052\n",
      "Iteration:790, Price of Hedge: 0.047733376750011304, Loss: 0.0007089111668454607\n",
      "Iteration:800, Price of Hedge: 0.04576312354560628, Loss: 0.0008176079516688085\n",
      "Iteration:810, Price of Hedge: 0.05040412085609774, Loss: 0.0008140135998027987\n",
      "Iteration:820, Price of Hedge: 0.051478589785469354, Loss: 0.0005810412503436391\n",
      "Iteration:830, Price of Hedge: 0.049258233618010655, Loss: 0.0006452016693511142\n",
      "Iteration:840, Price of Hedge: 0.04742980809016189, Loss: 0.000592729404027681\n",
      "Iteration:850, Price of Hedge: 0.050381801613428936, Loss: 0.0007558685312226921\n",
      "Iteration:860, Price of Hedge: 0.05168714235752248, Loss: 0.0007279562661735684\n",
      "Iteration:870, Price of Hedge: 0.05136129530281295, Loss: 0.0007811435596231987\n",
      "Iteration:880, Price of Hedge: 0.04805486125875263, Loss: 0.0006420561327830977\n",
      "Iteration:890, Price of Hedge: 0.05403467409255996, Loss: 0.0006278890277091165\n",
      "Iteration:900, Price of Hedge: 0.05000588739960677, Loss: 0.0007958918524252124\n",
      "Iteration:910, Price of Hedge: 0.050724702628266984, Loss: 0.0008486815179871155\n",
      "Iteration:920, Price of Hedge: 0.048521106316714226, Loss: 0.0006422377778823708\n",
      "Iteration:930, Price of Hedge: 0.04403401129502811, Loss: 0.000701342450843212\n",
      "Iteration:940, Price of Hedge: 0.04857694118641405, Loss: 0.0006972046316475078\n",
      "Iteration:950, Price of Hedge: 0.049210114899372576, Loss: 0.0006830077204381225\n",
      "Iteration:960, Price of Hedge: 0.04800677930314237, Loss: 0.0007965055907507957\n",
      "Iteration:970, Price of Hedge: 0.04759847277702818, Loss: 0.0007036479266956165\n",
      "Iteration:980, Price of Hedge: 0.05150762440788697, Loss: 0.0007175572438019363\n",
      "Iteration:990, Price of Hedge: 0.04628112277717947, Loss: 0.0006264220807794985\n",
      "tf.Tensor(0.029524127, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_92 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.030785827205520637, Loss: 0.0005527168691996432\n",
      "Iteration:20, Price of Hedge: 0.034998426995193205, Loss: 0.0006266139378309443\n",
      "Iteration:30, Price of Hedge: 0.034287319748032986, Loss: 0.00043142973663014007\n",
      "Iteration:40, Price of Hedge: 0.030160498314221233, Loss: 0.00042002403916072687\n",
      "Iteration:50, Price of Hedge: 0.027378972908574186, Loss: 0.0004142243204859564\n",
      "Iteration:60, Price of Hedge: 0.03323304189049736, Loss: 0.0004062144162374937\n",
      "Iteration:70, Price of Hedge: 0.03141769174621061, Loss: 0.0004089269022086839\n",
      "Iteration:80, Price of Hedge: 0.03412840543310125, Loss: 0.00035815572473077987\n",
      "Iteration:90, Price of Hedge: 0.03273196794845532, Loss: 0.0003965926510756113\n",
      "Iteration:100, Price of Hedge: 0.032719693181943656, Loss: 0.0004889471850121785\n",
      "Iteration:110, Price of Hedge: 0.032014643664812326, Loss: 0.0004196571109542191\n",
      "Iteration:120, Price of Hedge: 0.034298487538929126, Loss: 0.0003728963266563135\n",
      "Iteration:130, Price of Hedge: 0.03840477477931188, Loss: 0.0004024988612641334\n",
      "Iteration:140, Price of Hedge: 0.035056643292139714, Loss: 0.0004173062238269965\n",
      "Iteration:150, Price of Hedge: 0.03421835435022942, Loss: 0.0005480906633912764\n",
      "Iteration:160, Price of Hedge: 0.032052323725939406, Loss: 0.0003867070984241661\n",
      "Iteration:170, Price of Hedge: 0.028458649933553917, Loss: 0.0004102304898158882\n",
      "Iteration:180, Price of Hedge: 0.027350477477231298, Loss: 0.00037317160259207064\n",
      "Iteration:190, Price of Hedge: 0.030250404341150276, Loss: 0.0003360334770018625\n",
      "Iteration:200, Price of Hedge: 0.02759665496586976, Loss: 0.0003760400761326999\n",
      "Iteration:210, Price of Hedge: 0.029393740012500304, Loss: 0.0003709677356637853\n",
      "Iteration:220, Price of Hedge: 0.0342730516084572, Loss: 0.000432591441926844\n",
      "Iteration:230, Price of Hedge: 0.03342462219803935, Loss: 0.00039379866096114215\n",
      "Iteration:240, Price of Hedge: 0.029985683989756498, Loss: 0.0004632056618714797\n",
      "Iteration:250, Price of Hedge: 0.026285675181786417, Loss: 0.00040543562723491803\n",
      "Iteration:260, Price of Hedge: 0.02599850078995516, Loss: 0.0003859650405370619\n",
      "Iteration:270, Price of Hedge: 0.02800555786999084, Loss: 0.0003899465211274711\n",
      "Iteration:280, Price of Hedge: 0.03243949763822727, Loss: 0.00041084674921716414\n",
      "Iteration:290, Price of Hedge: 0.034148232959439896, Loss: 0.00046738193544958455\n",
      "Iteration:300, Price of Hedge: 0.029686373713963123, Loss: 0.0003611861534503991\n",
      "Iteration:310, Price of Hedge: 0.030194418334558295, Loss: 0.0003119697776031494\n",
      "Iteration:320, Price of Hedge: 0.029571532142218616, Loss: 0.00039455198390798697\n",
      "Iteration:330, Price of Hedge: 0.030853628440776507, Loss: 0.0003370256000677974\n",
      "Iteration:340, Price of Hedge: 0.03355833341500869, Loss: 0.0004569383634365987\n",
      "Iteration:350, Price of Hedge: 0.0334362045941937, Loss: 0.00033659213461041394\n",
      "Iteration:360, Price of Hedge: 0.03428264267393786, Loss: 0.0003796260988752187\n",
      "Iteration:370, Price of Hedge: 0.03575583931828561, Loss: 0.0004222414050132906\n",
      "Iteration:380, Price of Hedge: 0.03402280976285397, Loss: 0.0003162657544081293\n",
      "Iteration:390, Price of Hedge: 0.029926891738707443, Loss: 0.0002696689995919988\n",
      "Iteration:400, Price of Hedge: 0.03238469621808733, Loss: 0.000432551072803411\n",
      "Iteration:410, Price of Hedge: 0.03387519599419662, Loss: 0.0003082246398808386\n",
      "Iteration:420, Price of Hedge: 0.03298616998911115, Loss: 0.00022353084120930178\n",
      "Iteration:430, Price of Hedge: 0.030968790667819237, Loss: 0.00028040042100685447\n",
      "Iteration:440, Price of Hedge: 0.03229013966813881, Loss: 0.0003189230958375866\n",
      "Iteration:450, Price of Hedge: 0.03132726286733032, Loss: 0.0003306473743024396\n",
      "Iteration:460, Price of Hedge: 0.029561783812674495, Loss: 0.00029198192361539204\n",
      "Iteration:470, Price of Hedge: 0.029214526379039544, Loss: 0.0003092349529865812\n",
      "Iteration:480, Price of Hedge: 0.03162085444990695, Loss: 0.00024305317378355842\n",
      "Iteration:490, Price of Hedge: 0.03472694020428975, Loss: 0.000260783994867031\n",
      "Iteration:500, Price of Hedge: 0.035133702683235415, Loss: 0.00025298005292895276\n",
      "Iteration:510, Price of Hedge: 0.03362790948755219, Loss: 0.0002684040897536488\n",
      "Iteration:520, Price of Hedge: 0.030443504187175566, Loss: 0.0002877512713919672\n",
      "Iteration:530, Price of Hedge: 0.031001044097561707, Loss: 0.00041250721264045613\n",
      "Iteration:540, Price of Hedge: 0.031422403540943125, Loss: 0.0002647001987444109\n",
      "Iteration:550, Price of Hedge: 0.031563975918695066, Loss: 0.0002724405234116878\n",
      "Iteration:560, Price of Hedge: 0.030088455034032794, Loss: 0.0002581112716846135\n",
      "Iteration:570, Price of Hedge: 0.028446328192062255, Loss: 0.0002328102825869427\n",
      "Iteration:580, Price of Hedge: 0.029960354263587164, Loss: 0.00025573029121083173\n",
      "Iteration:590, Price of Hedge: 0.03063721470794079, Loss: 0.0002541011816719452\n",
      "Iteration:600, Price of Hedge: 0.03264005629411955, Loss: 0.0002894012994766326\n",
      "Iteration:610, Price of Hedge: 0.03210562194671951, Loss: 0.0002356263400918102\n",
      "Iteration:620, Price of Hedge: 0.033522799906228334, Loss: 0.00029900956571423667\n",
      "Iteration:630, Price of Hedge: 0.03144939373053575, Loss: 0.0002668597553739716\n",
      "Iteration:640, Price of Hedge: 0.03025678476886782, Loss: 0.0002462545090964941\n",
      "Iteration:650, Price of Hedge: 0.030803087447083047, Loss: 0.0003702944808044451\n",
      "Iteration:660, Price of Hedge: 0.029673962107292343, Loss: 0.00028669749366478926\n",
      "Iteration:670, Price of Hedge: 0.028085180461081907, Loss: 0.0002739369573532047\n",
      "Iteration:680, Price of Hedge: 0.024869575604427045, Loss: 0.0002847513827918147\n",
      "Iteration:690, Price of Hedge: 0.02837059022757771, Loss: 0.0002503449224954713\n",
      "Iteration:700, Price of Hedge: 0.02722722942645817, Loss: 0.00024601580471445564\n",
      "Iteration:710, Price of Hedge: 0.0269244144086791, Loss: 0.0003470549178584248\n",
      "Iteration:720, Price of Hedge: 0.029053502274788912, Loss: 0.00023253808619301265\n",
      "Iteration:730, Price of Hedge: 0.032792914921412834, Loss: 0.00036828716204313495\n",
      "Iteration:740, Price of Hedge: 0.032058810357959544, Loss: 0.0003320787708735562\n",
      "Iteration:750, Price of Hedge: 0.035126484875439706, Loss: 0.00029108716513095436\n",
      "Iteration:760, Price of Hedge: 0.03565793529041486, Loss: 0.00023518590178583378\n",
      "Iteration:770, Price of Hedge: 0.03323328085017821, Loss: 0.00020273442399591502\n",
      "Iteration:780, Price of Hedge: 0.03260212501896902, Loss: 0.00027955413738288697\n",
      "Iteration:790, Price of Hedge: 0.030709343768527478, Loss: 0.00025208420942459677\n",
      "Iteration:800, Price of Hedge: 0.028213989941008325, Loss: 0.00023596478652546107\n",
      "Iteration:810, Price of Hedge: 0.028102191531011303, Loss: 0.0002052375809037388\n",
      "Iteration:820, Price of Hedge: 0.028007381724648898, Loss: 0.0002719696885918222\n",
      "Iteration:830, Price of Hedge: 0.033272666307318136, Loss: 0.00021698692651994091\n",
      "Iteration:840, Price of Hedge: 0.032274658348644895, Loss: 0.00021868164785153745\n",
      "Iteration:850, Price of Hedge: 0.03189939769976178, Loss: 0.0002713376325770289\n",
      "Iteration:860, Price of Hedge: 0.03230191404899401, Loss: 0.00027745044332294633\n",
      "Iteration:870, Price of Hedge: 0.030734552993661172, Loss: 0.00031844415528068385\n",
      "Iteration:880, Price of Hedge: 0.03226597818929804, Loss: 0.00022320070794296654\n",
      "Iteration:890, Price of Hedge: 0.03338659901531926, Loss: 0.00023245399714934002\n",
      "Iteration:900, Price of Hedge: 0.035327121142168495, Loss: 0.00025574565700761664\n",
      "Iteration:910, Price of Hedge: 0.029397287644685122, Loss: 0.0002429215512937566\n",
      "Iteration:920, Price of Hedge: 0.029296759145105968, Loss: 0.00023473518770298355\n",
      "Iteration:930, Price of Hedge: 0.028748489644902266, Loss: 0.0003588464037335149\n",
      "Iteration:940, Price of Hedge: 0.02968883479443676, Loss: 0.0003234678294150251\n",
      "Iteration:950, Price of Hedge: 0.029216131697921102, Loss: 0.0002324031448187547\n",
      "Iteration:960, Price of Hedge: 0.03167811899291095, Loss: 0.00032817340123918464\n",
      "Iteration:970, Price of Hedge: 0.028633727726384707, Loss: 0.0003232821314472334\n",
      "Iteration:980, Price of Hedge: 0.02631904171431572, Loss: 0.0002806630915641484\n",
      "Iteration:990, Price of Hedge: 0.028590310590526972, Loss: 0.00028589027075788255\n",
      "tf.Tensor(0.0351895, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_93 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.03428345554533081, Loss: 0.0011061744878800184\n",
      "Iteration:20, Price of Hedge: 0.05492453135055229, Loss: 0.0009485960239418834\n",
      "Iteration:30, Price of Hedge: 0.04219153412098962, Loss: 0.0007862344092554263\n",
      "Iteration:40, Price of Hedge: 0.042945989062732795, Loss: 0.0008247533822534959\n",
      "Iteration:50, Price of Hedge: 0.0469426571237122, Loss: 0.0006935841754787564\n",
      "Iteration:60, Price of Hedge: 0.04118126977731862, Loss: 0.0009867900015620547\n",
      "Iteration:70, Price of Hedge: 0.04760767578832628, Loss: 0.0009206036588929046\n",
      "Iteration:80, Price of Hedge: 0.04035863984287005, Loss: 0.0009501393690386939\n",
      "Iteration:90, Price of Hedge: 0.04625279073707134, Loss: 0.0010800003609154009\n",
      "Iteration:100, Price of Hedge: 0.044226784358583876, Loss: 0.0007706483534270392\n",
      "Iteration:110, Price of Hedge: 0.04251598418064191, Loss: 0.0008786932965782591\n",
      "Iteration:120, Price of Hedge: 0.04626601725752551, Loss: 0.0008020245764778667\n",
      "Iteration:130, Price of Hedge: 0.045157219829729915, Loss: 0.0009863636525588417\n",
      "Iteration:140, Price of Hedge: 0.0453338457545101, Loss: 0.0009227729328332046\n",
      "Iteration:150, Price of Hedge: 0.04139923368449416, Loss: 0.0007999094258840822\n",
      "Iteration:160, Price of Hedge: 0.04806443190032895, Loss: 0.0007822689167526376\n",
      "Iteration:170, Price of Hedge: 0.042575417742287416, Loss: 0.0007105089544122922\n",
      "Iteration:180, Price of Hedge: 0.04794001355983682, Loss: 0.0009007454328730403\n",
      "Iteration:190, Price of Hedge: 0.04157362523413895, Loss: 0.0007912114594456288\n",
      "Iteration:200, Price of Hedge: 0.04227113424578591, Loss: 0.0008289240073455551\n",
      "Iteration:210, Price of Hedge: 0.045211592347878596, Loss: 0.0008418398291548669\n",
      "Iteration:220, Price of Hedge: 0.04213156953783113, Loss: 0.0007936669871702718\n",
      "Iteration:230, Price of Hedge: 0.04411605411878412, Loss: 0.0007954206984818413\n",
      "Iteration:240, Price of Hedge: 0.04376364781886367, Loss: 0.0007883269659050286\n",
      "Iteration:250, Price of Hedge: 0.04313624998605406, Loss: 0.0010119287004010547\n",
      "Iteration:260, Price of Hedge: 0.0440431366954897, Loss: 0.0007749523721443552\n",
      "Iteration:270, Price of Hedge: 0.044291013452969714, Loss: 0.0008771830126766078\n",
      "Iteration:280, Price of Hedge: 0.03989257451526669, Loss: 0.0008820901748191279\n",
      "Iteration:290, Price of Hedge: 0.04512367560923281, Loss: 0.0007724083195593146\n",
      "Iteration:300, Price of Hedge: 0.04393668730604077, Loss: 0.0008538095135953717\n",
      "Iteration:310, Price of Hedge: 0.045052073485378236, Loss: 0.000970857952029114\n",
      "Iteration:320, Price of Hedge: 0.039143311330008146, Loss: 0.0008287774658318759\n",
      "Iteration:330, Price of Hedge: 0.04707540433239644, Loss: 0.0007497550184050628\n",
      "Iteration:340, Price of Hedge: 0.046649030820498184, Loss: 0.0008253091677504987\n",
      "Iteration:350, Price of Hedge: 0.04237113785102338, Loss: 0.0006414489684017255\n",
      "Iteration:360, Price of Hedge: 0.04574926796889827, Loss: 0.0007564668239706141\n",
      "Iteration:370, Price of Hedge: 0.04189074719691206, Loss: 0.00057868879951124\n",
      "Iteration:380, Price of Hedge: 0.04667332301232677, Loss: 0.0006204450251727778\n",
      "Iteration:390, Price of Hedge: 0.04428329730190797, Loss: 0.000826274835477836\n",
      "Iteration:400, Price of Hedge: 0.04591344348158941, Loss: 0.0005640911330037746\n",
      "Iteration:410, Price of Hedge: 0.04316887513085561, Loss: 0.0006820969419537138\n",
      "Iteration:420, Price of Hedge: 0.04131186430648484, Loss: 0.0004984300676245113\n",
      "Iteration:430, Price of Hedge: 0.04798230329617468, Loss: 0.0005976855197159293\n",
      "Iteration:440, Price of Hedge: 0.04897188639430539, Loss: 0.0006806019759803217\n",
      "Iteration:450, Price of Hedge: 0.040458998824043135, Loss: 0.0005460421457854193\n",
      "Iteration:460, Price of Hedge: 0.043424402682903464, Loss: 0.000618495882626502\n",
      "Iteration:470, Price of Hedge: 0.04636936221351391, Loss: 0.0005256702904836152\n",
      "Iteration:480, Price of Hedge: 0.048727820737376255, Loss: 0.0005559088701500459\n",
      "Iteration:490, Price of Hedge: 0.04175596576735501, Loss: 0.0005566111333360269\n",
      "Iteration:500, Price of Hedge: 0.04222194122977925, Loss: 0.000473060833965211\n",
      "Iteration:510, Price of Hedge: 0.04985267135398744, Loss: 0.0006049468559577776\n",
      "Iteration:520, Price of Hedge: 0.044761094120167405, Loss: 0.0004894768342940892\n",
      "Iteration:530, Price of Hedge: 0.044343368089369055, Loss: 0.000521577627263925\n",
      "Iteration:540, Price of Hedge: 0.0472599792407479, Loss: 0.000547267324747347\n",
      "Iteration:550, Price of Hedge: 0.04446973895511661, Loss: 0.0005138924950069068\n",
      "Iteration:560, Price of Hedge: 0.040121338583060155, Loss: 0.0004827602737883075\n",
      "Iteration:570, Price of Hedge: 0.04247806107505312, Loss: 0.0005680614761838454\n",
      "Iteration:580, Price of Hedge: 0.04976175230140285, Loss: 0.0005963305213120052\n",
      "Iteration:590, Price of Hedge: 0.04491066245647062, Loss: 0.00060375065341014\n",
      "Iteration:600, Price of Hedge: 0.04226778472547324, Loss: 0.00043317754415685974\n",
      "Iteration:610, Price of Hedge: 0.04114226012001865, Loss: 0.000550824211513823\n",
      "Iteration:620, Price of Hedge: 0.04408980940170011, Loss: 0.0005649739562691103\n",
      "Iteration:630, Price of Hedge: 0.044989286318639195, Loss: 0.0006367159838684522\n",
      "Iteration:640, Price of Hedge: 0.04389072943648245, Loss: 0.0006800617637103824\n",
      "Iteration:650, Price of Hedge: 0.045112944889889664, Loss: 0.0006106148723618699\n",
      "Iteration:660, Price of Hedge: 0.0421772700661947, Loss: 0.000618876660793144\n",
      "Iteration:670, Price of Hedge: 0.03997998474108471, Loss: 0.000510450396965323\n",
      "Iteration:680, Price of Hedge: 0.04568562299817672, Loss: 0.0005765192702721356\n",
      "Iteration:690, Price of Hedge: 0.04385010629073918, Loss: 0.0005050991106403391\n",
      "Iteration:700, Price of Hedge: 0.045978289377886485, Loss: 0.0005058832609178055\n",
      "Iteration:710, Price of Hedge: 0.0458961771128557, Loss: 0.0004759196061512761\n",
      "Iteration:720, Price of Hedge: 0.046783509976270926, Loss: 0.0005729747654976691\n",
      "Iteration:730, Price of Hedge: 0.04387818098965255, Loss: 0.0007494973580868037\n",
      "Iteration:740, Price of Hedge: 0.04555520819936874, Loss: 0.000477977154952336\n",
      "Iteration:750, Price of Hedge: 0.04831681008632672, Loss: 0.0006400496756552521\n",
      "Iteration:760, Price of Hedge: 0.04450031762470275, Loss: 0.0005995686675212887\n",
      "Iteration:770, Price of Hedge: 0.040574937159451, Loss: 0.0005906199338322927\n",
      "Iteration:780, Price of Hedge: 0.045251606861272366, Loss: 0.0006269185093044972\n",
      "Iteration:790, Price of Hedge: 0.042841447265949746, Loss: 0.0004964275676281327\n",
      "Iteration:800, Price of Hedge: 0.042885897851367365, Loss: 0.0005885744159873863\n",
      "Iteration:810, Price of Hedge: 0.040373255188819714, Loss: 0.0004292611647615519\n",
      "Iteration:820, Price of Hedge: 0.041543994233714444, Loss: 0.0005217118506102959\n",
      "Iteration:830, Price of Hedge: 0.03957670249543952, Loss: 0.0007790211968381922\n",
      "Iteration:840, Price of Hedge: 0.04170236118800972, Loss: 0.00047229235265185967\n",
      "Iteration:850, Price of Hedge: 0.045011679087363636, Loss: 0.000583380744761719\n",
      "Iteration:860, Price of Hedge: 0.04697695294388922, Loss: 0.0004925122413403926\n",
      "Iteration:870, Price of Hedge: 0.04581488997356047, Loss: 0.0004797819260247694\n",
      "Iteration:880, Price of Hedge: 0.04346686398003783, Loss: 0.0006158573694838632\n",
      "Iteration:890, Price of Hedge: 0.04636333716173198, Loss: 0.0005684829745097764\n",
      "Iteration:900, Price of Hedge: 0.04116838637845746, Loss: 0.000547003409608382\n",
      "Iteration:910, Price of Hedge: 0.040417517874317355, Loss: 0.0004962765583853779\n",
      "Iteration:920, Price of Hedge: 0.04595357645362839, Loss: 0.00046407182688983366\n",
      "Iteration:930, Price of Hedge: 0.04690359436426093, Loss: 0.0005679426984151359\n",
      "Iteration:940, Price of Hedge: 0.04233967278398865, Loss: 0.00043187922208749453\n",
      "Iteration:950, Price of Hedge: 0.04078705574520285, Loss: 0.0005681561920402479\n",
      "Iteration:960, Price of Hedge: 0.045837123435831024, Loss: 0.0005231240359463874\n",
      "Iteration:970, Price of Hedge: 0.04679839491775795, Loss: 0.0005814917889085614\n",
      "Iteration:980, Price of Hedge: 0.04657615424501245, Loss: 0.0005664887078998371\n",
      "Iteration:990, Price of Hedge: 0.04125266766212974, Loss: 0.0006990272736362436\n",
      "tf.Tensor(0.045526404, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_94 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.03754705249241681, Loss: 0.001529559216676102\n",
      "Iteration:20, Price of Hedge: 0.04421915807270125, Loss: 0.0008733027899744617\n",
      "Iteration:30, Price of Hedge: 0.038252808676638494, Loss: 0.0007048471928289058\n",
      "Iteration:40, Price of Hedge: 0.04168145119474076, Loss: 0.0009891365805219543\n",
      "Iteration:50, Price of Hedge: 0.0411612012489087, Loss: 0.0008088975394136444\n",
      "Iteration:60, Price of Hedge: 0.04328169269367948, Loss: 0.0008023126173538398\n",
      "Iteration:70, Price of Hedge: 0.040087651395232626, Loss: 0.0007458314587308834\n",
      "Iteration:80, Price of Hedge: 0.03876891256988842, Loss: 0.0007777823593902334\n",
      "Iteration:90, Price of Hedge: 0.04134638887439053, Loss: 0.000724883681238886\n",
      "Iteration:100, Price of Hedge: 0.04277526973108934, Loss: 0.0007081785869264668\n",
      "Iteration:110, Price of Hedge: 0.03749074787291704, Loss: 0.0008751863207280276\n",
      "Iteration:120, Price of Hedge: 0.04250746741252982, Loss: 0.0008258434443232377\n",
      "Iteration:130, Price of Hedge: 0.04145577930606521, Loss: 0.0006090219992970214\n",
      "Iteration:140, Price of Hedge: 0.04116759801574972, Loss: 0.0008619927338196165\n",
      "Iteration:150, Price of Hedge: 0.04052036040225886, Loss: 0.0008154562933460064\n",
      "Iteration:160, Price of Hedge: 0.040776578282273594, Loss: 0.0007647060822824071\n",
      "Iteration:170, Price of Hedge: 0.04017639734439485, Loss: 0.0007896386273369194\n",
      "Iteration:180, Price of Hedge: 0.042586123952945344, Loss: 0.0006918794177129151\n",
      "Iteration:190, Price of Hedge: 0.04334653858997655, Loss: 0.0007754939885577184\n",
      "Iteration:200, Price of Hedge: 0.041609121979891486, Loss: 0.0008514307031614266\n",
      "Iteration:210, Price of Hedge: 0.03901693229469885, Loss: 0.00085908009358584\n",
      "Iteration:220, Price of Hedge: 0.03626033017952466, Loss: 0.0005917117829936647\n",
      "Iteration:230, Price of Hedge: 0.0440040780208193, Loss: 0.0007060038240618738\n",
      "Iteration:240, Price of Hedge: 0.04401832982127161, Loss: 0.00083480851713571\n",
      "Iteration:250, Price of Hedge: 0.03741312478206141, Loss: 0.0007352942558814135\n",
      "Iteration:260, Price of Hedge: 0.04159511526629132, Loss: 0.0006863881957308138\n",
      "Iteration:270, Price of Hedge: 0.03936509859207718, Loss: 0.0007170019689025421\n",
      "Iteration:280, Price of Hedge: 0.038459494503834436, Loss: 0.0007382344045613554\n",
      "Iteration:290, Price of Hedge: 0.04024607553646007, Loss: 0.0009000545304838515\n",
      "Iteration:300, Price of Hedge: 0.03774626317062229, Loss: 0.000684230346412007\n",
      "Iteration:310, Price of Hedge: 0.043355525107888586, Loss: 0.0008234876746063825\n",
      "Iteration:320, Price of Hedge: 0.0455425331243319, Loss: 0.0006917291105418722\n",
      "Iteration:330, Price of Hedge: 0.04171970925236082, Loss: 0.0007206045541549911\n",
      "Iteration:340, Price of Hedge: 0.04274882485974274, Loss: 0.0008012320651645589\n",
      "Iteration:350, Price of Hedge: 0.04479996081013696, Loss: 0.0007231292040309035\n",
      "Iteration:360, Price of Hedge: 0.03730680202081942, Loss: 0.0006606915413549741\n",
      "Iteration:370, Price of Hedge: 0.04379700822422166, Loss: 0.0006691601218177468\n",
      "Iteration:380, Price of Hedge: 0.04640688501057753, Loss: 0.0006846362076861735\n",
      "Iteration:390, Price of Hedge: 0.04285960003213205, Loss: 0.0008280060166699244\n",
      "Iteration:400, Price of Hedge: 0.039761514321081395, Loss: 0.0006533019812886565\n",
      "Iteration:410, Price of Hedge: 0.0408957231706637, Loss: 0.0006142610498851564\n",
      "Iteration:420, Price of Hedge: 0.04467123302582792, Loss: 0.0006091228423247275\n",
      "Iteration:430, Price of Hedge: 0.043724254192162, Loss: 0.0005176492807371647\n",
      "Iteration:440, Price of Hedge: 0.04106373020781007, Loss: 0.0004570864048307533\n",
      "Iteration:450, Price of Hedge: 0.0451236102527389, Loss: 0.0005291545128279119\n",
      "Iteration:460, Price of Hedge: 0.03813257315175633, Loss: 0.0006813960829111566\n",
      "Iteration:470, Price of Hedge: 0.03800255049191179, Loss: 0.0005259125052242131\n",
      "Iteration:480, Price of Hedge: 0.03692518545290398, Loss: 0.0005127710950089348\n",
      "Iteration:490, Price of Hedge: 0.04118517891261036, Loss: 0.0004886003296741604\n",
      "Iteration:500, Price of Hedge: 0.04128451669856617, Loss: 0.0004802674724382339\n",
      "Iteration:510, Price of Hedge: 0.039419806062257125, Loss: 0.0005892701690538571\n",
      "Iteration:520, Price of Hedge: 0.04058112151768683, Loss: 0.0005022529757450878\n",
      "Iteration:530, Price of Hedge: 0.03964114399843055, Loss: 0.0005403570881861386\n",
      "Iteration:540, Price of Hedge: 0.038734620834492264, Loss: 0.00036885801016959266\n",
      "Iteration:550, Price of Hedge: 0.039745489725731886, Loss: 0.000413472976104845\n",
      "Iteration:560, Price of Hedge: 0.04106714099983577, Loss: 0.0004329969202528039\n",
      "Iteration:570, Price of Hedge: 0.0420437508339262, Loss: 0.00046573978971550247\n",
      "Iteration:580, Price of Hedge: 0.04264277169403812, Loss: 0.0005157191579518106\n",
      "Iteration:590, Price of Hedge: 0.04422370443380857, Loss: 0.000509911333540003\n",
      "Iteration:600, Price of Hedge: 0.04477358538006513, Loss: 0.000530068929320282\n",
      "Iteration:610, Price of Hedge: 0.043242233710483906, Loss: 0.0005771069042949773\n",
      "Iteration:620, Price of Hedge: 0.03860408349225822, Loss: 0.00040412339138071743\n",
      "Iteration:630, Price of Hedge: 0.03924614977316879, Loss: 0.0005481721037098542\n",
      "Iteration:640, Price of Hedge: 0.041584854296748124, Loss: 0.0006024622241694422\n",
      "Iteration:650, Price of Hedge: 0.04150819521417759, Loss: 0.00043815711542275485\n",
      "Iteration:660, Price of Hedge: 0.042193441713655494, Loss: 0.0004117570171039642\n",
      "Iteration:670, Price of Hedge: 0.04599964052748931, Loss: 0.0004843871015941304\n",
      "Iteration:680, Price of Hedge: 0.04631123578174652, Loss: 0.0004423022744590832\n",
      "Iteration:690, Price of Hedge: 0.042556995380567744, Loss: 0.0005625825085443514\n",
      "Iteration:700, Price of Hedge: 0.04392901200278772, Loss: 0.0005109041586776498\n",
      "Iteration:710, Price of Hedge: 0.0434427637729101, Loss: 0.0004875806662497096\n",
      "Iteration:720, Price of Hedge: 0.04245051331287186, Loss: 0.000548295093908835\n",
      "Iteration:730, Price of Hedge: 0.036343087839932765, Loss: 0.0006209551121838076\n",
      "Iteration:740, Price of Hedge: 0.041108139945419, Loss: 0.000548889365700589\n",
      "Iteration:750, Price of Hedge: 0.03752418588911155, Loss: 0.00047984402745892\n",
      "Iteration:760, Price of Hedge: 0.03488961660240193, Loss: 0.00040113531035026464\n",
      "Iteration:770, Price of Hedge: 0.04093727764644513, Loss: 0.000492564577595278\n",
      "Iteration:780, Price of Hedge: 0.042733486507579244, Loss: 0.0004856532241018008\n",
      "Iteration:790, Price of Hedge: 0.039802799201325456, Loss: 0.0004921746724963817\n",
      "Iteration:800, Price of Hedge: 0.03801670425762325, Loss: 0.0004928247909015804\n",
      "Iteration:810, Price of Hedge: 0.04407692600283895, Loss: 0.0005460388907256642\n",
      "Iteration:820, Price of Hedge: 0.04396514188957497, Loss: 0.0004261332118986827\n",
      "Iteration:830, Price of Hedge: 0.03836921267706544, Loss: 0.0005549797739764274\n",
      "Iteration:840, Price of Hedge: 0.0383938765839531, Loss: 0.0003708504577755512\n",
      "Iteration:850, Price of Hedge: 0.04002354484427287, Loss: 0.00046494983139023783\n",
      "Iteration:860, Price of Hedge: 0.04245300094442115, Loss: 0.0004438993280418524\n",
      "Iteration:870, Price of Hedge: 0.04036509788142411, Loss: 0.00039963769565177777\n",
      "Iteration:880, Price of Hedge: 0.040006033388687, Loss: 0.00047382223073674237\n",
      "Iteration:890, Price of Hedge: 0.042948644170297715, Loss: 0.0003479941621595151\n",
      "Iteration:900, Price of Hedge: 0.04078498884608309, Loss: 0.0003799351380778471\n",
      "Iteration:910, Price of Hedge: 0.04311176580952463, Loss: 0.0004282052808192383\n",
      "Iteration:920, Price of Hedge: 0.044803931217141726, Loss: 0.00043290411913743393\n",
      "Iteration:930, Price of Hedge: 0.04282761211314608, Loss: 0.00047656857571185543\n",
      "Iteration:940, Price of Hedge: 0.04232108703103421, Loss: 0.00039493292163638176\n",
      "Iteration:950, Price of Hedge: 0.03911919886853781, Loss: 0.0004421829541804146\n",
      "Iteration:960, Price of Hedge: 0.04144879433077904, Loss: 0.00046882383118402877\n",
      "Iteration:970, Price of Hedge: 0.0399664722859697, Loss: 0.0005028152394492502\n",
      "Iteration:980, Price of Hedge: 0.041274913378742895, Loss: 0.0004279775542857856\n",
      "Iteration:990, Price of Hedge: 0.044097496959295775, Loss: 0.0004322745522859828\n",
      "tf.Tensor(0.056017257, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_95 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.054804491895151845, Loss: 0.001055428042473783\n",
      "Iteration:20, Price of Hedge: 0.046929463281504984, Loss: 0.0014572593611893226\n",
      "Iteration:30, Price of Hedge: 0.0495378001054732, Loss: 0.0009281984153731937\n",
      "Iteration:40, Price of Hedge: 0.04841417900790362, Loss: 0.0011270683973243047\n",
      "Iteration:50, Price of Hedge: 0.05230149340023616, Loss: 0.0011101538303429415\n",
      "Iteration:60, Price of Hedge: 0.046666436071781454, Loss: 0.0010235185640454338\n",
      "Iteration:70, Price of Hedge: 0.05230281278445688, Loss: 0.0011304569783540332\n",
      "Iteration:80, Price of Hedge: 0.04487377280044172, Loss: 0.0010650628916993865\n",
      "Iteration:90, Price of Hedge: 0.05131419369461128, Loss: 0.0011491507227026966\n",
      "Iteration:100, Price of Hedge: 0.0476754504725065, Loss: 0.0010880043613790136\n",
      "Iteration:110, Price of Hedge: 0.04768071983982765, Loss: 0.0011353666296598953\n",
      "Iteration:120, Price of Hedge: 0.04999908623945971, Loss: 0.001240362347717028\n",
      "Iteration:130, Price of Hedge: 0.04604244903099755, Loss: 0.000941293839891344\n",
      "Iteration:140, Price of Hedge: 0.046748103095697505, Loss: 0.0010614403931402006\n",
      "Iteration:150, Price of Hedge: 0.05006357675982116, Loss: 0.0012968229547862366\n",
      "Iteration:160, Price of Hedge: 0.05041557866643558, Loss: 0.0011708837993167798\n",
      "Iteration:170, Price of Hedge: 0.04835031345901513, Loss: 0.0012107095192447571\n",
      "Iteration:180, Price of Hedge: 0.048015810753643966, Loss: 0.0012389645867633805\n",
      "Iteration:190, Price of Hedge: 0.04575642450498094, Loss: 0.001310719124004134\n",
      "Iteration:200, Price of Hedge: 0.05147437020683157, Loss: 0.0011319762615385365\n",
      "Iteration:210, Price of Hedge: 0.04896595120770258, Loss: 0.0013767388842034656\n",
      "Iteration:220, Price of Hedge: 0.04822417542577711, Loss: 0.0009708885878856323\n",
      "Iteration:230, Price of Hedge: 0.0478101338673227, Loss: 0.0010242454635660315\n",
      "Iteration:240, Price of Hedge: 0.04962549626595206, Loss: 0.0010361235595604868\n",
      "Iteration:250, Price of Hedge: 0.05318556252373697, Loss: 0.001275460827334829\n",
      "Iteration:260, Price of Hedge: 0.04835108548259939, Loss: 0.001087627157395632\n",
      "Iteration:270, Price of Hedge: 0.049534430161256186, Loss: 0.0011074089852483038\n",
      "Iteration:280, Price of Hedge: 0.05210917783213773, Loss: 0.0011171260406888984\n",
      "Iteration:290, Price of Hedge: 0.04693695068483806, Loss: 0.0010685867172707032\n",
      "Iteration:300, Price of Hedge: 0.04980187710388009, Loss: 0.0011552698520940208\n",
      "Iteration:310, Price of Hedge: 0.0538886676851746, Loss: 0.0009526816345321044\n",
      "Iteration:320, Price of Hedge: 0.04079811324701552, Loss: 0.0010432121223365122\n",
      "Iteration:330, Price of Hedge: 0.054404992156591454, Loss: 0.0010102761512406967\n",
      "Iteration:340, Price of Hedge: 0.04864533675728638, Loss: 0.0012559561263342457\n",
      "Iteration:350, Price of Hedge: 0.04961161209577796, Loss: 0.001204164168499622\n",
      "Iteration:360, Price of Hedge: 0.05393545885003022, Loss: 0.0009757111822992216\n",
      "Iteration:370, Price of Hedge: 0.0485922591146732, Loss: 0.0011372569896564767\n",
      "Iteration:380, Price of Hedge: 0.044747357002104596, Loss: 0.0010788873857779714\n",
      "Iteration:390, Price of Hedge: 0.04533684806844889, Loss: 0.0009642945388935732\n",
      "Iteration:400, Price of Hedge: 0.0501013609828604, Loss: 0.001134732212131162\n",
      "Iteration:410, Price of Hedge: 0.05407049353600116, Loss: 0.0010008015658395043\n",
      "Iteration:420, Price of Hedge: 0.048769444654432455, Loss: 0.0009460288029903509\n",
      "Iteration:430, Price of Hedge: 0.049901656046169765, Loss: 0.0009590097898194651\n",
      "Iteration:440, Price of Hedge: 0.04542657436501969, Loss: 0.0009377897361526611\n",
      "Iteration:450, Price of Hedge: 0.05404298662162859, Loss: 0.0009205957446299707\n",
      "Iteration:460, Price of Hedge: 0.050503805848427424, Loss: 0.0012730928032753663\n",
      "Iteration:470, Price of Hedge: 0.046103226485548994, Loss: 0.0007839256145185659\n",
      "Iteration:480, Price of Hedge: 0.050145492955370234, Loss: 0.0008755365268628524\n",
      "Iteration:490, Price of Hedge: 0.04332343506938088, Loss: 0.0008189221022640415\n",
      "Iteration:500, Price of Hedge: 0.05304824036047933, Loss: 0.0009336319398255189\n",
      "Iteration:510, Price of Hedge: 0.049861077833016056, Loss: 0.0006945264833654986\n",
      "Iteration:520, Price of Hedge: 0.04981819171867131, Loss: 0.0006411075700756497\n",
      "Iteration:530, Price of Hedge: 0.052611981678877845, Loss: 0.0007217383999696737\n",
      "Iteration:540, Price of Hedge: 0.04908639914118993, Loss: 0.0005858790988607865\n",
      "Iteration:550, Price of Hedge: 0.04542690114748922, Loss: 0.0007381981521311421\n",
      "Iteration:560, Price of Hedge: 0.04925180008814181, Loss: 0.0006975331373839656\n",
      "Iteration:570, Price of Hedge: 0.04934740438438326, Loss: 0.0009473956727886758\n",
      "Iteration:580, Price of Hedge: 0.05049570572796398, Loss: 0.0005117388581183714\n",
      "Iteration:590, Price of Hedge: 0.0442575631824326, Loss: 0.0006430800086378197\n",
      "Iteration:600, Price of Hedge: 0.04870844662171408, Loss: 0.0006364251985303327\n",
      "Iteration:610, Price of Hedge: 0.05523290371270378, Loss: 0.0008815588341826386\n",
      "Iteration:620, Price of Hedge: 0.04922885995878091, Loss: 0.0005373654967971265\n",
      "Iteration:630, Price of Hedge: 0.04898181241181732, Loss: 0.0007525173514677963\n",
      "Iteration:640, Price of Hedge: 0.046659140653149224, Loss: 0.0006274481266740573\n",
      "Iteration:650, Price of Hedge: 0.04755731860977193, Loss: 0.0008286943022463689\n",
      "Iteration:660, Price of Hedge: 0.050728542322283944, Loss: 0.0006319016228413022\n",
      "Iteration:670, Price of Hedge: 0.0509790455938628, Loss: 0.0005731084782464313\n",
      "Iteration:680, Price of Hedge: 0.04959333270138871, Loss: 0.0007364531848036205\n",
      "Iteration:690, Price of Hedge: 0.04407032499695447, Loss: 0.0005941080175710045\n",
      "Iteration:700, Price of Hedge: 0.05136801068256176, Loss: 0.0005998320082379439\n",
      "Iteration:710, Price of Hedge: 0.05253067411567827, Loss: 0.0006782904367813148\n",
      "Iteration:720, Price of Hedge: 0.05047093970155459, Loss: 0.000591354428492319\n",
      "Iteration:730, Price of Hedge: 0.049633294112631184, Loss: 0.0007695750772536814\n",
      "Iteration:740, Price of Hedge: 0.05012570219205941, Loss: 0.0007582474693060393\n",
      "Iteration:750, Price of Hedge: 0.048921680352643195, Loss: 0.0006825117386860314\n",
      "Iteration:760, Price of Hedge: 0.04763225799959656, Loss: 0.0007675299423569815\n",
      "Iteration:770, Price of Hedge: 0.04733064594978345, Loss: 0.0006170403603183773\n",
      "Iteration:780, Price of Hedge: 0.05093133535331163, Loss: 0.000563753883283269\n",
      "Iteration:790, Price of Hedge: 0.05203577840470076, Loss: 0.0006670476518614078\n",
      "Iteration:800, Price of Hedge: 0.04889829498216756, Loss: 0.0007219344694513908\n",
      "Iteration:810, Price of Hedge: 0.05051111352140226, Loss: 0.0007442659664627983\n",
      "Iteration:820, Price of Hedge: 0.05159574130079534, Loss: 0.0009878057716797397\n",
      "Iteration:830, Price of Hedge: 0.049515542134517435, Loss: 0.0007360692154019245\n",
      "Iteration:840, Price of Hedge: 0.048690706418399544, Loss: 0.0010735899355883483\n",
      "Iteration:850, Price of Hedge: 0.04956445330064412, Loss: 0.000816225444818719\n",
      "Iteration:860, Price of Hedge: 0.04502268757180588, Loss: 0.0009154670469500027\n",
      "Iteration:870, Price of Hedge: 0.045055124816687456, Loss: 0.0007172662669897135\n",
      "Iteration:880, Price of Hedge: 0.05041864633686828, Loss: 0.0007937287056562159\n",
      "Iteration:890, Price of Hedge: 0.053537343852184456, Loss: 0.0008249096889464403\n",
      "Iteration:900, Price of Hedge: 0.052008140777340374, Loss: 0.0006500417517327995\n",
      "Iteration:910, Price of Hedge: 0.05639167843443289, Loss: 0.0007404225706131751\n",
      "Iteration:920, Price of Hedge: 0.04633505413899428, Loss: 0.0005878760461081712\n",
      "Iteration:930, Price of Hedge: 0.048141769056523745, Loss: 0.0006411791175655601\n",
      "Iteration:940, Price of Hedge: 0.047362364273232066, Loss: 0.0004728023439258378\n",
      "Iteration:950, Price of Hedge: 0.04845829872607084, Loss: 0.0005457262135150743\n",
      "Iteration:960, Price of Hedge: 0.047773203363485096, Loss: 0.0006234536577569783\n",
      "Iteration:970, Price of Hedge: 0.04445333447514628, Loss: 0.0006158543058982114\n",
      "Iteration:980, Price of Hedge: 0.05032905075328529, Loss: 0.0006173098920310372\n",
      "Iteration:990, Price of Hedge: 0.04725149923566364, Loss: 0.0006391303446608987\n",
      "tf.Tensor(0.051602215, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_96 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.05258259168052462, Loss: 0.0018250328620381675\n",
      "Iteration:20, Price of Hedge: 0.051332240256490996, Loss: 0.0011589076047567649\n",
      "Iteration:30, Price of Hedge: 0.0482792872892631, Loss: 0.000982489493203298\n",
      "Iteration:40, Price of Hedge: 0.04878178069265716, Loss: 0.0009575346733281088\n",
      "Iteration:50, Price of Hedge: 0.051805331407189216, Loss: 0.0012283953439139684\n",
      "Iteration:60, Price of Hedge: 0.04279266681281087, Loss: 0.001100747984144812\n",
      "Iteration:70, Price of Hedge: 0.05140436931707768, Loss: 0.0011053599570448381\n",
      "Iteration:80, Price of Hedge: 0.0490056552777503, Loss: 0.0009514105656101003\n",
      "Iteration:90, Price of Hedge: 0.05630060416017529, Loss: 0.0012975684272948486\n",
      "Iteration:100, Price of Hedge: 0.05137558386629309, Loss: 0.0011353998185044567\n",
      "Iteration:110, Price of Hedge: 0.050549624835436194, Loss: 0.0010949986550715441\n",
      "Iteration:120, Price of Hedge: 0.04649468329057811, Loss: 0.0009544889585925809\n",
      "Iteration:130, Price of Hedge: 0.05254092691565973, Loss: 0.000918437193239452\n",
      "Iteration:140, Price of Hedge: 0.04935800847551946, Loss: 0.0009168500005729996\n",
      "Iteration:150, Price of Hedge: 0.04996316467649678, Loss: 0.0010952464225611358\n",
      "Iteration:160, Price of Hedge: 0.05566664208450903, Loss: 0.0010818420864897593\n",
      "Iteration:170, Price of Hedge: 0.043259532757464574, Loss: 0.0010327056191682617\n",
      "Iteration:180, Price of Hedge: 0.04500850112784747, Loss: 0.000969286332589725\n",
      "Iteration:190, Price of Hedge: 0.05376162283058364, Loss: 0.0009271770925065149\n",
      "Iteration:200, Price of Hedge: 0.05014499052732333, Loss: 0.0011397178148313094\n",
      "Iteration:210, Price of Hedge: 0.04775303680033432, Loss: 0.0009989913696674792\n",
      "Iteration:220, Price of Hedge: 0.04621556612901117, Loss: 0.0009558557007415037\n",
      "Iteration:230, Price of Hedge: 0.04892418023853509, Loss: 0.001047428062966338\n",
      "Iteration:240, Price of Hedge: 0.052178329087470846, Loss: 0.0010646981335327155\n",
      "Iteration:250, Price of Hedge: 0.05550074279429112, Loss: 0.0009691523645421585\n",
      "Iteration:260, Price of Hedge: 0.0461243938200127, Loss: 0.001218424010864272\n",
      "Iteration:270, Price of Hedge: 0.05002736109263566, Loss: 0.0010926756912510438\n",
      "Iteration:280, Price of Hedge: 0.04411474698890601, Loss: 0.0010160460318677123\n",
      "Iteration:290, Price of Hedge: 0.04633061806697043, Loss: 0.0011371961008916466\n",
      "Iteration:300, Price of Hedge: 0.05170316286809112, Loss: 0.0011568086656370546\n",
      "Iteration:310, Price of Hedge: 0.050397785360969755, Loss: 0.0008623471523847127\n",
      "Iteration:320, Price of Hedge: 0.0500101805043002, Loss: 0.0011198628438712\n",
      "Iteration:330, Price of Hedge: 0.047143268881755775, Loss: 0.0009589031387439606\n",
      "Iteration:340, Price of Hedge: 0.052353223065162525, Loss: 0.0010169636395951365\n",
      "Iteration:350, Price of Hedge: 0.056196691419646075, Loss: 0.0010496602680619028\n",
      "Iteration:360, Price of Hedge: 0.04415801707265246, Loss: 0.0010901612533273043\n",
      "Iteration:370, Price of Hedge: 0.04694717080657256, Loss: 0.0009362522629283499\n",
      "Iteration:380, Price of Hedge: 0.049433862856258774, Loss: 0.0009732978427019923\n",
      "Iteration:390, Price of Hedge: 0.05187445406905625, Loss: 0.0011305638209036406\n",
      "Iteration:400, Price of Hedge: 0.05318590973011084, Loss: 0.0013456314907935865\n",
      "Iteration:410, Price of Hedge: 0.046961030468061445, Loss: 0.001092695732207183\n",
      "Iteration:420, Price of Hedge: 0.038939783038424026, Loss: 0.0012356541271677736\n",
      "Iteration:430, Price of Hedge: 0.04847553650133847, Loss: 0.001000990040181793\n",
      "Iteration:440, Price of Hedge: 0.053845887775132446, Loss: 0.0009834224826836824\n",
      "Iteration:450, Price of Hedge: 0.04716488554211509, Loss: 0.0009048942937420313\n",
      "Iteration:460, Price of Hedge: 0.047386509412949356, Loss: 0.0009203012574591885\n",
      "Iteration:470, Price of Hedge: 0.051490219156603706, Loss: 0.0009125690225727734\n",
      "Iteration:480, Price of Hedge: 0.04511950096318458, Loss: 0.001056705493865895\n",
      "Iteration:490, Price of Hedge: 0.049061878201632686, Loss: 0.001038769476368451\n",
      "Iteration:500, Price of Hedge: 0.0451111680102116, Loss: 0.0007229031369396789\n",
      "Iteration:510, Price of Hedge: 0.04883921679645767, Loss: 0.0007652736753491097\n",
      "Iteration:520, Price of Hedge: 0.04952991647839582, Loss: 0.000908558214532218\n",
      "Iteration:530, Price of Hedge: 0.04516148842573813, Loss: 0.0008057802771882062\n",
      "Iteration:540, Price of Hedge: 0.0479053337702581, Loss: 0.0006385921747813939\n",
      "Iteration:550, Price of Hedge: 0.05128249171028614, Loss: 0.0009886618523953228\n",
      "Iteration:560, Price of Hedge: 0.047949633218783566, Loss: 0.0009677478381701966\n",
      "Iteration:570, Price of Hedge: 0.04553612410314827, Loss: 0.0007699599402011926\n",
      "Iteration:580, Price of Hedge: 0.045399316622280146, Loss: 0.0006199609148150875\n",
      "Iteration:590, Price of Hedge: 0.053135319719046954, Loss: 0.0006596616659783506\n",
      "Iteration:600, Price of Hedge: 0.05480874823681745, Loss: 0.0009687609276504362\n",
      "Iteration:610, Price of Hedge: 0.04579749697661981, Loss: 0.0007732853986015532\n",
      "Iteration:620, Price of Hedge: 0.044298227175984556, Loss: 0.0006798842033919783\n",
      "Iteration:630, Price of Hedge: 0.04951552579539396, Loss: 0.0006025325589900321\n",
      "Iteration:640, Price of Hedge: 0.05473071666787491, Loss: 0.0007096694681189898\n",
      "Iteration:650, Price of Hedge: 0.049120151685511364, Loss: 0.0007121672477957476\n",
      "Iteration:660, Price of Hedge: 0.046585504308421836, Loss: 0.0006675771415815657\n",
      "Iteration:670, Price of Hedge: 0.045907496040643994, Loss: 0.0005064141228690367\n",
      "Iteration:680, Price of Hedge: 0.05093255261801062, Loss: 0.0007895594208828794\n",
      "Iteration:690, Price of Hedge: 0.051769936780958405, Loss: 0.0005968987526257186\n",
      "Iteration:700, Price of Hedge: 0.045243036991008984, Loss: 0.0007106295830973331\n",
      "Iteration:710, Price of Hedge: 0.05058353260143065, Loss: 0.0006733596594993952\n",
      "Iteration:720, Price of Hedge: 0.0513188585143638, Loss: 0.0006657814336166857\n",
      "Iteration:730, Price of Hedge: 0.04987407560574156, Loss: 0.0006325989715253\n",
      "Iteration:740, Price of Hedge: 0.050378439838773666, Loss: 0.0006033036890284783\n",
      "Iteration:750, Price of Hedge: 0.05220444309156705, Loss: 0.000639892794539998\n",
      "Iteration:760, Price of Hedge: 0.04753152321858352, Loss: 0.0006080541615298475\n",
      "Iteration:770, Price of Hedge: 0.047091461605992896, Loss: 0.0006067823267114303\n",
      "Iteration:780, Price of Hedge: 0.04330145894830509, Loss: 0.000593401286655948\n",
      "Iteration:790, Price of Hedge: 0.048867577430031874, Loss: 0.000740648893003204\n",
      "Iteration:800, Price of Hedge: 0.04534632067528435, Loss: 0.0006892080348492203\n",
      "Iteration:810, Price of Hedge: 0.052866345068378, Loss: 0.0006466954864798868\n",
      "Iteration:820, Price of Hedge: 0.051377622171946774, Loss: 0.0006546492569037499\n",
      "Iteration:830, Price of Hedge: 0.04799521528850193, Loss: 0.0007648914930390439\n",
      "Iteration:840, Price of Hedge: 0.043940253319739504, Loss: 0.0005364305287510085\n",
      "Iteration:850, Price of Hedge: 0.05027930629186131, Loss: 0.0007056871258951159\n",
      "Iteration:860, Price of Hedge: 0.05303358416672097, Loss: 0.0006092910204120727\n",
      "Iteration:870, Price of Hedge: 0.05176646880200054, Loss: 0.0006553321173806026\n",
      "Iteration:880, Price of Hedge: 0.047161748430407616, Loss: 0.0008147593276102151\n",
      "Iteration:890, Price of Hedge: 0.05137985654708217, Loss: 0.0007318372547721275\n",
      "Iteration:900, Price of Hedge: 0.04892055703790419, Loss: 0.0007973916052511854\n",
      "Iteration:910, Price of Hedge: 0.047584600861196695, Loss: 0.0005300755032644933\n",
      "Iteration:920, Price of Hedge: 0.04954411517669684, Loss: 0.0005794871826970472\n",
      "Iteration:930, Price of Hedge: 0.05069437721509474, Loss: 0.0006239568517002914\n",
      "Iteration:940, Price of Hedge: 0.052053236758135314, Loss: 0.0006646048252522797\n",
      "Iteration:950, Price of Hedge: 0.04939192032629478, Loss: 0.000540954870336452\n",
      "Iteration:960, Price of Hedge: 0.052520041431075984, Loss: 0.0007811635367546366\n",
      "Iteration:970, Price of Hedge: 0.04728039906031257, Loss: 0.0006169192848604288\n",
      "Iteration:980, Price of Hedge: 0.04368555497820808, Loss: 0.0007669091833142794\n",
      "Iteration:990, Price of Hedge: 0.05034197908473601, Loss: 0.0005854988312917532\n",
      "tf.Tensor(0.049274687, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_97 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.03313805031138628, Loss: 0.0011667466821927875\n",
      "Iteration:20, Price of Hedge: 0.05263907194560176, Loss: 0.0010151277220685762\n",
      "Iteration:30, Price of Hedge: 0.04605863293280095, Loss: 0.0010589119137822236\n",
      "Iteration:40, Price of Hedge: 0.046868481587910085, Loss: 0.0010518290314045942\n",
      "Iteration:50, Price of Hedge: 0.047614550474528984, Loss: 0.001045725985837942\n",
      "Iteration:60, Price of Hedge: 0.04432698403330307, Loss: 0.0009623755216062069\n",
      "Iteration:70, Price of Hedge: 0.047973410728222636, Loss: 0.000852659583956017\n",
      "Iteration:80, Price of Hedge: 0.043290662872468036, Loss: 0.0008895807055625539\n",
      "Iteration:90, Price of Hedge: 0.04762988882669248, Loss: 0.0008709507859149701\n",
      "Iteration:100, Price of Hedge: 0.04519397468799014, Loss: 0.0008809562013550432\n",
      "Iteration:110, Price of Hedge: 0.04640462204197605, Loss: 0.0009520352179595682\n",
      "Iteration:120, Price of Hedge: 0.04473149579798986, Loss: 0.0009126915659988466\n",
      "Iteration:130, Price of Hedge: 0.0470009673706187, Loss: 0.0009278063402344606\n",
      "Iteration:140, Price of Hedge: 0.04488904171133044, Loss: 0.0009583903710954857\n",
      "Iteration:150, Price of Hedge: 0.04702397285647351, Loss: 0.0010801641350983715\n",
      "Iteration:160, Price of Hedge: 0.04602095899884518, Loss: 0.0009453289651430109\n",
      "Iteration:170, Price of Hedge: 0.047088708463687116, Loss: 0.0008862389080387168\n",
      "Iteration:180, Price of Hedge: 0.045967191028265124, Loss: 0.0011157407893766626\n",
      "Iteration:190, Price of Hedge: 0.047685691018145356, Loss: 0.0011782287459170427\n",
      "Iteration:200, Price of Hedge: 0.045459722361772495, Loss: 0.0009709527317102175\n",
      "Iteration:210, Price of Hedge: 0.04757990744797809, Loss: 0.0009309073271611235\n",
      "Iteration:220, Price of Hedge: 0.04892227673065009, Loss: 0.0008761251182562102\n",
      "Iteration:230, Price of Hedge: 0.04628743376362224, Loss: 0.0009357643230885949\n",
      "Iteration:240, Price of Hedge: 0.04479931132997877, Loss: 0.0008724276256732556\n",
      "Iteration:250, Price of Hedge: 0.04731903291777258, Loss: 0.0009882727131928393\n",
      "Iteration:260, Price of Hedge: 0.04839910616649661, Loss: 0.0009572008701414614\n",
      "Iteration:270, Price of Hedge: 0.03967991673844012, Loss: 0.000926598968364134\n",
      "Iteration:280, Price of Hedge: 0.050964524197873125, Loss: 0.001119746938214039\n",
      "Iteration:290, Price of Hedge: 0.043296026189749176, Loss: 0.0009409254437167115\n",
      "Iteration:300, Price of Hedge: 0.04525860000612028, Loss: 0.0007861042706899247\n",
      "Iteration:310, Price of Hedge: 0.05280891304935836, Loss: 0.000855207083074916\n",
      "Iteration:320, Price of Hedge: 0.047098920415859884, Loss: 0.0009619904671845926\n",
      "Iteration:330, Price of Hedge: 0.04541385435739329, Loss: 0.000811283944987018\n",
      "Iteration:340, Price of Hedge: 0.04924755191603794, Loss: 0.0009517925564460629\n",
      "Iteration:350, Price of Hedge: 0.04662884791822393, Loss: 0.001208966466658268\n",
      "Iteration:360, Price of Hedge: 0.04212079388589843, Loss: 0.000847574861495093\n",
      "Iteration:370, Price of Hedge: 0.04939188764804783, Loss: 0.0009225698426343688\n",
      "Iteration:380, Price of Hedge: 0.04919303643055884, Loss: 0.0010504712885385237\n",
      "Iteration:390, Price of Hedge: 0.04459343837417578, Loss: 0.0008737810284596526\n",
      "Iteration:400, Price of Hedge: 0.04544357930777779, Loss: 0.0008963135094547603\n",
      "Iteration:410, Price of Hedge: 0.04582538786039408, Loss: 0.0010973480423182914\n",
      "Iteration:420, Price of Hedge: 0.04583690285766409, Loss: 0.0008789229378527442\n",
      "Iteration:430, Price of Hedge: 0.04613971991783359, Loss: 0.0010221463329722182\n",
      "Iteration:440, Price of Hedge: 0.04119917337186792, Loss: 0.000955785557395017\n",
      "Iteration:450, Price of Hedge: 0.05058809938644231, Loss: 0.0009490543491203374\n",
      "Iteration:460, Price of Hedge: 0.04972925378480824, Loss: 0.0008840465295566259\n",
      "Iteration:470, Price of Hedge: 0.044590721994897824, Loss: 0.0008806730111563522\n",
      "Iteration:480, Price of Hedge: 0.04660456389595709, Loss: 0.0009302111911464462\n",
      "Iteration:490, Price of Hedge: 0.04772999455145169, Loss: 0.0009720075625449632\n",
      "Iteration:500, Price of Hedge: 0.04639933633553142, Loss: 0.0006309051277833433\n",
      "Iteration:510, Price of Hedge: 0.04475817758662686, Loss: 0.0010694175234046588\n",
      "Iteration:520, Price of Hedge: 0.0421085926454424, Loss: 0.0008203527329387451\n",
      "Iteration:530, Price of Hedge: 0.04468961862451977, Loss: 0.001055716019525055\n",
      "Iteration:540, Price of Hedge: 0.04609602910165762, Loss: 0.000819732803617157\n",
      "Iteration:550, Price of Hedge: 0.045558149241594494, Loss: 0.000960765479696768\n",
      "Iteration:560, Price of Hedge: 0.04337274245925187, Loss: 0.0006301163183026981\n",
      "Iteration:570, Price of Hedge: 0.04768435529480115, Loss: 0.0006308021147158005\n",
      "Iteration:580, Price of Hedge: 0.048993968719683784, Loss: 0.0006237803764018058\n",
      "Iteration:590, Price of Hedge: 0.04216423553044138, Loss: 0.0009366628472303962\n",
      "Iteration:600, Price of Hedge: 0.04373706406496752, Loss: 0.0008179564983614052\n",
      "Iteration:610, Price of Hedge: 0.04904514285441195, Loss: 0.0005637857318091078\n",
      "Iteration:620, Price of Hedge: 0.048176530541719845, Loss: 0.0005245844089317942\n",
      "Iteration:630, Price of Hedge: 0.048667974612862965, Loss: 0.0007367098239266624\n",
      "Iteration:640, Price of Hedge: 0.04404366363222181, Loss: 0.0006110079048711192\n",
      "Iteration:650, Price of Hedge: 0.04787375024457816, Loss: 0.0006375639588469984\n",
      "Iteration:660, Price of Hedge: 0.04685476489375163, Loss: 0.000585523531451071\n",
      "Iteration:670, Price of Hedge: 0.041959293904676544, Loss: 0.0005653468201728185\n",
      "Iteration:680, Price of Hedge: 0.04642545850918936, Loss: 0.0006658389396723586\n",
      "Iteration:690, Price of Hedge: 0.051365858003043746, Loss: 0.0007625214904138478\n",
      "Iteration:700, Price of Hedge: 0.04634971441753351, Loss: 0.0006292880013320846\n",
      "Iteration:710, Price of Hedge: 0.043488983068444044, Loss: 0.0006152218031105106\n",
      "Iteration:720, Price of Hedge: 0.04309017365785053, Loss: 0.0006313550919259559\n",
      "Iteration:730, Price of Hedge: 0.0497586396983806, Loss: 0.000658064644307932\n",
      "Iteration:740, Price of Hedge: 0.044742443010719064, Loss: 0.0006383345144631348\n",
      "Iteration:750, Price of Hedge: 0.044601125931771436, Loss: 0.0004743287116521611\n",
      "Iteration:760, Price of Hedge: 0.04705455152605965, Loss: 0.0007091519136179337\n",
      "Iteration:770, Price of Hedge: 0.046826955705594746, Loss: 0.0006083452021667713\n",
      "Iteration:780, Price of Hedge: 0.04478606438562025, Loss: 0.0005813376522554537\n",
      "Iteration:790, Price of Hedge: 0.04621568050287551, Loss: 0.0006308673435603041\n",
      "Iteration:800, Price of Hedge: 0.040991343806028625, Loss: 0.0005734803847796233\n",
      "Iteration:810, Price of Hedge: 0.05087039859230629, Loss: 0.0006586988065378608\n",
      "Iteration:820, Price of Hedge: 0.0478936717208768, Loss: 0.0005114240108679447\n",
      "Iteration:830, Price of Hedge: 0.038777061707722285, Loss: 0.0007445227970599434\n",
      "Iteration:840, Price of Hedge: 0.0440656806011063, Loss: 0.0006587465474142684\n",
      "Iteration:850, Price of Hedge: 0.045954466935857856, Loss: 0.0006337001390930297\n",
      "Iteration:860, Price of Hedge: 0.04753385154367891, Loss: 0.0006278340108167857\n",
      "Iteration:870, Price of Hedge: 0.04328889007757084, Loss: 0.000525202614986453\n",
      "Iteration:880, Price of Hedge: 0.04025232933597067, Loss: 0.0006573926340302628\n",
      "Iteration:890, Price of Hedge: 0.047067206177192136, Loss: 0.0005533767527841071\n",
      "Iteration:900, Price of Hedge: 0.04660189244926869, Loss: 0.0005755643250945797\n",
      "Iteration:910, Price of Hedge: 0.04371945048985993, Loss: 0.0006979001294151744\n",
      "Iteration:920, Price of Hedge: 0.04626011066438878, Loss: 0.0005679914604867609\n",
      "Iteration:930, Price of Hedge: 0.04601952115597925, Loss: 0.0005876604462679236\n",
      "Iteration:940, Price of Hedge: 0.04790816860818126, Loss: 0.0005056197606393975\n",
      "Iteration:950, Price of Hedge: 0.05078691384090348, Loss: 0.0005355709376768658\n",
      "Iteration:960, Price of Hedge: 0.04673500728823115, Loss: 0.0006170313610355249\n",
      "Iteration:970, Price of Hedge: 0.04368801810107215, Loss: 0.0005324760140968055\n",
      "Iteration:980, Price of Hedge: 0.045563455371943465, Loss: 0.0005233842173403392\n",
      "Iteration:990, Price of Hedge: 0.04831026218259354, Loss: 0.0004702321870380555\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 15 \n",
      "\n",
      "tf.Tensor(0.11862767, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_98 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.08198902306397429, Loss: 0.00481039571803128\n",
      "Iteration:20, Price of Hedge: 0.16373852765107558, Loss: 0.002089426315657472\n",
      "Iteration:30, Price of Hedge: 0.1168401470878088, Loss: 0.0015088773902794173\n",
      "Iteration:40, Price of Hedge: 0.14203009324612523, Loss: 0.0013533480909255547\n",
      "Iteration:50, Price of Hedge: 0.1317686225623824, Loss: 0.001884887676292324\n",
      "Iteration:60, Price of Hedge: 0.14083655341409554, Loss: 0.0020757333110547837\n",
      "Iteration:70, Price of Hedge: 0.12446637029829688, Loss: 0.0019120483412356504\n",
      "Iteration:80, Price of Hedge: 0.12621742276778392, Loss: 0.0015864670337151\n",
      "Iteration:90, Price of Hedge: 0.13681508036504084, Loss: 0.0017873556730621189\n",
      "Iteration:100, Price of Hedge: 0.14095233784700412, Loss: 0.0016758497441478283\n",
      "Iteration:110, Price of Hedge: 0.12479571549276046, Loss: 0.0016453485479236086\n",
      "Iteration:120, Price of Hedge: 0.12819309548217747, Loss: 0.0016538671380561976\n",
      "Iteration:130, Price of Hedge: 0.13583136944781132, Loss: 0.0019301887061799361\n",
      "Iteration:140, Price of Hedge: 0.12430789314977915, Loss: 0.0013923496553743808\n",
      "Iteration:150, Price of Hedge: 0.1396223523680014, Loss: 0.0015749339326052714\n",
      "Iteration:160, Price of Hedge: 0.14099740184023873, Loss: 0.0017798312398592086\n",
      "Iteration:170, Price of Hedge: 0.119535696928547, Loss: 0.0019924133331063023\n",
      "Iteration:180, Price of Hedge: 0.12858795208021975, Loss: 0.001653948377395953\n",
      "Iteration:190, Price of Hedge: 0.14334004920387358, Loss: 0.001595733785019604\n",
      "Iteration:200, Price of Hedge: 0.1484532526406781, Loss: 0.0015260998266090843\n",
      "Iteration:210, Price of Hedge: 0.13210165101184615, Loss: 0.0016528187709502708\n",
      "Iteration:220, Price of Hedge: 0.12088460403679875, Loss: 0.0015193428394307041\n",
      "Iteration:230, Price of Hedge: 0.13036020999142295, Loss: 0.001748606178340384\n",
      "Iteration:240, Price of Hedge: 0.12227103369796809, Loss: 0.001761574406553068\n",
      "Iteration:250, Price of Hedge: 0.13742310899060114, Loss: 0.0017567761226335743\n",
      "Iteration:260, Price of Hedge: 0.12516752988076194, Loss: 0.0016284689871624793\n",
      "Iteration:270, Price of Hedge: 0.12089633408636402, Loss: 0.0018613606116499426\n",
      "Iteration:280, Price of Hedge: 0.14026157690002777, Loss: 0.0014833258716601793\n",
      "Iteration:290, Price of Hedge: 0.14216179633784734, Loss: 0.00198765513738437\n",
      "Iteration:300, Price of Hedge: 0.14213069761489053, Loss: 0.0017632650959153785\n",
      "Iteration:310, Price of Hedge: 0.13855534546500223, Loss: 0.001434247136549327\n",
      "Iteration:320, Price of Hedge: 0.13283409396593557, Loss: 0.0013165641326781997\n",
      "Iteration:330, Price of Hedge: 0.13416701438691733, Loss: 0.0016389156070088506\n",
      "Iteration:340, Price of Hedge: 0.12106645381928871, Loss: 0.0013233032016470637\n",
      "Iteration:350, Price of Hedge: 0.11667811302285287, Loss: 0.0017366328663035446\n",
      "Iteration:360, Price of Hedge: 0.13645052558517962, Loss: 0.0016033405205069019\n",
      "Iteration:370, Price of Hedge: 0.13428018458342736, Loss: 0.0013532870475338134\n",
      "Iteration:380, Price of Hedge: 0.13222266391755186, Loss: 0.0014646057463435836\n",
      "Iteration:390, Price of Hedge: 0.13909781409522923, Loss: 0.0013827123919408991\n",
      "Iteration:400, Price of Hedge: 0.1349540550364978, Loss: 0.0014472360162577247\n",
      "Iteration:410, Price of Hedge: 0.1280686519985956, Loss: 0.0010768630571022896\n",
      "Iteration:420, Price of Hedge: 0.12550969358009426, Loss: 0.0015969135017122383\n",
      "Iteration:430, Price of Hedge: 0.13140087044506715, Loss: 0.0011306496499142726\n",
      "Iteration:440, Price of Hedge: 0.13124265569202437, Loss: 0.0012429257581392905\n",
      "Iteration:450, Price of Hedge: 0.1299594057626152, Loss: 0.0010262831404721452\n",
      "Iteration:460, Price of Hedge: 0.11755938280299248, Loss: 0.0008215862742060154\n",
      "Iteration:470, Price of Hedge: 0.12699037180852457, Loss: 0.0012498577515589193\n",
      "Iteration:480, Price of Hedge: 0.1439778742933669, Loss: 0.0012419452676405984\n",
      "Iteration:490, Price of Hedge: 0.14114131118072137, Loss: 0.0009659674861807966\n",
      "Iteration:500, Price of Hedge: 0.13928127712397256, Loss: 0.0012545404022873408\n",
      "Iteration:510, Price of Hedge: 0.1357146812082668, Loss: 0.0011384351119490322\n",
      "Iteration:520, Price of Hedge: 0.12202586885920823, Loss: 0.0008844756211506599\n",
      "Iteration:530, Price of Hedge: 0.12673644101723128, Loss: 0.00133713378165502\n",
      "Iteration:540, Price of Hedge: 0.13934533077491268, Loss: 0.0011928111075596326\n",
      "Iteration:550, Price of Hedge: 0.13081714741516778, Loss: 0.0015239318751068653\n",
      "Iteration:560, Price of Hedge: 0.12661465064345165, Loss: 0.0012762423909960408\n",
      "Iteration:570, Price of Hedge: 0.12650460975593916, Loss: 0.0012215685431145428\n",
      "Iteration:580, Price of Hedge: 0.1194788154205888, Loss: 0.0013914335489505602\n",
      "Iteration:590, Price of Hedge: 0.12318461699493, Loss: 0.0008028316031888693\n",
      "Iteration:600, Price of Hedge: 0.11655727504746381, Loss: 0.0012044079094227834\n",
      "Iteration:610, Price of Hedge: 0.12099031053979914, Loss: 0.0010060272879357068\n",
      "Iteration:620, Price of Hedge: 0.12289668169375362, Loss: 0.0011387465547262998\n",
      "Iteration:630, Price of Hedge: 0.1285220713793059, Loss: 0.0008555060522169866\n",
      "Iteration:640, Price of Hedge: 0.1289133613425591, Loss: 0.0011393261632493769\n",
      "Iteration:650, Price of Hedge: 0.1328635114141825, Loss: 0.0010776418158946921\n",
      "Iteration:660, Price of Hedge: 0.12745324714468395, Loss: 0.001210741085391337\n",
      "Iteration:670, Price of Hedge: 0.13080892569028607, Loss: 0.0010263791091875197\n",
      "Iteration:680, Price of Hedge: 0.13201346669556174, Loss: 0.00114493759981259\n",
      "Iteration:690, Price of Hedge: 0.13478864870377125, Loss: 0.001107875909317735\n",
      "Iteration:700, Price of Hedge: 0.11655556461770118, Loss: 0.0009467400325761211\n",
      "Iteration:710, Price of Hedge: 0.11858463967042213, Loss: 0.0011208433023596365\n",
      "Iteration:720, Price of Hedge: 0.12009445351492261, Loss: 0.0008820783773063279\n",
      "Iteration:730, Price of Hedge: 0.11692293771933038, Loss: 0.0008430882015499908\n",
      "Iteration:740, Price of Hedge: 0.12836731635919207, Loss: 0.0015618220550179917\n",
      "Iteration:750, Price of Hedge: 0.13269400393736605, Loss: 0.001043463894187302\n",
      "Iteration:760, Price of Hedge: 0.13700819371625172, Loss: 0.0010750185444667604\n",
      "Iteration:770, Price of Hedge: 0.14257539963482202, Loss: 0.0009875507287891439\n",
      "Iteration:780, Price of Hedge: 0.14687188257832418, Loss: 0.0009482091739072108\n",
      "Iteration:790, Price of Hedge: 0.13065236305690037, Loss: 0.0010116765349579837\n",
      "Iteration:800, Price of Hedge: 0.13130843920942895, Loss: 0.001375650947049978\n",
      "Iteration:810, Price of Hedge: 0.13832711971190292, Loss: 0.0009729041869266542\n",
      "Iteration:820, Price of Hedge: 0.13005939787527226, Loss: 0.0014531857729124797\n",
      "Iteration:830, Price of Hedge: 0.11637437568307406, Loss: 0.0009496693561335424\n",
      "Iteration:840, Price of Hedge: 0.11240014353786094, Loss: 0.0010351204621451948\n",
      "Iteration:850, Price of Hedge: 0.11115003318510262, Loss: 0.001069964318664729\n",
      "Iteration:860, Price of Hedge: 0.1275216837718908, Loss: 0.001200200698643472\n",
      "Iteration:870, Price of Hedge: 0.1145082093468922, Loss: 0.0015546783078426829\n",
      "Iteration:880, Price of Hedge: 0.13428675418865196, Loss: 0.0008794696074801656\n",
      "Iteration:890, Price of Hedge: 0.14381805601242165, Loss: 0.0011968102089648604\n",
      "Iteration:900, Price of Hedge: 0.12056814537566041, Loss: 0.0010698918865804986\n",
      "Iteration:910, Price of Hedge: 0.11694914811177241, Loss: 0.0009290154308323029\n",
      "Iteration:920, Price of Hedge: 0.12507850978629806, Loss: 0.000796593332991058\n",
      "Iteration:930, Price of Hedge: 0.1272000549480609, Loss: 0.0010412848576910605\n",
      "Iteration:940, Price of Hedge: 0.13350922780462612, Loss: 0.0009960918685328612\n",
      "Iteration:950, Price of Hedge: 0.1320806205004466, Loss: 0.0011132443111832313\n",
      "Iteration:960, Price of Hedge: 0.1399653907189169, Loss: 0.0010152564565549971\n",
      "Iteration:970, Price of Hedge: 0.14421065795304955, Loss: 0.0009283794862437134\n",
      "Iteration:980, Price of Hedge: 0.14039160843539095, Loss: 0.0008520817001593739\n",
      "Iteration:990, Price of Hedge: 0.12399752789467017, Loss: 0.0010968827840811214\n",
      "tf.Tensor(0.15164833, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_99 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.14989809930925163, Loss: 0.0030147843058592194\n",
      "Iteration:20, Price of Hedge: 0.16680091608414216, Loss: 0.002440605607662616\n",
      "Iteration:30, Price of Hedge: 0.16569296576870016, Loss: 0.003217297428302879\n",
      "Iteration:40, Price of Hedge: 0.15424352386800708, Loss: 0.0024265489241464436\n",
      "Iteration:50, Price of Hedge: 0.1648923680195807, Loss: 0.0020818775865772523\n",
      "Iteration:60, Price of Hedge: 0.1512945971819782, Loss: 0.0021681188400737962\n",
      "Iteration:70, Price of Hedge: 0.17147783359291538, Loss: 0.002162084958943855\n",
      "Iteration:80, Price of Hedge: 0.15845329968456526, Loss: 0.002538391654659944\n",
      "Iteration:90, Price of Hedge: 0.15608187628384443, Loss: 0.002315313590565693\n",
      "Iteration:100, Price of Hedge: 0.15319936480803023, Loss: 0.002214250333417711\n",
      "Iteration:110, Price of Hedge: 0.1725889520907586, Loss: 0.002087889297719148\n",
      "Iteration:120, Price of Hedge: 0.158094245491327, Loss: 0.002400859374574238\n",
      "Iteration:130, Price of Hedge: 0.15502305223232327, Loss: 0.001733437654738812\n",
      "Iteration:140, Price of Hedge: 0.16452382871584065, Loss: 0.0018335879942968703\n",
      "Iteration:150, Price of Hedge: 0.16913992878453143, Loss: 0.0022471422439692356\n",
      "Iteration:160, Price of Hedge: 0.15003616792082894, Loss: 0.002111317660359957\n",
      "Iteration:170, Price of Hedge: 0.14725247263721003, Loss: 0.002081651331219803\n",
      "Iteration:180, Price of Hedge: 0.15170154340856998, Loss: 0.00221677558616562\n",
      "Iteration:190, Price of Hedge: 0.15562896225738215, Loss: 0.002249603568189973\n",
      "Iteration:200, Price of Hedge: 0.1693208456053327, Loss: 0.002653121950191739\n",
      "Iteration:210, Price of Hedge: 0.15582872296062505, Loss: 0.00322542834734314\n",
      "Iteration:220, Price of Hedge: 0.1627765858399158, Loss: 0.0023596854549954305\n",
      "Iteration:230, Price of Hedge: 0.1692144879728204, Loss: 0.002478754386817861\n",
      "Iteration:240, Price of Hedge: 0.15348384037627769, Loss: 0.0025044837208891614\n",
      "Iteration:250, Price of Hedge: 0.1661719249756388, Loss: 0.002488778106549805\n",
      "Iteration:260, Price of Hedge: 0.1648926012600029, Loss: 0.001923853556171351\n",
      "Iteration:270, Price of Hedge: 0.17583744694401987, Loss: 0.0024207605832265665\n",
      "Iteration:280, Price of Hedge: 0.17325273489556992, Loss: 0.0021283088303074792\n",
      "Iteration:290, Price of Hedge: 0.14575645885102162, Loss: 0.002079170418447984\n",
      "Iteration:300, Price of Hedge: 0.15657654034587623, Loss: 0.0026014813666677796\n",
      "Iteration:310, Price of Hedge: 0.15654716177103298, Loss: 0.0019765844171895975\n",
      "Iteration:320, Price of Hedge: 0.1597895340632121, Loss: 0.0028474412880125977\n",
      "Iteration:330, Price of Hedge: 0.13898921152365348, Loss: 0.002056221443836348\n",
      "Iteration:340, Price of Hedge: 0.16122285476758977, Loss: 0.002428779589381969\n",
      "Iteration:350, Price of Hedge: 0.17849351112495385, Loss: 0.0023390609884454297\n",
      "Iteration:360, Price of Hedge: 0.17851108190342443, Loss: 0.002077472288473248\n",
      "Iteration:370, Price of Hedge: 0.16614459697284048, Loss: 0.002161508994802375\n",
      "Iteration:380, Price of Hedge: 0.15188451080141618, Loss: 0.0023415473677896427\n",
      "Iteration:390, Price of Hedge: 0.14506952693430933, Loss: 0.002036284398764987\n",
      "Iteration:400, Price of Hedge: 0.15497373160138395, Loss: 0.00204164239895801\n",
      "Iteration:410, Price of Hedge: 0.16368282206357918, Loss: 0.002378670253525472\n",
      "Iteration:420, Price of Hedge: 0.16427616626089334, Loss: 0.0023647582823285275\n",
      "Iteration:430, Price of Hedge: 0.16175108601371307, Loss: 0.002195007998588183\n",
      "Iteration:440, Price of Hedge: 0.16652944366943104, Loss: 0.002025558072631084\n",
      "Iteration:450, Price of Hedge: 0.16243582158311654, Loss: 0.0019585094992648155\n",
      "Iteration:460, Price of Hedge: 0.1543189188344755, Loss: 0.0020583763363045127\n",
      "Iteration:470, Price of Hedge: 0.1516091218912827, Loss: 0.0023314377013917142\n",
      "Iteration:480, Price of Hedge: 0.15057772302606906, Loss: 0.0022359662922558643\n",
      "Iteration:490, Price of Hedge: 0.14171382895200538, Loss: 0.001926202815657996\n",
      "Iteration:500, Price of Hedge: 0.15936148929676436, Loss: 0.001951457317177119\n",
      "Iteration:510, Price of Hedge: 0.15561235359565304, Loss: 0.002584162961622738\n",
      "Iteration:520, Price of Hedge: 0.1382488869869647, Loss: 0.0016038630337183001\n",
      "Iteration:530, Price of Hedge: 0.1486913911117199, Loss: 0.0016459457709577352\n",
      "Iteration:540, Price of Hedge: 0.1711137064204948, Loss: 0.002272382319811206\n",
      "Iteration:550, Price of Hedge: 0.16811724728009667, Loss: 0.001671132851417323\n",
      "Iteration:560, Price of Hedge: 0.18925569068500323, Loss: 0.0016313828220981153\n",
      "Iteration:570, Price of Hedge: 0.16969189224361117, Loss: 0.0014400023743363689\n",
      "Iteration:580, Price of Hedge: 0.15454698909396, Loss: 0.0016373318195067044\n",
      "Iteration:590, Price of Hedge: 0.14064286668018014, Loss: 0.0014159193896512879\n",
      "Iteration:600, Price of Hedge: 0.14650282820198512, Loss: 0.0018744715781418232\n",
      "Iteration:610, Price of Hedge: 0.13988217247995466, Loss: 0.0012394536494978404\n",
      "Iteration:620, Price of Hedge: 0.1641857855973001, Loss: 0.001490764813744805\n",
      "Iteration:630, Price of Hedge: 0.17103069226690196, Loss: 0.0017557348924416073\n",
      "Iteration:640, Price of Hedge: 0.15633161846588947, Loss: 0.0015254072422565157\n",
      "Iteration:650, Price of Hedge: 0.14777858528283191, Loss: 0.0017966453536008343\n",
      "Iteration:660, Price of Hedge: 0.15003257213098706, Loss: 0.0013333422581515598\n",
      "Iteration:670, Price of Hedge: 0.14590492609808764, Loss: 0.001806062283796961\n",
      "Iteration:680, Price of Hedge: 0.16710807428344623, Loss: 0.0014381719836795259\n",
      "Iteration:690, Price of Hedge: 0.1578461845839918, Loss: 0.001256001191910605\n",
      "Iteration:700, Price of Hedge: 0.15363928539930713, Loss: 0.0018986052804707888\n",
      "Iteration:710, Price of Hedge: 0.1669566429393484, Loss: 0.0011893375563504672\n",
      "Iteration:720, Price of Hedge: 0.15219181477598412, Loss: 0.0013155057435228824\n",
      "Iteration:730, Price of Hedge: 0.16800428116895602, Loss: 0.001574668803844126\n",
      "Iteration:740, Price of Hedge: 0.18112813662374946, Loss: 0.0016556913028944798\n",
      "Iteration:750, Price of Hedge: 0.18402420519910265, Loss: 0.0013919815728331343\n",
      "Iteration:760, Price of Hedge: 0.15996593185083371, Loss: 0.001828936548585869\n",
      "Iteration:770, Price of Hedge: 0.1621763221767438, Loss: 0.0015613472224658143\n",
      "Iteration:780, Price of Hedge: 0.150158415057102, Loss: 0.0013890065426565236\n",
      "Iteration:790, Price of Hedge: 0.14666946876527903, Loss: 0.0015342494231050275\n",
      "Iteration:800, Price of Hedge: 0.14582291293463998, Loss: 0.0012855679079537886\n",
      "Iteration:810, Price of Hedge: 0.16187367329226846, Loss: 0.0015268933907017224\n",
      "Iteration:820, Price of Hedge: 0.16793158790404447, Loss: 0.0017308953948767859\n",
      "Iteration:830, Price of Hedge: 0.16641393135034832, Loss: 0.0015773869051181834\n",
      "Iteration:840, Price of Hedge: 0.1719478519170039, Loss: 0.001674128381240414\n",
      "Iteration:850, Price of Hedge: 0.17361175021540448, Loss: 0.0016894384283273167\n",
      "Iteration:860, Price of Hedge: 0.15743138592985348, Loss: 0.0014027334096382126\n",
      "Iteration:870, Price of Hedge: 0.15701676220603175, Loss: 0.0015856941211181753\n",
      "Iteration:880, Price of Hedge: 0.15497392596840243, Loss: 0.0016354463075782145\n",
      "Iteration:890, Price of Hedge: 0.16392045518037293, Loss: 0.0014867180316803564\n",
      "Iteration:900, Price of Hedge: 0.1478690728482853, Loss: 0.0013848282591561345\n",
      "Iteration:910, Price of Hedge: 0.14028772898236427, Loss: 0.0013531104468756162\n",
      "Iteration:920, Price of Hedge: 0.16218006374184954, Loss: 0.0015078962923837924\n",
      "Iteration:930, Price of Hedge: 0.17026583861248099, Loss: 0.0018343353962226195\n",
      "Iteration:940, Price of Hedge: 0.1741910028038788, Loss: 0.0014830804832993484\n",
      "Iteration:950, Price of Hedge: 0.17524235344353942, Loss: 0.0013675028690463664\n",
      "Iteration:960, Price of Hedge: 0.17126863637092526, Loss: 0.0013482210534162097\n",
      "Iteration:970, Price of Hedge: 0.16203787454948043, Loss: 0.0012556876232440728\n",
      "Iteration:980, Price of Hedge: 0.1516157692433147, Loss: 0.0014016276435221409\n",
      "Iteration:990, Price of Hedge: 0.15914500331158124, Loss: 0.0015997980297458691\n",
      "tf.Tensor(0.14734349, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_100 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.16383258185131808, Loss: 0.003407969954939505\n",
      "Iteration:20, Price of Hedge: 0.12279300632609634, Loss: 0.0018026707311737168\n",
      "Iteration:30, Price of Hedge: 0.13335157671593692, Loss: 0.0013791203983298474\n",
      "Iteration:40, Price of Hedge: 0.12924944135421298, Loss: 0.0014444716009675452\n",
      "Iteration:50, Price of Hedge: 0.13421435247426813, Loss: 0.0017456378295300334\n",
      "Iteration:60, Price of Hedge: 0.12519964903056577, Loss: 0.0016986943983362645\n",
      "Iteration:70, Price of Hedge: 0.13538333403351288, Loss: 0.0017539898410538159\n",
      "Iteration:80, Price of Hedge: 0.13869285041222598, Loss: 0.0017842855852655327\n",
      "Iteration:90, Price of Hedge: 0.12951351810387096, Loss: 0.0016440121228223248\n",
      "Iteration:100, Price of Hedge: 0.13565962675028231, Loss: 0.0016746114136511837\n",
      "Iteration:110, Price of Hedge: 0.1353776682349242, Loss: 0.0016869843928697726\n",
      "Iteration:120, Price of Hedge: 0.14114615091948154, Loss: 0.0015351831440398977\n",
      "Iteration:130, Price of Hedge: 0.12580577285934497, Loss: 0.001399162523070574\n",
      "Iteration:140, Price of Hedge: 0.12917484329252035, Loss: 0.0014593028674222076\n",
      "Iteration:150, Price of Hedge: 0.13895297179305785, Loss: 0.001866225861081272\n",
      "Iteration:160, Price of Hedge: 0.1448633132460529, Loss: 0.001846432769082973\n",
      "Iteration:170, Price of Hedge: 0.13946196070435166, Loss: 0.0016172599323162728\n",
      "Iteration:180, Price of Hedge: 0.11489888705403715, Loss: 0.001159320911029349\n",
      "Iteration:190, Price of Hedge: 0.1379033315831599, Loss: 0.0020186509065610813\n",
      "Iteration:200, Price of Hedge: 0.14695007642985872, Loss: 0.0016168245805647241\n",
      "Iteration:210, Price of Hedge: 0.13057385821813625, Loss: 0.0016544051398893812\n",
      "Iteration:220, Price of Hedge: 0.13295474729265708, Loss: 0.0014638302523096948\n",
      "Iteration:230, Price of Hedge: 0.12166300507240778, Loss: 0.0017845412993742205\n",
      "Iteration:240, Price of Hedge: 0.11347691738353874, Loss: 0.0013021914509077637\n",
      "Iteration:250, Price of Hedge: 0.13659016856960662, Loss: 0.0019144659328772296\n",
      "Iteration:260, Price of Hedge: 0.15017553879143009, Loss: 0.0016003671606718561\n",
      "Iteration:270, Price of Hedge: 0.1390355874942628, Loss: 0.0017336760580349165\n",
      "Iteration:280, Price of Hedge: 0.11878897771695023, Loss: 0.0018981266516877816\n",
      "Iteration:290, Price of Hedge: 0.13636514987231224, Loss: 0.0014087436022877764\n",
      "Iteration:300, Price of Hedge: 0.14461171485898136, Loss: 0.0016007019882310347\n",
      "Iteration:310, Price of Hedge: 0.13659219970494973, Loss: 0.001938436700978985\n",
      "Iteration:320, Price of Hedge: 0.12877962711549387, Loss: 0.001541155678079631\n",
      "Iteration:330, Price of Hedge: 0.13068346177985718, Loss: 0.0016966667555255112\n",
      "Iteration:340, Price of Hedge: 0.12193693622990268, Loss: 0.001827973976296693\n",
      "Iteration:350, Price of Hedge: 0.14603672637331896, Loss: 0.0016239982420389709\n",
      "Iteration:360, Price of Hedge: 0.13181481388432417, Loss: 0.0013882664294939673\n",
      "Iteration:370, Price of Hedge: 0.13037710048532888, Loss: 0.0017979618864525705\n",
      "Iteration:380, Price of Hedge: 0.130757272655125, Loss: 0.0019039679879900406\n",
      "Iteration:390, Price of Hedge: 0.13000997034247277, Loss: 0.0016636696134553874\n",
      "Iteration:400, Price of Hedge: 0.124930431273269, Loss: 0.0018125620383743213\n",
      "Iteration:410, Price of Hedge: 0.13809328647032046, Loss: 0.0013810364319542078\n",
      "Iteration:420, Price of Hedge: 0.13074118878434576, Loss: 0.0015964707093482633\n",
      "Iteration:430, Price of Hedge: 0.11576573480140553, Loss: 0.0016414068455285259\n",
      "Iteration:440, Price of Hedge: 0.12353929793025245, Loss: 0.0013629185406964339\n",
      "Iteration:450, Price of Hedge: 0.12738312924276726, Loss: 0.0016348247886667777\n",
      "Iteration:460, Price of Hedge: 0.1448010088982791, Loss: 0.0014977577746315585\n",
      "Iteration:470, Price of Hedge: 0.1440841638974227, Loss: 0.0016745462703301461\n",
      "Iteration:480, Price of Hedge: 0.13046211661921206, Loss: 0.0016201444603499038\n",
      "Iteration:490, Price of Hedge: 0.1465645980404581, Loss: 0.001757297269201874\n",
      "Iteration:500, Price of Hedge: 0.14207204736706416, Loss: 0.0014910149094318648\n",
      "Iteration:510, Price of Hedge: 0.14740083298241588, Loss: 0.001538080731107583\n",
      "Iteration:520, Price of Hedge: 0.14241928404557883, Loss: 0.0015655185209014766\n",
      "Iteration:530, Price of Hedge: 0.1333999157934329, Loss: 0.0015560947574898565\n",
      "Iteration:540, Price of Hedge: 0.13422301152494143, Loss: 0.001453754296441534\n",
      "Iteration:550, Price of Hedge: 0.1327110304881849, Loss: 0.0013076115574371606\n",
      "Iteration:560, Price of Hedge: 0.13304428245971991, Loss: 0.0017116679412721104\n",
      "Iteration:570, Price of Hedge: 0.13843224311384789, Loss: 0.001422615637136393\n",
      "Iteration:580, Price of Hedge: 0.13809834973115187, Loss: 0.0016059016096738432\n",
      "Iteration:590, Price of Hedge: 0.13625610997494492, Loss: 0.001918908585892598\n",
      "Iteration:600, Price of Hedge: 0.1348686307318758, Loss: 0.001707279650282223\n",
      "Iteration:610, Price of Hedge: 0.14444226569227042, Loss: 0.001455804109240333\n",
      "Iteration:620, Price of Hedge: 0.13864073089622053, Loss: 0.0013536999255988503\n",
      "Iteration:630, Price of Hedge: 0.14281820291430733, Loss: 0.001357052908516865\n",
      "Iteration:640, Price of Hedge: 0.1389578018134671, Loss: 0.0013995099541161073\n",
      "Iteration:650, Price of Hedge: 0.1335211619395608, Loss: 0.0016125989201035806\n",
      "Iteration:660, Price of Hedge: 0.12942108686823275, Loss: 0.001764299492891852\n",
      "Iteration:670, Price of Hedge: 0.12584494753191963, Loss: 0.0009981010616617826\n",
      "Iteration:680, Price of Hedge: 0.12507154172868554, Loss: 0.0012458366320148796\n",
      "Iteration:690, Price of Hedge: 0.13653661073766443, Loss: 0.0014518412998018372\n",
      "Iteration:700, Price of Hedge: 0.1437343615742641, Loss: 0.001202130702397286\n",
      "Iteration:710, Price of Hedge: 0.1399739331493791, Loss: 0.0012192148040755192\n",
      "Iteration:720, Price of Hedge: 0.11441142429004003, Loss: 0.0011114124779586733\n",
      "Iteration:730, Price of Hedge: 0.1230797948618637, Loss: 0.0012405723227987332\n",
      "Iteration:740, Price of Hedge: 0.13188656446919608, Loss: 0.0011206972993219268\n",
      "Iteration:750, Price of Hedge: 0.11929137758631754, Loss: 0.0008521305196878437\n",
      "Iteration:760, Price of Hedge: 0.12926755636033535, Loss: 0.001153951142520754\n",
      "Iteration:770, Price of Hedge: 0.13363133888398623, Loss: 0.0009535520651015317\n",
      "Iteration:780, Price of Hedge: 0.12244725655527305, Loss: 0.0011995270195204355\n",
      "Iteration:790, Price of Hedge: 0.1247857736197652, Loss: 0.0009242516166887427\n",
      "Iteration:800, Price of Hedge: 0.12613201789986378, Loss: 0.0008755827226582636\n",
      "Iteration:810, Price of Hedge: 0.13110900893011745, Loss: 0.0011057639901825623\n",
      "Iteration:820, Price of Hedge: 0.1264616352081532, Loss: 0.0009310499068585498\n",
      "Iteration:830, Price of Hedge: 0.12871978151050387, Loss: 0.0008599015560454504\n",
      "Iteration:840, Price of Hedge: 0.1407426158340641, Loss: 0.0011843717827267676\n",
      "Iteration:850, Price of Hedge: 0.1402098947098139, Loss: 0.001134945616570382\n",
      "Iteration:860, Price of Hedge: 0.14095711927565874, Loss: 0.0008750286248063622\n",
      "Iteration:870, Price of Hedge: 0.1383023379170467, Loss: 0.0009853959122455957\n",
      "Iteration:880, Price of Hedge: 0.13705087671350996, Loss: 0.0010246157599671291\n",
      "Iteration:890, Price of Hedge: 0.1298919701255535, Loss: 0.0011300569823571415\n",
      "Iteration:900, Price of Hedge: 0.12200189368747871, Loss: 0.0009657854948748213\n",
      "Iteration:910, Price of Hedge: 0.11938039768078142, Loss: 0.0010112531033712403\n",
      "Iteration:920, Price of Hedge: 0.12804966234089007, Loss: 0.0011098122907393427\n",
      "Iteration:930, Price of Hedge: 0.11902080897824234, Loss: 0.0011540638905763957\n",
      "Iteration:940, Price of Hedge: 0.13235409489544808, Loss: 0.0009053797180635759\n",
      "Iteration:950, Price of Hedge: 0.12683202099856886, Loss: 0.0010257709530086035\n",
      "Iteration:960, Price of Hedge: 0.12664918966263558, Loss: 0.0009365104812085912\n",
      "Iteration:970, Price of Hedge: 0.1288426797762888, Loss: 0.0011919919568712024\n",
      "Iteration:980, Price of Hedge: 0.1298496175522267, Loss: 0.0011151073494252096\n",
      "Iteration:990, Price of Hedge: 0.11871551670231568, Loss: 0.000980680613932039\n",
      "tf.Tensor(0.17590973, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_101 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.19473857047260595, Loss: 0.0030763321407532686\n",
      "Iteration:20, Price of Hedge: 0.1589474195189453, Loss: 0.0029146069371376536\n",
      "Iteration:30, Price of Hedge: 0.1710636569132362, Loss: 0.0028833861273973582\n",
      "Iteration:40, Price of Hedge: 0.19631961011102847, Loss: 0.0027834255993807846\n",
      "Iteration:50, Price of Hedge: 0.18510576047343505, Loss: 0.003470756575877898\n",
      "Iteration:60, Price of Hedge: 0.17681713446396685, Loss: 0.0029480842264831167\n",
      "Iteration:70, Price of Hedge: 0.17004606782468557, Loss: 0.003262528759392458\n",
      "Iteration:80, Price of Hedge: 0.18066159746929175, Loss: 0.002487842107876437\n",
      "Iteration:90, Price of Hedge: 0.2054249080220444, Loss: 0.003246520813229825\n",
      "Iteration:100, Price of Hedge: 0.1834932916881243, Loss: 0.0028743389500840433\n",
      "Iteration:110, Price of Hedge: 0.17065855717331999, Loss: 0.0029623516767349535\n",
      "Iteration:120, Price of Hedge: 0.20386464621789743, Loss: 0.0035929523871101265\n",
      "Iteration:130, Price of Hedge: 0.16601357416568305, Loss: 0.0027968414791329057\n",
      "Iteration:140, Price of Hedge: 0.15339225463716985, Loss: 0.0028742718327229746\n",
      "Iteration:150, Price of Hedge: 0.1779072030137087, Loss: 0.002746149042220969\n",
      "Iteration:160, Price of Hedge: 0.20161640291513835, Loss: 0.0034489911141897256\n",
      "Iteration:170, Price of Hedge: 0.17555435138160363, Loss: 0.0031872759238062986\n",
      "Iteration:180, Price of Hedge: 0.16711437177484498, Loss: 0.0028286535897872334\n",
      "Iteration:190, Price of Hedge: 0.16800391187162092, Loss: 0.0029803467219630788\n",
      "Iteration:200, Price of Hedge: 0.19822409590490367, Loss: 0.0028695802988144116\n",
      "Iteration:210, Price of Hedge: 0.20531266106887217, Loss: 0.003139569146517296\n",
      "Iteration:220, Price of Hedge: 0.17795484236993817, Loss: 0.0027734269347723163\n",
      "Iteration:230, Price of Hedge: 0.17073962765672804, Loss: 0.003230586058397589\n",
      "Iteration:240, Price of Hedge: 0.19935519533224663, Loss: 0.0031819147347793785\n",
      "Iteration:250, Price of Hedge: 0.16739392985752488, Loss: 0.0030240881083766213\n",
      "Iteration:260, Price of Hedge: 0.15774959389415813, Loss: 0.002760445647525578\n",
      "Iteration:270, Price of Hedge: 0.1590915912549029, Loss: 0.0024058532403060775\n",
      "Iteration:280, Price of Hedge: 0.1801260191498699, Loss: 0.0031112380276845596\n",
      "Iteration:290, Price of Hedge: 0.1659682866503772, Loss: 0.002443773486365375\n",
      "Iteration:300, Price of Hedge: 0.16940059439301508, Loss: 0.0028206969936666717\n",
      "Iteration:310, Price of Hedge: 0.1961025798981936, Loss: 0.002896109574646144\n",
      "Iteration:320, Price of Hedge: 0.18383874019006896, Loss: 0.0024673429169438156\n",
      "Iteration:330, Price of Hedge: 0.1705034911659766, Loss: 0.0030613713469026973\n",
      "Iteration:340, Price of Hedge: 0.18385325940634942, Loss: 0.002701624721161111\n",
      "Iteration:350, Price of Hedge: 0.18140755864951644, Loss: 0.0028371049107095204\n",
      "Iteration:360, Price of Hedge: 0.19066924426360146, Loss: 0.003001242694942019\n",
      "Iteration:370, Price of Hedge: 0.1673845419305323, Loss: 0.0026443550865628885\n",
      "Iteration:380, Price of Hedge: 0.19818137403424174, Loss: 0.002985739191932035\n",
      "Iteration:390, Price of Hedge: 0.1970922773195923, Loss: 0.003003336088470743\n",
      "Iteration:400, Price of Hedge: 0.17708522489255643, Loss: 0.0027004576079548317\n",
      "Iteration:410, Price of Hedge: 0.14459774958870356, Loss: 0.0029571259372240368\n",
      "Iteration:420, Price of Hedge: 0.18149016463237047, Loss: 0.0028308475075083275\n",
      "Iteration:430, Price of Hedge: 0.16995018657446934, Loss: 0.0037834587906856454\n",
      "Iteration:440, Price of Hedge: 0.1801273214088937, Loss: 0.0028636250755872616\n",
      "Iteration:450, Price of Hedge: 0.20050343793061956, Loss: 0.0031633125963169695\n",
      "Iteration:460, Price of Hedge: 0.18410793851066387, Loss: 0.002990799415778778\n",
      "Iteration:470, Price of Hedge: 0.17696518382194312, Loss: 0.0036382711833580217\n",
      "Iteration:480, Price of Hedge: 0.18557346583000367, Loss: 0.002899254979662391\n",
      "Iteration:490, Price of Hedge: 0.16880548145583277, Loss: 0.002991626083004251\n",
      "Iteration:500, Price of Hedge: 0.17864468979192766, Loss: 0.002773659871496026\n",
      "Iteration:510, Price of Hedge: 0.17210746611257974, Loss: 0.0033854419064022648\n",
      "Iteration:520, Price of Hedge: 0.1712341945352506, Loss: 0.0027341487010206222\n",
      "Iteration:530, Price of Hedge: 0.15417020862863637, Loss: 0.002592364946104131\n",
      "Iteration:540, Price of Hedge: 0.1792866257438618, Loss: 0.0033369239505095737\n",
      "Iteration:550, Price of Hedge: 0.19731836503548836, Loss: 0.00275752315718365\n",
      "Iteration:560, Price of Hedge: 0.21185946704223113, Loss: 0.002771471420347327\n",
      "Iteration:570, Price of Hedge: 0.1834978204396549, Loss: 0.0026557292015255696\n",
      "Iteration:580, Price of Hedge: 0.17343407932381183, Loss: 0.002975869902870243\n",
      "Iteration:590, Price of Hedge: 0.18404766529823322, Loss: 0.00260322398846784\n",
      "Iteration:600, Price of Hedge: 0.1670680929877449, Loss: 0.002589587927327597\n",
      "Iteration:610, Price of Hedge: 0.16112304730360025, Loss: 0.0024650613822151724\n",
      "Iteration:620, Price of Hedge: 0.17730334356069477, Loss: 0.0036650914023205416\n",
      "Iteration:630, Price of Hedge: 0.17335707111109003, Loss: 0.002799342739701971\n",
      "Iteration:640, Price of Hedge: 0.18676355564745536, Loss: 0.0031993941000115988\n",
      "Iteration:650, Price of Hedge: 0.17613684989928657, Loss: 0.0022220459693510944\n",
      "Iteration:660, Price of Hedge: 0.1766405909010814, Loss: 0.0030273695703058046\n",
      "Iteration:670, Price of Hedge: 0.16940632822006024, Loss: 0.002567619595063886\n",
      "Iteration:680, Price of Hedge: 0.14820271355385728, Loss: 0.001728302417370875\n",
      "Iteration:690, Price of Hedge: 0.1663156205124011, Loss: 0.0025239228523249004\n",
      "Iteration:700, Price of Hedge: 0.18300418652282105, Loss: 0.002229546106676694\n",
      "Iteration:710, Price of Hedge: 0.19291270613770592, Loss: 0.002109877066684707\n",
      "Iteration:720, Price of Hedge: 0.18712177406251415, Loss: 0.0019522949175473814\n",
      "Iteration:730, Price of Hedge: 0.1688566194183949, Loss: 0.001891986172396143\n",
      "Iteration:740, Price of Hedge: 0.17865149263757446, Loss: 0.0022527946798254097\n",
      "Iteration:750, Price of Hedge: 0.1770551757514994, Loss: 0.0016911228918710663\n",
      "Iteration:760, Price of Hedge: 0.1805386603301031, Loss: 0.0018182893359024565\n",
      "Iteration:770, Price of Hedge: 0.17980710174594777, Loss: 0.0019005916202901151\n",
      "Iteration:780, Price of Hedge: 0.1656136251517566, Loss: 0.0019306957307695495\n",
      "Iteration:790, Price of Hedge: 0.18126378536594673, Loss: 0.002250401080362674\n",
      "Iteration:800, Price of Hedge: 0.17926911327549674, Loss: 0.00213581853413477\n",
      "Iteration:810, Price of Hedge: 0.1724269666175573, Loss: 0.0017676167912400677\n",
      "Iteration:820, Price of Hedge: 0.1944310624126686, Loss: 0.0015431122554492528\n",
      "Iteration:830, Price of Hedge: 0.1732880319461259, Loss: 0.0017136424368512481\n",
      "Iteration:840, Price of Hedge: 0.15910998809320206, Loss: 0.0019266718779393122\n",
      "Iteration:850, Price of Hedge: 0.1723523491191628, Loss: 0.0019185649510778946\n",
      "Iteration:860, Price of Hedge: 0.1766605135204756, Loss: 0.0017694804368789784\n",
      "Iteration:870, Price of Hedge: 0.1969963183225687, Loss: 0.0020475256456486293\n",
      "Iteration:880, Price of Hedge: 0.20408029642490108, Loss: 0.0018137206480235424\n",
      "Iteration:890, Price of Hedge: 0.18533991442059802, Loss: 0.0017503260227554663\n",
      "Iteration:900, Price of Hedge: 0.18561822855435964, Loss: 0.0022615512177064034\n",
      "Iteration:910, Price of Hedge: 0.18457373907045138, Loss: 0.0020415998811727175\n",
      "Iteration:920, Price of Hedge: 0.16594321330499326, Loss: 0.0015923486100641539\n",
      "Iteration:930, Price of Hedge: 0.18230186073824514, Loss: 0.0016140156734492205\n",
      "Iteration:940, Price of Hedge: 0.16467529893334218, Loss: 0.0016741403773298357\n",
      "Iteration:950, Price of Hedge: 0.1746441695074651, Loss: 0.0018852621365013644\n",
      "Iteration:960, Price of Hedge: 0.17700685611070527, Loss: 0.002586229022289488\n",
      "Iteration:970, Price of Hedge: 0.17923173649784305, Loss: 0.001868182590300127\n",
      "Iteration:980, Price of Hedge: 0.18419344056209327, Loss: 0.002096837013784725\n",
      "Iteration:990, Price of Hedge: 0.17632713521037857, Loss: 0.0021832285980221246\n",
      "tf.Tensor(0.14310275, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_102 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.12280788512136098, Loss: 0.0016906422890480277\n",
      "Iteration:20, Price of Hedge: 0.11843307226941135, Loss: 0.0014988328672025264\n",
      "Iteration:30, Price of Hedge: 0.13054842529376814, Loss: 0.0017614565715481146\n",
      "Iteration:40, Price of Hedge: 0.12225540658968229, Loss: 0.001716126082909264\n",
      "Iteration:50, Price of Hedge: 0.1226327021276049, Loss: 0.0016353394057180505\n",
      "Iteration:60, Price of Hedge: 0.14738677052862884, Loss: 0.0017172810481768887\n",
      "Iteration:70, Price of Hedge: 0.1479163234704778, Loss: 0.0015079962091792299\n",
      "Iteration:80, Price of Hedge: 0.1332263460459302, Loss: 0.0016556223633426125\n",
      "Iteration:90, Price of Hedge: 0.14398735940386873, Loss: 0.0017961580694115353\n",
      "Iteration:100, Price of Hedge: 0.13470764624881967, Loss: 0.0017816470529896655\n",
      "Iteration:110, Price of Hedge: 0.13863745581195916, Loss: 0.0016656489682099873\n",
      "Iteration:120, Price of Hedge: 0.13002443124864768, Loss: 0.002000989170399803\n",
      "Iteration:130, Price of Hedge: 0.14191758389747805, Loss: 0.0018707029838725743\n",
      "Iteration:140, Price of Hedge: 0.1350341050930588, Loss: 0.0017308849172796958\n",
      "Iteration:150, Price of Hedge: 0.119470477075496, Loss: 0.0019212371938835294\n",
      "Iteration:160, Price of Hedge: 0.1270805095133447, Loss: 0.0016212786222725816\n",
      "Iteration:170, Price of Hedge: 0.1126624807027035, Loss: 0.0016805593481151405\n",
      "Iteration:180, Price of Hedge: 0.113407955965382, Loss: 0.0017563529188206807\n",
      "Iteration:190, Price of Hedge: 0.12249828761597499, Loss: 0.0019013930805428791\n",
      "Iteration:200, Price of Hedge: 0.13163241015583155, Loss: 0.0016641904563252207\n",
      "Iteration:210, Price of Hedge: 0.13917535681725185, Loss: 0.0016010008275219479\n",
      "Iteration:220, Price of Hedge: 0.13127319075062757, Loss: 0.001496530073581237\n",
      "Iteration:230, Price of Hedge: 0.12156591874667698, Loss: 0.001496698322531609\n",
      "Iteration:240, Price of Hedge: 0.11650396017429472, Loss: 0.0017074075073365668\n",
      "Iteration:250, Price of Hedge: 0.12138744123195765, Loss: 0.001985903404630318\n",
      "Iteration:260, Price of Hedge: 0.10787583329364736, Loss: 0.001828700271179029\n",
      "Iteration:270, Price of Hedge: 0.1347953154925051, Loss: 0.0014803765040039775\n",
      "Iteration:280, Price of Hedge: 0.13813950694731503, Loss: 0.0016246672897603954\n",
      "Iteration:290, Price of Hedge: 0.14401826375980706, Loss: 0.0019013469183759902\n",
      "Iteration:300, Price of Hedge: 0.12072921732387486, Loss: 0.001662111640322883\n",
      "Iteration:310, Price of Hedge: 0.12982490378582698, Loss: 0.002081065648727398\n",
      "Iteration:320, Price of Hedge: 0.12636605522681563, Loss: 0.0018781844437424922\n",
      "Iteration:330, Price of Hedge: 0.12737825063060343, Loss: 0.0016134794938068354\n",
      "Iteration:340, Price of Hedge: 0.13640456750366, Loss: 0.0014166573769245794\n",
      "Iteration:350, Price of Hedge: 0.1313667201599202, Loss: 0.0018356569400990509\n",
      "Iteration:360, Price of Hedge: 0.1325385200409329, Loss: 0.001422698243119247\n",
      "Iteration:370, Price of Hedge: 0.11950349031358486, Loss: 0.0014679444554336785\n",
      "Iteration:380, Price of Hedge: 0.13510049114822067, Loss: 0.0014855630664127317\n",
      "Iteration:390, Price of Hedge: 0.1264770971044733, Loss: 0.001476227071857894\n",
      "Iteration:400, Price of Hedge: 0.14263040550105188, Loss: 0.0016642833880559317\n",
      "Iteration:410, Price of Hedge: 0.11793510396806539, Loss: 0.0015568823994624003\n",
      "Iteration:420, Price of Hedge: 0.12192550744921604, Loss: 0.0014265758651379246\n",
      "Iteration:430, Price of Hedge: 0.13058247839540585, Loss: 0.0015954653155753286\n",
      "Iteration:440, Price of Hedge: 0.12737456737560324, Loss: 0.0015597121099228505\n",
      "Iteration:450, Price of Hedge: 0.1289512143194081, Loss: 0.0014144705961174453\n",
      "Iteration:460, Price of Hedge: 0.14616912918630762, Loss: 0.0015794484103079376\n",
      "Iteration:470, Price of Hedge: 0.144185536015911, Loss: 0.0015582271762715095\n",
      "Iteration:480, Price of Hedge: 0.1410179172790393, Loss: 0.0014970497016572049\n",
      "Iteration:490, Price of Hedge: 0.1443472007835318, Loss: 0.0014969880508685308\n",
      "Iteration:500, Price of Hedge: 0.13891289331384726, Loss: 0.0016807669260169079\n",
      "Iteration:510, Price of Hedge: 0.16064932628780967, Loss: 0.0015496340281654253\n",
      "Iteration:520, Price of Hedge: 0.13708448277100516, Loss: 0.001147532399509299\n",
      "Iteration:530, Price of Hedge: 0.1443526624967511, Loss: 0.0011388917225932272\n",
      "Iteration:540, Price of Hedge: 0.14098097782717717, Loss: 0.0011289172779374525\n",
      "Iteration:550, Price of Hedge: 0.1297643876146232, Loss: 0.0013713769985326807\n",
      "Iteration:560, Price of Hedge: 0.12186266859214144, Loss: 0.0010216376928058547\n",
      "Iteration:570, Price of Hedge: 0.12849104068480557, Loss: 0.001086624153585436\n",
      "Iteration:580, Price of Hedge: 0.13281068245855962, Loss: 0.0009146043312058705\n",
      "Iteration:590, Price of Hedge: 0.14319225252302134, Loss: 0.0010538741461423252\n",
      "Iteration:600, Price of Hedge: 0.14106102788373817, Loss: 0.001064249852396798\n",
      "Iteration:610, Price of Hedge: 0.14660446271594837, Loss: 0.0012521663913756865\n",
      "Iteration:620, Price of Hedge: 0.13766173337918916, Loss: 0.001021865466655636\n",
      "Iteration:630, Price of Hedge: 0.136160316189887, Loss: 0.0013110878419325233\n",
      "Iteration:640, Price of Hedge: 0.13563939314365855, Loss: 0.001232001420605311\n",
      "Iteration:650, Price of Hedge: 0.11892006855256412, Loss: 0.0009263075793814857\n",
      "Iteration:660, Price of Hedge: 0.13408814996916904, Loss: 0.0009343843641701155\n",
      "Iteration:670, Price of Hedge: 0.14035599067925447, Loss: 0.0010128561757260014\n",
      "Iteration:680, Price of Hedge: 0.13384975882100322, Loss: 0.0010548931304216302\n",
      "Iteration:690, Price of Hedge: 0.13906051506438288, Loss: 0.0010493281597237726\n",
      "Iteration:700, Price of Hedge: 0.1337521477043225, Loss: 0.0008389968517356017\n",
      "Iteration:710, Price of Hedge: 0.1409310255034278, Loss: 0.0013024330430377652\n",
      "Iteration:720, Price of Hedge: 0.14335946646901973, Loss: 0.0010408973384479659\n",
      "Iteration:730, Price of Hedge: 0.12609414548631293, Loss: 0.0008134460923625297\n",
      "Iteration:740, Price of Hedge: 0.1264140152886256, Loss: 0.0009384041170710566\n",
      "Iteration:750, Price of Hedge: 0.12220064368222552, Loss: 0.0010558468954552814\n",
      "Iteration:760, Price of Hedge: 0.11704473781146092, Loss: 0.000987129802714748\n",
      "Iteration:770, Price of Hedge: 0.11974535091303054, Loss: 0.001314328304568746\n",
      "Iteration:780, Price of Hedge: 0.1295043536989496, Loss: 0.0009348634485008223\n",
      "Iteration:790, Price of Hedge: 0.1331606014019293, Loss: 0.001044407561246946\n",
      "Iteration:800, Price of Hedge: 0.11520369341241761, Loss: 0.0010009747324752406\n",
      "Iteration:810, Price of Hedge: 0.1293279461929771, Loss: 0.0016506289531584728\n",
      "Iteration:820, Price of Hedge: 0.1467195765826432, Loss: 0.0011002511037716879\n",
      "Iteration:830, Price of Hedge: 0.13437986570885485, Loss: 0.0009948794283304752\n",
      "Iteration:840, Price of Hedge: 0.12588855377251562, Loss: 0.0009391857609988896\n",
      "Iteration:850, Price of Hedge: 0.12044142779796232, Loss: 0.0010158585387645858\n",
      "Iteration:860, Price of Hedge: 0.11616098985183569, Loss: 0.0008999796556329598\n",
      "Iteration:870, Price of Hedge: 0.12895937773418426, Loss: 0.000929686604442992\n",
      "Iteration:880, Price of Hedge: 0.12897811471476572, Loss: 0.0008987499046179903\n",
      "Iteration:890, Price of Hedge: 0.12694294625601543, Loss: 0.0010639352967102501\n",
      "Iteration:900, Price of Hedge: 0.12348517643395668, Loss: 0.001013081444063435\n",
      "Iteration:910, Price of Hedge: 0.12830761652946593, Loss: 0.0008954171176479897\n",
      "Iteration:920, Price of Hedge: 0.13388282065084667, Loss: 0.0010813824699050345\n",
      "Iteration:930, Price of Hedge: 0.13549603774917857, Loss: 0.0009319673040008525\n",
      "Iteration:940, Price of Hedge: 0.13020610610082103, Loss: 0.0009024852439051712\n",
      "Iteration:950, Price of Hedge: 0.14403022704979448, Loss: 0.0011715260968452657\n",
      "Iteration:960, Price of Hedge: 0.13354170653341413, Loss: 0.0008531654481366335\n",
      "Iteration:970, Price of Hedge: 0.1345930474547238, Loss: 0.0010317883584967436\n",
      "Iteration:980, Price of Hedge: 0.1500812027590108, Loss: 0.0009585372754270793\n",
      "Iteration:990, Price of Hedge: 0.1341541278535921, Loss: 0.0012077624867577463\n",
      "tf.Tensor(0.12755522, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_103 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.12131893657629433, Loss: 0.0017225918232583904\n",
      "Iteration:20, Price of Hedge: 0.14191286077892898, Loss: 0.0014812648220181247\n",
      "Iteration:30, Price of Hedge: 0.12197568329503668, Loss: 0.0018967739787185468\n",
      "Iteration:40, Price of Hedge: 0.14469932579256126, Loss: 0.0013540942780574383\n",
      "Iteration:50, Price of Hedge: 0.12224381259702995, Loss: 0.0014413134406157102\n",
      "Iteration:60, Price of Hedge: 0.12615657617264872, Loss: 0.001491994640684391\n",
      "Iteration:70, Price of Hedge: 0.14729588451078754, Loss: 0.001734301525026416\n",
      "Iteration:80, Price of Hedge: 0.12319539464610473, Loss: 0.0022788527674865613\n",
      "Iteration:90, Price of Hedge: 0.12142477913620767, Loss: 0.0015843060672776077\n",
      "Iteration:100, Price of Hedge: 0.15081365543145112, Loss: 0.0017802925578296325\n",
      "Iteration:110, Price of Hedge: 0.128643035693257, Loss: 0.0016943355660976156\n",
      "Iteration:120, Price of Hedge: 0.1257096778054084, Loss: 0.0017005027708542953\n",
      "Iteration:130, Price of Hedge: 0.12426691086393263, Loss: 0.0016765140845430239\n",
      "Iteration:140, Price of Hedge: 0.1341601629495159, Loss: 0.0016925683447217789\n",
      "Iteration:150, Price of Hedge: 0.14665414292587187, Loss: 0.0017975190940885954\n",
      "Iteration:160, Price of Hedge: 0.14631891812909928, Loss: 0.0014420277394086246\n",
      "Iteration:170, Price of Hedge: 0.12076414507709572, Loss: 0.001996571420658677\n",
      "Iteration:180, Price of Hedge: 0.10663559678542782, Loss: 0.0013296309110432225\n",
      "Iteration:190, Price of Hedge: 0.12508117261445123, Loss: 0.0018220515525039116\n",
      "Iteration:200, Price of Hedge: 0.157881967552094, Loss: 0.0015331775193679566\n",
      "Iteration:210, Price of Hedge: 0.14514567993214983, Loss: 0.0016172288032234694\n",
      "Iteration:220, Price of Hedge: 0.130611614011476, Loss: 0.001690869911048576\n",
      "Iteration:230, Price of Hedge: 0.10999918606868207, Loss: 0.0017010415319336448\n",
      "Iteration:240, Price of Hedge: 0.12243384523099793, Loss: 0.0018515333848257431\n",
      "Iteration:250, Price of Hedge: 0.11489600070381271, Loss: 0.0015782995190096406\n",
      "Iteration:260, Price of Hedge: 0.13092800464415788, Loss: 0.0015153924816293297\n",
      "Iteration:270, Price of Hedge: 0.139434418897833, Loss: 0.0017165751010917996\n",
      "Iteration:280, Price of Hedge: 0.12393552481577502, Loss: 0.0013999346764213328\n",
      "Iteration:290, Price of Hedge: 0.14581803432247611, Loss: 0.0016638627656800022\n",
      "Iteration:300, Price of Hedge: 0.13231087738888903, Loss: 0.0015852071406273428\n",
      "Iteration:310, Price of Hedge: 0.13647002059713317, Loss: 0.0016499085803962311\n",
      "Iteration:320, Price of Hedge: 0.13673703228877018, Loss: 0.0017216813352561977\n",
      "Iteration:330, Price of Hedge: 0.14841952024462088, Loss: 0.0017968561203364987\n",
      "Iteration:340, Price of Hedge: 0.1365631126806342, Loss: 0.0015496025953741555\n",
      "Iteration:350, Price of Hedge: 0.13627633386321777, Loss: 0.0014587524139519027\n",
      "Iteration:360, Price of Hedge: 0.12368315867898048, Loss: 0.00145236259821937\n",
      "Iteration:370, Price of Hedge: 0.1250564296929987, Loss: 0.0018584097255014088\n",
      "Iteration:380, Price of Hedge: 0.14227266328518837, Loss: 0.0013206075740595181\n",
      "Iteration:390, Price of Hedge: 0.1480853839031518, Loss: 0.0016099286513379773\n",
      "Iteration:400, Price of Hedge: 0.13942864619738415, Loss: 0.0014018856353693267\n",
      "Iteration:410, Price of Hedge: 0.13483906750836497, Loss: 0.0014898916806539765\n",
      "Iteration:420, Price of Hedge: 0.1354550360266302, Loss: 0.0014666838030997554\n",
      "Iteration:430, Price of Hedge: 0.11959807902312818, Loss: 0.0014846299528747942\n",
      "Iteration:440, Price of Hedge: 0.10977448807696817, Loss: 0.0012606690373387908\n",
      "Iteration:450, Price of Hedge: 0.11770249523869936, Loss: 0.0013839165563600765\n",
      "Iteration:460, Price of Hedge: 0.12367156468632814, Loss: 0.0012495732620205425\n",
      "Iteration:470, Price of Hedge: 0.13967540484569554, Loss: 0.0012464564805847512\n",
      "Iteration:480, Price of Hedge: 0.14844844205697072, Loss: 0.001046035157252867\n",
      "Iteration:490, Price of Hedge: 0.1378760035803616, Loss: 0.0016510199649339308\n",
      "Iteration:500, Price of Hedge: 0.13585241939591272, Loss: 0.0016495828637910438\n",
      "Iteration:510, Price of Hedge: 0.13286551339447286, Loss: 0.001371113236414634\n",
      "Iteration:520, Price of Hedge: 0.11982362251137246, Loss: 0.0010741903587489555\n",
      "Iteration:530, Price of Hedge: 0.14181474430800023, Loss: 0.001788574263158449\n",
      "Iteration:540, Price of Hedge: 0.13600396736022163, Loss: 0.001672195796049636\n",
      "Iteration:550, Price of Hedge: 0.13423588833991573, Loss: 0.0014220585022998277\n",
      "Iteration:560, Price of Hedge: 0.12304670387696746, Loss: 0.0012199988016664664\n",
      "Iteration:570, Price of Hedge: 0.12959097336073527, Loss: 0.001111713215365001\n",
      "Iteration:580, Price of Hedge: 0.13465612927057152, Loss: 0.0010013481297396487\n",
      "Iteration:590, Price of Hedge: 0.1312608970367087, Loss: 0.000996399591003916\n",
      "Iteration:600, Price of Hedge: 0.13162862971732212, Loss: 0.0009861991187645415\n",
      "Iteration:610, Price of Hedge: 0.14515107361691265, Loss: 0.0010442582934507229\n",
      "Iteration:620, Price of Hedge: 0.1351242622345808, Loss: 0.001376517246925313\n",
      "Iteration:630, Price of Hedge: 0.1274660948046055, Loss: 0.0010166028277810546\n",
      "Iteration:640, Price of Hedge: 0.13131462979896755, Loss: 0.0009553776725075291\n",
      "Iteration:650, Price of Hedge: 0.13162083559988105, Loss: 0.001077582594693749\n",
      "Iteration:660, Price of Hedge: 0.12096896904117004, Loss: 0.0010884297928172692\n",
      "Iteration:670, Price of Hedge: 0.12885030868176414, Loss: 0.001262441801211639\n",
      "Iteration:680, Price of Hedge: 0.14489872691681996, Loss: 0.0010513979406967355\n",
      "Iteration:690, Price of Hedge: 0.14551436501115375, Loss: 0.0010660053813816796\n",
      "Iteration:700, Price of Hedge: 0.15193399664432122, Loss: 0.0013443218688064197\n",
      "Iteration:710, Price of Hedge: 0.1495235443462896, Loss: 0.0010976080919434417\n",
      "Iteration:720, Price of Hedge: 0.140701963972149, Loss: 0.001139722717521846\n",
      "Iteration:730, Price of Hedge: 0.13153697594975783, Loss: 0.0012311840161830622\n",
      "Iteration:740, Price of Hedge: 0.12808195642101056, Loss: 0.0012275164775784996\n",
      "Iteration:750, Price of Hedge: 0.12293195930760775, Loss: 0.0013319230752181887\n",
      "Iteration:760, Price of Hedge: 0.13285113995345627, Loss: 0.0012958183385908817\n",
      "Iteration:770, Price of Hedge: 0.13380871822505114, Loss: 0.001163513012809958\n",
      "Iteration:780, Price of Hedge: 0.13922743745985358, Loss: 0.0009301296245808167\n",
      "Iteration:790, Price of Hedge: 0.14170506299947191, Loss: 0.0011071887156129446\n",
      "Iteration:800, Price of Hedge: 0.13026527142124636, Loss: 0.0008456107210117026\n",
      "Iteration:810, Price of Hedge: 0.12577286652311628, Loss: 0.0009642423270425527\n",
      "Iteration:820, Price of Hedge: 0.1333112066861986, Loss: 0.001002055519392453\n",
      "Iteration:830, Price of Hedge: 0.13436565747980397, Loss: 0.0010799386873958873\n",
      "Iteration:840, Price of Hedge: 0.1322384756745052, Loss: 0.0008384911937890871\n",
      "Iteration:850, Price of Hedge: 0.13008834884267487, Loss: 0.0010107787263667622\n",
      "Iteration:860, Price of Hedge: 0.14436775509573607, Loss: 0.0011497007306346008\n",
      "Iteration:870, Price of Hedge: 0.15923842581901368, Loss: 0.0010700283990411341\n",
      "Iteration:880, Price of Hedge: 0.14978477361912682, Loss: 0.000985681464728605\n",
      "Iteration:890, Price of Hedge: 0.14465495180224225, Loss: 0.0011931989305011936\n",
      "Iteration:900, Price of Hedge: 0.13444901177567914, Loss: 0.0010533880767468918\n",
      "Iteration:910, Price of Hedge: 0.13615948041170753, Loss: 0.0009769560559404146\n",
      "Iteration:920, Price of Hedge: 0.13671070527611703, Loss: 0.0010824479200496951\n",
      "Iteration:930, Price of Hedge: 0.13913650285025767, Loss: 0.001080203588383183\n",
      "Iteration:940, Price of Hedge: 0.14344485190023804, Loss: 0.0011908624263501366\n",
      "Iteration:950, Price of Hedge: 0.16604964868431296, Loss: 0.001214436792028656\n",
      "Iteration:960, Price of Hedge: 0.1446881788440514, Loss: 0.0009194029188238306\n",
      "Iteration:970, Price of Hedge: 0.13054632612996855, Loss: 0.0010117854867827958\n",
      "Iteration:980, Price of Hedge: 0.1343318667736412, Loss: 0.001223244882724317\n",
      "Iteration:990, Price of Hedge: 0.1327326538189908, Loss: 0.001165553866503999\n",
      "tf.Tensor(0.1346231, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_104 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.1503438800661357, Loss: 0.001994603758295033\n",
      "Iteration:20, Price of Hedge: 0.13104951318576072, Loss: 0.0016600118691263656\n",
      "Iteration:30, Price of Hedge: 0.11209230505399219, Loss: 0.0014239804580442829\n",
      "Iteration:40, Price of Hedge: 0.12024418414760873, Loss: 0.0015228264126892598\n",
      "Iteration:50, Price of Hedge: 0.12739339182134302, Loss: 0.001558775655701783\n",
      "Iteration:60, Price of Hedge: 0.12458401093623195, Loss: 0.0012762574240701263\n",
      "Iteration:70, Price of Hedge: 0.12449894621059415, Loss: 0.001450446260896543\n",
      "Iteration:80, Price of Hedge: 0.11931685910244028, Loss: 0.0014154474422345409\n",
      "Iteration:90, Price of Hedge: 0.12449311520003975, Loss: 0.0017157920145962513\n",
      "Iteration:100, Price of Hedge: 0.13008700771024737, Loss: 0.0015367282099875812\n",
      "Iteration:110, Price of Hedge: 0.12366073844339881, Loss: 0.001403655893729827\n",
      "Iteration:120, Price of Hedge: 0.12826247478942393, Loss: 0.0015026858896454276\n",
      "Iteration:130, Price of Hedge: 0.11208170233313411, Loss: 0.0013608749537161958\n",
      "Iteration:140, Price of Hedge: 0.12481161471487212, Loss: 0.001500293808675024\n",
      "Iteration:150, Price of Hedge: 0.11095604518230857, Loss: 0.0015623937673809429\n",
      "Iteration:160, Price of Hedge: 0.10505283699889177, Loss: 0.0015145788734379107\n",
      "Iteration:170, Price of Hedge: 0.12365078685205262, Loss: 0.0017478779094180165\n",
      "Iteration:180, Price of Hedge: 0.1278973174718054, Loss: 0.0014441850614645203\n",
      "Iteration:190, Price of Hedge: 0.12708845912440056, Loss: 0.0016701825789160352\n",
      "Iteration:200, Price of Hedge: 0.11983856933509358, Loss: 0.00119299461735794\n",
      "Iteration:210, Price of Hedge: 0.12506339775061123, Loss: 0.0016390982816363753\n",
      "Iteration:220, Price of Hedge: 0.12137360230024186, Loss: 0.0015423987159025043\n",
      "Iteration:230, Price of Hedge: 0.13020305453863087, Loss: 0.0012269675426005266\n",
      "Iteration:240, Price of Hedge: 0.1278887361679395, Loss: 0.0013735718273491738\n",
      "Iteration:250, Price of Hedge: 0.12148773461349337, Loss: 0.001282861802769153\n",
      "Iteration:260, Price of Hedge: 0.11217297708501235, Loss: 0.0013633702921651669\n",
      "Iteration:270, Price of Hedge: 0.11025588658998871, Loss: 0.0012737614782242224\n",
      "Iteration:280, Price of Hedge: 0.09642152249914133, Loss: 0.0014032238826614085\n",
      "Iteration:290, Price of Hedge: 0.12227117947323195, Loss: 0.0017757426992556335\n",
      "Iteration:300, Price of Hedge: 0.12903590002935986, Loss: 0.0013676689921074737\n",
      "Iteration:310, Price of Hedge: 0.14237763119351854, Loss: 0.0013665774998193215\n",
      "Iteration:320, Price of Hedge: 0.13369019321718198, Loss: 0.0016346741542274557\n",
      "Iteration:330, Price of Hedge: 0.12104857205358854, Loss: 0.0014053652605478196\n",
      "Iteration:340, Price of Hedge: 0.1117893063088836, Loss: 0.0010750747286830398\n",
      "Iteration:350, Price of Hedge: 0.11309739634325454, Loss: 0.001214860679163099\n",
      "Iteration:360, Price of Hedge: 0.1192127755640442, Loss: 0.00117882397099226\n",
      "Iteration:370, Price of Hedge: 0.12797833936345882, Loss: 0.0013909406463396335\n",
      "Iteration:380, Price of Hedge: 0.11935484813620222, Loss: 0.001591789349338324\n",
      "Iteration:390, Price of Hedge: 0.1239008983314328, Loss: 0.0012703586128331057\n",
      "Iteration:400, Price of Hedge: 0.11560283580321738, Loss: 0.0010089858424705167\n",
      "Iteration:410, Price of Hedge: 0.11496657536822284, Loss: 0.0010730386582398445\n",
      "Iteration:420, Price of Hedge: 0.12590170270131582, Loss: 0.0007493500754863603\n",
      "Iteration:430, Price of Hedge: 0.12123376494879637, Loss: 0.0009818385402597107\n",
      "Iteration:440, Price of Hedge: 0.13777715823311354, Loss: 0.0009072675836551803\n",
      "Iteration:450, Price of Hedge: 0.1200123820413694, Loss: 0.0009532631719353923\n",
      "Iteration:460, Price of Hedge: 0.13973580439668823, Loss: 0.0012397221189421159\n",
      "Iteration:470, Price of Hedge: 0.14577541935367436, Loss: 0.0008870638913303419\n",
      "Iteration:480, Price of Hedge: 0.14611974052691182, Loss: 0.00103569164303583\n",
      "Iteration:490, Price of Hedge: 0.13542586153715633, Loss: 0.0009635807199335545\n",
      "Iteration:500, Price of Hedge: 0.13689046561315835, Loss: 0.001008919256581764\n",
      "Iteration:510, Price of Hedge: 0.1304417372373244, Loss: 0.0009395116294533102\n",
      "Iteration:520, Price of Hedge: 0.13517121158789466, Loss: 0.000799378399776951\n",
      "Iteration:530, Price of Hedge: 0.13254034709090662, Loss: 0.0009403226562077649\n",
      "Iteration:540, Price of Hedge: 0.12418996096131636, Loss: 0.0009655866483039622\n",
      "Iteration:550, Price of Hedge: 0.12161556980154771, Loss: 0.0010092378362729915\n",
      "Iteration:560, Price of Hedge: 0.12331286035372316, Loss: 0.0009475898568096552\n",
      "Iteration:570, Price of Hedge: 0.1320765679481113, Loss: 0.0014224110962192894\n",
      "Iteration:580, Price of Hedge: 0.1407031301742599, Loss: 0.000917716405315433\n",
      "Iteration:590, Price of Hedge: 0.12842451857273077, Loss: 0.0010238645618105503\n",
      "Iteration:600, Price of Hedge: 0.12597232595748054, Loss: 0.0007137926034954612\n",
      "Iteration:610, Price of Hedge: 0.11545375630004316, Loss: 0.0007988241500758164\n",
      "Iteration:620, Price of Hedge: 0.12363477100972986, Loss: 0.0009558077095359164\n",
      "Iteration:630, Price of Hedge: 0.12473172987027681, Loss: 0.000852544460697513\n",
      "Iteration:640, Price of Hedge: 0.12538562911219842, Loss: 0.0008124590723468106\n",
      "Iteration:650, Price of Hedge: 0.1156130886634422, Loss: 0.0008656648418418512\n",
      "Iteration:660, Price of Hedge: 0.1253204384142002, Loss: 0.0009360695869600311\n",
      "Iteration:670, Price of Hedge: 0.1147274067519831, Loss: 0.0007376047650731521\n",
      "Iteration:680, Price of Hedge: 0.11457670428420456, Loss: 0.00083591173086493\n",
      "Iteration:690, Price of Hedge: 0.11693190775723324, Loss: 0.0008825917036391185\n",
      "Iteration:700, Price of Hedge: 0.11882241856247973, Loss: 0.000864195776435378\n",
      "Iteration:710, Price of Hedge: 0.12408375882241884, Loss: 0.0009972705982054797\n",
      "Iteration:720, Price of Hedge: 0.11194127216228225, Loss: 0.0007559570356223511\n",
      "Iteration:730, Price of Hedge: 0.12064910895720829, Loss: 0.0009175287955878298\n",
      "Iteration:740, Price of Hedge: 0.10844200498177799, Loss: 0.000763175720394238\n",
      "Iteration:750, Price of Hedge: 0.11501704276457118, Loss: 0.0008596579898754175\n",
      "Iteration:760, Price of Hedge: 0.11943829961558663, Loss: 0.0011026332386173177\n",
      "Iteration:770, Price of Hedge: 0.13143645904615084, Loss: 0.0008103502661209183\n",
      "Iteration:780, Price of Hedge: 0.12106869875835216, Loss: 0.0007781394753048565\n",
      "Iteration:790, Price of Hedge: 0.12047576273177683, Loss: 0.0007496066247658306\n",
      "Iteration:800, Price of Hedge: 0.1373613780255319, Loss: 0.0009638912516154231\n",
      "Iteration:810, Price of Hedge: 0.12284480513652128, Loss: 0.0009519376799788981\n",
      "Iteration:820, Price of Hedge: 0.1284989902958614, Loss: 0.000971250852475708\n",
      "Iteration:830, Price of Hedge: 0.13423863863322724, Loss: 0.0009344583147466778\n",
      "Iteration:840, Price of Hedge: 0.13064303344001332, Loss: 0.0006881705509074077\n",
      "Iteration:850, Price of Hedge: 0.12420486891163379, Loss: 0.0009382143814541888\n",
      "Iteration:860, Price of Hedge: 0.13326604550945476, Loss: 0.0010448277280751762\n",
      "Iteration:870, Price of Hedge: 0.12403328170771957, Loss: 0.0009993217017227607\n",
      "Iteration:880, Price of Hedge: 0.12293228001318823, Loss: 0.0008910956403207049\n",
      "Iteration:890, Price of Hedge: 0.10823620918261127, Loss: 0.000991004159974912\n",
      "Iteration:900, Price of Hedge: 0.12396346507468153, Loss: 0.0009262009052951715\n",
      "Iteration:910, Price of Hedge: 0.12724886050640125, Loss: 0.0008183887089781684\n",
      "Iteration:920, Price of Hedge: 0.12778270895935862, Loss: 0.0008406647637129339\n",
      "Iteration:930, Price of Hedge: 0.13609284167942165, Loss: 0.0009689908803381775\n",
      "Iteration:940, Price of Hedge: 0.12493335649689713, Loss: 0.0013530686883364896\n",
      "Iteration:950, Price of Hedge: 0.12587666822933558, Loss: 0.0009826699907360293\n",
      "Iteration:960, Price of Hedge: 0.12945864829455403, Loss: 0.0009350202328340884\n",
      "Iteration:970, Price of Hedge: 0.1224543217963948, Loss: 0.000927921812654886\n",
      "Iteration:980, Price of Hedge: 0.13831838291442225, Loss: 0.0009339055835378751\n",
      "Iteration:990, Price of Hedge: 0.12621817108080507, Loss: 0.0008863357742572075\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 16 \n",
      "\n",
      "tf.Tensor(0.056438334, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_105 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.06147644131379337, Loss: 0.0008686897390764448\n",
      "Iteration:20, Price of Hedge: 0.04555563168904975, Loss: 0.0005788492441299586\n",
      "Iteration:30, Price of Hedge: 0.04386983797720845, Loss: 0.0006711472815439101\n",
      "Iteration:40, Price of Hedge: 0.04987018872602178, Loss: 0.000630265508272998\n",
      "Iteration:50, Price of Hedge: 0.04360316426694233, Loss: 0.000538903839423982\n",
      "Iteration:60, Price of Hedge: 0.04824333127648295, Loss: 0.0007192010636441482\n",
      "Iteration:70, Price of Hedge: 0.04762397487265524, Loss: 0.0007725476129703812\n",
      "Iteration:80, Price of Hedge: 0.050401602884747376, Loss: 0.0006061151149111266\n",
      "Iteration:90, Price of Hedge: 0.04761158859126269, Loss: 0.0005777370342909816\n",
      "Iteration:100, Price of Hedge: 0.05149654522085889, Loss: 0.0006495936614042408\n",
      "Iteration:110, Price of Hedge: 0.048911040392576766, Loss: 0.0006156034328866911\n",
      "Iteration:120, Price of Hedge: 0.045252797516159404, Loss: 0.0006906808768157024\n",
      "Iteration:130, Price of Hedge: 0.04410875809142922, Loss: 0.0005699907025042139\n",
      "Iteration:140, Price of Hedge: 0.044759776949115704, Loss: 0.0006204089709524185\n",
      "Iteration:150, Price of Hedge: 0.04933243854867442, Loss: 0.000624836753453567\n",
      "Iteration:160, Price of Hedge: 0.05597651961704919, Loss: 0.0005784497151160861\n",
      "Iteration:170, Price of Hedge: 0.05089376618423813, Loss: 0.0006529990839964084\n",
      "Iteration:180, Price of Hedge: 0.04801275099969082, Loss: 0.000688825393077297\n",
      "Iteration:190, Price of Hedge: 0.04448312647901531, Loss: 0.0006156530984001429\n",
      "Iteration:200, Price of Hedge: 0.048820371119415285, Loss: 0.0005890366276344872\n",
      "Iteration:210, Price of Hedge: 0.05156699991345093, Loss: 0.0006748778175637571\n",
      "Iteration:220, Price of Hedge: 0.04476363641702896, Loss: 0.0005840950468526673\n",
      "Iteration:230, Price of Hedge: 0.04587797840035712, Loss: 0.0005715142376055415\n",
      "Iteration:240, Price of Hedge: 0.05054474539898912, Loss: 0.0006635354490388545\n",
      "Iteration:250, Price of Hedge: 0.04822050255905452, Loss: 0.0006353403756380882\n",
      "Iteration:260, Price of Hedge: 0.049675828885304085, Loss: 0.000680603407888114\n",
      "Iteration:270, Price of Hedge: 0.048805734069715, Loss: 0.0006118845828700092\n",
      "Iteration:280, Price of Hedge: 0.05264212278819436, Loss: 0.0005992445718898676\n",
      "Iteration:290, Price of Hedge: 0.04523158455403653, Loss: 0.0006628321941880011\n",
      "Iteration:300, Price of Hedge: 0.04825641254432789, Loss: 0.0005976158076373972\n",
      "Iteration:310, Price of Hedge: 0.04885996065225129, Loss: 0.0005496963594509019\n",
      "Iteration:320, Price of Hedge: 0.04625484097790178, Loss: 0.0005872247459173252\n",
      "Iteration:330, Price of Hedge: 0.04428413104338169, Loss: 0.0005636010495377319\n",
      "Iteration:340, Price of Hedge: 0.0451994387847261, Loss: 0.0006421892554553665\n",
      "Iteration:350, Price of Hedge: 0.04430232416589419, Loss: 0.0006153189999794639\n",
      "Iteration:360, Price of Hedge: 0.04962743383883783, Loss: 0.00046003550016632255\n",
      "Iteration:370, Price of Hedge: 0.04646605335812737, Loss: 0.0007413087216036895\n",
      "Iteration:380, Price of Hedge: 0.05101829223396592, Loss: 0.0004358741649571479\n",
      "Iteration:390, Price of Hedge: 0.05279783150417927, Loss: 0.00046086862399574713\n",
      "Iteration:400, Price of Hedge: 0.05087521674887441, Loss: 0.0005896834368851467\n",
      "Iteration:410, Price of Hedge: 0.046923195690547814, Loss: 0.0003768247909636674\n",
      "Iteration:420, Price of Hedge: 0.05227338837707762, Loss: 0.000502667969005749\n",
      "Iteration:430, Price of Hedge: 0.047096441348942975, Loss: 0.000464713815140988\n",
      "Iteration:440, Price of Hedge: 0.04474244462200616, Loss: 0.00037786809748209527\n",
      "Iteration:450, Price of Hedge: 0.04919927984996697, Loss: 0.00043281899172399607\n",
      "Iteration:460, Price of Hedge: 0.050049050721636235, Loss: 0.00044866047146747967\n",
      "Iteration:470, Price of Hedge: 0.050918358826672616, Loss: 0.0004524035754529948\n",
      "Iteration:480, Price of Hedge: 0.05126943282062868, Loss: 0.0004143925074454602\n",
      "Iteration:490, Price of Hedge: 0.048406582535793774, Loss: 0.0003290659426367082\n",
      "Iteration:500, Price of Hedge: 0.04818029918031641, Loss: 0.0004482610251375918\n",
      "Iteration:510, Price of Hedge: 0.044441952941523866, Loss: 0.000343417870396559\n",
      "Iteration:520, Price of Hedge: 0.04866261272257333, Loss: 0.00036020164439054536\n",
      "Iteration:530, Price of Hedge: 0.054453522071867155, Loss: 0.0003950819108802933\n",
      "Iteration:540, Price of Hedge: 0.0483141987275264, Loss: 0.000412421514180486\n",
      "Iteration:550, Price of Hedge: 0.04819498209206685, Loss: 0.0005904479881299607\n",
      "Iteration:560, Price of Hedge: 0.045275287559986666, Loss: 0.0003655763514453375\n",
      "Iteration:570, Price of Hedge: 0.048528325111862, Loss: 0.00036941886914174105\n",
      "Iteration:580, Price of Hedge: 0.04374413362557661, Loss: 0.0003248574380628755\n",
      "Iteration:590, Price of Hedge: 0.04386584092314472, Loss: 0.0003843348670449359\n",
      "Iteration:600, Price of Hedge: 0.0426668622901758, Loss: 0.00029628681400378776\n",
      "Iteration:610, Price of Hedge: 0.04464851561543348, Loss: 0.0003233906517363522\n",
      "Iteration:620, Price of Hedge: 0.04393231267307307, Loss: 0.0002927692443670943\n",
      "Iteration:630, Price of Hedge: 0.05118667298719437, Loss: 0.00042710111857154065\n",
      "Iteration:640, Price of Hedge: 0.045428805481114054, Loss: 0.0004914298925468297\n",
      "Iteration:650, Price of Hedge: 0.04164933509473023, Loss: 0.0004112829557117309\n",
      "Iteration:660, Price of Hedge: 0.04628763587161444, Loss: 0.0003397458195151942\n",
      "Iteration:670, Price of Hedge: 0.04112613024298284, Loss: 0.0002629466745349557\n",
      "Iteration:680, Price of Hedge: 0.04377464952818144, Loss: 0.0004174741946763594\n",
      "Iteration:690, Price of Hedge: 0.04664847495440405, Loss: 0.0004020736961843907\n",
      "Iteration:700, Price of Hedge: 0.047166250444982794, Loss: 0.00036033994713555173\n",
      "Iteration:710, Price of Hedge: 0.045017800371152106, Loss: 0.00033178045785306476\n",
      "Iteration:720, Price of Hedge: 0.04915914350037909, Loss: 0.0003873643255588588\n",
      "Iteration:730, Price of Hedge: 0.04791391122590127, Loss: 0.0003602559126458099\n",
      "Iteration:740, Price of Hedge: 0.042089441439442155, Loss: 0.00038895439370650875\n",
      "Iteration:750, Price of Hedge: 0.048043030536344844, Loss: 0.00033853700722080715\n",
      "Iteration:760, Price of Hedge: 0.04946315950302349, Loss: 0.0003527300439234715\n",
      "Iteration:770, Price of Hedge: 0.04204935095190443, Loss: 0.0003208399886162616\n",
      "Iteration:780, Price of Hedge: 0.040518747362096263, Loss: 0.0003928928248251168\n",
      "Iteration:790, Price of Hedge: 0.04423414140870996, Loss: 0.0004054311069427996\n",
      "Iteration:800, Price of Hedge: 0.04004580731732155, Loss: 0.0004031734483030125\n",
      "Iteration:810, Price of Hedge: 0.039826251571817295, Loss: 0.00033964420089804825\n",
      "Iteration:820, Price of Hedge: 0.04400397389036925, Loss: 0.00041215177146119997\n",
      "Iteration:830, Price of Hedge: 0.042169375465016756, Loss: 0.00030782304891138756\n",
      "Iteration:840, Price of Hedge: 0.042696101111076246, Loss: 0.000405021655850768\n",
      "Iteration:850, Price of Hedge: 0.04257524049751105, Loss: 0.00034773521465553126\n",
      "Iteration:860, Price of Hedge: 0.048376257137089596, Loss: 0.00036851460952418147\n",
      "Iteration:870, Price of Hedge: 0.047842835631707104, Loss: 0.00032337182734917813\n",
      "Iteration:880, Price of Hedge: 0.04581417370503793, Loss: 0.0003517795088358311\n",
      "Iteration:890, Price of Hedge: 0.04501514742794299, Loss: 0.00027644213402037987\n",
      "Iteration:900, Price of Hedge: 0.04856006165057103, Loss: 0.00044408774394122386\n",
      "Iteration:910, Price of Hedge: 0.05123664498261604, Loss: 0.0003796995477422932\n",
      "Iteration:920, Price of Hedge: 0.04993953214586, Loss: 0.0003535724559205061\n",
      "Iteration:930, Price of Hedge: 0.049637280068221656, Loss: 0.0003438576389496323\n",
      "Iteration:940, Price of Hedge: 0.047069823720601534, Loss: 0.00037635831548354926\n",
      "Iteration:950, Price of Hedge: 0.045211084217616104, Loss: 0.0003804698041820487\n",
      "Iteration:960, Price of Hedge: 0.047711140990754686, Loss: 0.000348305017555145\n",
      "Iteration:970, Price of Hedge: 0.052204796389291985, Loss: 0.00039393880479238197\n",
      "Iteration:980, Price of Hedge: 0.04849296547119053, Loss: 0.0003153953033491197\n",
      "Iteration:990, Price of Hedge: 0.05477192111901097, Loss: 0.00036487736860035813\n",
      "tf.Tensor(0.050860956, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_106 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.04863368788032396, Loss: 0.0007746072710282381\n",
      "Iteration:20, Price of Hedge: 0.044596652692405314, Loss: 0.0008465932710161606\n",
      "Iteration:30, Price of Hedge: 0.04968956633325128, Loss: 0.0006611329831806012\n",
      "Iteration:40, Price of Hedge: 0.06445936550164078, Loss: 0.0007423433738650564\n",
      "Iteration:50, Price of Hedge: 0.05874742354701823, Loss: 0.000697715464862525\n",
      "Iteration:60, Price of Hedge: 0.05063388005739533, Loss: 0.0006910868551803784\n",
      "Iteration:70, Price of Hedge: 0.04743112495174273, Loss: 0.0007497008153106444\n",
      "Iteration:80, Price of Hedge: 0.05153660748559652, Loss: 0.0008064057124804458\n",
      "Iteration:90, Price of Hedge: 0.06378388100412025, Loss: 0.0008071425370290708\n",
      "Iteration:100, Price of Hedge: 0.048089224204403536, Loss: 0.0007458849494186293\n",
      "Iteration:110, Price of Hedge: 0.04805920572865041, Loss: 0.000716577059829665\n",
      "Iteration:120, Price of Hedge: 0.056675612486850824, Loss: 0.0006411843694284769\n",
      "Iteration:130, Price of Hedge: 0.05960037301154841, Loss: 0.0006925317853736235\n",
      "Iteration:140, Price of Hedge: 0.05871517899790746, Loss: 0.0007551579031754851\n",
      "Iteration:150, Price of Hedge: 0.05441902322659864, Loss: 0.000834740025711378\n",
      "Iteration:160, Price of Hedge: 0.04680715764794918, Loss: 0.0007615455717263353\n",
      "Iteration:170, Price of Hedge: 0.05051658257234237, Loss: 0.000854785710461492\n",
      "Iteration:180, Price of Hedge: 0.059240334750711554, Loss: 0.0008554267869558818\n",
      "Iteration:190, Price of Hedge: 0.059367922974249865, Loss: 0.0006679260788695629\n",
      "Iteration:200, Price of Hedge: 0.05644260504925036, Loss: 0.000619703566317964\n",
      "Iteration:210, Price of Hedge: 0.058575017516925953, Loss: 0.00070208911691505\n",
      "Iteration:220, Price of Hedge: 0.060452038338674186, Loss: 0.0007525427741086888\n",
      "Iteration:230, Price of Hedge: 0.05814146238968654, Loss: 0.0007276198918394761\n",
      "Iteration:240, Price of Hedge: 0.051294893314166146, Loss: 0.0006508841379141428\n",
      "Iteration:250, Price of Hedge: 0.0566977568013769, Loss: 0.000710334694601189\n",
      "Iteration:260, Price of Hedge: 0.05700408707362925, Loss: 0.0007556266662458455\n",
      "Iteration:270, Price of Hedge: 0.0563926648044788, Loss: 0.0006151660897305011\n",
      "Iteration:280, Price of Hedge: 0.058471736179971145, Loss: 0.0006203163648896004\n",
      "Iteration:290, Price of Hedge: 0.06477559492102714, Loss: 0.0006481233747890336\n",
      "Iteration:300, Price of Hedge: 0.061887068943804024, Loss: 0.0007609458923469314\n",
      "Iteration:310, Price of Hedge: 0.059713031373835435, Loss: 0.0007477602221906965\n",
      "Iteration:320, Price of Hedge: 0.057826541802654674, Loss: 0.0006183677238618124\n",
      "Iteration:330, Price of Hedge: 0.05028992173691371, Loss: 0.0007678679199293048\n",
      "Iteration:340, Price of Hedge: 0.054026084236548755, Loss: 0.0006552524981916497\n",
      "Iteration:350, Price of Hedge: 0.05775210063954894, Loss: 0.0008030852890245077\n",
      "Iteration:360, Price of Hedge: 0.06055565834923016, Loss: 0.000645104362018506\n",
      "Iteration:370, Price of Hedge: 0.05728569417299667, Loss: 0.000615217133310364\n",
      "Iteration:380, Price of Hedge: 0.059329970363819484, Loss: 0.0005327796020482556\n",
      "Iteration:390, Price of Hedge: 0.05323497445488101, Loss: 0.0006502868839316223\n",
      "Iteration:400, Price of Hedge: 0.05130249230309225, Loss: 0.0006255081474089985\n",
      "Iteration:410, Price of Hedge: 0.052981353789659735, Loss: 0.0005642803811556907\n",
      "Iteration:420, Price of Hedge: 0.054271936576043345, Loss: 0.0006485531661412913\n",
      "Iteration:430, Price of Hedge: 0.049667919445576914, Loss: 0.0006251643474007862\n",
      "Iteration:440, Price of Hedge: 0.054546117551135254, Loss: 0.0004728691570385357\n",
      "Iteration:450, Price of Hedge: 0.05722788329484807, Loss: 0.00048416191517264284\n",
      "Iteration:460, Price of Hedge: 0.053955174451305155, Loss: 0.0005071028623295781\n",
      "Iteration:470, Price of Hedge: 0.057616613559833496, Loss: 0.000517059943375503\n",
      "Iteration:480, Price of Hedge: 0.05897680082695622, Loss: 0.0005236895452654655\n",
      "Iteration:490, Price of Hedge: 0.056451050722179374, Loss: 0.0005607867071905637\n",
      "Iteration:500, Price of Hedge: 0.05958053943878028, Loss: 0.0005002330359028528\n",
      "Iteration:510, Price of Hedge: 0.05729153982046675, Loss: 0.00045216729218616747\n",
      "Iteration:520, Price of Hedge: 0.05472470084659875, Loss: 0.00044557746129282594\n",
      "Iteration:530, Price of Hedge: 0.054739323784898986, Loss: 0.000649990268917322\n",
      "Iteration:540, Price of Hedge: 0.04889388445796783, Loss: 0.0005088795757919318\n",
      "Iteration:550, Price of Hedge: 0.05026060177546299, Loss: 0.0005533903491495296\n",
      "Iteration:560, Price of Hedge: 0.05254117336009756, Loss: 0.00044606405654254444\n",
      "Iteration:570, Price of Hedge: 0.051470619051119826, Loss: 0.0005026277294665482\n",
      "Iteration:580, Price of Hedge: 0.05294712306099214, Loss: 0.0004874585256409991\n",
      "Iteration:590, Price of Hedge: 0.05034544656825446, Loss: 0.0005137895712916118\n",
      "Iteration:600, Price of Hedge: 0.05140600295029785, Loss: 0.00044743242136599526\n",
      "Iteration:610, Price of Hedge: 0.04829609732911422, Loss: 0.00046950182420196773\n",
      "Iteration:620, Price of Hedge: 0.05734804186626086, Loss: 0.000548918027541978\n",
      "Iteration:630, Price of Hedge: 0.05961945868011398, Loss: 0.0003527978999135484\n",
      "Iteration:640, Price of Hedge: 0.060062733034136784, Loss: 0.0005973527623208685\n",
      "Iteration:650, Price of Hedge: 0.053658588100786275, Loss: 0.0005101587521572637\n",
      "Iteration:660, Price of Hedge: 0.05813124220820143, Loss: 0.0004603496166240423\n",
      "Iteration:670, Price of Hedge: 0.05412465589373738, Loss: 0.0005133884437207026\n",
      "Iteration:680, Price of Hedge: 0.057628731724625126, Loss: 0.00040462185122361327\n",
      "Iteration:690, Price of Hedge: 0.05199474114387037, Loss: 0.0004900239891943436\n",
      "Iteration:700, Price of Hedge: 0.05159762517940614, Loss: 0.0006030954406687217\n",
      "Iteration:710, Price of Hedge: 0.052512636581349525, Loss: 0.00039341128097025724\n",
      "Iteration:720, Price of Hedge: 0.05571649943190593, Loss: 0.0004767614229323758\n",
      "Iteration:730, Price of Hedge: 0.054725805063652544, Loss: 0.0005474437169728508\n",
      "Iteration:740, Price of Hedge: 0.05327223560670902, Loss: 0.00040831209258160306\n",
      "Iteration:750, Price of Hedge: 0.04943936062684173, Loss: 0.0004306486473720089\n",
      "Iteration:760, Price of Hedge: 0.051200544493442024, Loss: 0.0004344994610282066\n",
      "Iteration:770, Price of Hedge: 0.04816336902810825, Loss: 0.00047180666783566694\n",
      "Iteration:780, Price of Hedge: 0.052898840905726274, Loss: 0.00044959317437576196\n",
      "Iteration:790, Price of Hedge: 0.054374607594946056, Loss: 0.0005190997021543853\n",
      "Iteration:800, Price of Hedge: 0.055476062342179944, Loss: 0.0005211073244245634\n",
      "Iteration:810, Price of Hedge: 0.05707403022796953, Loss: 0.0005685845786611021\n",
      "Iteration:820, Price of Hedge: 0.053307785751281145, Loss: 0.0004532097167420923\n",
      "Iteration:830, Price of Hedge: 0.050839126843250426, Loss: 0.00042824414197546734\n",
      "Iteration:840, Price of Hedge: 0.0528441521748384, Loss: 0.000473060267288411\n",
      "Iteration:850, Price of Hedge: 0.049685399942386965, Loss: 0.0004036425696706397\n",
      "Iteration:860, Price of Hedge: 0.05291477973208103, Loss: 0.0004176260300335216\n",
      "Iteration:870, Price of Hedge: 0.05383112818917901, Loss: 0.0005046252091679415\n",
      "Iteration:880, Price of Hedge: 0.05163409962068144, Loss: 0.0004942597794831138\n",
      "Iteration:890, Price of Hedge: 0.05467743118428636, Loss: 0.0005207073544294394\n",
      "Iteration:900, Price of Hedge: 0.05398272695989981, Loss: 0.0004366617850336818\n",
      "Iteration:910, Price of Hedge: 0.05303942572870923, Loss: 0.00040033647810537587\n",
      "Iteration:920, Price of Hedge: 0.05333617788817868, Loss: 0.0005503270177632247\n",
      "Iteration:930, Price of Hedge: 0.0585596325630231, Loss: 0.0005293564299607145\n",
      "Iteration:940, Price of Hedge: 0.06145809649373035, Loss: 0.00038439597050959895\n",
      "Iteration:950, Price of Hedge: 0.060118649456828877, Loss: 0.0005420264276659592\n",
      "Iteration:960, Price of Hedge: 0.059065028827909316, Loss: 0.0005076623572924377\n",
      "Iteration:970, Price of Hedge: 0.057154271176495186, Loss: 0.0005139198261287781\n",
      "Iteration:980, Price of Hedge: 0.054848486047824, Loss: 0.00041697900029223633\n",
      "Iteration:990, Price of Hedge: 0.052785039520035326, Loss: 0.0005144648238329941\n",
      "tf.Tensor(0.052310184, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_107 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.06377829288970105, Loss: 0.000693512196941054\n",
      "Iteration:20, Price of Hedge: 0.03188934047660119, Loss: 0.0006372353823211607\n",
      "Iteration:30, Price of Hedge: 0.05220959779315848, Loss: 0.0005138600180465414\n",
      "Iteration:40, Price of Hedge: 0.03889012598755137, Loss: 0.0005636330206784668\n",
      "Iteration:50, Price of Hedge: 0.05021662712506192, Loss: 0.0005855706252428927\n",
      "Iteration:60, Price of Hedge: 0.04124305377593451, Loss: 0.0005929947651027723\n",
      "Iteration:70, Price of Hedge: 0.04459959139146541, Loss: 0.0005195937665240513\n",
      "Iteration:80, Price of Hedge: 0.04608738804922652, Loss: 0.0006679713345704996\n",
      "Iteration:90, Price of Hedge: 0.04762248964780014, Loss: 0.0005088456202355651\n",
      "Iteration:100, Price of Hedge: 0.04307780389883753, Loss: 0.0005613113646345536\n",
      "Iteration:110, Price of Hedge: 0.041335204746101084, Loss: 0.0004992289215931534\n",
      "Iteration:120, Price of Hedge: 0.04891527381259131, Loss: 0.0005063062296987164\n",
      "Iteration:130, Price of Hedge: 0.04917394635902994, Loss: 0.0005332389942670213\n",
      "Iteration:140, Price of Hedge: 0.04006058900887233, Loss: 0.0004964255486546165\n",
      "Iteration:150, Price of Hedge: 0.04466342783743471, Loss: 0.0006587241782168574\n",
      "Iteration:160, Price of Hedge: 0.04386686047179822, Loss: 0.0007152173492632752\n",
      "Iteration:170, Price of Hedge: 0.049019818119850456, Loss: 0.0006232874209490258\n",
      "Iteration:180, Price of Hedge: 0.04326136851851814, Loss: 0.000583358553039981\n",
      "Iteration:190, Price of Hedge: 0.04553980575389538, Loss: 0.0006022052097672259\n",
      "Iteration:200, Price of Hedge: 0.04524555484008452, Loss: 0.0005858435926375805\n",
      "Iteration:210, Price of Hedge: 0.04865443869409525, Loss: 0.0006037896002812626\n",
      "Iteration:220, Price of Hedge: 0.04732912422434232, Loss: 0.0006143715517605841\n",
      "Iteration:230, Price of Hedge: 0.04698848561072211, Loss: 0.0005798580438654555\n",
      "Iteration:240, Price of Hedge: 0.039285993093111315, Loss: 0.0005410351018125537\n",
      "Iteration:250, Price of Hedge: 0.04493115637485445, Loss: 0.0006327819126621115\n",
      "Iteration:260, Price of Hedge: 0.04682629976211494, Loss: 0.00048436173480223554\n",
      "Iteration:270, Price of Hedge: 0.0432197892782753, Loss: 0.0005520474509933537\n",
      "Iteration:280, Price of Hedge: 0.04450600811419392, Loss: 0.0005198189425756061\n",
      "Iteration:290, Price of Hedge: 0.041674471026066584, Loss: 0.000548950770399903\n",
      "Iteration:300, Price of Hedge: 0.04187421083805276, Loss: 0.000508292078519601\n",
      "Iteration:310, Price of Hedge: 0.046798140463318205, Loss: 0.0005074542692643791\n",
      "Iteration:320, Price of Hedge: 0.04475676063735534, Loss: 0.0004532280725866866\n",
      "Iteration:330, Price of Hedge: 0.046924977254803935, Loss: 0.0004100431369230967\n",
      "Iteration:340, Price of Hedge: 0.04927019316306058, Loss: 0.0006091169845355016\n",
      "Iteration:350, Price of Hedge: 0.049358332967763374, Loss: 0.0005775206227418006\n",
      "Iteration:360, Price of Hedge: 0.04471070455544712, Loss: 0.0005110656852236606\n",
      "Iteration:370, Price of Hedge: 0.036963778766933686, Loss: 0.0005378809282884367\n",
      "Iteration:380, Price of Hedge: 0.04007076685615729, Loss: 0.0005652448071527538\n",
      "Iteration:390, Price of Hedge: 0.04148026641074942, Loss: 0.000495160097830738\n",
      "Iteration:400, Price of Hedge: 0.041418666621687805, Loss: 0.0004308281267413755\n",
      "Iteration:410, Price of Hedge: 0.04316829325164839, Loss: 0.0005260953184831052\n",
      "Iteration:420, Price of Hedge: 0.0439479234093767, Loss: 0.00046672750090337445\n",
      "Iteration:430, Price of Hedge: 0.042985395395620074, Loss: 0.0004489706742165922\n",
      "Iteration:440, Price of Hedge: 0.044857604229951775, Loss: 0.00031096286298350206\n",
      "Iteration:450, Price of Hedge: 0.04170648979277658, Loss: 0.0003666569484408466\n",
      "Iteration:460, Price of Hedge: 0.03735535247902888, Loss: 0.00043419135294003874\n",
      "Iteration:470, Price of Hedge: 0.03937375894571282, Loss: 0.0003370544558145422\n",
      "Iteration:480, Price of Hedge: 0.042253147791404544, Loss: 0.00042823198742972246\n",
      "Iteration:490, Price of Hedge: 0.04204019970897299, Loss: 0.0004374178198280759\n",
      "Iteration:500, Price of Hedge: 0.042477377938174854, Loss: 0.00030280515081172743\n",
      "Iteration:510, Price of Hedge: 0.0477008996421695, Loss: 0.0003330050352271935\n",
      "Iteration:520, Price of Hedge: 0.0497953841943648, Loss: 0.0002952652533733252\n",
      "Iteration:530, Price of Hedge: 0.045195604011762924, Loss: 0.0003008605888605159\n",
      "Iteration:540, Price of Hedge: 0.047192353007222465, Loss: 0.0004360208739072613\n",
      "Iteration:550, Price of Hedge: 0.04242099231143115, Loss: 0.00029607955281557574\n",
      "Iteration:560, Price of Hedge: 0.04254621334761133, Loss: 0.0003568935408483215\n",
      "Iteration:570, Price of Hedge: 0.04705235733519153, Loss: 0.00033998965458595376\n",
      "Iteration:580, Price of Hedge: 0.04341038137518005, Loss: 0.00027965418633375816\n",
      "Iteration:590, Price of Hedge: 0.04028080093447883, Loss: 0.00034476608788908125\n",
      "Iteration:600, Price of Hedge: 0.04091821287466857, Loss: 0.00034404436694832063\n",
      "Iteration:610, Price of Hedge: 0.0417589206996567, Loss: 0.0003192743122440861\n",
      "Iteration:620, Price of Hedge: 0.04599887429242244, Loss: 0.0002871319054156968\n",
      "Iteration:630, Price of Hedge: 0.0418941326070712, Loss: 0.0002967156131482296\n",
      "Iteration:640, Price of Hedge: 0.040367243843325795, Loss: 0.0003490933817875408\n",
      "Iteration:650, Price of Hedge: 0.04476530861793471, Loss: 0.00028577652197783743\n",
      "Iteration:660, Price of Hedge: 0.04918166529485646, Loss: 0.0004135814878012678\n",
      "Iteration:670, Price of Hedge: 0.048277932429401815, Loss: 0.00032351845361530684\n",
      "Iteration:680, Price of Hedge: 0.0422433544797709, Loss: 0.0003427178126597791\n",
      "Iteration:690, Price of Hedge: 0.045778542419915524, Loss: 0.0002927684175272477\n",
      "Iteration:700, Price of Hedge: 0.038518008368273016, Loss: 0.0003023392541195019\n",
      "Iteration:710, Price of Hedge: 0.03863772595843429, Loss: 0.00034400291471067823\n",
      "Iteration:720, Price of Hedge: 0.04676717652376183, Loss: 0.00025720275592733266\n",
      "Iteration:730, Price of Hedge: 0.048114342496489826, Loss: 0.0003739626848346944\n",
      "Iteration:740, Price of Hedge: 0.049287941776471555, Loss: 0.00028110079776802466\n",
      "Iteration:750, Price of Hedge: 0.048513931483812556, Loss: 0.00032055202785902237\n",
      "Iteration:760, Price of Hedge: 0.04092843305615368, Loss: 0.00027837840001179726\n",
      "Iteration:770, Price of Hedge: 0.04939028823317315, Loss: 0.0003218910398679192\n",
      "Iteration:780, Price of Hedge: 0.04666322489530472, Loss: 0.0003186744674967129\n",
      "Iteration:790, Price of Hedge: 0.043233297415971705, Loss: 0.0002619539430538109\n",
      "Iteration:800, Price of Hedge: 0.0466934338749585, Loss: 0.00033618508883850873\n",
      "Iteration:810, Price of Hedge: 0.0499010785807279, Loss: 0.0003081010875904677\n",
      "Iteration:820, Price of Hedge: 0.046711432965720334, Loss: 0.0003109437629830458\n",
      "Iteration:830, Price of Hedge: 0.04509764267262639, Loss: 0.0003426416882712363\n",
      "Iteration:840, Price of Hedge: 0.04352355127571883, Loss: 0.00030598672029609475\n",
      "Iteration:850, Price of Hedge: 0.04316196781657666, Loss: 0.0003133224709763738\n",
      "Iteration:860, Price of Hedge: 0.03892130159810847, Loss: 0.0003189745276770406\n",
      "Iteration:870, Price of Hedge: 0.042894479172957745, Loss: 0.00044440728998060286\n",
      "Iteration:880, Price of Hedge: 0.04633484556047662, Loss: 0.00035140307621500666\n",
      "Iteration:890, Price of Hedge: 0.04427084868808606, Loss: 0.0002797669397275049\n",
      "Iteration:900, Price of Hedge: 0.0419457133020984, Loss: 0.00025189516070675544\n",
      "Iteration:910, Price of Hedge: 0.044062388030869926, Loss: 0.0003130211980976044\n",
      "Iteration:920, Price of Hedge: 0.04437829641590518, Loss: 0.0003035342581884509\n",
      "Iteration:930, Price of Hedge: 0.040893320364983055, Loss: 0.00032335082561707473\n",
      "Iteration:940, Price of Hedge: 0.04093164692751472, Loss: 0.0002885170550880334\n",
      "Iteration:950, Price of Hedge: 0.03961804491980203, Loss: 0.00028305175394738313\n",
      "Iteration:960, Price of Hedge: 0.05074999924054424, Loss: 0.00030714233922701784\n",
      "Iteration:970, Price of Hedge: 0.045740194690283786, Loss: 0.00027830541761467154\n",
      "Iteration:980, Price of Hedge: 0.04329687632889012, Loss: 0.00033114905538488004\n",
      "Iteration:990, Price of Hedge: 0.04337143038319624, Loss: 0.00036759794730892303\n",
      "tf.Tensor(0.06792525, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_108 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.047077652019778427, Loss: 0.0019780079537420336\n",
      "Iteration:20, Price of Hedge: 0.06166820818475216, Loss: 0.000805327788933774\n",
      "Iteration:30, Price of Hedge: 0.04466507181554036, Loss: 0.0006262881329976155\n",
      "Iteration:40, Price of Hedge: 0.0548799826927322, Loss: 0.0006776676854514663\n",
      "Iteration:50, Price of Hedge: 0.05093649197573491, Loss: 0.0007400708321080307\n",
      "Iteration:60, Price of Hedge: 0.051243640709190075, Loss: 0.0007079905485134486\n",
      "Iteration:70, Price of Hedge: 0.05517933134981057, Loss: 0.0008864301943342645\n",
      "Iteration:80, Price of Hedge: 0.05142455238566157, Loss: 0.0007821669023776456\n",
      "Iteration:90, Price of Hedge: 0.05132089709660548, Loss: 0.0006668386191033271\n",
      "Iteration:100, Price of Hedge: 0.053628992967034605, Loss: 0.0006993200302688185\n",
      "Iteration:110, Price of Hedge: 0.05426626379322386, Loss: 0.0007829976008101869\n",
      "Iteration:120, Price of Hedge: 0.049699617177935806, Loss: 0.000678088436688068\n",
      "Iteration:130, Price of Hedge: 0.04972498947522297, Loss: 0.0007768331238952597\n",
      "Iteration:140, Price of Hedge: 0.05586187860305536, Loss: 0.0008123210901109235\n",
      "Iteration:150, Price of Hedge: 0.052257629471073486, Loss: 0.0007202322983008158\n",
      "Iteration:160, Price of Hedge: 0.04882728923328905, Loss: 0.000713780191364588\n",
      "Iteration:170, Price of Hedge: 0.054429634999435095, Loss: 0.0007018245832867975\n",
      "Iteration:180, Price of Hedge: 0.04977141598138246, Loss: 0.0008362051859195363\n",
      "Iteration:190, Price of Hedge: 0.05192323162412471, Loss: 0.000640251969694805\n",
      "Iteration:200, Price of Hedge: 0.05625263032609773, Loss: 0.0005791768380771778\n",
      "Iteration:210, Price of Hedge: 0.047260867382307836, Loss: 0.0007552861184743631\n",
      "Iteration:220, Price of Hedge: 0.05457920525639892, Loss: 0.0009178485650703228\n",
      "Iteration:230, Price of Hedge: 0.0546689431771572, Loss: 0.0008742860116487949\n",
      "Iteration:240, Price of Hedge: 0.048304546529893244, Loss: 0.0007060274653496734\n",
      "Iteration:250, Price of Hedge: 0.05204086778277883, Loss: 0.00077843603562186\n",
      "Iteration:260, Price of Hedge: 0.05225317732435819, Loss: 0.0008088004611667976\n",
      "Iteration:270, Price of Hedge: 0.05423394868711284, Loss: 0.0006739272273534602\n",
      "Iteration:280, Price of Hedge: 0.0499388336315576, Loss: 0.0007148062996142068\n",
      "Iteration:290, Price of Hedge: 0.049974214439329145, Loss: 0.0007558235643746469\n",
      "Iteration:300, Price of Hedge: 0.05549770922985431, Loss: 0.0007881692084373282\n",
      "Iteration:310, Price of Hedge: 0.04709791246239803, Loss: 0.000658433571572109\n",
      "Iteration:320, Price of Hedge: 0.04975428474172361, Loss: 0.0006093723126801287\n",
      "Iteration:330, Price of Hedge: 0.05457875016374736, Loss: 0.0006600997089856453\n",
      "Iteration:340, Price of Hedge: 0.04977842581935654, Loss: 0.0005766425188247215\n",
      "Iteration:350, Price of Hedge: 0.05007631394652989, Loss: 0.0007301676058974471\n",
      "Iteration:360, Price of Hedge: 0.053265624415786306, Loss: 0.0007635964652818183\n",
      "Iteration:370, Price of Hedge: 0.05192284708847339, Loss: 0.0006601854247164085\n",
      "Iteration:380, Price of Hedge: 0.04894761361365241, Loss: 0.0007840656022786996\n",
      "Iteration:390, Price of Hedge: 0.053071437439719205, Loss: 0.000744226088195743\n",
      "Iteration:400, Price of Hedge: 0.05342495976158368, Loss: 0.0006835468474966633\n",
      "Iteration:410, Price of Hedge: 0.055107486684313756, Loss: 0.0007589573976385378\n",
      "Iteration:420, Price of Hedge: 0.05085662497931054, Loss: 0.0007511319097171232\n",
      "Iteration:430, Price of Hedge: 0.05354818756250701, Loss: 0.0006469095187715823\n",
      "Iteration:440, Price of Hedge: 0.05122520063717673, Loss: 0.0006459546289940832\n",
      "Iteration:450, Price of Hedge: 0.052707218676617984, Loss: 0.0006449987470087681\n",
      "Iteration:460, Price of Hedge: 0.053531151574798486, Loss: 0.0007246132816666473\n",
      "Iteration:470, Price of Hedge: 0.045714589554895824, Loss: 0.0007105118588189852\n",
      "Iteration:480, Price of Hedge: 0.04798093332043152, Loss: 0.0006689988760091858\n",
      "Iteration:490, Price of Hedge: 0.05184005903223898, Loss: 0.0005018332466192876\n",
      "Iteration:500, Price of Hedge: 0.05596678275101574, Loss: 0.0006251904755399385\n",
      "Iteration:510, Price of Hedge: 0.05241400495071069, Loss: 0.0008927398092035965\n",
      "Iteration:520, Price of Hedge: 0.04858309851115017, Loss: 0.0004862082335476414\n",
      "Iteration:530, Price of Hedge: 0.050542805081482456, Loss: 0.0005744603231015999\n",
      "Iteration:540, Price of Hedge: 0.053545047775996224, Loss: 0.00047045280027085967\n",
      "Iteration:550, Price of Hedge: 0.05309103817438654, Loss: 0.00039775491873635105\n",
      "Iteration:560, Price of Hedge: 0.05233637108334399, Loss: 0.0003860403620351699\n",
      "Iteration:570, Price of Hedge: 0.046721751927005784, Loss: 0.0005050902790203204\n",
      "Iteration:580, Price of Hedge: 0.05756017854318962, Loss: 0.0004376281127623921\n",
      "Iteration:590, Price of Hedge: 0.05752257518991044, Loss: 0.0005604349695198241\n",
      "Iteration:600, Price of Hedge: 0.048172301544338936, Loss: 0.00043998185019235303\n",
      "Iteration:610, Price of Hedge: 0.04700461494097752, Loss: 0.000406192323266899\n",
      "Iteration:620, Price of Hedge: 0.044478222767498465, Loss: 0.000382220885609158\n",
      "Iteration:630, Price of Hedge: 0.04991902475373955, Loss: 0.000530599666354048\n",
      "Iteration:640, Price of Hedge: 0.057411458498078716, Loss: 0.0004897323903417794\n",
      "Iteration:650, Price of Hedge: 0.051222036155715855, Loss: 0.0004546053397191524\n",
      "Iteration:660, Price of Hedge: 0.05175999094836392, Loss: 0.000408089893153496\n",
      "Iteration:670, Price of Hedge: 0.05251862334282009, Loss: 0.00044659056059552504\n",
      "Iteration:680, Price of Hedge: 0.05234701813468057, Loss: 0.00041512831222494107\n",
      "Iteration:690, Price of Hedge: 0.050218137044867106, Loss: 0.0005780522807631583\n",
      "Iteration:700, Price of Hedge: 0.05062191006230421, Loss: 0.00044948615373828493\n",
      "Iteration:710, Price of Hedge: 0.04818723846129025, Loss: 0.0007016971948277662\n",
      "Iteration:720, Price of Hedge: 0.054661153684330444, Loss: 0.000481961749463522\n",
      "Iteration:730, Price of Hedge: 0.05360764947446128, Loss: 0.0004790540844590019\n",
      "Iteration:740, Price of Hedge: 0.052823905843618846, Loss: 0.0003951526056871768\n",
      "Iteration:750, Price of Hedge: 0.05127843942170962, Loss: 0.0005368645216263512\n",
      "Iteration:760, Price of Hedge: 0.0504217539640166, Loss: 0.0004225174491979816\n",
      "Iteration:770, Price of Hedge: 0.04846152527188252, Loss: 0.00041556560025847455\n",
      "Iteration:780, Price of Hedge: 0.046596298052724805, Loss: 0.0004927372365896021\n",
      "Iteration:790, Price of Hedge: 0.05132248110126092, Loss: 0.0004522267144098091\n",
      "Iteration:800, Price of Hedge: 0.05266579818962569, Loss: 0.00038031490951745406\n",
      "Iteration:810, Price of Hedge: 0.055471571389114516, Loss: 0.0004308678977379965\n",
      "Iteration:820, Price of Hedge: 0.05610761452349955, Loss: 0.00040953159867133937\n",
      "Iteration:830, Price of Hedge: 0.055984199746525576, Loss: 0.00044808000233384493\n",
      "Iteration:840, Price of Hedge: 0.05527261828768104, Loss: 0.00042474713308962575\n",
      "Iteration:850, Price of Hedge: 0.05787147250040903, Loss: 0.00038400881653209706\n",
      "Iteration:860, Price of Hedge: 0.05804706417906225, Loss: 0.0004882166275350097\n",
      "Iteration:870, Price of Hedge: 0.052854531109574054, Loss: 0.0004656815484974375\n",
      "Iteration:880, Price of Hedge: 0.054925086255137145, Loss: 0.00045513512357019115\n",
      "Iteration:890, Price of Hedge: 0.05354572159534854, Loss: 0.00040503212915549147\n",
      "Iteration:900, Price of Hedge: 0.055414709502619175, Loss: 0.0003979844770390928\n",
      "Iteration:910, Price of Hedge: 0.059657037338443075, Loss: 0.0005197242969744997\n",
      "Iteration:920, Price of Hedge: 0.05701795152417688, Loss: 0.00043693588244282655\n",
      "Iteration:930, Price of Hedge: 0.057247417000365175, Loss: 0.0004795324388715827\n",
      "Iteration:940, Price of Hedge: 0.04829636897356515, Loss: 0.0004234332018894088\n",
      "Iteration:950, Price of Hedge: 0.05349537211997557, Loss: 0.0004719825091097085\n",
      "Iteration:960, Price of Hedge: 0.05332131505607762, Loss: 0.000481467188989948\n",
      "Iteration:970, Price of Hedge: 0.04783921958544468, Loss: 0.00040914455493915036\n",
      "Iteration:980, Price of Hedge: 0.04941040403394226, Loss: 0.00046752540135533427\n",
      "Iteration:990, Price of Hedge: 0.047371758291738786, Loss: 0.00039363364576633364\n",
      "tf.Tensor(0.06361739, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_109 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.03406269011581742, Loss: 0.0005443373347918667\n",
      "Iteration:20, Price of Hedge: 0.061453856018015784, Loss: 0.000599990987780713\n",
      "Iteration:30, Price of Hedge: 0.03696273805118011, Loss: 0.000794471767606636\n",
      "Iteration:40, Price of Hedge: 0.052733222459057316, Loss: 0.0006018211702198129\n",
      "Iteration:50, Price of Hedge: 0.04485217134093311, Loss: 0.0005590805507284524\n",
      "Iteration:60, Price of Hedge: 0.04816037741129797, Loss: 0.0006104281871642248\n",
      "Iteration:70, Price of Hedge: 0.04550864425473833, Loss: 0.0006418719694449015\n",
      "Iteration:80, Price of Hedge: 0.050911532436899165, Loss: 0.00056228146826523\n",
      "Iteration:90, Price of Hedge: 0.04495329010583049, Loss: 0.0006563663065876635\n",
      "Iteration:100, Price of Hedge: 0.050628612977327236, Loss: 0.0007318197972789042\n",
      "Iteration:110, Price of Hedge: 0.046940623269607684, Loss: 0.0005755031886387763\n",
      "Iteration:120, Price of Hedge: 0.046398413889845, Loss: 0.0005648041015145211\n",
      "Iteration:130, Price of Hedge: 0.050494099584215135, Loss: 0.0005292534608384858\n",
      "Iteration:140, Price of Hedge: 0.04586322845945645, Loss: 0.0007065004728645796\n",
      "Iteration:150, Price of Hedge: 0.051236867237166805, Loss: 0.0005840684226096071\n",
      "Iteration:160, Price of Hedge: 0.04549639555949625, Loss: 0.0005849655989658142\n",
      "Iteration:170, Price of Hedge: 0.04700483366767827, Loss: 0.0005747882477847577\n",
      "Iteration:180, Price of Hedge: 0.04698606197776378, Loss: 0.0005366913262398187\n",
      "Iteration:190, Price of Hedge: 0.04680801491550213, Loss: 0.0005088226340878299\n",
      "Iteration:200, Price of Hedge: 0.04855048000993811, Loss: 0.0006774517148835368\n",
      "Iteration:210, Price of Hedge: 0.050771113422866776, Loss: 0.0006717308651076337\n",
      "Iteration:220, Price of Hedge: 0.04743704468406307, Loss: 0.0006236018957040124\n",
      "Iteration:230, Price of Hedge: 0.04997530101713288, Loss: 0.0006448616569622034\n",
      "Iteration:240, Price of Hedge: 0.04646380964551966, Loss: 0.000752029802667864\n",
      "Iteration:250, Price of Hedge: 0.047993012678873015, Loss: 0.000599234208830457\n",
      "Iteration:260, Price of Hedge: 0.047334073797909326, Loss: 0.0007320979462032973\n",
      "Iteration:270, Price of Hedge: 0.04836256202334255, Loss: 0.0006525338487760601\n",
      "Iteration:280, Price of Hedge: 0.044804739397520166, Loss: 0.0006202496664753088\n",
      "Iteration:290, Price of Hedge: 0.04916897914621288, Loss: 0.0005529647471191612\n",
      "Iteration:300, Price of Hedge: 0.050428463934739653, Loss: 0.0005800669587333607\n",
      "Iteration:310, Price of Hedge: 0.04561717503251117, Loss: 0.0006728668879341926\n",
      "Iteration:320, Price of Hedge: 0.04563521645747315, Loss: 0.0006900990571769849\n",
      "Iteration:330, Price of Hedge: 0.04619215461103643, Loss: 0.0005504915037700397\n",
      "Iteration:340, Price of Hedge: 0.05228945773388283, Loss: 0.0005754598622308149\n",
      "Iteration:350, Price of Hedge: 0.045419350843081574, Loss: 0.00048529545747966196\n",
      "Iteration:360, Price of Hedge: 0.05158021876744634, Loss: 0.00076158807129445\n",
      "Iteration:370, Price of Hedge: 0.048374278013232797, Loss: 0.0005909638810715767\n",
      "Iteration:380, Price of Hedge: 0.041534933974537225, Loss: 0.000554394463459229\n",
      "Iteration:390, Price of Hedge: 0.04541729410652451, Loss: 0.0005058828876972621\n",
      "Iteration:400, Price of Hedge: 0.04967049477608576, Loss: 0.0005265930209480962\n",
      "Iteration:410, Price of Hedge: 0.04652859508314222, Loss: 0.00045619678593321333\n",
      "Iteration:420, Price of Hedge: 0.04946074998146521, Loss: 0.0005238311553698582\n",
      "Iteration:430, Price of Hedge: 0.04569839319549018, Loss: 0.0006574321031499186\n",
      "Iteration:440, Price of Hedge: 0.050790968162734984, Loss: 0.000538100647197004\n",
      "Iteration:450, Price of Hedge: 0.04933673546998918, Loss: 0.00045734471525356313\n",
      "Iteration:460, Price of Hedge: 0.04533704610229883, Loss: 0.0004966636234077781\n",
      "Iteration:470, Price of Hedge: 0.048746201600760486, Loss: 0.0003622803748875303\n",
      "Iteration:480, Price of Hedge: 0.04059759480986713, Loss: 0.0003676665198935336\n",
      "Iteration:490, Price of Hedge: 0.04440033489493089, Loss: 0.00034680110611950976\n",
      "Iteration:500, Price of Hedge: 0.04939919252660374, Loss: 0.00033943106914692545\n",
      "Iteration:510, Price of Hedge: 0.052643103530497726, Loss: 0.00030152647055030346\n",
      "Iteration:520, Price of Hedge: 0.04666914815547507, Loss: 0.00042636487281080826\n",
      "Iteration:530, Price of Hedge: 0.040809713847545837, Loss: 0.00038156013032641933\n",
      "Iteration:540, Price of Hedge: 0.042865286214107456, Loss: 0.0003433739927620333\n",
      "Iteration:550, Price of Hedge: 0.05104380211740356, Loss: 0.00037128989746926244\n",
      "Iteration:560, Price of Hedge: 0.05094377698600994, Loss: 0.00034665180640454374\n",
      "Iteration:570, Price of Hedge: 0.05072971057512454, Loss: 0.0003098665284695795\n",
      "Iteration:580, Price of Hedge: 0.04709688233019449, Loss: 0.0003632023013164787\n",
      "Iteration:590, Price of Hedge: 0.046763750981400065, Loss: 0.0003364985989470076\n",
      "Iteration:600, Price of Hedge: 0.04728442636468877, Loss: 0.0004129072825903579\n",
      "Iteration:610, Price of Hedge: 0.04812735320733452, Loss: 0.0003548293351713083\n",
      "Iteration:620, Price of Hedge: 0.04775507330695561, Loss: 0.0003500580282752297\n",
      "Iteration:630, Price of Hedge: 0.04386466262124067, Loss: 0.00032743665471900163\n",
      "Iteration:640, Price of Hedge: 0.04644962416062093, Loss: 0.00028634381679658316\n",
      "Iteration:650, Price of Hedge: 0.04928305570420477, Loss: 0.0003925175497800776\n",
      "Iteration:660, Price of Hedge: 0.05032159830217253, Loss: 0.0004499117557686533\n",
      "Iteration:670, Price of Hedge: 0.04993412747964143, Loss: 0.0003567229913492981\n",
      "Iteration:680, Price of Hedge: 0.04958991868180895, Loss: 0.0003960610546266258\n",
      "Iteration:690, Price of Hedge: 0.047509048102810425, Loss: 0.0004718673578804067\n",
      "Iteration:700, Price of Hedge: 0.04816781411912352, Loss: 0.00037982018367591075\n",
      "Iteration:710, Price of Hedge: 0.05270990689832722, Loss: 0.00037978206635898293\n",
      "Iteration:720, Price of Hedge: 0.05251395599725406, Loss: 0.000332734355422748\n",
      "Iteration:730, Price of Hedge: 0.05013887683864482, Loss: 0.00045962268659224814\n",
      "Iteration:740, Price of Hedge: 0.04835764067257564, Loss: 0.0003567417881751439\n",
      "Iteration:750, Price of Hedge: 0.04564039886914095, Loss: 0.00032905034292493585\n",
      "Iteration:760, Price of Hedge: 0.04566462814302419, Loss: 0.00036298941761730985\n",
      "Iteration:770, Price of Hedge: 0.05061295637897345, Loss: 0.00043947006388864174\n",
      "Iteration:780, Price of Hedge: 0.04665338219377091, Loss: 0.000285057832783181\n",
      "Iteration:790, Price of Hedge: 0.04790941674498583, Loss: 0.00036437134261424475\n",
      "Iteration:800, Price of Hedge: 0.045325887512710494, Loss: 0.0003861545210566558\n",
      "Iteration:810, Price of Hedge: 0.045164742379856904, Loss: 0.0004504283377434748\n",
      "Iteration:820, Price of Hedge: 0.044132930919712265, Loss: 0.0003581729652656074\n",
      "Iteration:830, Price of Hedge: 0.049953057922806465, Loss: 0.0003757408590474437\n",
      "Iteration:840, Price of Hedge: 0.04784394690446092, Loss: 0.000527950085626977\n",
      "Iteration:850, Price of Hedge: 0.04699891393535793, Loss: 0.0003979222986826292\n",
      "Iteration:860, Price of Hedge: 0.05107478016835998, Loss: 0.0003274459704479399\n",
      "Iteration:870, Price of Hedge: 0.05282029685305645, Loss: 0.00035398110773401936\n",
      "Iteration:880, Price of Hedge: 0.05071999840404118, Loss: 0.00035928724220420094\n",
      "Iteration:890, Price of Hedge: 0.05046648710217028, Loss: 0.00042540022632311936\n",
      "Iteration:900, Price of Hedge: 0.049821758401055405, Loss: 0.00035212408056123357\n",
      "Iteration:910, Price of Hedge: 0.051368681825019635, Loss: 0.0003544853697951267\n",
      "Iteration:920, Price of Hedge: 0.04594147617272526, Loss: 0.000408143720427509\n",
      "Iteration:930, Price of Hedge: 0.04581650561389594, Loss: 0.00035493982853614103\n",
      "Iteration:940, Price of Hedge: 0.04559493193818476, Loss: 0.00039014879142623693\n",
      "Iteration:950, Price of Hedge: 0.047699770730165625, Loss: 0.0003496454903144375\n",
      "Iteration:960, Price of Hedge: 0.04616768897120238, Loss: 0.0003266570825503079\n",
      "Iteration:970, Price of Hedge: 0.044276627306405913, Loss: 0.00035945936269893286\n",
      "Iteration:980, Price of Hedge: 0.0477689553967533, Loss: 0.0005398262068341819\n",
      "Iteration:990, Price of Hedge: 0.04987789707829826, Loss: 0.0003823071250051574\n",
      "tf.Tensor(0.045874976, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_110 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.054802574607766275, Loss: 0.0006626347999552917\n",
      "Iteration:20, Price of Hedge: 0.03988267600491113, Loss: 0.0007305105239431564\n",
      "Iteration:30, Price of Hedge: 0.051615299707966855, Loss: 0.0005905798415241637\n",
      "Iteration:40, Price of Hedge: 0.04294773912459071, Loss: 0.000556242726129641\n",
      "Iteration:50, Price of Hedge: 0.05176553320073296, Loss: 0.0004921204140640456\n",
      "Iteration:60, Price of Hedge: 0.046168528599505265, Loss: 0.0005900823044271419\n",
      "Iteration:70, Price of Hedge: 0.04877903882867329, Loss: 0.0005738150021626642\n",
      "Iteration:80, Price of Hedge: 0.04406041596271315, Loss: 0.0005580990918305495\n",
      "Iteration:90, Price of Hedge: 0.049753762619921815, Loss: 0.0005737184823912389\n",
      "Iteration:100, Price of Hedge: 0.04979196923555307, Loss: 0.0005551829379369377\n",
      "Iteration:110, Price of Hedge: 0.0454050948011826, Loss: 0.0004901822463409811\n",
      "Iteration:120, Price of Hedge: 0.04666718314301832, Loss: 0.0004880237533601284\n",
      "Iteration:130, Price of Hedge: 0.044889697081512026, Loss: 0.0005831611036846152\n",
      "Iteration:140, Price of Hedge: 0.051267227914371105, Loss: 0.0005988173713024625\n",
      "Iteration:150, Price of Hedge: 0.04735181888347029, Loss: 0.0005365801438417805\n",
      "Iteration:160, Price of Hedge: 0.04439312396950612, Loss: 0.0005587888967532317\n",
      "Iteration:170, Price of Hedge: 0.049911496321813686, Loss: 0.0006568019960641602\n",
      "Iteration:180, Price of Hedge: 0.049427245989900115, Loss: 0.0005869624723179867\n",
      "Iteration:190, Price of Hedge: 0.04334441763565344, Loss: 0.0005258338717236133\n",
      "Iteration:200, Price of Hedge: 0.044893676496325696, Loss: 0.0005819915111602847\n",
      "Iteration:210, Price of Hedge: 0.04968279991692803, Loss: 0.0005330198265850183\n",
      "Iteration:220, Price of Hedge: 0.05339641945498563, Loss: 0.0006469685551366289\n",
      "Iteration:230, Price of Hedge: 0.04331756011351118, Loss: 0.0006818424549595581\n",
      "Iteration:240, Price of Hedge: 0.038091650055058324, Loss: 0.0004743355299451357\n",
      "Iteration:250, Price of Hedge: 0.04787678766022374, Loss: 0.0007246799800809389\n",
      "Iteration:260, Price of Hedge: 0.0456152911606047, Loss: 0.0004846762095572221\n",
      "Iteration:270, Price of Hedge: 0.05122195854301559, Loss: 0.0005687302678420714\n",
      "Iteration:280, Price of Hedge: 0.05465164260069777, Loss: 0.0006178891489586058\n",
      "Iteration:290, Price of Hedge: 0.05021849335771833, Loss: 0.0005346549299429793\n",
      "Iteration:300, Price of Hedge: 0.04746186663674834, Loss: 0.000592455500154826\n",
      "Iteration:310, Price of Hedge: 0.046401832376506746, Loss: 0.0006239057317863062\n",
      "Iteration:320, Price of Hedge: 0.044442965434477344, Loss: 0.0006922375406335501\n",
      "Iteration:330, Price of Hedge: 0.04520748228275373, Loss: 0.0005121958650486369\n",
      "Iteration:340, Price of Hedge: 0.046567669549876456, Loss: 0.00045698796142108755\n",
      "Iteration:350, Price of Hedge: 0.050429716321493956, Loss: 0.0005188666986856161\n",
      "Iteration:360, Price of Hedge: 0.04777478693282333, Loss: 0.0005301109488820566\n",
      "Iteration:370, Price of Hedge: 0.04319279064213255, Loss: 0.0004047427076478566\n",
      "Iteration:380, Price of Hedge: 0.04926661239529828, Loss: 0.001070708431925138\n",
      "Iteration:390, Price of Hedge: 0.046301641436162555, Loss: 0.00047297719744515687\n",
      "Iteration:400, Price of Hedge: 0.04742890593408511, Loss: 0.0006166790412817924\n",
      "Iteration:410, Price of Hedge: 0.04633822171293822, Loss: 0.00048584784161984085\n",
      "Iteration:420, Price of Hedge: 0.050581756073466266, Loss: 0.0005849434396579256\n",
      "Iteration:430, Price of Hedge: 0.054549730069547664, Loss: 0.0005407614729459886\n",
      "Iteration:440, Price of Hedge: 0.055048726814511895, Loss: 0.0005710139994983543\n",
      "Iteration:450, Price of Hedge: 0.0493458232116204, Loss: 0.0005885809837563594\n",
      "Iteration:460, Price of Hedge: 0.046831916099334236, Loss: 0.0006755336669300727\n",
      "Iteration:470, Price of Hedge: 0.04503210227510124, Loss: 0.0005786095708197603\n",
      "Iteration:480, Price of Hedge: 0.0483196986456953, Loss: 0.0004377391573537892\n",
      "Iteration:490, Price of Hedge: 0.051632476809675865, Loss: 0.0008118013937060131\n",
      "Iteration:500, Price of Hedge: 0.047919407616220155, Loss: 0.0006254278888212228\n",
      "Iteration:510, Price of Hedge: 0.04763225120878367, Loss: 0.000552002691396325\n",
      "Iteration:520, Price of Hedge: 0.04516431903785545, Loss: 0.0004968934297624739\n",
      "Iteration:530, Price of Hedge: 0.04787824819012876, Loss: 0.00047378639804168676\n",
      "Iteration:540, Price of Hedge: 0.04750837428345811, Loss: 0.0004580139869867217\n",
      "Iteration:550, Price of Hedge: 0.04949966216709889, Loss: 0.00041389312373944775\n",
      "Iteration:560, Price of Hedge: 0.0492047903516859, Loss: 0.0008960633195282952\n",
      "Iteration:570, Price of Hedge: 0.04990077871347687, Loss: 0.0004525862794977631\n",
      "Iteration:580, Price of Hedge: 0.052361161285379154, Loss: 0.00040222429128178305\n",
      "Iteration:590, Price of Hedge: 0.05128935811749713, Loss: 0.0003381592516562282\n",
      "Iteration:600, Price of Hedge: 0.047020765438333, Loss: 0.0004928981396237486\n",
      "Iteration:610, Price of Hedge: 0.04547503442767287, Loss: 0.0003830335589330436\n",
      "Iteration:620, Price of Hedge: 0.04491528810549994, Loss: 0.00038981753182236456\n",
      "Iteration:630, Price of Hedge: 0.04371872252193931, Loss: 0.00032400292664275243\n",
      "Iteration:640, Price of Hedge: 0.04546994374010538, Loss: 0.00041837217031108487\n",
      "Iteration:650, Price of Hedge: 0.04766740623415444, Loss: 0.0003498008259602836\n",
      "Iteration:660, Price of Hedge: 0.04316204190142692, Loss: 0.0003132279631819085\n",
      "Iteration:670, Price of Hedge: 0.046888259391877796, Loss: 0.0004061009574638508\n",
      "Iteration:680, Price of Hedge: 0.04731847011730572, Loss: 0.00036452717436399884\n",
      "Iteration:690, Price of Hedge: 0.04648607743479616, Loss: 0.00034839585969295706\n",
      "Iteration:700, Price of Hedge: 0.04172068938907536, Loss: 0.00033772866102545207\n",
      "Iteration:710, Price of Hedge: 0.04855044473143799, Loss: 0.0003382515821057641\n",
      "Iteration:720, Price of Hedge: 0.04727601949810989, Loss: 0.0004072879963089443\n",
      "Iteration:730, Price of Hedge: 0.048928298634836054, Loss: 0.0004852946857624718\n",
      "Iteration:740, Price of Hedge: 0.048130136680994084, Loss: 0.0003993611102610095\n",
      "Iteration:750, Price of Hedge: 0.04831362368797443, Loss: 0.0004376468820269097\n",
      "Iteration:760, Price of Hedge: 0.04667000895087803, Loss: 0.0004294485720186675\n",
      "Iteration:770, Price of Hedge: 0.051352153847712856, Loss: 0.0003505622352136806\n",
      "Iteration:780, Price of Hedge: 0.04892918765303911, Loss: 0.0003475785560659306\n",
      "Iteration:790, Price of Hedge: 0.04573575312711853, Loss: 0.0004073544742326102\n",
      "Iteration:800, Price of Hedge: 0.04622807870770984, Loss: 0.0004824415921878267\n",
      "Iteration:810, Price of Hedge: 0.047778402979085755, Loss: 0.00031973075540073226\n",
      "Iteration:820, Price of Hedge: 0.04774567511452332, Loss: 0.00028545325515914877\n",
      "Iteration:830, Price of Hedge: 0.048283224204419994, Loss: 0.00040967232681322907\n",
      "Iteration:840, Price of Hedge: 0.048832637453907424, Loss: 0.00032409172924227625\n",
      "Iteration:850, Price of Hedge: 0.05215124362610801, Loss: 0.0004402899031578644\n",
      "Iteration:860, Price of Hedge: 0.046640209201825655, Loss: 0.00034545332960823905\n",
      "Iteration:870, Price of Hedge: 0.05030164125465397, Loss: 0.0004065867809963791\n",
      "Iteration:880, Price of Hedge: 0.049167130552806526, Loss: 0.00037841598912577434\n",
      "Iteration:890, Price of Hedge: 0.048059163394450266, Loss: 0.00043154207538757816\n",
      "Iteration:900, Price of Hedge: 0.04742051670675629, Loss: 0.00038646863751437555\n",
      "Iteration:910, Price of Hedge: 0.047464678333208, Loss: 0.00034128247380875443\n",
      "Iteration:920, Price of Hedge: 0.05063562281530132, Loss: 0.0002857599851809056\n",
      "Iteration:930, Price of Hedge: 0.04976149566714838, Loss: 0.00042006713687393893\n",
      "Iteration:940, Price of Hedge: 0.04810211496834782, Loss: 0.0003982724929189885\n",
      "Iteration:950, Price of Hedge: 0.05534231096467046, Loss: 0.00039875624935190035\n",
      "Iteration:960, Price of Hedge: 0.052711247481331824, Loss: 0.00034288191280799907\n",
      "Iteration:970, Price of Hedge: 0.05234691935488023, Loss: 0.00040932392406320406\n",
      "Iteration:980, Price of Hedge: 0.05060684967060247, Loss: 0.0006557260018104638\n",
      "Iteration:990, Price of Hedge: 0.04905131476475866, Loss: 0.0003425052872578771\n",
      "tf.Tensor(0.06249379, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_111 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.06478246011715072, Loss: 0.0008836276482355743\n",
      "Iteration:20, Price of Hedge: 0.04703496503463178, Loss: 0.0008106844984412387\n",
      "Iteration:30, Price of Hedge: 0.04979388133025964, Loss: 0.0007270617749430275\n",
      "Iteration:40, Price of Hedge: 0.05575646997254324, Loss: 0.0007689756648331103\n",
      "Iteration:50, Price of Hedge: 0.045836388576564246, Loss: 0.000752466153616238\n",
      "Iteration:60, Price of Hedge: 0.055686593847353194, Loss: 0.0006664447126004114\n",
      "Iteration:70, Price of Hedge: 0.05333324624481861, Loss: 0.0005300937506132475\n",
      "Iteration:80, Price of Hedge: 0.050141833176954975, Loss: 0.0007531934970679555\n",
      "Iteration:90, Price of Hedge: 0.05334142027329669, Loss: 0.0009723861496342412\n",
      "Iteration:100, Price of Hedge: 0.057252077290231185, Loss: 0.0006686635097674087\n",
      "Iteration:110, Price of Hedge: 0.052519311273572455, Loss: 0.0005203442614914733\n",
      "Iteration:120, Price of Hedge: 0.05325137190173734, Loss: 0.0008487486771282526\n",
      "Iteration:130, Price of Hedge: 0.051616266338870176, Loss: 0.0008688747307114553\n",
      "Iteration:140, Price of Hedge: 0.053306155884575546, Loss: 0.0007276755105998234\n",
      "Iteration:150, Price of Hedge: 0.04899042407354948, Loss: 0.0008115874626763719\n",
      "Iteration:160, Price of Hedge: 0.05434145991623218, Loss: 0.0008186618492811437\n",
      "Iteration:170, Price of Hedge: 0.05442058606415401, Loss: 0.0006504057283789055\n",
      "Iteration:180, Price of Hedge: 0.05182199644017693, Loss: 0.0006339263141324492\n",
      "Iteration:190, Price of Hedge: 0.05077050310481468, Loss: 0.0007579831598086284\n",
      "Iteration:200, Price of Hedge: 0.0532210570865832, Loss: 0.0007630232447775054\n",
      "Iteration:210, Price of Hedge: 0.0531969548153004, Loss: 0.0008474815175020245\n",
      "Iteration:220, Price of Hedge: 0.05336277787727006, Loss: 0.0006455204829519667\n",
      "Iteration:230, Price of Hedge: 0.048865016061318656, Loss: 0.0008402267695653831\n",
      "Iteration:240, Price of Hedge: 0.051273951996494205, Loss: 0.0007187544598816764\n",
      "Iteration:250, Price of Hedge: 0.050408175269319955, Loss: 0.0006115831170619423\n",
      "Iteration:260, Price of Hedge: 0.048155357280730726, Loss: 0.0005942604364172765\n",
      "Iteration:270, Price of Hedge: 0.055165279923212296, Loss: 0.0006872919910204667\n",
      "Iteration:280, Price of Hedge: 0.05416757924483484, Loss: 0.0006583061831130776\n",
      "Iteration:290, Price of Hedge: 0.055331699191834005, Loss: 0.000682121596091767\n",
      "Iteration:300, Price of Hedge: 0.054013786151406507, Loss: 0.0009101960520448149\n",
      "Iteration:310, Price of Hedge: 0.057328578717743994, Loss: 0.0007165087628583366\n",
      "Iteration:320, Price of Hedge: 0.054134660876371754, Loss: 0.0006635037535114019\n",
      "Iteration:330, Price of Hedge: 0.05997409227473227, Loss: 0.0008192680331340074\n",
      "Iteration:340, Price of Hedge: 0.05566824197159015, Loss: 0.0006425903279036194\n",
      "Iteration:350, Price of Hedge: 0.05195060068451873, Loss: 0.0006509927846699848\n",
      "Iteration:360, Price of Hedge: 0.05158737324727092, Loss: 0.0006285126077982262\n",
      "Iteration:370, Price of Hedge: 0.04417195952439634, Loss: 0.000600642868315765\n",
      "Iteration:380, Price of Hedge: 0.046515517343147295, Loss: 0.0007056215421076539\n",
      "Iteration:390, Price of Hedge: 0.048924054631271474, Loss: 0.0006872849353204424\n",
      "Iteration:400, Price of Hedge: 0.05057152530843112, Loss: 0.0007365922617507681\n",
      "Iteration:410, Price of Hedge: 0.04691200535030937, Loss: 0.0006331606604345064\n",
      "Iteration:420, Price of Hedge: 0.04880042112759675, Loss: 0.0005820051264564252\n",
      "Iteration:430, Price of Hedge: 0.05050945278746788, Loss: 0.0005783563373360778\n",
      "Iteration:440, Price of Hedge: 0.05276472615966554, Loss: 0.0008305153701992085\n",
      "Iteration:450, Price of Hedge: 0.05355820312869142, Loss: 0.0007950922833501739\n",
      "Iteration:460, Price of Hedge: 0.050017261265177027, Loss: 0.00052897597338597\n",
      "Iteration:470, Price of Hedge: 0.051522369082947606, Loss: 0.0005166718798741698\n",
      "Iteration:480, Price of Hedge: 0.04540945169594757, Loss: 0.0005297320357416924\n",
      "Iteration:490, Price of Hedge: 0.04816041268979809, Loss: 0.000550816727443032\n",
      "Iteration:500, Price of Hedge: 0.04857831827438375, Loss: 0.0004334338849565772\n",
      "Iteration:510, Price of Hedge: 0.05009239035903512, Loss: 0.0005269174177812419\n",
      "Iteration:520, Price of Hedge: 0.04843897878245507, Loss: 0.000409931017439899\n",
      "Iteration:530, Price of Hedge: 0.05098976956661794, Loss: 0.00045365587952331254\n",
      "Iteration:540, Price of Hedge: 0.04628077067549086, Loss: 0.0004267384941761543\n",
      "Iteration:550, Price of Hedge: 0.04851986532753294, Loss: 0.0004169789176082517\n",
      "Iteration:560, Price of Hedge: 0.048483602557258365, Loss: 0.00038328486312375065\n",
      "Iteration:570, Price of Hedge: 0.05383919638215673, Loss: 0.000411692847785014\n",
      "Iteration:580, Price of Hedge: 0.05267439908795524, Loss: 0.00048152187066513585\n",
      "Iteration:590, Price of Hedge: 0.055458204365418595, Loss: 0.00036862253968548975\n",
      "Iteration:600, Price of Hedge: 0.05670272048634395, Loss: 0.00042547331896555796\n",
      "Iteration:610, Price of Hedge: 0.04870514095446943, Loss: 0.00046081780090651003\n",
      "Iteration:620, Price of Hedge: 0.04804818119736254, Loss: 0.00043542510823646463\n",
      "Iteration:630, Price of Hedge: 0.04382988154797118, Loss: 0.0003987812750379238\n",
      "Iteration:640, Price of Hedge: 0.04556843778459374, Loss: 0.00036198555135956434\n",
      "Iteration:650, Price of Hedge: 0.05045049888591535, Loss: 0.0004227557720030972\n",
      "Iteration:660, Price of Hedge: 0.05085671317556084, Loss: 0.0004318738862180149\n",
      "Iteration:670, Price of Hedge: 0.05111850434141019, Loss: 0.00042191650199747965\n",
      "Iteration:680, Price of Hedge: 0.0522647945344481, Loss: 0.00043935248726245657\n",
      "Iteration:690, Price of Hedge: 0.05645677289489903, Loss: 0.00045990510752251523\n",
      "Iteration:700, Price of Hedge: 0.05463273685248282, Loss: 0.00042624035072991173\n",
      "Iteration:710, Price of Hedge: 0.06273470546621596, Loss: 0.0004903603476439367\n",
      "Iteration:720, Price of Hedge: 0.06399294845153847, Loss: 0.0005526911733752526\n",
      "Iteration:730, Price of Hedge: 0.05560758764633178, Loss: 0.000505260222170123\n",
      "Iteration:740, Price of Hedge: 0.04745770730158405, Loss: 0.0004317806186833195\n",
      "Iteration:750, Price of Hedge: 0.04958784430600183, Loss: 0.0004729898756561379\n",
      "Iteration:760, Price of Hedge: 0.0562036884628796, Loss: 0.00040316818408932253\n",
      "Iteration:770, Price of Hedge: 0.059327543203011146, Loss: 0.0004282592455833317\n",
      "Iteration:780, Price of Hedge: 0.05437676311130346, Loss: 0.0004444062150888023\n",
      "Iteration:790, Price of Hedge: 0.05488398327464594, Loss: 0.00042381806827666846\n",
      "Iteration:800, Price of Hedge: 0.05470419698232831, Loss: 0.00035691266841010594\n",
      "Iteration:810, Price of Hedge: 0.04983021112968444, Loss: 0.0005078594759118649\n",
      "Iteration:820, Price of Hedge: 0.05035382521203324, Loss: 0.0003452090259948998\n",
      "Iteration:830, Price of Hedge: 0.04951549163010327, Loss: 0.0004193154567694035\n",
      "Iteration:840, Price of Hedge: 0.050275259992263344, Loss: 0.00045011799718772116\n",
      "Iteration:850, Price of Hedge: 0.05397747399123176, Loss: 0.0004622407371598358\n",
      "Iteration:860, Price of Hedge: 0.0537290392655283, Loss: 0.0004601639359558263\n",
      "Iteration:870, Price of Hedge: 0.047470030081676384, Loss: 0.0004289358210684685\n",
      "Iteration:880, Price of Hedge: 0.04902608358147198, Loss: 0.00035409267599065264\n",
      "Iteration:890, Price of Hedge: 0.049805812519000625, Loss: 0.0003706212045239965\n",
      "Iteration:900, Price of Hedge: 0.051406383958099156, Loss: 0.0005152197837355876\n",
      "Iteration:910, Price of Hedge: 0.05263101358850619, Loss: 0.0004066694925423664\n",
      "Iteration:920, Price of Hedge: 0.04768649895842003, Loss: 0.0004696991081893642\n",
      "Iteration:930, Price of Hedge: 0.049790148864946815, Loss: 0.0005018226630692513\n",
      "Iteration:940, Price of Hedge: 0.0558261732330827, Loss: 0.00043243795636135895\n",
      "Iteration:950, Price of Hedge: 0.05585193006602118, Loss: 0.0003337603809883821\n",
      "Iteration:960, Price of Hedge: 0.05720121980445647, Loss: 0.0004348777126966935\n",
      "Iteration:970, Price of Hedge: 0.05874324657260388, Loss: 0.0004341921246572289\n",
      "Iteration:980, Price of Hedge: 0.05401382142990663, Loss: 0.000431905636868124\n",
      "Iteration:990, Price of Hedge: 0.05082183332249102, Loss: 0.00043833043052808607\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 17 \n",
      "\n",
      "tf.Tensor(0.07924682, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_112 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.09541461276804171, Loss: 0.003007359130269105\n",
      "Iteration:20, Price of Hedge: 0.07922434724526113, Loss: 0.0021145457678756864\n",
      "Iteration:30, Price of Hedge: 0.0874718535183547, Loss: 0.0015194091039945957\n",
      "Iteration:40, Price of Hedge: 0.08760062151353339, Loss: 0.0017868714479615468\n",
      "Iteration:50, Price of Hedge: 0.0843643773205656, Loss: 0.0019114482944022184\n",
      "Iteration:60, Price of Hedge: 0.09173960615347597, Loss: 0.0018231726048221653\n",
      "Iteration:70, Price of Hedge: 0.07738830198309472, Loss: 0.001569389667427501\n",
      "Iteration:80, Price of Hedge: 0.08761570097479136, Loss: 0.0016643672721063042\n",
      "Iteration:90, Price of Hedge: 0.08462436937622612, Loss: 0.001873185574672265\n",
      "Iteration:100, Price of Hedge: 0.08850124116761152, Loss: 0.0017441197084783868\n",
      "Iteration:110, Price of Hedge: 0.08753985144060437, Loss: 0.0018420726121072485\n",
      "Iteration:120, Price of Hedge: 0.08290331475244272, Loss: 0.0014295296622493403\n",
      "Iteration:130, Price of Hedge: 0.08440195901821994, Loss: 0.0014695854558449462\n",
      "Iteration:140, Price of Hedge: 0.08975458298735077, Loss: 0.0018993862848023736\n",
      "Iteration:150, Price of Hedge: 0.08405289366089903, Loss: 0.0015905770073547654\n",
      "Iteration:160, Price of Hedge: 0.09715068447682143, Loss: 0.001568422226228483\n",
      "Iteration:170, Price of Hedge: 0.08277110046880694, Loss: 0.002022832683328968\n",
      "Iteration:180, Price of Hedge: 0.0832969791368555, Loss: 0.0017305713895185094\n",
      "Iteration:190, Price of Hedge: 0.08271836133956754, Loss: 0.0015375517026492425\n",
      "Iteration:200, Price of Hedge: 0.08288604432499369, Loss: 0.0018200949698178094\n",
      "Iteration:210, Price of Hedge: 0.09110039761501128, Loss: 0.0016326218970914574\n",
      "Iteration:220, Price of Hedge: 0.0880890042512874, Loss: 0.0017670487105868828\n",
      "Iteration:230, Price of Hedge: 0.0833644390638483, Loss: 0.0017234829121575146\n",
      "Iteration:240, Price of Hedge: 0.08694871160878677, Loss: 0.0014681490962257016\n",
      "Iteration:250, Price of Hedge: 0.09125955844368719, Loss: 0.0015537285962609283\n",
      "Iteration:260, Price of Hedge: 0.08554425549812664, Loss: 0.001482497585667275\n",
      "Iteration:270, Price of Hedge: 0.07533742507871466, Loss: 0.0018377091976778282\n",
      "Iteration:280, Price of Hedge: 0.08406957931089494, Loss: 0.0014673260219604245\n",
      "Iteration:290, Price of Hedge: 0.09817837237294783, Loss: 0.001560317210728135\n",
      "Iteration:300, Price of Hedge: 0.0809873031228193, Loss: 0.0015897165316982155\n",
      "Iteration:310, Price of Hedge: 0.08175661294905581, Loss: 0.0015836080438857538\n",
      "Iteration:320, Price of Hedge: 0.08599997646586531, Loss: 0.0016281895276540226\n",
      "Iteration:330, Price of Hedge: 0.08594423547903318, Loss: 0.0015755926942615517\n",
      "Iteration:340, Price of Hedge: 0.08763832796371106, Loss: 0.001660403821089096\n",
      "Iteration:350, Price of Hedge: 0.08419089334280443, Loss: 0.0018843605499728967\n",
      "Iteration:360, Price of Hedge: 0.07895628526074745, Loss: 0.0016768214480856526\n",
      "Iteration:370, Price of Hedge: 0.09220417675333863, Loss: 0.0019404325452092143\n",
      "Iteration:380, Price of Hedge: 0.0858975702382736, Loss: 0.001459100517939005\n",
      "Iteration:390, Price of Hedge: 0.09002856291969011, Loss: 0.0015842169434088227\n",
      "Iteration:400, Price of Hedge: 0.08276008326159001, Loss: 0.0015409573003418943\n",
      "Iteration:410, Price of Hedge: 0.09105220415584085, Loss: 0.0016398855640311185\n",
      "Iteration:420, Price of Hedge: 0.0803177017508574, Loss: 0.0014896260228209003\n",
      "Iteration:430, Price of Hedge: 0.08105626787712482, Loss: 0.002027349601839834\n",
      "Iteration:440, Price of Hedge: 0.08330467480813866, Loss: 0.001535895685999167\n",
      "Iteration:450, Price of Hedge: 0.08639744580223976, Loss: 0.0019776988285247657\n",
      "Iteration:460, Price of Hedge: 0.07926898525751654, Loss: 0.0016498809944773376\n",
      "Iteration:470, Price of Hedge: 0.08186035246924064, Loss: 0.001336806252823708\n",
      "Iteration:480, Price of Hedge: 0.07978398706493693, Loss: 0.0016679977654611379\n",
      "Iteration:490, Price of Hedge: 0.090866626980349, Loss: 0.0016750150948986688\n",
      "Iteration:500, Price of Hedge: 0.088139973454102, Loss: 0.0018171668185499091\n",
      "Iteration:510, Price of Hedge: 0.08078766789735425, Loss: 0.0016425477633864817\n",
      "Iteration:520, Price of Hedge: 0.09107963411690889, Loss: 0.002155953128359833\n",
      "Iteration:530, Price of Hedge: 0.09476732650369116, Loss: 0.001459462958131308\n",
      "Iteration:540, Price of Hedge: 0.0822594124002876, Loss: 0.0013595476388326589\n",
      "Iteration:550, Price of Hedge: 0.08256252204682539, Loss: 0.0015678916625184059\n",
      "Iteration:560, Price of Hedge: 0.0803368044809929, Loss: 0.0018314537845302683\n",
      "Iteration:570, Price of Hedge: 0.07820561813971665, Loss: 0.0011119548144366222\n",
      "Iteration:580, Price of Hedge: 0.08650870166195546, Loss: 0.0012681915121896205\n",
      "Iteration:590, Price of Hedge: 0.09273655814666597, Loss: 0.0012596688681248303\n",
      "Iteration:600, Price of Hedge: 0.0855094651381819, Loss: 0.00134554697014706\n",
      "Iteration:610, Price of Hedge: 0.08645238369470291, Loss: 0.0012326712768861992\n",
      "Iteration:620, Price of Hedge: 0.08605676225508034, Loss: 0.001336975838285115\n",
      "Iteration:630, Price of Hedge: 0.07930131175512543, Loss: 0.0010483154334709256\n",
      "Iteration:640, Price of Hedge: 0.08767066225835266, Loss: 0.0009859550704409915\n",
      "Iteration:650, Price of Hedge: 0.08681871168244015, Loss: 0.0011997024987079553\n",
      "Iteration:660, Price of Hedge: 0.08818931307708056, Loss: 0.0010795273208884294\n",
      "Iteration:670, Price of Hedge: 0.08321521945187556, Loss: 0.0011196223433048492\n",
      "Iteration:680, Price of Hedge: 0.08176094030220896, Loss: 0.0009079799311261905\n",
      "Iteration:690, Price of Hedge: 0.08762656224135412, Loss: 0.0017840910748291973\n",
      "Iteration:700, Price of Hedge: 0.09157826995267442, Loss: 0.00126634507738137\n",
      "Iteration:710, Price of Hedge: 0.09483933989778563, Loss: 0.0014124758461152354\n",
      "Iteration:720, Price of Hedge: 0.085910794005747, Loss: 0.001113652374651597\n",
      "Iteration:730, Price of Hedge: 0.08533565368504696, Loss: 0.0012857031603380699\n",
      "Iteration:740, Price of Hedge: 0.08267197679198546, Loss: 0.0011958508863786578\n",
      "Iteration:750, Price of Hedge: 0.08709346352101761, Loss: 0.001179615149535751\n",
      "Iteration:760, Price of Hedge: 0.08043095365094644, Loss: 0.0011195628909304479\n",
      "Iteration:770, Price of Hedge: 0.08601174218822223, Loss: 0.0011405717519058724\n",
      "Iteration:780, Price of Hedge: 0.08705622489280244, Loss: 0.001177890787020841\n",
      "Iteration:790, Price of Hedge: 0.08565080974711918, Loss: 0.0008405782382214345\n",
      "Iteration:800, Price of Hedge: 0.07662086344470823, Loss: 0.0011677033546441784\n",
      "Iteration:810, Price of Hedge: 0.08993221498651281, Loss: 0.0011222137602226567\n",
      "Iteration:820, Price of Hedge: 0.08719932383409912, Loss: 0.0012529394197543287\n",
      "Iteration:830, Price of Hedge: 0.09076871184359732, Loss: 0.0010187725983675567\n",
      "Iteration:840, Price of Hedge: 0.08573985186064874, Loss: 0.001136153149104313\n",
      "Iteration:850, Price of Hedge: 0.08600720431518596, Loss: 0.0009450858270423579\n",
      "Iteration:860, Price of Hedge: 0.0908452942988589, Loss: 0.0010558258033986246\n",
      "Iteration:870, Price of Hedge: 0.08239092495097965, Loss: 0.0010555619225729007\n",
      "Iteration:880, Price of Hedge: 0.07945322134338255, Loss: 0.000985261926416081\n",
      "Iteration:890, Price of Hedge: 0.09086442821712525, Loss: 0.000908598455111509\n",
      "Iteration:900, Price of Hedge: 0.09170866752768916, Loss: 0.0014700462117465563\n",
      "Iteration:910, Price of Hedge: 0.08974105513560175, Loss: 0.0009527061473141086\n",
      "Iteration:920, Price of Hedge: 0.08585619918272301, Loss: 0.0011030984817376412\n",
      "Iteration:930, Price of Hedge: 0.08374540987901184, Loss: 0.0010232833036179835\n",
      "Iteration:940, Price of Hedge: 0.0886814461875673, Loss: 0.0011901398035770506\n",
      "Iteration:950, Price of Hedge: 0.08454390399867577, Loss: 0.0008794325578081353\n",
      "Iteration:960, Price of Hedge: 0.08194719581954645, Loss: 0.0011353974460747817\n",
      "Iteration:970, Price of Hedge: 0.0839054517723838, Loss: 0.0011818014862386317\n",
      "Iteration:980, Price of Hedge: 0.09319500027881987, Loss: 0.0012365890421648818\n",
      "Iteration:990, Price of Hedge: 0.082672951421074, Loss: 0.000968382690717462\n",
      "tf.Tensor(0.07430511, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_113 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.09806546354229795, Loss: 0.0030457271099406215\n",
      "Iteration:20, Price of Hedge: 0.06310939715992703, Loss: 0.0010301516366336028\n",
      "Iteration:30, Price of Hedge: 0.07613236375146358, Loss: 0.0015691229845431476\n",
      "Iteration:40, Price of Hedge: 0.08221603750733096, Loss: 0.001206042948243491\n",
      "Iteration:50, Price of Hedge: 0.07218463252682454, Loss: 0.0014306118660235346\n",
      "Iteration:60, Price of Hedge: 0.07503662335385855, Loss: 0.0009991684824803171\n",
      "Iteration:70, Price of Hedge: 0.07805818404823413, Loss: 0.0015583251906997832\n",
      "Iteration:80, Price of Hedge: 0.0742130461799718, Loss: 0.001402972603358732\n",
      "Iteration:90, Price of Hedge: 0.07718840165851759, Loss: 0.0015286037548159382\n",
      "Iteration:100, Price of Hedge: 0.0759274733259531, Loss: 0.0012542853825256107\n",
      "Iteration:110, Price of Hedge: 0.07485620781401962, Loss: 0.001236566382038573\n",
      "Iteration:120, Price of Hedge: 0.07537934972358755, Loss: 0.0013731678366878165\n",
      "Iteration:130, Price of Hedge: 0.0758964567298392, Loss: 0.001326496869982341\n",
      "Iteration:140, Price of Hedge: 0.07367087171356275, Loss: 0.001358421333092208\n",
      "Iteration:150, Price of Hedge: 0.07706173106513746, Loss: 0.0012198369955623179\n",
      "Iteration:160, Price of Hedge: 0.078815533226296, Loss: 0.0013782149534228517\n",
      "Iteration:170, Price of Hedge: 0.07774261474342836, Loss: 0.0014905481437673008\n",
      "Iteration:180, Price of Hedge: 0.07814713259737119, Loss: 0.0014498807704186323\n",
      "Iteration:190, Price of Hedge: 0.07490848691832923, Loss: 0.0014454240352539838\n",
      "Iteration:200, Price of Hedge: 0.07544848601261266, Loss: 0.0012884084870306012\n",
      "Iteration:210, Price of Hedge: 0.07658602630256724, Loss: 0.0015233803520445122\n",
      "Iteration:220, Price of Hedge: 0.08094429469039995, Loss: 0.0013308089945559766\n",
      "Iteration:230, Price of Hedge: 0.07416567920626847, Loss: 0.0012816586932778763\n",
      "Iteration:240, Price of Hedge: 0.0763818298129678, Loss: 0.0014451448040201154\n",
      "Iteration:250, Price of Hedge: 0.07366096948202312, Loss: 0.0012118903572888584\n",
      "Iteration:260, Price of Hedge: 0.0713271382606564, Loss: 0.0012840869816519885\n",
      "Iteration:270, Price of Hedge: 0.0880692387733717, Loss: 0.0013527566670009429\n",
      "Iteration:280, Price of Hedge: 0.0683789008618703, Loss: 0.001245901013962758\n",
      "Iteration:290, Price of Hedge: 0.07994065284314615, Loss: 0.0013974523042012078\n",
      "Iteration:300, Price of Hedge: 0.07650310485971375, Loss: 0.0013501439300718232\n",
      "Iteration:310, Price of Hedge: 0.07876265375046786, Loss: 0.0013109751707754303\n",
      "Iteration:320, Price of Hedge: 0.07349118909479842, Loss: 0.0017516978151277396\n",
      "Iteration:330, Price of Hedge: 0.07852517172823639, Loss: 0.0012879105733949903\n",
      "Iteration:340, Price of Hedge: 0.07334154844305943, Loss: 0.0012988619931484369\n",
      "Iteration:350, Price of Hedge: 0.08168078680596694, Loss: 0.001975989816418\n",
      "Iteration:360, Price of Hedge: 0.06992003115887542, Loss: 0.0013897669883521147\n",
      "Iteration:370, Price of Hedge: 0.07398332220528517, Loss: 0.0012784546001492814\n",
      "Iteration:380, Price of Hedge: 0.07718914237662489, Loss: 0.0013908429788658694\n",
      "Iteration:390, Price of Hedge: 0.07397350574110532, Loss: 0.001421708020156487\n",
      "Iteration:400, Price of Hedge: 0.07487683096553326, Loss: 0.0017319848453541732\n",
      "Iteration:410, Price of Hedge: 0.07949889636098817, Loss: 0.0012603833930753705\n",
      "Iteration:420, Price of Hedge: 0.07789048546874255, Loss: 0.0012005487204140852\n",
      "Iteration:430, Price of Hedge: 0.07830037547822144, Loss: 0.0012874517667515572\n",
      "Iteration:440, Price of Hedge: 0.08369122050168869, Loss: 0.001402122970450792\n",
      "Iteration:450, Price of Hedge: 0.07143747407051251, Loss: 0.001431471367050996\n",
      "Iteration:460, Price of Hedge: 0.0751369399766844, Loss: 0.0013048545000993617\n",
      "Iteration:470, Price of Hedge: 0.08337971345092399, Loss: 0.001295961496980924\n",
      "Iteration:480, Price of Hedge: 0.07871579358389057, Loss: 0.0010937895556556666\n",
      "Iteration:490, Price of Hedge: 0.07195824568213709, Loss: 0.001276468549724097\n",
      "Iteration:500, Price of Hedge: 0.07460977479823896, Loss: 0.0013748209294506264\n",
      "Iteration:510, Price of Hedge: 0.07882118607500957, Loss: 0.001269706451279129\n",
      "Iteration:520, Price of Hedge: 0.08030362810681879, Loss: 0.0012703555542521005\n",
      "Iteration:530, Price of Hedge: 0.07578244072054474, Loss: 0.0009342728655338029\n",
      "Iteration:540, Price of Hedge: 0.07793690900148818, Loss: 0.0009502748132240946\n",
      "Iteration:550, Price of Hedge: 0.08160812625815765, Loss: 0.0012729463620267279\n",
      "Iteration:560, Price of Hedge: 0.07199864210859915, Loss: 0.0014813739601568178\n",
      "Iteration:570, Price of Hedge: 0.07839362019238082, Loss: 0.0013581094517838733\n",
      "Iteration:580, Price of Hedge: 0.08243936011816402, Loss: 0.001289836318645321\n",
      "Iteration:590, Price of Hedge: 0.08284290334301829, Loss: 0.001512456100076909\n",
      "Iteration:600, Price of Hedge: 0.07017505650470071, Loss: 0.0011598546665941179\n",
      "Iteration:610, Price of Hedge: 0.07305949858186693, Loss: 0.0011974070035471573\n",
      "Iteration:620, Price of Hedge: 0.07719293953155386, Loss: 0.0009689716712585339\n",
      "Iteration:630, Price of Hedge: 0.07247483808422998, Loss: 0.0008183394562505831\n",
      "Iteration:640, Price of Hedge: 0.08512280248914124, Loss: 0.000957980352626775\n",
      "Iteration:650, Price of Hedge: 0.07477104082574614, Loss: 0.0010046742231158313\n",
      "Iteration:660, Price of Hedge: 0.07307141244784532, Loss: 0.0007951010703207917\n",
      "Iteration:670, Price of Hedge: 0.07993622412856781, Loss: 0.0010033089505057326\n",
      "Iteration:680, Price of Hedge: 0.08050604687296073, Loss: 0.0008322639820386391\n",
      "Iteration:690, Price of Hedge: 0.07441621346125374, Loss: 0.0009523005797846374\n",
      "Iteration:700, Price of Hedge: 0.07315052893873712, Loss: 0.0008259250553610542\n",
      "Iteration:710, Price of Hedge: 0.07560762345019044, Loss: 0.0008261914945881355\n",
      "Iteration:720, Price of Hedge: 0.07330390436914343, Loss: 0.0007652707196363018\n",
      "Iteration:730, Price of Hedge: 0.07728105379819113, Loss: 0.001017759227772741\n",
      "Iteration:740, Price of Hedge: 0.07486993838861906, Loss: 0.000916169373871334\n",
      "Iteration:750, Price of Hedge: 0.07892253970318563, Loss: 0.00117963500760343\n",
      "Iteration:760, Price of Hedge: 0.0773922862668087, Loss: 0.0010028447834023126\n",
      "Iteration:770, Price of Hedge: 0.07263190151110735, Loss: 0.0010053456207292034\n",
      "Iteration:780, Price of Hedge: 0.0801521161672298, Loss: 0.0009944512776917547\n",
      "Iteration:790, Price of Hedge: 0.0799578375032354, Loss: 0.0007993553262922948\n",
      "Iteration:800, Price of Hedge: 0.07437044487925562, Loss: 0.000898496059122822\n",
      "Iteration:810, Price of Hedge: 0.06979063160404735, Loss: 0.0008807643275433153\n",
      "Iteration:820, Price of Hedge: 0.07644158627164473, Loss: 0.0008661304545217519\n",
      "Iteration:830, Price of Hedge: 0.07240062592691175, Loss: 0.0007469672462677269\n",
      "Iteration:840, Price of Hedge: 0.0734794311694742, Loss: 0.0009707030389200178\n",
      "Iteration:850, Price of Hedge: 0.07820980514628105, Loss: 0.0007474190477645859\n",
      "Iteration:860, Price of Hedge: 0.07717212925125523, Loss: 0.0008930177908447412\n",
      "Iteration:870, Price of Hedge: 0.08299216973718729, Loss: 0.0007193395573233508\n",
      "Iteration:880, Price of Hedge: 0.08460882989003836, Loss: 0.0007261713417481497\n",
      "Iteration:890, Price of Hedge: 0.07669177745719083, Loss: 0.0008214352437217132\n",
      "Iteration:900, Price of Hedge: 0.07507936668716582, Loss: 0.0008001480652271909\n",
      "Iteration:910, Price of Hedge: 0.07844603184624646, Loss: 0.0009993684032721052\n",
      "Iteration:920, Price of Hedge: 0.07664233647278706, Loss: 0.000798721878299058\n",
      "Iteration:930, Price of Hedge: 0.07447015333353023, Loss: 0.0009290504983057835\n",
      "Iteration:940, Price of Hedge: 0.07359205150991387, Loss: 0.0008767271092869678\n",
      "Iteration:950, Price of Hedge: 0.07433020439344773, Loss: 0.0008377409711160411\n",
      "Iteration:960, Price of Hedge: 0.06942407750236157, Loss: 0.000797979271847904\n",
      "Iteration:970, Price of Hedge: 0.07778701104766982, Loss: 0.0007804871162812255\n",
      "Iteration:980, Price of Hedge: 0.0791891826277464, Loss: 0.0008174243404507564\n",
      "Iteration:990, Price of Hedge: 0.07936009358471381, Loss: 0.0007347011127881497\n",
      "tf.Tensor(0.072070666, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_114 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.0731449150751871, Loss: 0.0026002687428470675\n",
      "Iteration:20, Price of Hedge: 0.10079379343057725, Loss: 0.0023007934881804637\n",
      "Iteration:30, Price of Hedge: 0.08298598669024955, Loss: 0.0022344719279630888\n",
      "Iteration:40, Price of Hedge: 0.08980962224123915, Loss: 0.0017658867090560638\n",
      "Iteration:50, Price of Hedge: 0.09115610741371256, Loss: 0.0015796975883252352\n",
      "Iteration:60, Price of Hedge: 0.08753098621441495, Loss: 0.0018561918200557415\n",
      "Iteration:70, Price of Hedge: 0.08538632660061865, Loss: 0.0019229654863415658\n",
      "Iteration:80, Price of Hedge: 0.09000954595691439, Loss: 0.001950247060130872\n",
      "Iteration:90, Price of Hedge: 0.09150701287075265, Loss: 0.0017543700044312606\n",
      "Iteration:100, Price of Hedge: 0.09074467359175742, Loss: 0.0019271453050164313\n",
      "Iteration:110, Price of Hedge: 0.07716054286065059, Loss: 0.0017292539346480673\n",
      "Iteration:120, Price of Hedge: 0.09943215862355147, Loss: 0.0018968387261935505\n",
      "Iteration:130, Price of Hedge: 0.09727175680071697, Loss: 0.0020927900973611636\n",
      "Iteration:140, Price of Hedge: 0.07549097204384055, Loss: 0.0019314548711887093\n",
      "Iteration:150, Price of Hedge: 0.0907655228572196, Loss: 0.0019873751897731217\n",
      "Iteration:160, Price of Hedge: 0.08780173037818031, Loss: 0.0017011428296757726\n",
      "Iteration:170, Price of Hedge: 0.09180471917362354, Loss: 0.0016669210439755667\n",
      "Iteration:180, Price of Hedge: 0.08331008594883826, Loss: 0.0020719997969588454\n",
      "Iteration:190, Price of Hedge: 0.07661687136396154, Loss: 0.0019197869772265453\n",
      "Iteration:200, Price of Hedge: 0.09325743111971577, Loss: 0.0015160775781126734\n",
      "Iteration:210, Price of Hedge: 0.0852628138054854, Loss: 0.0017401317699053287\n",
      "Iteration:220, Price of Hedge: 0.08535389094455184, Loss: 0.001626038764912874\n",
      "Iteration:230, Price of Hedge: 0.08561902124476717, Loss: 0.0015747731530267207\n",
      "Iteration:240, Price of Hedge: 0.08910372568201978, Loss: 0.001732193659636394\n",
      "Iteration:250, Price of Hedge: 0.0859207586135483, Loss: 0.0018933071576912042\n",
      "Iteration:260, Price of Hedge: 0.08869431129153611, Loss: 0.0016807684522369916\n",
      "Iteration:270, Price of Hedge: 0.08438012732663651, Loss: 0.0017630085075289515\n",
      "Iteration:280, Price of Hedge: 0.08592289500051038, Loss: 0.0016038799634416013\n",
      "Iteration:290, Price of Hedge: 0.0927799174455572, Loss: 0.0013271961663533728\n",
      "Iteration:300, Price of Hedge: 0.07971545894446308, Loss: 0.0017657721901381596\n",
      "Iteration:310, Price of Hedge: 0.09197462431337158, Loss: 0.0017507339069591677\n",
      "Iteration:320, Price of Hedge: 0.08435287669732076, Loss: 0.0017484895798255185\n",
      "Iteration:330, Price of Hedge: 0.08822275455036675, Loss: 0.0014929588888178192\n",
      "Iteration:340, Price of Hedge: 0.10591850233660978, Loss: 0.0017287550463833679\n",
      "Iteration:350, Price of Hedge: 0.07835918849594066, Loss: 0.0013587025135842535\n",
      "Iteration:360, Price of Hedge: 0.0820277547614893, Loss: 0.002299198264019786\n",
      "Iteration:370, Price of Hedge: 0.0824643184198635, Loss: 0.0013885389557005468\n",
      "Iteration:380, Price of Hedge: 0.08984634626529556, Loss: 0.0016467659580817085\n",
      "Iteration:390, Price of Hedge: 0.08535182473088412, Loss: 0.0014714019208087238\n",
      "Iteration:400, Price of Hedge: 0.07530396801136306, Loss: 0.0017459140006303997\n",
      "Iteration:410, Price of Hedge: 0.08844666973568564, Loss: 0.0016094064758595652\n",
      "Iteration:420, Price of Hedge: 0.0870452778588799, Loss: 0.0015409629044591533\n",
      "Iteration:430, Price of Hedge: 0.08008182591736386, Loss: 0.0020945161654769783\n",
      "Iteration:440, Price of Hedge: 0.08753953955929604, Loss: 0.001600757130013264\n",
      "Iteration:450, Price of Hedge: 0.09381276697733654, Loss: 0.0011568737635268\n",
      "Iteration:460, Price of Hedge: 0.09013114068200138, Loss: 0.0016841678366692038\n",
      "Iteration:470, Price of Hedge: 0.08310279403725361, Loss: 0.0018097018907034636\n",
      "Iteration:480, Price of Hedge: 0.08859003377609441, Loss: 0.0020205436450858815\n",
      "Iteration:490, Price of Hedge: 0.08439389688639949, Loss: 0.0019147390076910576\n",
      "Iteration:500, Price of Hedge: 0.09033610907783896, Loss: 0.0018043389941437395\n",
      "Iteration:510, Price of Hedge: 0.08909939053183394, Loss: 0.0017594397812926044\n",
      "Iteration:520, Price of Hedge: 0.09625100826370102, Loss: 0.0017569649543795142\n",
      "Iteration:530, Price of Hedge: 0.09875334115892827, Loss: 0.0017376458565863562\n",
      "Iteration:540, Price of Hedge: 0.08447204654523546, Loss: 0.0018259823386558073\n",
      "Iteration:550, Price of Hedge: 0.0815908324396105, Loss: 0.0016902119989618215\n",
      "Iteration:560, Price of Hedge: 0.08109701517005874, Loss: 0.0013834435948256285\n",
      "Iteration:570, Price of Hedge: 0.09084367251605556, Loss: 0.0016060916405007842\n",
      "Iteration:580, Price of Hedge: 0.09399864044007132, Loss: 0.0016522417897870678\n",
      "Iteration:590, Price of Hedge: 0.09537922203657843, Loss: 0.0017302701073015126\n",
      "Iteration:600, Price of Hedge: 0.09131598556939764, Loss: 0.0013438271152916847\n",
      "Iteration:610, Price of Hedge: 0.09560323858332254, Loss: 0.0012783207104782423\n",
      "Iteration:620, Price of Hedge: 0.08942476850378682, Loss: 0.0015388311469852313\n",
      "Iteration:630, Price of Hedge: 0.08601463488735704, Loss: 0.0014394943918792703\n",
      "Iteration:640, Price of Hedge: 0.07489301760543583, Loss: 0.0010423031902809577\n",
      "Iteration:650, Price of Hedge: 0.08343546223478882, Loss: 0.0015036828545077264\n",
      "Iteration:660, Price of Hedge: 0.08172029437070023, Loss: 0.0014026753414867255\n",
      "Iteration:670, Price of Hedge: 0.09037037703659223, Loss: 0.0010696990393308959\n",
      "Iteration:680, Price of Hedge: 0.09659521606964461, Loss: 0.0011830877529782403\n",
      "Iteration:690, Price of Hedge: 0.09236207446271578, Loss: 0.0009919126734876827\n",
      "Iteration:700, Price of Hedge: 0.08833850150092247, Loss: 0.0009499824244975308\n",
      "Iteration:710, Price of Hedge: 0.0806664786179681, Loss: 0.0010377744543923928\n",
      "Iteration:720, Price of Hedge: 0.08470072571753917, Loss: 0.0013756346229109263\n",
      "Iteration:730, Price of Hedge: 0.09120220347108443, Loss: 0.001555652514081718\n",
      "Iteration:740, Price of Hedge: 0.08326044224158409, Loss: 0.001505590569119919\n",
      "Iteration:750, Price of Hedge: 0.08025055370517294, Loss: 0.0010123767168026098\n",
      "Iteration:760, Price of Hedge: 0.08934014730780292, Loss: 0.0010828794358098471\n",
      "Iteration:770, Price of Hedge: 0.10137174068305228, Loss: 0.0012346780381795152\n",
      "Iteration:780, Price of Hedge: 0.09314007018338942, Loss: 0.001060059104844724\n",
      "Iteration:790, Price of Hedge: 0.08432245267569272, Loss: 0.0013913659892005104\n",
      "Iteration:800, Price of Hedge: 0.07807265534094086, Loss: 0.001081177855249882\n",
      "Iteration:810, Price of Hedge: 0.08362896899254509, Loss: 0.0009300639298149172\n",
      "Iteration:820, Price of Hedge: 0.08594914760963945, Loss: 0.001074812065358044\n",
      "Iteration:830, Price of Hedge: 0.09370462993070419, Loss: 0.0009123379850956237\n",
      "Iteration:840, Price of Hedge: 0.08697770097639648, Loss: 0.0013741446586918117\n",
      "Iteration:850, Price of Hedge: 0.08607924110037857, Loss: 0.001504887252403897\n",
      "Iteration:860, Price of Hedge: 0.07981898794476479, Loss: 0.0010148346095352867\n",
      "Iteration:870, Price of Hedge: 0.08208898485934811, Loss: 0.001053339890079652\n",
      "Iteration:880, Price of Hedge: 0.08636451893311232, Loss: 0.0010719430009786368\n",
      "Iteration:890, Price of Hedge: 0.08750417221893088, Loss: 0.0010331772508103576\n",
      "Iteration:900, Price of Hedge: 0.09604886239370387, Loss: 0.0011072468686244008\n",
      "Iteration:910, Price of Hedge: 0.08382884592602409, Loss: 0.0009482662245012375\n",
      "Iteration:920, Price of Hedge: 0.0843477774379295, Loss: 0.0009029353727925127\n",
      "Iteration:930, Price of Hedge: 0.09691283599405268, Loss: 0.0010758355477296533\n",
      "Iteration:940, Price of Hedge: 0.09687017842810519, Loss: 0.0012396184330293548\n",
      "Iteration:950, Price of Hedge: 0.0875959666850065, Loss: 0.0010844093598215922\n",
      "Iteration:960, Price of Hedge: 0.08246122299787828, Loss: 0.0010427845352220632\n",
      "Iteration:970, Price of Hedge: 0.08924833724766189, Loss: 0.0011253246544446593\n",
      "Iteration:980, Price of Hedge: 0.09653463312550059, Loss: 0.0013493001449384147\n",
      "Iteration:990, Price of Hedge: 0.09163447876146905, Loss: 0.001030387618701667\n",
      "tf.Tensor(0.076216675, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_115 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.0601018126466812, Loss: 0.002410447301331864\n",
      "Iteration:20, Price of Hedge: 0.08341027002210809, Loss: 0.0010889878017936727\n",
      "Iteration:30, Price of Hedge: 0.05598019589709651, Loss: 0.001072712714301316\n",
      "Iteration:40, Price of Hedge: 0.07581717650126052, Loss: 0.0009200349964937793\n",
      "Iteration:50, Price of Hedge: 0.06360063751016867, Loss: 0.0011246210940713652\n",
      "Iteration:60, Price of Hedge: 0.06494168815084436, Loss: 0.0011773685076580166\n",
      "Iteration:70, Price of Hedge: 0.07199241227946516, Loss: 0.0010732889637499188\n",
      "Iteration:80, Price of Hedge: 0.06279385124621939, Loss: 0.0008864709026853879\n",
      "Iteration:90, Price of Hedge: 0.07391721896198362, Loss: 0.0012820719360114197\n",
      "Iteration:100, Price of Hedge: 0.06704722225451008, Loss: 0.0010970373852646099\n",
      "Iteration:110, Price of Hedge: 0.0681798582108911, Loss: 0.0009118309343123077\n",
      "Iteration:120, Price of Hedge: 0.06769827448565878, Loss: 0.0010269381627000308\n",
      "Iteration:130, Price of Hedge: 0.06925324451572124, Loss: 0.0013542930479303994\n",
      "Iteration:140, Price of Hedge: 0.0696514623672357, Loss: 0.0009603121527211212\n",
      "Iteration:150, Price of Hedge: 0.06061592559237283, Loss: 0.0010434340036809431\n",
      "Iteration:160, Price of Hedge: 0.0679330275464423, Loss: 0.0011761362110041863\n",
      "Iteration:170, Price of Hedge: 0.07228518306063166, Loss: 0.001170276862752484\n",
      "Iteration:180, Price of Hedge: 0.06522570676279571, Loss: 0.0009216561092396214\n",
      "Iteration:190, Price of Hedge: 0.07139094917634169, Loss: 0.001121698425092088\n",
      "Iteration:200, Price of Hedge: 0.06379301759669857, Loss: 0.0011059391600448444\n",
      "Iteration:210, Price of Hedge: 0.062155648524974086, Loss: 0.0009292858103163494\n",
      "Iteration:220, Price of Hedge: 0.07045684906381382, Loss: 0.0010491280304735008\n",
      "Iteration:230, Price of Hedge: 0.06353673303009089, Loss: 0.001149632756713448\n",
      "Iteration:240, Price of Hedge: 0.06839692760149206, Loss: 0.0008871201884013136\n",
      "Iteration:250, Price of Hedge: 0.06799675269476779, Loss: 0.0009043912249935282\n",
      "Iteration:260, Price of Hedge: 0.06974886289982862, Loss: 0.0009111874963709133\n",
      "Iteration:270, Price of Hedge: 0.06106064884547635, Loss: 0.0010585760848578652\n",
      "Iteration:280, Price of Hedge: 0.07198677502481701, Loss: 0.0009954845672685674\n",
      "Iteration:290, Price of Hedge: 0.06883407603731939, Loss: 0.0010900707365396835\n",
      "Iteration:300, Price of Hedge: 0.06545247956060223, Loss: 0.0012990743404611039\n",
      "Iteration:310, Price of Hedge: 0.06837433959773591, Loss: 0.000991561319701262\n",
      "Iteration:320, Price of Hedge: 0.06648136819976572, Loss: 0.0011175374898558133\n",
      "Iteration:330, Price of Hedge: 0.06605324872781466, Loss: 0.0010486502185628411\n",
      "Iteration:340, Price of Hedge: 0.0749260692270866, Loss: 0.0010420588020370047\n",
      "Iteration:350, Price of Hedge: 0.06281773355740512, Loss: 0.0010157947410161406\n",
      "Iteration:360, Price of Hedge: 0.0623977892742488, Loss: 0.0011193368988105413\n",
      "Iteration:370, Price of Hedge: 0.07451601547992084, Loss: 0.001176935650514066\n",
      "Iteration:380, Price of Hedge: 0.07829887065090872, Loss: 0.001026392492239081\n",
      "Iteration:390, Price of Hedge: 0.06639746433079097, Loss: 0.0010040627651914048\n",
      "Iteration:400, Price of Hedge: 0.060265105902692545, Loss: 0.0008449282515008872\n",
      "Iteration:410, Price of Hedge: 0.06980521985224471, Loss: 0.0008009593830290874\n",
      "Iteration:420, Price of Hedge: 0.07294934990079582, Loss: 0.0010871946060993843\n",
      "Iteration:430, Price of Hedge: 0.06596806614547575, Loss: 0.0020630863266295485\n",
      "Iteration:440, Price of Hedge: 0.061581475036329894, Loss: 0.0007899474753578329\n",
      "Iteration:450, Price of Hedge: 0.06725409312632849, Loss: 0.0008402080619107411\n",
      "Iteration:460, Price of Hedge: 0.07156637461524724, Loss: 0.0007831978034337439\n",
      "Iteration:470, Price of Hedge: 0.06917603829784298, Loss: 0.0007759083088232366\n",
      "Iteration:480, Price of Hedge: 0.06215658027038273, Loss: 0.0008084070721235293\n",
      "Iteration:490, Price of Hedge: 0.07295236735245396, Loss: 0.0010690345859497798\n",
      "Iteration:500, Price of Hedge: 0.06758559176895744, Loss: 0.0008792116215766255\n",
      "Iteration:510, Price of Hedge: 0.06467386787434463, Loss: 0.0007101733534885301\n",
      "Iteration:520, Price of Hedge: 0.07686587740053596, Loss: 0.0007591823335487913\n",
      "Iteration:530, Price of Hedge: 0.06187806636352349, Loss: 0.000838824393176596\n",
      "Iteration:540, Price of Hedge: 0.06698750478099669, Loss: 0.0006289029323110374\n",
      "Iteration:550, Price of Hedge: 0.07335219918973905, Loss: 0.0007135177932058756\n",
      "Iteration:560, Price of Hedge: 0.06955208138833484, Loss: 0.0007013136705020573\n",
      "Iteration:570, Price of Hedge: 0.0706992744047824, Loss: 0.000601369295073706\n",
      "Iteration:580, Price of Hedge: 0.06757200933797947, Loss: 0.0006569378943857895\n",
      "Iteration:590, Price of Hedge: 0.06623432701543379, Loss: 0.0006851510917551096\n",
      "Iteration:600, Price of Hedge: 0.06233016171105277, Loss: 0.0007389012159309205\n",
      "Iteration:610, Price of Hedge: 0.06473675874017033, Loss: 0.0007172734654842694\n",
      "Iteration:620, Price of Hedge: 0.07028325592759473, Loss: 0.0006557565830161539\n",
      "Iteration:630, Price of Hedge: 0.06847434433925344, Loss: 0.0007839640446402952\n",
      "Iteration:640, Price of Hedge: 0.06464158036189929, Loss: 0.0006556227542594328\n",
      "Iteration:650, Price of Hedge: 0.06707542412181625, Loss: 0.0006519800171266743\n",
      "Iteration:660, Price of Hedge: 0.06882988123372229, Loss: 0.0005810326235977881\n",
      "Iteration:670, Price of Hedge: 0.06656783729250151, Loss: 0.0006685247723049681\n",
      "Iteration:680, Price of Hedge: 0.06466830469150722, Loss: 0.0007713178667305032\n",
      "Iteration:690, Price of Hedge: 0.06680577933966277, Loss: 0.0007151655864230166\n",
      "Iteration:700, Price of Hedge: 0.07217372447806554, Loss: 0.0005282445801610081\n",
      "Iteration:710, Price of Hedge: 0.06965429269010884, Loss: 0.0006505136267486389\n",
      "Iteration:720, Price of Hedge: 0.0759692264361064, Loss: 0.0007185572347368386\n",
      "Iteration:730, Price of Hedge: 0.0713644080770024, Loss: 0.0007221204786845625\n",
      "Iteration:740, Price of Hedge: 0.06796851184229809, Loss: 0.0006743665772330765\n",
      "Iteration:750, Price of Hedge: 0.06894984637897324, Loss: 0.0007378563526336812\n",
      "Iteration:760, Price of Hedge: 0.06601832581831389, Loss: 0.0005849233429192635\n",
      "Iteration:770, Price of Hedge: 0.06887076107621226, Loss: 0.0006835833399518654\n",
      "Iteration:780, Price of Hedge: 0.07109547282482538, Loss: 0.0008095663934243547\n",
      "Iteration:790, Price of Hedge: 0.06848579038326932, Loss: 0.0006084537520897104\n",
      "Iteration:800, Price of Hedge: 0.06512095362835879, Loss: 0.000746137288684512\n",
      "Iteration:810, Price of Hedge: 0.0654400588874978, Loss: 0.0006168556030618389\n",
      "Iteration:820, Price of Hedge: 0.06426968529280828, Loss: 0.0006626572006203313\n",
      "Iteration:830, Price of Hedge: 0.07205303420877272, Loss: 0.000580828926118282\n",
      "Iteration:840, Price of Hedge: 0.07038813381455498, Loss: 0.0006787013619330206\n",
      "Iteration:850, Price of Hedge: 0.0670530232468451, Loss: 0.0007787960129839622\n",
      "Iteration:860, Price of Hedge: 0.06344498534621153, Loss: 0.000683543258330599\n",
      "Iteration:870, Price of Hedge: 0.06932953068373991, Loss: 0.0008130073214214662\n",
      "Iteration:880, Price of Hedge: 0.07167940819842045, Loss: 0.0007770355891927761\n",
      "Iteration:890, Price of Hedge: 0.06564973669109123, Loss: 0.0005326923609209055\n",
      "Iteration:900, Price of Hedge: 0.0710976248058529, Loss: 0.0006957120507299575\n",
      "Iteration:910, Price of Hedge: 0.06914669026672869, Loss: 0.00050046326530655\n",
      "Iteration:920, Price of Hedge: 0.0653697062613702, Loss: 0.000589869280972044\n",
      "Iteration:930, Price of Hedge: 0.06904724691156616, Loss: 0.000591895413018495\n",
      "Iteration:940, Price of Hedge: 0.07026388809834715, Loss: 0.0005669282178285773\n",
      "Iteration:950, Price of Hedge: 0.0671548602910491, Loss: 0.0005602830748742349\n",
      "Iteration:960, Price of Hedge: 0.06814136426040988, Loss: 0.0006290778782324314\n",
      "Iteration:970, Price of Hedge: 0.07030364516812711, Loss: 0.0006853622816957339\n",
      "Iteration:980, Price of Hedge: 0.06835542399638542, Loss: 0.0005677903381717142\n",
      "Iteration:990, Price of Hedge: 0.06893046295566023, Loss: 0.0006497930103662952\n",
      "tf.Tensor(0.09224329, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_116 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.08712426180021567, Loss: 0.0029265519015659438\n",
      "Iteration:20, Price of Hedge: 0.09152118007918375, Loss: 0.0019142804447048968\n",
      "Iteration:30, Price of Hedge: 0.08257045942612251, Loss: 0.0017000312652002858\n",
      "Iteration:40, Price of Hedge: 0.08842468210344805, Loss: 0.0015869383514813152\n",
      "Iteration:50, Price of Hedge: 0.08165579731613662, Loss: 0.0013272773042249941\n",
      "Iteration:60, Price of Hedge: 0.0906174650031204, Loss: 0.0013179330478385598\n",
      "Iteration:70, Price of Hedge: 0.08296137925502194, Loss: 0.0016880650129083908\n",
      "Iteration:80, Price of Hedge: 0.08372987818985678, Loss: 0.0015783556458989435\n",
      "Iteration:90, Price of Hedge: 0.08281239355403046, Loss: 0.0018175822541989018\n",
      "Iteration:100, Price of Hedge: 0.08706813096174813, Loss: 0.0014842471667098512\n",
      "Iteration:110, Price of Hedge: 0.08181565208072357, Loss: 0.0014971957232943645\n",
      "Iteration:120, Price of Hedge: 0.09005404362258106, Loss: 0.0017129946848783995\n",
      "Iteration:130, Price of Hedge: 0.08580781079773488, Loss: 0.0014809322095224342\n",
      "Iteration:140, Price of Hedge: 0.07890831011849286, Loss: 0.0017256002938523807\n",
      "Iteration:150, Price of Hedge: 0.07956276185590241, Loss: 0.0017040112849119994\n",
      "Iteration:160, Price of Hedge: 0.09245532697390786, Loss: 0.001970191016998424\n",
      "Iteration:170, Price of Hedge: 0.07692667866159582, Loss: 0.001742420808148415\n",
      "Iteration:180, Price of Hedge: 0.08635444516685312, Loss: 0.0016554263903338917\n",
      "Iteration:190, Price of Hedge: 0.09038657147352751, Loss: 0.0018928771026058833\n",
      "Iteration:200, Price of Hedge: 0.08614789397337574, Loss: 0.001601212403626251\n",
      "Iteration:210, Price of Hedge: 0.08791959032459999, Loss: 0.001664061482229773\n",
      "Iteration:220, Price of Hedge: 0.08726353239845253, Loss: 0.00173154370386297\n",
      "Iteration:230, Price of Hedge: 0.08305276827539672, Loss: 0.0018717632253461682\n",
      "Iteration:240, Price of Hedge: 0.09298002049298475, Loss: 0.001631626678963416\n",
      "Iteration:250, Price of Hedge: 0.08308147694982893, Loss: 0.0011823354611505189\n",
      "Iteration:260, Price of Hedge: 0.08700460073924035, Loss: 0.0014644994757750053\n",
      "Iteration:270, Price of Hedge: 0.08990429381238414, Loss: 0.0015096394220110111\n",
      "Iteration:280, Price of Hedge: 0.07721024894416643, Loss: 0.0014912997046232057\n",
      "Iteration:290, Price of Hedge: 0.09005840996089774, Loss: 0.0015488143945678436\n",
      "Iteration:300, Price of Hedge: 0.09240041247254283, Loss: 0.002221478172954594\n",
      "Iteration:310, Price of Hedge: 0.07206246082131713, Loss: 0.0011037382039056354\n",
      "Iteration:320, Price of Hedge: 0.08364760390071808, Loss: 0.001328796020002221\n",
      "Iteration:330, Price of Hedge: 0.09274713872005123, Loss: 0.0011238268931928364\n",
      "Iteration:340, Price of Hedge: 0.08223393169739666, Loss: 0.0011627790411743\n",
      "Iteration:350, Price of Hedge: 0.08691014748501118, Loss: 0.0011617732239549206\n",
      "Iteration:360, Price of Hedge: 0.08352743603261673, Loss: 0.0010560805470766434\n",
      "Iteration:370, Price of Hedge: 0.08542843057724384, Loss: 0.001032645590642556\n",
      "Iteration:380, Price of Hedge: 0.08549114990834994, Loss: 0.001314053902237511\n",
      "Iteration:390, Price of Hedge: 0.08129560559314086, Loss: 0.0014744250984127572\n",
      "Iteration:400, Price of Hedge: 0.08513174568565773, Loss: 0.0012544248763139089\n",
      "Iteration:410, Price of Hedge: 0.08248448934348006, Loss: 0.0014126654114729575\n",
      "Iteration:420, Price of Hedge: 0.08693951890722361, Loss: 0.001024321527254557\n",
      "Iteration:430, Price of Hedge: 0.08111898720823092, Loss: 0.000959626379328693\n",
      "Iteration:440, Price of Hedge: 0.0874539671253217, Loss: 0.001357367880876126\n",
      "Iteration:450, Price of Hedge: 0.08610305323826993, Loss: 0.001367713203165133\n",
      "Iteration:460, Price of Hedge: 0.08145213102476134, Loss: 0.0008888627642973158\n",
      "Iteration:470, Price of Hedge: 0.08684441849927964, Loss: 0.0009836721236297086\n",
      "Iteration:480, Price of Hedge: 0.08106824411936486, Loss: 0.0009729858639026646\n",
      "Iteration:490, Price of Hedge: 0.08309045913150896, Loss: 0.0009350518987471413\n",
      "Iteration:500, Price of Hedge: 0.09102319139713302, Loss: 0.0010140137890997769\n",
      "Iteration:510, Price of Hedge: 0.08384997588466377, Loss: 0.0009854697051548955\n",
      "Iteration:520, Price of Hedge: 0.08592470391209872, Loss: 0.0011190207534999442\n",
      "Iteration:530, Price of Hedge: 0.08692315293556874, Loss: 0.0010179456255859254\n",
      "Iteration:540, Price of Hedge: 0.08909442382199871, Loss: 0.0008645591087737437\n",
      "Iteration:550, Price of Hedge: 0.08540486794439915, Loss: 0.0010910441473418687\n",
      "Iteration:560, Price of Hedge: 0.08301526454806947, Loss: 0.0011649058036741434\n",
      "Iteration:570, Price of Hedge: 0.08895778082378457, Loss: 0.00092911567662608\n",
      "Iteration:580, Price of Hedge: 0.08579717564512067, Loss: 0.001197836571317934\n",
      "Iteration:590, Price of Hedge: 0.08775451154809844, Loss: 0.0011941239654623904\n",
      "Iteration:600, Price of Hedge: 0.08665061545428046, Loss: 0.0012342494450378273\n",
      "Iteration:610, Price of Hedge: 0.08321337935215638, Loss: 0.0010846824996236571\n",
      "Iteration:620, Price of Hedge: 0.08182023673595609, Loss: 0.0011188092589877296\n",
      "Iteration:630, Price of Hedge: 0.09201698559207615, Loss: 0.001017871675603832\n",
      "Iteration:640, Price of Hedge: 0.08683042282556812, Loss: 0.0009646111198020613\n",
      "Iteration:650, Price of Hedge: 0.08464123435797433, Loss: 0.0010702409331041275\n",
      "Iteration:660, Price of Hedge: 0.07934498293532499, Loss: 0.0009901641889028313\n",
      "Iteration:670, Price of Hedge: 0.08012465501803093, Loss: 0.0009449923235641755\n",
      "Iteration:680, Price of Hedge: 0.09395043138683548, Loss: 0.001176564073174058\n",
      "Iteration:690, Price of Hedge: 0.08482864383615266, Loss: 0.0010127362331076473\n",
      "Iteration:700, Price of Hedge: 0.07636593166327543, Loss: 0.0010041657103888825\n",
      "Iteration:710, Price of Hedge: 0.08509268255178881, Loss: 0.001187686296675272\n",
      "Iteration:720, Price of Hedge: 0.08662359873594597, Loss: 0.001040937978585177\n",
      "Iteration:730, Price of Hedge: 0.08389250869808791, Loss: 0.0010468902820861992\n",
      "Iteration:740, Price of Hedge: 0.0901107436444363, Loss: 0.0009012379953204919\n",
      "Iteration:750, Price of Hedge: 0.08437254081381128, Loss: 0.0010951502596919128\n",
      "Iteration:760, Price of Hedge: 0.08276282002007065, Loss: 0.0009044331340443357\n",
      "Iteration:770, Price of Hedge: 0.0915589722967212, Loss: 0.00098875499706943\n",
      "Iteration:780, Price of Hedge: 0.0941702687240479, Loss: 0.0011145210128267636\n",
      "Iteration:790, Price of Hedge: 0.08504506607303881, Loss: 0.001415412038073116\n",
      "Iteration:800, Price of Hedge: 0.08082799415052193, Loss: 0.0011788573754194065\n",
      "Iteration:810, Price of Hedge: 0.0892626058175182, Loss: 0.0011430518174503136\n",
      "Iteration:820, Price of Hedge: 0.081248386763059, Loss: 0.0011996083251722745\n",
      "Iteration:830, Price of Hedge: 0.08164821080331137, Loss: 0.001101359743443675\n",
      "Iteration:840, Price of Hedge: 0.09644856168143293, Loss: 0.0014793460006808257\n",
      "Iteration:850, Price of Hedge: 0.09264272865505348, Loss: 0.0011564009465902193\n",
      "Iteration:860, Price of Hedge: 0.08116658029588279, Loss: 0.0011107825793003733\n",
      "Iteration:870, Price of Hedge: 0.07912822542603237, Loss: 0.0009174823819965594\n",
      "Iteration:880, Price of Hedge: 0.08563456852798766, Loss: 0.0010035210541611272\n",
      "Iteration:890, Price of Hedge: 0.08132538246105413, Loss: 0.0011371838193654504\n",
      "Iteration:900, Price of Hedge: 0.08260798654454789, Loss: 0.0009598926967271382\n",
      "Iteration:910, Price of Hedge: 0.08894828403794577, Loss: 0.001109871179273947\n",
      "Iteration:920, Price of Hedge: 0.09154632550966824, Loss: 0.0011971308180291906\n",
      "Iteration:930, Price of Hedge: 0.09135220278632801, Loss: 0.0012040504409005948\n",
      "Iteration:940, Price of Hedge: 0.09195378284494211, Loss: 0.0008480864152336843\n",
      "Iteration:950, Price of Hedge: 0.08875886292532868, Loss: 0.0010451093910841536\n",
      "Iteration:960, Price of Hedge: 0.07813050152660424, Loss: 0.0009727991006035719\n",
      "Iteration:970, Price of Hedge: 0.0719658010068315, Loss: 0.0011224481585184521\n",
      "Iteration:980, Price of Hedge: 0.08486645164775553, Loss: 0.0011005789437151137\n",
      "Iteration:990, Price of Hedge: 0.0911307904485085, Loss: 0.0012179781342331886\n",
      "tf.Tensor(0.07419966, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_117 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.0883035941854871, Loss: 0.00375799019002363\n",
      "Iteration:20, Price of Hedge: 0.08095557699672895, Loss: 0.0020558482437034622\n",
      "Iteration:30, Price of Hedge: 0.0857733635072293, Loss: 0.0017788429408446495\n",
      "Iteration:40, Price of Hedge: 0.08377805605496179, Loss: 0.0021741496971002584\n",
      "Iteration:50, Price of Hedge: 0.08442198179821503, Loss: 0.0020799954103440043\n",
      "Iteration:60, Price of Hedge: 0.08394007059760895, Loss: 0.0017113346478833337\n",
      "Iteration:70, Price of Hedge: 0.08886278177726581, Loss: 0.0014576137212644281\n",
      "Iteration:80, Price of Hedge: 0.08366109276730356, Loss: 0.001666323474515652\n",
      "Iteration:90, Price of Hedge: 0.08390591179731359, Loss: 0.0018540919816844694\n",
      "Iteration:100, Price of Hedge: 0.08120215815613108, Loss: 0.001693429858726292\n",
      "Iteration:110, Price of Hedge: 0.09064109001222675, Loss: 0.0016061543822483593\n",
      "Iteration:120, Price of Hedge: 0.08308203833618392, Loss: 0.0013539254909353815\n",
      "Iteration:130, Price of Hedge: 0.08570448452028359, Loss: 0.0014314074070170602\n",
      "Iteration:140, Price of Hedge: 0.07759539117182897, Loss: 0.0019039666760326313\n",
      "Iteration:150, Price of Hedge: 0.09632445631181384, Loss: 0.0017125040809609527\n",
      "Iteration:160, Price of Hedge: 0.09084085778724785, Loss: 0.001643282024576065\n",
      "Iteration:170, Price of Hedge: 0.07835312240449355, Loss: 0.0018051980078566566\n",
      "Iteration:180, Price of Hedge: 0.07944303062163272, Loss: 0.00169501886962653\n",
      "Iteration:190, Price of Hedge: 0.09875329437673203, Loss: 0.0014389973310441118\n",
      "Iteration:200, Price of Hedge: 0.08682381873886413, Loss: 0.0019699919490070886\n",
      "Iteration:210, Price of Hedge: 0.07975973829321391, Loss: 0.0015564098008835183\n",
      "Iteration:220, Price of Hedge: 0.08404697571307339, Loss: 0.0018568645577841103\n",
      "Iteration:230, Price of Hedge: 0.08479329208985291, Loss: 0.0015850300277259423\n",
      "Iteration:240, Price of Hedge: 0.0870661427184075, Loss: 0.0018216979910111954\n",
      "Iteration:250, Price of Hedge: 0.08356305287802855, Loss: 0.0016013180290537221\n",
      "Iteration:260, Price of Hedge: 0.08963776784331401, Loss: 0.0019015671392166311\n",
      "Iteration:270, Price of Hedge: 0.0897396126845507, Loss: 0.0017590261730731527\n",
      "Iteration:280, Price of Hedge: 0.08483468653650164, Loss: 0.0015225487497747103\n",
      "Iteration:290, Price of Hedge: 0.0903100513945276, Loss: 0.0015751496035121715\n",
      "Iteration:300, Price of Hedge: 0.08861269195314492, Loss: 0.001632306726409949\n",
      "Iteration:310, Price of Hedge: 0.0817960191523639, Loss: 0.0014520193502961744\n",
      "Iteration:320, Price of Hedge: 0.08844366787809292, Loss: 0.0015147963063471437\n",
      "Iteration:330, Price of Hedge: 0.08845084114818462, Loss: 0.001317756518144897\n",
      "Iteration:340, Price of Hedge: 0.09356074348910397, Loss: 0.0017139365420638431\n",
      "Iteration:350, Price of Hedge: 0.08030319927001983, Loss: 0.0014696456391911639\n",
      "Iteration:360, Price of Hedge: 0.08646536575416235, Loss: 0.001913267074110081\n",
      "Iteration:370, Price of Hedge: 0.08254118156830259, Loss: 0.0013642423053235487\n",
      "Iteration:380, Price of Hedge: 0.08218956658128605, Loss: 0.0016497101907295697\n",
      "Iteration:390, Price of Hedge: 0.0874152080757284, Loss: 0.001747731683880538\n",
      "Iteration:400, Price of Hedge: 0.08792278710801042, Loss: 0.0014352708367240564\n",
      "Iteration:410, Price of Hedge: 0.0842260969454827, Loss: 0.0021790628023356184\n",
      "Iteration:420, Price of Hedge: 0.08695956507831681, Loss: 0.0015031973673929945\n",
      "Iteration:430, Price of Hedge: 0.08594218485943088, Loss: 0.0015021319759705777\n",
      "Iteration:440, Price of Hedge: 0.092807674881999, Loss: 0.0014203312347402797\n",
      "Iteration:450, Price of Hedge: 0.08893481076542571, Loss: 0.0021043830667121454\n",
      "Iteration:460, Price of Hedge: 0.08753549289932039, Loss: 0.001208676030554834\n",
      "Iteration:470, Price of Hedge: 0.08514395583887904, Loss: 0.0012097326503154539\n",
      "Iteration:480, Price of Hedge: 0.08306494724048719, Loss: 0.0013323518324031447\n",
      "Iteration:490, Price of Hedge: 0.089106072588865, Loss: 0.0009219911989031271\n",
      "Iteration:500, Price of Hedge: 0.08855044044400132, Loss: 0.0010866329760871097\n",
      "Iteration:510, Price of Hedge: 0.08733707401095785, Loss: 0.0011354648173105275\n",
      "Iteration:520, Price of Hedge: 0.08517577552936188, Loss: 0.001084105641031874\n",
      "Iteration:530, Price of Hedge: 0.0909670839497636, Loss: 0.0011545461056060803\n",
      "Iteration:540, Price of Hedge: 0.09004963829910083, Loss: 0.0009172805728609124\n",
      "Iteration:550, Price of Hedge: 0.0829277038707545, Loss: 0.0010673327617325423\n",
      "Iteration:560, Price of Hedge: 0.08867590249731165, Loss: 0.0010649663623055528\n",
      "Iteration:570, Price of Hedge: 0.08001297811854897, Loss: 0.0010773499995046178\n",
      "Iteration:580, Price of Hedge: 0.07931894864311176, Loss: 0.0011692458270054385\n",
      "Iteration:590, Price of Hedge: 0.08230079125287092, Loss: 0.001166409778186406\n",
      "Iteration:600, Price of Hedge: 0.08536570344910502, Loss: 0.001043408541496005\n",
      "Iteration:610, Price of Hedge: 0.09089106288085702, Loss: 0.0009108137870297739\n",
      "Iteration:620, Price of Hedge: 0.09237557112633397, Loss: 0.00107038493455196\n",
      "Iteration:630, Price of Hedge: 0.08413428688534168, Loss: 0.0011235307277785544\n",
      "Iteration:640, Price of Hedge: 0.08593947149204838, Loss: 0.0012413251303920348\n",
      "Iteration:650, Price of Hedge: 0.08390966996707903, Loss: 0.0012625882477309337\n",
      "Iteration:660, Price of Hedge: 0.08513803009402068, Loss: 0.0013470545995184046\n",
      "Iteration:670, Price of Hedge: 0.08261781080576043, Loss: 0.0010334944925786793\n",
      "Iteration:680, Price of Hedge: 0.09106815688476218, Loss: 0.0011431899711236149\n",
      "Iteration:690, Price of Hedge: 0.09144076148382965, Loss: 0.0012386171234695098\n",
      "Iteration:700, Price of Hedge: 0.08563144971490431, Loss: 0.0010939149173221808\n",
      "Iteration:710, Price of Hedge: 0.0773995531012929, Loss: 0.0009781808196875686\n",
      "Iteration:720, Price of Hedge: 0.07769346224923482, Loss: 0.0009630546980619715\n",
      "Iteration:730, Price of Hedge: 0.08471707609512862, Loss: 0.0012504306026517753\n",
      "Iteration:740, Price of Hedge: 0.08726697088987692, Loss: 0.0010165977135564665\n",
      "Iteration:750, Price of Hedge: 0.09173263560623468, Loss: 0.0009216796221663826\n",
      "Iteration:760, Price of Hedge: 0.09762323144114475, Loss: 0.0013497133876719581\n",
      "Iteration:770, Price of Hedge: 0.08572852277212349, Loss: 0.0010142537915128313\n",
      "Iteration:780, Price of Hedge: 0.08035808258325404, Loss: 0.0012945457264011751\n",
      "Iteration:790, Price of Hedge: 0.08225327613554612, Loss: 0.001358162569069199\n",
      "Iteration:800, Price of Hedge: 0.07725556529826748, Loss: 0.0009329732585585449\n",
      "Iteration:810, Price of Hedge: 0.08199838333927688, Loss: 0.0010010978825897299\n",
      "Iteration:820, Price of Hedge: 0.0839658241966447, Loss: 0.001030383963842585\n",
      "Iteration:830, Price of Hedge: 0.08602689961980729, Loss: 0.0011978281651420454\n",
      "Iteration:840, Price of Hedge: 0.094115377613781, Loss: 0.0011454933851457571\n",
      "Iteration:850, Price of Hedge: 0.09261464374323794, Loss: 0.0010289076444307099\n",
      "Iteration:860, Price of Hedge: 0.09255496525488809, Loss: 0.000965353360767307\n",
      "Iteration:870, Price of Hedge: 0.08652619040632033, Loss: 0.0009676654855369283\n",
      "Iteration:880, Price of Hedge: 0.09128829830625022, Loss: 0.001101418830332168\n",
      "Iteration:890, Price of Hedge: 0.08109188472253663, Loss: 0.0009630810130473622\n",
      "Iteration:900, Price of Hedge: 0.08145052483602343, Loss: 0.0010556651114276506\n",
      "Iteration:910, Price of Hedge: 0.08146339773702493, Loss: 0.0010839155883596075\n",
      "Iteration:920, Price of Hedge: 0.08416661338295058, Loss: 0.0013363932537474366\n",
      "Iteration:930, Price of Hedge: 0.08916922855380278, Loss: 0.0010839481166054377\n",
      "Iteration:940, Price of Hedge: 0.08858939441941231, Loss: 0.0008816152396519339\n",
      "Iteration:950, Price of Hedge: 0.0883419711804777, Loss: 0.0010869872537607962\n",
      "Iteration:960, Price of Hedge: 0.08744294991810478, Loss: 0.0011198232387257256\n",
      "Iteration:970, Price of Hedge: 0.08977660180771921, Loss: 0.0010647149080007079\n",
      "Iteration:980, Price of Hedge: 0.09383245448492517, Loss: 0.0009739567163034924\n",
      "Iteration:990, Price of Hedge: 0.0816000641263372, Loss: 0.0010740684233634834\n",
      "tf.Tensor(0.089238144, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_118 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.09451724447660297, Loss: 0.0014630896747984234\n",
      "Iteration:20, Price of Hedge: 0.07302837282729513, Loss: 0.0014063578556691603\n",
      "Iteration:30, Price of Hedge: 0.08561155948446526, Loss: 0.0014478690141512373\n",
      "Iteration:40, Price of Hedge: 0.07182299055574504, Loss: 0.0017029131215864802\n",
      "Iteration:50, Price of Hedge: 0.07879768581842654, Loss: 0.0014486719866915632\n",
      "Iteration:60, Price of Hedge: 0.08375853228506003, Loss: 0.0014983585776256359\n",
      "Iteration:70, Price of Hedge: 0.07301307504912131, Loss: 0.0015426842212581616\n",
      "Iteration:80, Price of Hedge: 0.08451399458120648, Loss: 0.0016711421625580593\n",
      "Iteration:90, Price of Hedge: 0.0897161202250004, Loss: 0.0014597011331148213\n",
      "Iteration:100, Price of Hedge: 0.07046663433986282, Loss: 0.0016453049890779782\n",
      "Iteration:110, Price of Hedge: 0.0845455959547735, Loss: 0.0014334609505066264\n",
      "Iteration:120, Price of Hedge: 0.0840209024356966, Loss: 0.001347845998338304\n",
      "Iteration:130, Price of Hedge: 0.08108535860615973, Loss: 0.0013194783222584495\n",
      "Iteration:140, Price of Hedge: 0.07592822184109309, Loss: 0.001591050798920435\n",
      "Iteration:150, Price of Hedge: 0.07415682957414448, Loss: 0.001384831344819082\n",
      "Iteration:160, Price of Hedge: 0.082452755420357, Loss: 0.0012809081070510597\n",
      "Iteration:170, Price of Hedge: 0.08780534820135699, Loss: 0.0014402853033846253\n",
      "Iteration:180, Price of Hedge: 0.07716785647733104, Loss: 0.0015244375809483125\n",
      "Iteration:190, Price of Hedge: 0.07993494541520363, Loss: 0.0016971391752086619\n",
      "Iteration:200, Price of Hedge: 0.07788160464848773, Loss: 0.002123621270290954\n",
      "Iteration:210, Price of Hedge: 0.07886743027600289, Loss: 0.0016479508633961083\n",
      "Iteration:220, Price of Hedge: 0.080191171504066, Loss: 0.0016189117897028817\n",
      "Iteration:230, Price of Hedge: 0.08666967919925242, Loss: 0.0013390122039369956\n",
      "Iteration:240, Price of Hedge: 0.08628341419887989, Loss: 0.0014616028781238466\n",
      "Iteration:250, Price of Hedge: 0.07791603634492787, Loss: 0.001476850950214148\n",
      "Iteration:260, Price of Hedge: 0.07241141702018013, Loss: 0.0015729946985973964\n",
      "Iteration:270, Price of Hedge: 0.07649677366915456, Loss: 0.0012799261682443497\n",
      "Iteration:280, Price of Hedge: 0.08803465893331008, Loss: 0.0015160920757203657\n",
      "Iteration:290, Price of Hedge: 0.08144619748287028, Loss: 0.0013050324917366575\n",
      "Iteration:300, Price of Hedge: 0.0814803250950348, Loss: 0.0012956146508540378\n",
      "Iteration:310, Price of Hedge: 0.08473331731426015, Loss: 0.0013968345111877057\n",
      "Iteration:320, Price of Hedge: 0.07924893128939062, Loss: 0.001494758054115275\n",
      "Iteration:330, Price of Hedge: 0.08055179206386072, Loss: 0.0013815886320128535\n",
      "Iteration:340, Price of Hedge: 0.08209194773177729, Loss: 0.001601843963275629\n",
      "Iteration:350, Price of Hedge: 0.08240748584845221, Loss: 0.001228645205950052\n",
      "Iteration:360, Price of Hedge: 0.09056572389406768, Loss: 0.001375925306036585\n",
      "Iteration:370, Price of Hedge: 0.08271064227718626, Loss: 0.001309789412660578\n",
      "Iteration:380, Price of Hedge: 0.08049613684438839, Loss: 0.0018997389787037912\n",
      "Iteration:390, Price of Hedge: 0.07442184291886918, Loss: 0.001292969385679088\n",
      "Iteration:400, Price of Hedge: 0.08043963954538356, Loss: 0.001418609065140819\n",
      "Iteration:410, Price of Hedge: 0.08835970942988923, Loss: 0.0015186694823450253\n",
      "Iteration:420, Price of Hedge: 0.09125730510123446, Loss: 0.001412787605594934\n",
      "Iteration:430, Price of Hedge: 0.07365589361372997, Loss: 0.0011594288755110594\n",
      "Iteration:440, Price of Hedge: 0.07449180569336136, Loss: 0.0014276223131230558\n",
      "Iteration:450, Price of Hedge: 0.08603588180148734, Loss: 0.0013538891860018331\n",
      "Iteration:460, Price of Hedge: 0.08676548913717284, Loss: 0.001482283045439159\n",
      "Iteration:470, Price of Hedge: 0.07615667489944826, Loss: 0.0013753942550119636\n",
      "Iteration:480, Price of Hedge: 0.08102215585902571, Loss: 0.0008877970073889907\n",
      "Iteration:490, Price of Hedge: 0.08021191940810297, Loss: 0.0008925227401820779\n",
      "Iteration:500, Price of Hedge: 0.08358700536250865, Loss: 0.0012710647187426539\n",
      "Iteration:510, Price of Hedge: 0.08709347131805033, Loss: 0.0011318017957098637\n",
      "Iteration:520, Price of Hedge: 0.0798809587607309, Loss: 0.0014736887661363606\n",
      "Iteration:530, Price of Hedge: 0.07415508303881779, Loss: 0.0009815076551670022\n",
      "Iteration:540, Price of Hedge: 0.082129973860296, Loss: 0.00102199192007566\n",
      "Iteration:550, Price of Hedge: 0.07520885980638639, Loss: 0.0009042870615096898\n",
      "Iteration:560, Price of Hedge: 0.08878417209350005, Loss: 0.0011048507430102105\n",
      "Iteration:570, Price of Hedge: 0.08256844779168375, Loss: 0.000905522647536694\n",
      "Iteration:580, Price of Hedge: 0.07826301209748295, Loss: 0.0007497186850990101\n",
      "Iteration:590, Price of Hedge: 0.0792156535537913, Loss: 0.0009394914560741041\n",
      "Iteration:600, Price of Hedge: 0.0735224785870571, Loss: 0.0008805577061765436\n",
      "Iteration:610, Price of Hedge: 0.07192876510146676, Loss: 0.0011016563961725012\n",
      "Iteration:620, Price of Hedge: 0.07461471031994336, Loss: 0.000910465905359481\n",
      "Iteration:630, Price of Hedge: 0.084130294804595, Loss: 0.001198850429227294\n",
      "Iteration:640, Price of Hedge: 0.09329364833664613, Loss: 0.0010064738757278313\n",
      "Iteration:650, Price of Hedge: 0.08733080519666032, Loss: 0.0009779413655033764\n",
      "Iteration:660, Price of Hedge: 0.0802351389715085, Loss: 0.0010011665330261544\n",
      "Iteration:670, Price of Hedge: 0.082530476242394, Loss: 0.0009609917128531099\n",
      "Iteration:680, Price of Hedge: 0.08151784441642747, Loss: 0.0009074272555186669\n",
      "Iteration:690, Price of Hedge: 0.07857534563371474, Loss: 0.0007640703420851213\n",
      "Iteration:700, Price of Hedge: 0.07905867589427373, Loss: 0.0009639042091412753\n",
      "Iteration:710, Price of Hedge: 0.08469724824095125, Loss: 0.0008770379550518959\n",
      "Iteration:720, Price of Hedge: 0.08385879432865694, Loss: 0.0009613640211649344\n",
      "Iteration:730, Price of Hedge: 0.08712943902993402, Loss: 0.000966118992830678\n",
      "Iteration:740, Price of Hedge: 0.08741143431189756, Loss: 0.0009411292593430876\n",
      "Iteration:750, Price of Hedge: 0.08132679372397433, Loss: 0.0009813936235636422\n",
      "Iteration:760, Price of Hedge: 0.0741696167077862, Loss: 0.0010158103350815574\n",
      "Iteration:770, Price of Hedge: 0.08120749912353631, Loss: 0.0009425208469385771\n",
      "Iteration:780, Price of Hedge: 0.07770827661138072, Loss: 0.000766326060196243\n",
      "Iteration:790, Price of Hedge: 0.08270307135842643, Loss: 0.0009780390720695031\n",
      "Iteration:800, Price of Hedge: 0.08406857349367557, Loss: 0.001148781174547331\n",
      "Iteration:810, Price of Hedge: 0.08335845873976098, Loss: 0.0008759874876373974\n",
      "Iteration:820, Price of Hedge: 0.09499846953833072, Loss: 0.0008355881982023972\n",
      "Iteration:830, Price of Hedge: 0.08619830958686805, Loss: 0.001036309099557764\n",
      "Iteration:840, Price of Hedge: 0.08250155704807867, Loss: 0.0010206079467699248\n",
      "Iteration:850, Price of Hedge: 0.08528235316945257, Loss: 0.00075294245355233\n",
      "Iteration:860, Price of Hedge: 0.09055339678535575, Loss: 0.0009028426002861468\n",
      "Iteration:870, Price of Hedge: 0.08511301721309224, Loss: 0.0010178603455406777\n",
      "Iteration:880, Price of Hedge: 0.07348572337486985, Loss: 0.000823980670329405\n",
      "Iteration:890, Price of Hedge: 0.0739446879082152, Loss: 0.0010665687743557585\n",
      "Iteration:900, Price of Hedge: 0.0749443298776896, Loss: 0.0008672655319239997\n",
      "Iteration:910, Price of Hedge: 0.08331655748598621, Loss: 0.0010438321396636142\n",
      "Iteration:920, Price of Hedge: 0.06959689873234254, Loss: 0.0008988080622597928\n",
      "Iteration:930, Price of Hedge: 0.07102727997675799, Loss: 0.000964374954991043\n",
      "Iteration:940, Price of Hedge: 0.07595932420456677, Loss: 0.0008617633852332496\n",
      "Iteration:950, Price of Hedge: 0.07283559119358074, Loss: 0.0009887799110255059\n",
      "Iteration:960, Price of Hedge: 0.08392086650604824, Loss: 0.0008277249516303265\n",
      "Iteration:970, Price of Hedge: 0.08813019597508572, Loss: 0.0009721327588785967\n",
      "Iteration:980, Price of Hedge: 0.08780047505591426, Loss: 0.0008118155937034467\n",
      "Iteration:990, Price of Hedge: 0.08066951166369166, Loss: 0.0007967055534578105\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 18 \n",
      "\n",
      "tf.Tensor(0.25684664, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_119 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.2625844137451452, Loss: 0.004379211920434533\n",
      "Iteration:20, Price of Hedge: 0.29217733722142897, Loss: 0.002558323124724815\n",
      "Iteration:30, Price of Hedge: 0.27375529616406025, Loss: 0.002710224533655725\n",
      "Iteration:40, Price of Hedge: 0.2914890588325903, Loss: 0.002458761287045652\n",
      "Iteration:50, Price of Hedge: 0.27661241471263054, Loss: 0.0023398211059628025\n",
      "Iteration:60, Price of Hedge: 0.29136323899139993, Loss: 0.002411283377868534\n",
      "Iteration:70, Price of Hedge: 0.2969023877264675, Loss: 0.0022044766255452596\n",
      "Iteration:80, Price of Hedge: 0.3009195948288834, Loss: 0.002308800004117706\n",
      "Iteration:90, Price of Hedge: 0.30718136752283837, Loss: 0.0019831287178263767\n",
      "Iteration:100, Price of Hedge: 0.3260752757030417, Loss: 0.002204578526658718\n",
      "Iteration:110, Price of Hedge: 0.29857973879175287, Loss: 0.0028707376991314424\n",
      "Iteration:120, Price of Hedge: 0.28329701383984796, Loss: 0.0022538917683356586\n",
      "Iteration:130, Price of Hedge: 0.27506518380452005, Loss: 0.0026542078451504245\n",
      "Iteration:140, Price of Hedge: 0.25885290710602077, Loss: 0.0026181306236473744\n",
      "Iteration:150, Price of Hedge: 0.2588478948171911, Loss: 0.001933781657439293\n",
      "Iteration:160, Price of Hedge: 0.3077297859659808, Loss: 0.002689546172335144\n",
      "Iteration:170, Price of Hedge: 0.25469817532884065, Loss: 0.002163389562619189\n",
      "Iteration:180, Price of Hedge: 0.2395349763781752, Loss: 0.002147239793576627\n",
      "Iteration:190, Price of Hedge: 0.20812941275657548, Loss: 0.002352513579367743\n",
      "Iteration:200, Price of Hedge: 0.22818647097385847, Loss: 0.0026517072630234395\n",
      "Iteration:210, Price of Hedge: 0.2161374270083101, Loss: 0.0023581795482658483\n",
      "Iteration:220, Price of Hedge: 0.23907677913396697, Loss: 0.0020815491740381995\n",
      "Iteration:230, Price of Hedge: 0.2550020168602259, Loss: 0.0024363181230352194\n",
      "Iteration:240, Price of Hedge: 0.2544517757666, Loss: 0.002359401249169779\n",
      "Iteration:250, Price of Hedge: 0.2695304777800061, Loss: 0.00223608488249607\n",
      "Iteration:260, Price of Hedge: 0.25217816168297985, Loss: 0.0023708052742165584\n",
      "Iteration:270, Price of Hedge: 0.2837971035662633, Loss: 0.002497818337397062\n",
      "Iteration:280, Price of Hedge: 0.26498077194726477, Loss: 0.002674692193870709\n",
      "Iteration:290, Price of Hedge: 0.2852815669483476, Loss: 0.002054254582562787\n",
      "Iteration:300, Price of Hedge: 0.2923060334329136, Loss: 0.00237614662799559\n",
      "Iteration:310, Price of Hedge: 0.2368677125084858, Loss: 0.00220968826677157\n",
      "Iteration:320, Price of Hedge: 0.2529937123376129, Loss: 0.0021463342531142346\n",
      "Iteration:330, Price of Hedge: 0.3083710171892136, Loss: 0.0024267447581664656\n",
      "Iteration:340, Price of Hedge: 0.25083341585202273, Loss: 0.0023264773998960876\n",
      "Iteration:350, Price of Hedge: 0.25080245927271677, Loss: 0.002353379961323654\n",
      "Iteration:360, Price of Hedge: 0.2683936849776529, Loss: 0.0024062497298535045\n",
      "Iteration:370, Price of Hedge: 0.30464671571528185, Loss: 0.003175100973117284\n",
      "Iteration:380, Price of Hedge: 0.2708450359623299, Loss: 0.002103642136405437\n",
      "Iteration:390, Price of Hedge: 0.30543506900723116, Loss: 0.0023056232702793667\n",
      "Iteration:400, Price of Hedge: 0.2815292991810594, Loss: 0.0024847583080108257\n",
      "Iteration:410, Price of Hedge: 0.2819603275414977, Loss: 0.00272624103028134\n",
      "Iteration:420, Price of Hedge: 0.26794972719034715, Loss: 0.0020955278708861603\n",
      "Iteration:430, Price of Hedge: 0.27537366739885555, Loss: 0.001973523536671107\n",
      "Iteration:440, Price of Hedge: 0.2694211472299088, Loss: 0.00209228817194933\n",
      "Iteration:450, Price of Hedge: 0.24134600746486112, Loss: 0.0021482950708280103\n",
      "Iteration:460, Price of Hedge: 0.22040912168448726, Loss: 0.0023313726581893454\n",
      "Iteration:470, Price of Hedge: 0.2567450403007456, Loss: 0.00207693536751028\n",
      "Iteration:480, Price of Hedge: 0.24357807081323982, Loss: 0.0019766862535440578\n",
      "Iteration:490, Price of Hedge: 0.2586354705991198, Loss: 0.0023758269076898262\n",
      "Iteration:500, Price of Hedge: 0.2635114308684109, Loss: 0.0022075583555070774\n",
      "Iteration:510, Price of Hedge: 0.25441085156746224, Loss: 0.0019267217792053426\n",
      "Iteration:520, Price of Hedge: 0.2723843782113164, Loss: 0.0024285589539724483\n",
      "Iteration:530, Price of Hedge: 0.27362210028419437, Loss: 0.001793548927211186\n",
      "Iteration:540, Price of Hedge: 0.23626521260802774, Loss: 0.0016514606177554735\n",
      "Iteration:550, Price of Hedge: 0.2543840529095718, Loss: 0.0013473834678567663\n",
      "Iteration:560, Price of Hedge: 0.2829902959381684, Loss: 0.0017387568319994994\n",
      "Iteration:570, Price of Hedge: 0.2796636740166093, Loss: 0.0018778561904547741\n",
      "Iteration:580, Price of Hedge: 0.238806329129018, Loss: 0.0021592790318961663\n",
      "Iteration:590, Price of Hedge: 0.2415673740618672, Loss: 0.0015733585315944154\n",
      "Iteration:600, Price of Hedge: 0.27803522124632707, Loss: 0.0013370268216126191\n",
      "Iteration:610, Price of Hedge: 0.2567675101637377, Loss: 0.0014456505161696163\n",
      "Iteration:620, Price of Hedge: 0.2552327530198738, Loss: 0.0018635003704904117\n",
      "Iteration:630, Price of Hedge: 0.26413511908073983, Loss: 0.0013666626912909208\n",
      "Iteration:640, Price of Hedge: 0.3065771019297244, Loss: 0.0014529133066644273\n",
      "Iteration:650, Price of Hedge: 0.275492908610957, Loss: 0.0021708690598487347\n",
      "Iteration:660, Price of Hedge: 0.2265480933021152, Loss: 0.001362352696925506\n",
      "Iteration:670, Price of Hedge: 0.24734252755563657, Loss: 0.0012881711337344281\n",
      "Iteration:680, Price of Hedge: 0.22865951997161602, Loss: 0.001948147934504818\n",
      "Iteration:690, Price of Hedge: 0.2653596554165261, Loss: 0.002142774388888613\n",
      "Iteration:700, Price of Hedge: 0.29265034350081576, Loss: 0.0016850892089000811\n",
      "Iteration:710, Price of Hedge: 0.2689470872307112, Loss: 0.0014397307956996784\n",
      "Iteration:720, Price of Hedge: 0.2926271901438923, Loss: 0.001321282320862993\n",
      "Iteration:730, Price of Hedge: 0.29496041059410627, Loss: 0.0012941629414549348\n",
      "Iteration:740, Price of Hedge: 0.26928564455802473, Loss: 0.0017111022492542704\n",
      "Iteration:750, Price of Hedge: 0.274252993661716, Loss: 0.001447005934473522\n",
      "Iteration:760, Price of Hedge: 0.2636374215830841, Loss: 0.0012526445787287787\n",
      "Iteration:770, Price of Hedge: 0.2812641604935351, Loss: 0.001498731095409078\n",
      "Iteration:780, Price of Hedge: 0.24027044432718866, Loss: 0.0016497764682394831\n",
      "Iteration:790, Price of Hedge: 0.2691994104070233, Loss: 0.001546370755916948\n",
      "Iteration:800, Price of Hedge: 0.2845330271778977, Loss: 0.001472358063785073\n",
      "Iteration:810, Price of Hedge: 0.27305742038126934, Loss: 0.0020694273913669293\n",
      "Iteration:820, Price of Hedge: 0.25706542808105154, Loss: 0.0014356050243079397\n",
      "Iteration:830, Price of Hedge: 0.24335909644499337, Loss: 0.0012501080642222662\n",
      "Iteration:840, Price of Hedge: 0.21302442541920213, Loss: 0.0015408843376707225\n",
      "Iteration:850, Price of Hedge: 0.24577069086599862, Loss: 0.0015396268156330217\n",
      "Iteration:860, Price of Hedge: 0.25418045715478, Loss: 0.0013082887051937165\n",
      "Iteration:870, Price of Hedge: 0.260736331591599, Loss: 0.0011705761363458354\n",
      "Iteration:880, Price of Hedge: 0.25490142933666676, Loss: 0.0013114366263809794\n",
      "Iteration:890, Price of Hedge: 0.2877803922823375, Loss: 0.0013620505534493565\n",
      "Iteration:900, Price of Hedge: 0.29936943059265103, Loss: 0.001389330682976353\n",
      "Iteration:910, Price of Hedge: 0.26516391984194454, Loss: 0.0013782117808048943\n",
      "Iteration:920, Price of Hedge: 0.2599326851229364, Loss: 0.0013959458006736146\n",
      "Iteration:930, Price of Hedge: 0.2748129745438632, Loss: 0.0017934597081140312\n",
      "Iteration:940, Price of Hedge: 0.276878550162138, Loss: 0.0014811710639043851\n",
      "Iteration:950, Price of Hedge: 0.3041146726475773, Loss: 0.0017017520433741606\n",
      "Iteration:960, Price of Hedge: 0.23819811920634207, Loss: 0.0014236921611684105\n",
      "Iteration:970, Price of Hedge: 0.22887097590661795, Loss: 0.0015697095595173958\n",
      "Iteration:980, Price of Hedge: 0.2765549727434859, Loss: 0.0015322713574225876\n",
      "Iteration:990, Price of Hedge: 0.2595802870435136, Loss: 0.001606151110874787\n",
      "tf.Tensor(0.35676047, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_120 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.46842051924920436, Loss: 0.004747921742722116\n",
      "Iteration:20, Price of Hedge: 0.3364825245271902, Loss: 0.004618845515731351\n",
      "Iteration:30, Price of Hedge: 0.3823793983255115, Loss: 0.005965893243893339\n",
      "Iteration:40, Price of Hedge: 0.3519449514252045, Loss: 0.004902052739115836\n",
      "Iteration:50, Price of Hedge: 0.39601604205948887, Loss: 0.004744105123289222\n",
      "Iteration:60, Price of Hedge: 0.350761624077694, Loss: 0.003995266324244317\n",
      "Iteration:70, Price of Hedge: 0.3580632758303238, Loss: 0.003509814759524721\n",
      "Iteration:80, Price of Hedge: 0.3603884937057586, Loss: 0.004758456715914816\n",
      "Iteration:90, Price of Hedge: 0.37026199072737426, Loss: 0.004528870837394816\n",
      "Iteration:100, Price of Hedge: 0.3503064740772629, Loss: 0.004391464528116095\n",
      "Iteration:110, Price of Hedge: 0.3756629312937463, Loss: 0.003690353941201674\n",
      "Iteration:120, Price of Hedge: 0.3981947928812246, Loss: 0.0035281491727442438\n",
      "Iteration:130, Price of Hedge: 0.36352615803422167, Loss: 0.004463805863994042\n",
      "Iteration:140, Price of Hedge: 0.35426561267443046, Loss: 0.0039321717356924244\n",
      "Iteration:150, Price of Hedge: 0.3974005729330315, Loss: 0.004601206833476423\n",
      "Iteration:160, Price of Hedge: 0.38544919740237726, Loss: 0.003707121346687381\n",
      "Iteration:170, Price of Hedge: 0.38630293828042284, Loss: 0.004681568543454695\n",
      "Iteration:180, Price of Hedge: 0.4060577355460367, Loss: 0.0040404329915729505\n",
      "Iteration:190, Price of Hedge: 0.3529710466895977, Loss: 0.003948114587626872\n",
      "Iteration:200, Price of Hedge: 0.33763925256920685, Loss: 0.004833838175841443\n",
      "Iteration:210, Price of Hedge: 0.3428024226842211, Loss: 0.003835435985225377\n",
      "Iteration:220, Price of Hedge: 0.3230433535815365, Loss: 0.004385899125382364\n",
      "Iteration:230, Price of Hedge: 0.35063093434224296, Loss: 0.004241580004760514\n",
      "Iteration:240, Price of Hedge: 0.3815757233779351, Loss: 0.0035291383700159383\n",
      "Iteration:250, Price of Hedge: 0.40342799264528534, Loss: 0.004326468527084693\n",
      "Iteration:260, Price of Hedge: 0.38308396665304656, Loss: 0.003964260796805208\n",
      "Iteration:270, Price of Hedge: 0.371056410027964, Loss: 0.004498864741837049\n",
      "Iteration:280, Price of Hedge: 0.3525350060403298, Loss: 0.0041088771660898965\n",
      "Iteration:290, Price of Hedge: 0.3610339113293207, Loss: 0.004135047062961528\n",
      "Iteration:300, Price of Hedge: 0.3426832384299473, Loss: 0.0039216016088404965\n",
      "Iteration:310, Price of Hedge: 0.35907783713462604, Loss: 0.004103578308190059\n",
      "Iteration:320, Price of Hedge: 0.39372032833875603, Loss: 0.004136636097355239\n",
      "Iteration:330, Price of Hedge: 0.36201717430735125, Loss: 0.004446141817706506\n",
      "Iteration:340, Price of Hedge: 0.365633996360583, Loss: 0.004067887999430031\n",
      "Iteration:350, Price of Hedge: 0.3750815627473315, Loss: 0.004616579662151743\n",
      "Iteration:360, Price of Hedge: 0.40250470625972806, Loss: 0.004741752498019114\n",
      "Iteration:370, Price of Hedge: 0.37241644903563437, Loss: 0.0033592262730185226\n",
      "Iteration:380, Price of Hedge: 0.42859628967825925, Loss: 0.0035428507445215193\n",
      "Iteration:390, Price of Hedge: 0.4180576961036422, Loss: 0.004261642509570063\n",
      "Iteration:400, Price of Hedge: 0.35582041897361305, Loss: 0.003295777255484666\n",
      "Iteration:410, Price of Hedge: 0.32292923857392, Loss: 0.0026895886682143377\n",
      "Iteration:420, Price of Hedge: 0.30613921015105916, Loss: 0.0023033707661906043\n",
      "Iteration:430, Price of Hedge: 0.3322688983562614, Loss: 0.0029210463678424723\n",
      "Iteration:440, Price of Hedge: 0.3506890028474913, Loss: 0.0026762625389772365\n",
      "Iteration:450, Price of Hedge: 0.353329937961368, Loss: 0.0032870785047578455\n",
      "Iteration:460, Price of Hedge: 0.33355563263979776, Loss: 0.003009594875573618\n",
      "Iteration:470, Price of Hedge: 0.33799085323904304, Loss: 0.0022777849095434897\n",
      "Iteration:480, Price of Hedge: 0.3788052092062457, Loss: 0.002298086592730697\n",
      "Iteration:490, Price of Hedge: 0.39416351719538906, Loss: 0.002602765359683534\n",
      "Iteration:500, Price of Hedge: 0.36519325669053726, Loss: 0.002521387753451876\n",
      "Iteration:510, Price of Hedge: 0.3397267284721977, Loss: 0.0030836358241277837\n",
      "Iteration:520, Price of Hedge: 0.3351342473109213, Loss: 0.0027024598023051016\n",
      "Iteration:530, Price of Hedge: 0.34067003553415987, Loss: 0.002134598938202958\n",
      "Iteration:540, Price of Hedge: 0.32837118877617116, Loss: 0.0027341839773347585\n",
      "Iteration:550, Price of Hedge: 0.3419394831170166, Loss: 0.0030125987335055003\n",
      "Iteration:560, Price of Hedge: 0.3540442175985106, Loss: 0.0028298437588396117\n",
      "Iteration:570, Price of Hedge: 0.3751271005305057, Loss: 0.0024646802287952908\n",
      "Iteration:580, Price of Hedge: 0.32592721383016965, Loss: 0.002313771799491815\n",
      "Iteration:590, Price of Hedge: 0.31215028296678893, Loss: 0.002946725225942481\n",
      "Iteration:600, Price of Hedge: 0.34429605627655063, Loss: 0.002720330320717723\n",
      "Iteration:610, Price of Hedge: 0.36012566181025246, Loss: 0.0030238899553546306\n",
      "Iteration:620, Price of Hedge: 0.3663127912711246, Loss: 0.0021632304811866065\n",
      "Iteration:630, Price of Hedge: 0.36900154248127987, Loss: 0.0034376349524860125\n",
      "Iteration:640, Price of Hedge: 0.3905707313454087, Loss: 0.002821432689640524\n",
      "Iteration:650, Price of Hedge: 0.3806329004575076, Loss: 0.0028639913114408607\n",
      "Iteration:660, Price of Hedge: 0.3843919177273676, Loss: 0.002960261609660408\n",
      "Iteration:670, Price of Hedge: 0.35875024418912743, Loss: 0.002958634306726271\n",
      "Iteration:680, Price of Hedge: 0.3535650313948281, Loss: 0.0027345323990458415\n",
      "Iteration:690, Price of Hedge: 0.3469548191904693, Loss: 0.0027359147388229532\n",
      "Iteration:700, Price of Hedge: 0.39127940063653166, Loss: 0.003579514453655741\n",
      "Iteration:710, Price of Hedge: 0.45339547150940684, Loss: 0.003064417007139708\n",
      "Iteration:720, Price of Hedge: 0.42021055959272924, Loss: 0.002651058032785292\n",
      "Iteration:730, Price of Hedge: 0.40078574750137363, Loss: 0.002986060390686518\n",
      "Iteration:740, Price of Hedge: 0.4079062733622038, Loss: 0.0033587060878585537\n",
      "Iteration:750, Price of Hedge: 0.38833146283183734, Loss: 0.0023038849440796924\n",
      "Iteration:760, Price of Hedge: 0.4273023502295302, Loss: 0.0026369269292501715\n",
      "Iteration:770, Price of Hedge: 0.44080858901719466, Loss: 0.002612352296534648\n",
      "Iteration:780, Price of Hedge: 0.3816067369150687, Loss: 0.0026989086152485295\n",
      "Iteration:790, Price of Hedge: 0.3767967053312361, Loss: 0.0026077769810386674\n",
      "Iteration:800, Price of Hedge: 0.3728172612685256, Loss: 0.002504855966479602\n",
      "Iteration:810, Price of Hedge: 0.37832952590896124, Loss: 0.002542902682865478\n",
      "Iteration:820, Price of Hedge: 0.39474064238364687, Loss: 0.0027379478662788114\n",
      "Iteration:830, Price of Hedge: 0.3877731337266908, Loss: 0.0024036719431711263\n",
      "Iteration:840, Price of Hedge: 0.4200883565735921, Loss: 0.0030956677202273572\n",
      "Iteration:850, Price of Hedge: 0.39356050467448256, Loss: 0.003229425168674815\n",
      "Iteration:860, Price of Hedge: 0.3747081757084345, Loss: 0.002586183957103616\n",
      "Iteration:870, Price of Hedge: 0.4138980374743738, Loss: 0.0031540991091351996\n",
      "Iteration:880, Price of Hedge: 0.3816811523168411, Loss: 0.002391017738306611\n",
      "Iteration:890, Price of Hedge: 0.3621629009092913, Loss: 0.0024373284570007535\n",
      "Iteration:900, Price of Hedge: 0.374665314943158, Loss: 0.0025215123486997727\n",
      "Iteration:910, Price of Hedge: 0.3651736062400118, Loss: 0.0023606487590893455\n",
      "Iteration:920, Price of Hedge: 0.407896020953234, Loss: 0.0025404303571607834\n",
      "Iteration:930, Price of Hedge: 0.38438411450498505, Loss: 0.0025849453468446137\n",
      "Iteration:940, Price of Hedge: 0.35837426556907415, Loss: 0.0027255486366894563\n",
      "Iteration:950, Price of Hedge: 0.39450167581790935, Loss: 0.002827388342489989\n",
      "Iteration:960, Price of Hedge: 0.3859442463610492, Loss: 0.0022141318672912022\n",
      "Iteration:970, Price of Hedge: 0.36627685088190276, Loss: 0.0026512925388411544\n",
      "Iteration:980, Price of Hedge: 0.35170413373006965, Loss: 0.0022714981893210417\n",
      "Iteration:990, Price of Hedge: 0.3505637241056632, Loss: 0.002637409958327286\n",
      "tf.Tensor(0.27859703, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_121 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.13251771149142824, Loss: 0.0027459217396526903\n",
      "Iteration:20, Price of Hedge: 0.3218241428026317, Loss: 0.0029512847445409603\n",
      "Iteration:30, Price of Hedge: 0.27553351954204286, Loss: 0.0020040164436617267\n",
      "Iteration:40, Price of Hedge: 0.22130969613628507, Loss: 0.0020832260925799815\n",
      "Iteration:50, Price of Hedge: 0.2540596780813331, Loss: 0.0021368136187343233\n",
      "Iteration:60, Price of Hedge: 0.27978234565043464, Loss: 0.0018844454991364\n",
      "Iteration:70, Price of Hedge: 0.2649645104874821, Loss: 0.002936392942519128\n",
      "Iteration:80, Price of Hedge: 0.272401522517427, Loss: 0.002523932166407139\n",
      "Iteration:90, Price of Hedge: 0.2773921388936969, Loss: 0.002728797902761393\n",
      "Iteration:100, Price of Hedge: 0.2607062009007933, Loss: 0.0027030280456321163\n",
      "Iteration:110, Price of Hedge: 0.25449238669768587, Loss: 0.0023511319070651736\n",
      "Iteration:120, Price of Hedge: 0.25687182842500533, Loss: 0.0020236493173575454\n",
      "Iteration:130, Price of Hedge: 0.29226149241172267, Loss: 0.002942697684554218\n",
      "Iteration:140, Price of Hedge: 0.3103422991238801, Loss: 0.0023312387182978568\n",
      "Iteration:150, Price of Hedge: 0.284531660190035, Loss: 0.0025714396669556327\n",
      "Iteration:160, Price of Hedge: 0.30735562999641103, Loss: 0.0026424471662065407\n",
      "Iteration:170, Price of Hedge: 0.3020594348750137, Loss: 0.0025127593100435107\n",
      "Iteration:180, Price of Hedge: 0.24290491472763165, Loss: 0.0025782180934242446\n",
      "Iteration:190, Price of Hedge: 0.287322963968802, Loss: 0.0026636397054162096\n",
      "Iteration:200, Price of Hedge: 0.28426133834019823, Loss: 0.0018458590183373146\n",
      "Iteration:210, Price of Hedge: 0.25262468257252807, Loss: 0.0023447991310993066\n",
      "Iteration:220, Price of Hedge: 0.24318135954393652, Loss: 0.002606814927731693\n",
      "Iteration:230, Price of Hedge: 0.27448185021305277, Loss: 0.0025208920423584577\n",
      "Iteration:240, Price of Hedge: 0.27286900388753565, Loss: 0.0023783581936457575\n",
      "Iteration:250, Price of Hedge: 0.29256718507250523, Loss: 0.0024644577372811894\n",
      "Iteration:260, Price of Hedge: 0.2841071535008581, Loss: 0.0025142931665417256\n",
      "Iteration:270, Price of Hedge: 0.273173414997197, Loss: 0.002552796435514537\n",
      "Iteration:280, Price of Hedge: 0.2812359378899543, Loss: 0.0027085676393502124\n",
      "Iteration:290, Price of Hedge: 0.28337353668124193, Loss: 0.0021641017579558273\n",
      "Iteration:300, Price of Hedge: 0.28545813621393845, Loss: 0.0022499452138585283\n",
      "Iteration:310, Price of Hedge: 0.27697423931252274, Loss: 0.0022202757479615975\n",
      "Iteration:320, Price of Hedge: 0.2919697259397907, Loss: 0.0018947975843045084\n",
      "Iteration:330, Price of Hedge: 0.27940169648851737, Loss: 0.0022030455601265595\n",
      "Iteration:340, Price of Hedge: 0.263676722484135, Loss: 0.0024174699769096363\n",
      "Iteration:350, Price of Hedge: 0.24359646819155784, Loss: 0.002353789123218086\n",
      "Iteration:360, Price of Hedge: 0.2796952001741914, Loss: 0.002159037183620338\n",
      "Iteration:370, Price of Hedge: 0.28128930737442487, Loss: 0.003887581766368342\n",
      "Iteration:380, Price of Hedge: 0.27452659058664036, Loss: 0.0020681520700081\n",
      "Iteration:390, Price of Hedge: 0.2799218068913376, Loss: 0.0017596671407235308\n",
      "Iteration:400, Price of Hedge: 0.28610338296401777, Loss: 0.0022821457432198764\n",
      "Iteration:410, Price of Hedge: 0.28959774568788815, Loss: 0.002823706775406154\n",
      "Iteration:420, Price of Hedge: 0.28463481081583664, Loss: 0.0018143301908570386\n",
      "Iteration:430, Price of Hedge: 0.2747651869264985, Loss: 0.0015797623935990379\n",
      "Iteration:440, Price of Hedge: 0.2648613598616805, Loss: 0.0014901568286843968\n",
      "Iteration:450, Price of Hedge: 0.2866825301551557, Loss: 0.0013285926132960645\n",
      "Iteration:460, Price of Hedge: 0.26289862160115546, Loss: 0.001827799604629221\n",
      "Iteration:470, Price of Hedge: 0.23148625151915636, Loss: 0.0014860998071705156\n",
      "Iteration:480, Price of Hedge: 0.261558460875321, Loss: 0.0021403516787915633\n",
      "Iteration:490, Price of Hedge: 0.2722326425585635, Loss: 0.0015532182660006888\n",
      "Iteration:500, Price of Hedge: 0.28111225396729933, Loss: 0.001900945024839129\n",
      "Iteration:510, Price of Hedge: 0.27214407313663, Loss: 0.0014862323008671629\n",
      "Iteration:520, Price of Hedge: 0.2793933236878587, Loss: 0.0014791070101280667\n",
      "Iteration:530, Price of Hedge: 0.2552088307322776, Loss: 0.0014235750193862362\n",
      "Iteration:540, Price of Hedge: 0.22727265382714135, Loss: 0.0015424840516571113\n",
      "Iteration:550, Price of Hedge: 0.3004519425852919, Loss: 0.001598810893333069\n",
      "Iteration:560, Price of Hedge: 0.27344795172627695, Loss: 0.0015419954602921447\n",
      "Iteration:570, Price of Hedge: 0.23760279599216289, Loss: 0.0014039948761792598\n",
      "Iteration:580, Price of Hedge: 0.26726486627116514, Loss: 0.0016051363270789707\n",
      "Iteration:590, Price of Hedge: 0.2799027260190883, Loss: 0.0012317982363150514\n",
      "Iteration:600, Price of Hedge: 0.3056678271697592, Loss: 0.0013986779964667794\n",
      "Iteration:610, Price of Hedge: 0.2881438686592304, Loss: 0.0014935969924754322\n",
      "Iteration:620, Price of Hedge: 0.283368125687619, Loss: 0.0014239824013485558\n",
      "Iteration:630, Price of Hedge: 0.2634027838122449, Loss: 0.0016617697620613602\n",
      "Iteration:640, Price of Hedge: 0.208325746388347, Loss: 0.0015920711803879106\n",
      "Iteration:650, Price of Hedge: 0.2611049056940629, Loss: 0.0011670576555418365\n",
      "Iteration:660, Price of Hedge: 0.23836419399219577, Loss: 0.001625288607214459\n",
      "Iteration:670, Price of Hedge: 0.23734788123469455, Loss: 0.0017112670042204623\n",
      "Iteration:680, Price of Hedge: 0.25578048796908487, Loss: 0.001540422222795934\n",
      "Iteration:690, Price of Hedge: 0.2674537669064335, Loss: 0.0013060508855448848\n",
      "Iteration:700, Price of Hedge: 0.2521841992127065, Loss: 0.001168283250047264\n",
      "Iteration:710, Price of Hedge: 0.25372838287703986, Loss: 0.001261745594113095\n",
      "Iteration:720, Price of Hedge: 0.20352065589605955, Loss: 0.0016792749494078272\n",
      "Iteration:730, Price of Hedge: 0.2592659083140205, Loss: 0.0014711057702979534\n",
      "Iteration:740, Price of Hedge: 0.27601583842624394, Loss: 0.0019800747993038216\n",
      "Iteration:750, Price of Hedge: 0.2896710504120222, Loss: 0.0017885608899565475\n",
      "Iteration:760, Price of Hedge: 0.2474972250154252, Loss: 0.0013705733133885234\n",
      "Iteration:770, Price of Hedge: 0.20213155415685122, Loss: 0.0011868054461046883\n",
      "Iteration:780, Price of Hedge: 0.21090190621277427, Loss: 0.0015617608276846107\n",
      "Iteration:790, Price of Hedge: 0.28237529379454995, Loss: 0.0016716813140315477\n",
      "Iteration:800, Price of Hedge: 0.31470694897471674, Loss: 0.0014984560958976488\n",
      "Iteration:810, Price of Hedge: 0.28330854779993897, Loss: 0.0014758311563201952\n",
      "Iteration:820, Price of Hedge: 0.2766237493203249, Loss: 0.0012921492820065605\n",
      "Iteration:830, Price of Hedge: 0.24095291301761107, Loss: 0.0011869894465868502\n",
      "Iteration:840, Price of Hedge: 0.2256721958291294, Loss: 0.001700389950324832\n",
      "Iteration:850, Price of Hedge: 0.3169456763889258, Loss: 0.0016615439331745473\n",
      "Iteration:860, Price of Hedge: 0.2937680269520058, Loss: 0.001234150305356374\n",
      "Iteration:870, Price of Hedge: 0.27511761348483504, Loss: 0.001449824234482644\n",
      "Iteration:880, Price of Hedge: 0.2456904942447238, Loss: 0.0015115826502466012\n",
      "Iteration:890, Price of Hedge: 0.26082515732375666, Loss: 0.0013611461254445345\n",
      "Iteration:900, Price of Hedge: 0.2780044640194177, Loss: 0.0014670193799042107\n",
      "Iteration:910, Price of Hedge: 0.28236276307247576, Loss: 0.0012981005962715009\n",
      "Iteration:920, Price of Hedge: 0.2692722594685364, Loss: 0.001213844394830399\n",
      "Iteration:930, Price of Hedge: 0.27100053083170506, Loss: 0.0012272438350213965\n",
      "Iteration:940, Price of Hedge: 0.2803985439084329, Loss: 0.0015176986082319766\n",
      "Iteration:950, Price of Hedge: 0.2542262227692646, Loss: 0.0011709740624188058\n",
      "Iteration:960, Price of Hedge: 0.279809457576377, Loss: 0.0015866363801729565\n",
      "Iteration:970, Price of Hedge: 0.27508796693556403, Loss: 0.0013379941034701748\n",
      "Iteration:980, Price of Hedge: 0.2561617351881921, Loss: 0.0014011278505285496\n",
      "Iteration:990, Price of Hedge: 0.2666403521703358, Loss: 0.0012542814487980225\n",
      "tf.Tensor(0.2901359, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_122 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.40130246891345106, Loss: 0.007293324340240037\n",
      "Iteration:20, Price of Hedge: 0.24611334915690009, Loss: 0.00308840403976649\n",
      "Iteration:30, Price of Hedge: 0.274834476123786, Loss: 0.0022301877449148132\n",
      "Iteration:40, Price of Hedge: 0.29542282271755765, Loss: 0.002660796263865994\n",
      "Iteration:50, Price of Hedge: 0.25582961409539845, Loss: 0.002437256592241699\n",
      "Iteration:60, Price of Hedge: 0.2576338102427712, Loss: 0.00235276566225322\n",
      "Iteration:70, Price of Hedge: 0.31250199755228036, Loss: 0.0027212311888583193\n",
      "Iteration:80, Price of Hedge: 0.28137107033595893, Loss: 0.0025355838245091134\n",
      "Iteration:90, Price of Hedge: 0.2974232955388743, Loss: 0.0024266281726130767\n",
      "Iteration:100, Price of Hedge: 0.26791686252381625, Loss: 0.002525971078642364\n",
      "Iteration:110, Price of Hedge: 0.2477721319703846, Loss: 0.0028843297057278947\n",
      "Iteration:120, Price of Hedge: 0.26268844721727475, Loss: 0.0029525703005094384\n",
      "Iteration:130, Price of Hedge: 0.2637071949219063, Loss: 0.003122022507547206\n",
      "Iteration:140, Price of Hedge: 0.28657969279740597, Loss: 0.003211634524715756\n",
      "Iteration:150, Price of Hedge: 0.2681564556256575, Loss: 0.002482014987641956\n",
      "Iteration:160, Price of Hedge: 0.2873074999186059, Loss: 0.002388563211923045\n",
      "Iteration:170, Price of Hedge: 0.3123498347158204, Loss: 0.002211110877512734\n",
      "Iteration:180, Price of Hedge: 0.2914409009893461, Loss: 0.00223353468476144\n",
      "Iteration:190, Price of Hedge: 0.3191683416957488, Loss: 0.0026304882473235924\n",
      "Iteration:200, Price of Hedge: 0.28965857664777556, Loss: 0.0022444490059856824\n",
      "Iteration:210, Price of Hedge: 0.27549772154739, Loss: 0.00233486755489285\n",
      "Iteration:220, Price of Hedge: 0.3002994949596939, Loss: 0.002452534862023525\n",
      "Iteration:230, Price of Hedge: 0.30235054633192815, Loss: 0.0026066315947240737\n",
      "Iteration:240, Price of Hedge: 0.2948870489121447, Loss: 0.0023949914367484616\n",
      "Iteration:250, Price of Hedge: 0.28763691551458803, Loss: 0.0025433741423838583\n",
      "Iteration:260, Price of Hedge: 0.26124080707074027, Loss: 0.0025922677650652036\n",
      "Iteration:270, Price of Hedge: 0.2729480043944306, Loss: 0.002796840035112358\n",
      "Iteration:280, Price of Hedge: 0.2516653134031799, Loss: 0.002047163555516862\n",
      "Iteration:290, Price of Hedge: 0.24772417347953704, Loss: 0.002421701098033302\n",
      "Iteration:300, Price of Hedge: 0.22844488863772483, Loss: 0.0025599642221328265\n",
      "Iteration:310, Price of Hedge: 0.2495232434224249, Loss: 0.0023447733220836706\n",
      "Iteration:320, Price of Hedge: 0.27962158218200556, Loss: 0.0026172771461992817\n",
      "Iteration:330, Price of Hedge: 0.25889844488919495, Loss: 0.0035498705742829316\n",
      "Iteration:340, Price of Hedge: 0.31279387793986757, Loss: 0.002697300446584605\n",
      "Iteration:350, Price of Hedge: 0.2653434509145711, Loss: 0.0023833767122378277\n",
      "Iteration:360, Price of Hedge: 0.24666677988887215, Loss: 0.002531322889522558\n",
      "Iteration:370, Price of Hedge: 0.2590880290183946, Loss: 0.0026793591758704992\n",
      "Iteration:380, Price of Hedge: 0.25495983958888074, Loss: 0.0025616208939468255\n",
      "Iteration:390, Price of Hedge: 0.27134227779736475, Loss: 0.002704588156128995\n",
      "Iteration:400, Price of Hedge: 0.3059725800263862, Loss: 0.0025025956751878464\n",
      "Iteration:410, Price of Hedge: 0.2958743843748493, Loss: 0.0026254924228659602\n",
      "Iteration:420, Price of Hedge: 0.29278003647428363, Loss: 0.0027671407553525374\n",
      "Iteration:430, Price of Hedge: 0.2664917207191877, Loss: 0.0021315828432378003\n",
      "Iteration:440, Price of Hedge: 0.23094684665223325, Loss: 0.002436932199614139\n",
      "Iteration:450, Price of Hedge: 0.2484332699543671, Loss: 0.0024107429459807816\n",
      "Iteration:460, Price of Hedge: 0.25259603278524023, Loss: 0.0022404770874759447\n",
      "Iteration:470, Price of Hedge: 0.28075504295144355, Loss: 0.0021173905545363025\n",
      "Iteration:480, Price of Hedge: 0.2698362273986163, Loss: 0.00224659493663919\n",
      "Iteration:490, Price of Hedge: 0.28393702046978714, Loss: 0.002522126202787178\n",
      "Iteration:500, Price of Hedge: 0.26208791236186924, Loss: 0.0019406862365964005\n",
      "Iteration:510, Price of Hedge: 0.265384204240226, Loss: 0.002400346362509853\n",
      "Iteration:520, Price of Hedge: 0.29624663225719416, Loss: 0.00275800658873262\n",
      "Iteration:530, Price of Hedge: 0.27820290509081075, Loss: 0.0023676260929715643\n",
      "Iteration:540, Price of Hedge: 0.29556140111213264, Loss: 0.0022148872259815764\n",
      "Iteration:550, Price of Hedge: 0.2541385077147453, Loss: 0.003118879147435982\n",
      "Iteration:560, Price of Hedge: 0.2522059286239397, Loss: 0.00227618786545527\n",
      "Iteration:570, Price of Hedge: 0.24242649745462186, Loss: 0.0033288871076641467\n",
      "Iteration:580, Price of Hedge: 0.2539848924536812, Loss: 0.001911928763415771\n",
      "Iteration:590, Price of Hedge: 0.2476563367068536, Loss: 0.0022475741217927504\n",
      "Iteration:600, Price of Hedge: 0.22443854624092552, Loss: 0.0020593752247598297\n",
      "Iteration:610, Price of Hedge: 0.2510700756257421, Loss: 0.0016018892859221755\n",
      "Iteration:620, Price of Hedge: 0.2737783925631561, Loss: 0.001704224480324612\n",
      "Iteration:630, Price of Hedge: 0.28822158761500416, Loss: 0.0017141938800884658\n",
      "Iteration:640, Price of Hedge: 0.2856916917860531, Loss: 0.0013653118340630542\n",
      "Iteration:650, Price of Hedge: 0.2932444136427875, Loss: 0.0013884649684949846\n",
      "Iteration:660, Price of Hedge: 0.2682849809636593, Loss: 0.0017366299243704473\n",
      "Iteration:670, Price of Hedge: 0.27474109376541944, Loss: 0.0016128661272618804\n",
      "Iteration:680, Price of Hedge: 0.2726334547914547, Loss: 0.0014818090583210708\n",
      "Iteration:690, Price of Hedge: 0.2883904390949539, Loss: 0.0017204067331282324\n",
      "Iteration:700, Price of Hedge: 0.24511476452324243, Loss: 0.0016640947983837195\n",
      "Iteration:710, Price of Hedge: 0.2312447930484609, Loss: 0.0016918525059457345\n",
      "Iteration:720, Price of Hedge: 0.29227476358555576, Loss: 0.0022580650416656575\n",
      "Iteration:730, Price of Hedge: 0.3068528917310118, Loss: 0.001745450377955482\n",
      "Iteration:740, Price of Hedge: 0.30877900610838366, Loss: 0.0014958408193951444\n",
      "Iteration:750, Price of Hedge: 0.30087380073548503, Loss: 0.001666394359427714\n",
      "Iteration:760, Price of Hedge: 0.26902252787338055, Loss: 0.001574744876218781\n",
      "Iteration:770, Price of Hedge: 0.28663801761287855, Loss: 0.0016980668051803426\n",
      "Iteration:780, Price of Hedge: 0.30058075271243184, Loss: 0.0016916858598016726\n",
      "Iteration:790, Price of Hedge: 0.2823439385104507, Loss: 0.00139643594947918\n",
      "Iteration:800, Price of Hedge: 0.23291627745750246, Loss: 0.0018484549380780922\n",
      "Iteration:810, Price of Hedge: 0.25847727023293315, Loss: 0.001687867571682422\n",
      "Iteration:820, Price of Hedge: 0.2553077949577499, Loss: 0.001692354001818519\n",
      "Iteration:830, Price of Hedge: 0.25191145665519626, Loss: 0.0013568667236623089\n",
      "Iteration:840, Price of Hedge: 0.28167260507532604, Loss: 0.0017677332368300047\n",
      "Iteration:850, Price of Hedge: 0.2572489746805246, Loss: 0.001671635814516914\n",
      "Iteration:860, Price of Hedge: 0.2754935351470607, Loss: 0.0016480362508619394\n",
      "Iteration:870, Price of Hedge: 0.3145699084414872, Loss: 0.0015515212119768806\n",
      "Iteration:880, Price of Hedge: 0.2825294216760625, Loss: 0.001902938103822449\n",
      "Iteration:890, Price of Hedge: 0.27150887944312385, Loss: 0.0013671809852730198\n",
      "Iteration:900, Price of Hedge: 0.2443942764828904, Loss: 0.0014728842562159227\n",
      "Iteration:910, Price of Hedge: 0.24819931567745923, Loss: 0.001735985700191367\n",
      "Iteration:920, Price of Hedge: 0.23236888425525704, Loss: 0.001526648329386704\n",
      "Iteration:930, Price of Hedge: 0.27066262851940903, Loss: 0.0012446317693399322\n",
      "Iteration:940, Price of Hedge: 0.2940961325179529, Loss: 0.0016248440691692843\n",
      "Iteration:950, Price of Hedge: 0.27514122250437933, Loss: 0.0015457171870942752\n",
      "Iteration:960, Price of Hedge: 0.2694033479087807, Loss: 0.0011687810748100657\n",
      "Iteration:970, Price of Hedge: 0.2648735773157028, Loss: 0.0015620136892903868\n",
      "Iteration:980, Price of Hedge: 0.2513069632307719, Loss: 0.0016725124310824735\n",
      "Iteration:990, Price of Hedge: 0.269164837005664, Loss: 0.0017245321707826998\n",
      "tf.Tensor(0.29006, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_123 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.2423912120804175, Loss: 0.0035233328989384915\n",
      "Iteration:20, Price of Hedge: 0.2727948447959875, Loss: 0.0027716012652272415\n",
      "Iteration:30, Price of Hedge: 0.26287971160238893, Loss: 0.0027953250903928416\n",
      "Iteration:40, Price of Hedge: 0.2302223715639485, Loss: 0.0027912706275313726\n",
      "Iteration:50, Price of Hedge: 0.298351337903037, Loss: 0.0025366595709797935\n",
      "Iteration:60, Price of Hedge: 0.25917326640741295, Loss: 0.002863686053083514\n",
      "Iteration:70, Price of Hedge: 0.2562034852758302, Loss: 0.0027108270406759117\n",
      "Iteration:80, Price of Hedge: 0.2871203649759934, Loss: 0.002525196585681777\n",
      "Iteration:90, Price of Hedge: 0.2800634610086035, Loss: 0.002449766400113562\n",
      "Iteration:100, Price of Hedge: 0.2736003708729612, Loss: 0.0026872551772144427\n",
      "Iteration:110, Price of Hedge: 0.26726218925326745, Loss: 0.002892430176773297\n",
      "Iteration:120, Price of Hedge: 0.25555012203531646, Loss: 0.0024222030388891145\n",
      "Iteration:130, Price of Hedge: 0.2771470493614913, Loss: 0.0026116774797723783\n",
      "Iteration:140, Price of Hedge: 0.26353740363780104, Loss: 0.002066934151459909\n",
      "Iteration:150, Price of Hedge: 0.26523027571111013, Loss: 0.002571506414409863\n",
      "Iteration:160, Price of Hedge: 0.2693317803983888, Loss: 0.0024955769578840045\n",
      "Iteration:170, Price of Hedge: 0.26108554003267553, Loss: 0.0023483592178164424\n",
      "Iteration:180, Price of Hedge: 0.25173454564263975, Loss: 0.0022741709798799413\n",
      "Iteration:190, Price of Hedge: 0.23438191627756166, Loss: 0.0024056854913737436\n",
      "Iteration:200, Price of Hedge: 0.2398826184789925, Loss: 0.001929561215908304\n",
      "Iteration:210, Price of Hedge: 0.23612261868660622, Loss: 0.002485059339029405\n",
      "Iteration:220, Price of Hedge: 0.27778096150387627, Loss: 0.0025102540555947293\n",
      "Iteration:230, Price of Hedge: 0.31741714480696714, Loss: 0.002450940710324989\n",
      "Iteration:240, Price of Hedge: 0.3132939391873691, Loss: 0.002217089446988152\n",
      "Iteration:250, Price of Hedge: 0.2828495531461442, Loss: 0.0024238643830249095\n",
      "Iteration:260, Price of Hedge: 0.2818918072748829, Loss: 0.0024237460175394075\n",
      "Iteration:270, Price of Hedge: 0.27340258481658564, Loss: 0.0027362362390608297\n",
      "Iteration:280, Price of Hedge: 0.2733228438579317, Loss: 0.0020904630740591567\n",
      "Iteration:290, Price of Hedge: 0.25578031709560206, Loss: 0.002666098459138544\n",
      "Iteration:300, Price of Hedge: 0.25721340451718216, Loss: 0.002033910403496386\n",
      "Iteration:310, Price of Hedge: 0.2671673259913831, Loss: 0.00253867089426727\n",
      "Iteration:320, Price of Hedge: 0.25460445122350844, Loss: 0.0021856954493654213\n",
      "Iteration:330, Price of Hedge: 0.25583812929062616, Loss: 0.00210764854109986\n",
      "Iteration:340, Price of Hedge: 0.26570427875248015, Loss: 0.0025947959361399373\n",
      "Iteration:350, Price of Hedge: 0.2837983281595569, Loss: 0.0020140123199157587\n",
      "Iteration:360, Price of Hedge: 0.2750892200077715, Loss: 0.0024147600302678817\n",
      "Iteration:370, Price of Hedge: 0.23407900031087506, Loss: 0.002281237755350829\n",
      "Iteration:380, Price of Hedge: 0.27376030845288996, Loss: 0.00245406004135269\n",
      "Iteration:390, Price of Hedge: 0.2740803260073164, Loss: 0.002118694132317422\n",
      "Iteration:400, Price of Hedge: 0.2703605242017659, Loss: 0.002419545822736202\n",
      "Iteration:410, Price of Hedge: 0.27237213227838025, Loss: 0.0021190085128268477\n",
      "Iteration:420, Price of Hedge: 0.2316318357265274, Loss: 0.002654287719603987\n",
      "Iteration:430, Price of Hedge: 0.2632127724993381, Loss: 0.001953206724060941\n",
      "Iteration:440, Price of Hedge: 0.2830167528490932, Loss: 0.0018872455548413656\n",
      "Iteration:450, Price of Hedge: 0.29587432741702174, Loss: 0.0022116012488098136\n",
      "Iteration:460, Price of Hedge: 0.25269163649888354, Loss: 0.0033169882614900057\n",
      "Iteration:470, Price of Hedge: 0.22480183750487867, Loss: 0.0018938784718597556\n",
      "Iteration:480, Price of Hedge: 0.2128576386605033, Loss: 0.0015475436199335335\n",
      "Iteration:490, Price of Hedge: 0.2616428438969251, Loss: 0.00183640602137769\n",
      "Iteration:500, Price of Hedge: 0.2617917886161251, Loss: 0.0021163593063684427\n",
      "Iteration:510, Price of Hedge: 0.3010590845487002, Loss: 0.00225778470235789\n",
      "Iteration:520, Price of Hedge: 0.29270690262363247, Loss: 0.0016314645266628845\n",
      "Iteration:530, Price of Hedge: 0.28233115147815224, Loss: 0.0014620029749815243\n",
      "Iteration:540, Price of Hedge: 0.28367396074297063, Loss: 0.0013832998279951214\n",
      "Iteration:550, Price of Hedge: 0.2706720265609647, Loss: 0.0016961937603688802\n",
      "Iteration:560, Price of Hedge: 0.282380106730983, Loss: 0.0014372464554532225\n",
      "Iteration:570, Price of Hedge: 0.27071537146777586, Loss: 0.0015496249168021946\n",
      "Iteration:580, Price of Hedge: 0.2572757163805875, Loss: 0.001527822862089645\n",
      "Iteration:590, Price of Hedge: 0.2454843353876896, Loss: 0.0014707444440790528\n",
      "Iteration:600, Price of Hedge: 0.2697343298450221, Loss: 0.0015421845780791308\n",
      "Iteration:610, Price of Hedge: 0.26932021795938393, Loss: 0.0016680572610041078\n",
      "Iteration:620, Price of Hedge: 0.2526512533991081, Loss: 0.001518423930567947\n",
      "Iteration:630, Price of Hedge: 0.2211266763967174, Loss: 0.0014543831968523379\n",
      "Iteration:640, Price of Hedge: 0.22050670468264, Loss: 0.0014452855188407331\n",
      "Iteration:650, Price of Hedge: 0.2658397814243642, Loss: 0.00237490379039782\n",
      "Iteration:660, Price of Hedge: 0.29524144051553375, Loss: 0.0014636428486862084\n",
      "Iteration:670, Price of Hedge: 0.2826295820159146, Loss: 0.0014012986127656224\n",
      "Iteration:680, Price of Hedge: 0.2875492858968101, Loss: 0.0014102874924268316\n",
      "Iteration:690, Price of Hedge: 0.25876786906939914, Loss: 0.0011856595035613093\n",
      "Iteration:700, Price of Hedge: 0.2741392488799789, Loss: 0.001270185253471745\n",
      "Iteration:710, Price of Hedge: 0.26394624692438523, Loss: 0.0015450824188045441\n",
      "Iteration:720, Price of Hedge: 0.27106517796604235, Loss: 0.0015184161433649535\n",
      "Iteration:730, Price of Hedge: 0.24389387348842317, Loss: 0.0012045521479897125\n",
      "Iteration:740, Price of Hedge: 0.246285817458903, Loss: 0.0018415758341993492\n",
      "Iteration:750, Price of Hedge: 0.24447222326997461, Loss: 0.0013382173737045754\n",
      "Iteration:760, Price of Hedge: 0.24678169230607522, Loss: 0.0014896353085753432\n",
      "Iteration:770, Price of Hedge: 0.2987917643050309, Loss: 0.0015260633991961313\n",
      "Iteration:780, Price of Hedge: 0.2956447019350122, Loss: 0.001562437869362021\n",
      "Iteration:790, Price of Hedge: 0.290557456604202, Loss: 0.0015087249692394833\n",
      "Iteration:800, Price of Hedge: 0.26549305064878864, Loss: 0.0015240731013567376\n",
      "Iteration:810, Price of Hedge: 0.2794616730809906, Loss: 0.0016685021327865533\n",
      "Iteration:820, Price of Hedge: 0.2561980458032934, Loss: 0.0014543271289907843\n",
      "Iteration:830, Price of Hedge: 0.3074808802593253, Loss: 0.0015242982627690083\n",
      "Iteration:840, Price of Hedge: 0.29663929952073714, Loss: 0.001485394397825057\n",
      "Iteration:850, Price of Hedge: 0.26887438056376706, Loss: 0.0016643642356072963\n",
      "Iteration:860, Price of Hedge: 0.2810735511234384, Loss: 0.001645726121471025\n",
      "Iteration:870, Price of Hedge: 0.27027118584915966, Loss: 0.0017854972930531287\n",
      "Iteration:880, Price of Hedge: 0.2077819984870686, Loss: 0.0011692824594370932\n",
      "Iteration:890, Price of Hedge: 0.2726231169457435, Loss: 0.0018963630345977256\n",
      "Iteration:900, Price of Hedge: 0.30659891677769907, Loss: 0.0013999312911657123\n",
      "Iteration:910, Price of Hedge: 0.24074148556152294, Loss: 0.0013784606375634167\n",
      "Iteration:920, Price of Hedge: 0.2291311307842264, Loss: 0.001584525714424434\n",
      "Iteration:930, Price of Hedge: 0.2658539639234391, Loss: 0.001305884239400823\n",
      "Iteration:940, Price of Hedge: 0.2732967571728864, Loss: 0.001683815556227608\n",
      "Iteration:950, Price of Hedge: 0.24759761318658774, Loss: 0.0013658411413751015\n",
      "Iteration:960, Price of Hedge: 0.24184188231203335, Loss: 0.0011826510845533878\n",
      "Iteration:970, Price of Hedge: 0.282524523302888, Loss: 0.0016861913206151823\n",
      "Iteration:980, Price of Hedge: 0.3067272997211319, Loss: 0.0014009368415636935\n",
      "Iteration:990, Price of Hedge: 0.2663317831392589, Loss: 0.0016804936466763174\n",
      "tf.Tensor(0.2915546, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_124 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.20952650283110613, Loss: 0.002153933005795339\n",
      "Iteration:20, Price of Hedge: 0.2258211405483294, Loss: 0.002817109012046992\n",
      "Iteration:30, Price of Hedge: 0.2098000143192891, Loss: 0.0023183994004936093\n",
      "Iteration:40, Price of Hedge: 0.23289788007918444, Loss: 0.001996516477212884\n",
      "Iteration:50, Price of Hedge: 0.2758543060271421, Loss: 0.0023453967433061827\n",
      "Iteration:60, Price of Hedge: 0.24084936368701618, Loss: 0.002629962499875771\n",
      "Iteration:70, Price of Hedge: 0.2535552880389332, Loss: 0.0025101345776516568\n",
      "Iteration:80, Price of Hedge: 0.25934684538705427, Loss: 0.002694144404457077\n",
      "Iteration:90, Price of Hedge: 0.2574746985513428, Loss: 0.0018449312287235119\n",
      "Iteration:100, Price of Hedge: 0.26031378994747456, Loss: 0.00252043593475455\n",
      "Iteration:110, Price of Hedge: 0.2838907707137679, Loss: 0.00207002633852289\n",
      "Iteration:120, Price of Hedge: 0.26490721091290653, Loss: 0.002594404128583605\n",
      "Iteration:130, Price of Hedge: 0.2755015377218399, Loss: 0.002649537525777923\n",
      "Iteration:140, Price of Hedge: 0.30328152202421277, Loss: 0.0023800066332737347\n",
      "Iteration:150, Price of Hedge: 0.3025906235753041, Loss: 0.0021834772089698307\n",
      "Iteration:160, Price of Hedge: 0.2709550215274447, Loss: 0.002458822694703544\n",
      "Iteration:170, Price of Hedge: 0.23819958587040302, Loss: 0.002004504812535179\n",
      "Iteration:180, Price of Hedge: 0.2620613984931168, Loss: 0.003066146656170332\n",
      "Iteration:190, Price of Hedge: 0.2548185556974943, Loss: 0.0025389089601873583\n",
      "Iteration:200, Price of Hedge: 0.23580574805215518, Loss: 0.0024488524049736337\n",
      "Iteration:210, Price of Hedge: 0.17032252976337645, Loss: 0.0018322081627353826\n",
      "Iteration:220, Price of Hedge: 0.21240184788451158, Loss: 0.0021614943799020737\n",
      "Iteration:230, Price of Hedge: 0.2597977805082422, Loss: 0.002263055303835437\n",
      "Iteration:240, Price of Hedge: 0.2620137532703211, Loss: 0.0019319289706013708\n",
      "Iteration:250, Price of Hedge: 0.23747448424601458, Loss: 0.0020378865493448917\n",
      "Iteration:260, Price of Hedge: 0.2309602886995492, Loss: 0.0025939613704705432\n",
      "Iteration:270, Price of Hedge: 0.2652937267310676, Loss: 0.002044430469757641\n",
      "Iteration:280, Price of Hedge: 0.2671250348043827, Loss: 0.0020241768447374795\n",
      "Iteration:290, Price of Hedge: 0.2740813512482134, Loss: 0.002337896331874312\n",
      "Iteration:300, Price of Hedge: 0.29458240997117285, Loss: 0.0028119667881730814\n",
      "Iteration:310, Price of Hedge: 0.2458845780423047, Loss: 0.003308375392487628\n",
      "Iteration:320, Price of Hedge: 0.21862961675538342, Loss: 0.0023240980756442874\n",
      "Iteration:330, Price of Hedge: 0.2540846540887401, Loss: 0.002231587884013053\n",
      "Iteration:340, Price of Hedge: 0.23734997443485922, Loss: 0.00263582070144206\n",
      "Iteration:350, Price of Hedge: 0.2834111288474645, Loss: 0.0024934979971762417\n",
      "Iteration:360, Price of Hedge: 0.2641229301056313, Loss: 0.0022211209932236687\n",
      "Iteration:370, Price of Hedge: 0.2445810696785372, Loss: 0.0021931344531394004\n",
      "Iteration:380, Price of Hedge: 0.2177936894379229, Loss: 0.002482618162136685\n",
      "Iteration:390, Price of Hedge: 0.2650204145952813, Loss: 0.0019831680988243727\n",
      "Iteration:400, Price of Hedge: 0.2457248398147726, Loss: 0.0020789061973421896\n",
      "Iteration:410, Price of Hedge: 0.2773571383086306, Loss: 0.0021517125404846072\n",
      "Iteration:420, Price of Hedge: 0.2633993093847607, Loss: 0.0023288840906041217\n",
      "Iteration:430, Price of Hedge: 0.26360031355839625, Loss: 0.0018293762907439003\n",
      "Iteration:440, Price of Hedge: 0.2407927476063719, Loss: 0.0025298568929361443\n",
      "Iteration:450, Price of Hedge: 0.24394989151187757, Loss: 0.001795946384521385\n",
      "Iteration:460, Price of Hedge: 0.26284268901444247, Loss: 0.002260520013032252\n",
      "Iteration:470, Price of Hedge: 0.2808806919191511, Loss: 0.0026547654088847628\n",
      "Iteration:480, Price of Hedge: 0.31203764886269025, Loss: 0.0017741401024700676\n",
      "Iteration:490, Price of Hedge: 0.2719975206461896, Loss: 0.0019907049988645564\n",
      "Iteration:500, Price of Hedge: 0.27566435167206293, Loss: 0.002924346806962652\n",
      "Iteration:510, Price of Hedge: 0.2663559332581656, Loss: 0.001360918961608637\n",
      "Iteration:520, Price of Hedge: 0.23481846954727814, Loss: 0.0012833187050576343\n",
      "Iteration:530, Price of Hedge: 0.23072379979931268, Loss: 0.0016202408309882843\n",
      "Iteration:540, Price of Hedge: 0.28233593593567147, Loss: 0.0014667095604708246\n",
      "Iteration:550, Price of Hedge: 0.2639234922722551, Loss: 0.0017466875420196425\n",
      "Iteration:560, Price of Hedge: 0.2681405359128405, Loss: 0.001495043298562848\n",
      "Iteration:570, Price of Hedge: 0.2757923928685301, Loss: 0.0013917064473639273\n",
      "Iteration:580, Price of Hedge: 0.2919108885038696, Loss: 0.0012759917257610053\n",
      "Iteration:590, Price of Hedge: 0.27852238154587494, Loss: 0.001710374702003159\n",
      "Iteration:600, Price of Hedge: 0.2615570369296307, Loss: 0.0014166985854056624\n",
      "Iteration:610, Price of Hedge: 0.24093517065431058, Loss: 0.0014088960304976415\n",
      "Iteration:620, Price of Hedge: 0.27145895590722374, Loss: 0.0012251408452301105\n",
      "Iteration:630, Price of Hedge: 0.24221088359820442, Loss: 0.0016819233771459329\n",
      "Iteration:640, Price of Hedge: 0.26789940494965375, Loss: 0.0014886812649628767\n",
      "Iteration:650, Price of Hedge: 0.29581440778237605, Loss: 0.0015066366638881278\n",
      "Iteration:660, Price of Hedge: 0.28288623398712504, Loss: 0.0015930559278293233\n",
      "Iteration:670, Price of Hedge: 0.2572405164431245, Loss: 0.001778932680929568\n",
      "Iteration:680, Price of Hedge: 0.2697498793319596, Loss: 0.0015109339762372385\n",
      "Iteration:690, Price of Hedge: 0.251424495708045, Loss: 0.0017061248915923087\n",
      "Iteration:700, Price of Hedge: 0.2372965337531042, Loss: 0.0012123505868047223\n",
      "Iteration:710, Price of Hedge: 0.24223235669921336, Loss: 0.0014485620401231468\n",
      "Iteration:720, Price of Hedge: 0.2740348451819699, Loss: 0.0014127409063528272\n",
      "Iteration:730, Price of Hedge: 0.25459995155512727, Loss: 0.002106829549836453\n",
      "Iteration:740, Price of Hedge: 0.2624111195546419, Loss: 0.0018158925262690582\n",
      "Iteration:750, Price of Hedge: 0.27354122016898824, Loss: 0.001457131857017546\n",
      "Iteration:760, Price of Hedge: 0.31066821181346427, Loss: 0.0018582934015858976\n",
      "Iteration:770, Price of Hedge: 0.28058442577883796, Loss: 0.0013893430312553856\n",
      "Iteration:780, Price of Hedge: 0.25731333702572384, Loss: 0.0015992372983198444\n",
      "Iteration:790, Price of Hedge: 0.2732839701405879, Loss: 0.001320896075594513\n",
      "Iteration:800, Price of Hedge: 0.2577351382180893, Loss: 0.0014604272900786584\n",
      "Iteration:810, Price of Hedge: 0.29151557270134276, Loss: 0.0013725003123921554\n",
      "Iteration:820, Price of Hedge: 0.26714135322199295, Loss: 0.001494457033423191\n",
      "Iteration:830, Price of Hedge: 0.25658179916681545, Loss: 0.002008746168268494\n",
      "Iteration:840, Price of Hedge: 0.2717312143231993, Loss: 0.0015442725496932152\n",
      "Iteration:850, Price of Hedge: 0.28061934092716284, Loss: 0.0012423496738797944\n",
      "Iteration:860, Price of Hedge: 0.2652472206648241, Loss: 0.001526709848290353\n",
      "Iteration:870, Price of Hedge: 0.2831619953094986, Loss: 0.0015291650421484615\n",
      "Iteration:880, Price of Hedge: 0.3005344459985849, Loss: 0.0016086187642576854\n",
      "Iteration:890, Price of Hedge: 0.2319576487399132, Loss: 0.0013894941029934603\n",
      "Iteration:900, Price of Hedge: 0.209942992706047, Loss: 0.00120614474224765\n",
      "Iteration:910, Price of Hedge: 0.22487948526336793, Loss: 0.0014905447426392326\n",
      "Iteration:920, Price of Hedge: 0.2419538044432869, Loss: 0.001627753479453431\n",
      "Iteration:930, Price of Hedge: 0.25232303391750577, Loss: 0.0014882199288083874\n",
      "Iteration:940, Price of Hedge: 0.282550666945761, Loss: 0.0013366367939883993\n",
      "Iteration:950, Price of Hedge: 0.2729856535184808, Loss: 0.001175252574234975\n",
      "Iteration:960, Price of Hedge: 0.23306176198867518, Loss: 0.0011788079886303148\n",
      "Iteration:970, Price of Hedge: 0.2276461547816936, Loss: 0.001358993742537118\n",
      "Iteration:980, Price of Hedge: 0.26560428928611085, Loss: 0.00154468237906219\n",
      "Iteration:990, Price of Hedge: 0.2800757923782811, Loss: 0.0013703389185784176\n",
      "tf.Tensor(0.41432378, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_125 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.2695460842247712, Loss: 0.011129065583822761\n",
      "Iteration:20, Price of Hedge: 0.2975969314763432, Loss: 0.0034702168323025306\n",
      "Iteration:30, Price of Hedge: 0.36712352898932465, Loss: 0.00441434555542628\n",
      "Iteration:40, Price of Hedge: 0.3582886864330902, Loss: 0.004412492646096844\n",
      "Iteration:50, Price of Hedge: 0.37121925245710086, Loss: 0.0041519786671846415\n",
      "Iteration:60, Price of Hedge: 0.36427535281968915, Loss: 0.004073188637261982\n",
      "Iteration:70, Price of Hedge: 0.3545772004703707, Loss: 0.004118845675887694\n",
      "Iteration:80, Price of Hedge: 0.3575506269029205, Loss: 0.004429353943001501\n",
      "Iteration:90, Price of Hedge: 0.37983176013325987, Loss: 0.00409700457391442\n",
      "Iteration:100, Price of Hedge: 0.37452180969649473, Loss: 0.004339501634997722\n",
      "Iteration:110, Price of Hedge: 0.38125533559762914, Loss: 0.004013002012799393\n",
      "Iteration:120, Price of Hedge: 0.342002364558698, Loss: 0.004018743628812293\n",
      "Iteration:130, Price of Hedge: 0.3368077252439292, Loss: 0.0035547415810011527\n",
      "Iteration:140, Price of Hedge: 0.32766325993680706, Loss: 0.004393681433562602\n",
      "Iteration:150, Price of Hedge: 0.3053351934565171, Loss: 0.003201451978081393\n",
      "Iteration:160, Price of Hedge: 0.3061676321070365, Loss: 0.0045642131694267896\n",
      "Iteration:170, Price of Hedge: 0.32566142012762783, Loss: 0.003224729262778192\n",
      "Iteration:180, Price of Hedge: 0.3375279000162294, Loss: 0.003992717906441801\n",
      "Iteration:190, Price of Hedge: 0.31282830894665775, Loss: 0.003775058018060662\n",
      "Iteration:200, Price of Hedge: 0.32846958342336735, Loss: 0.005113388528700157\n",
      "Iteration:210, Price of Hedge: 0.32946993374968087, Loss: 0.003996278660633478\n",
      "Iteration:220, Price of Hedge: 0.34986077907621504, Loss: 0.004673856987575942\n",
      "Iteration:230, Price of Hedge: 0.3555064104699994, Loss: 0.0038964792020172554\n",
      "Iteration:240, Price of Hedge: 0.39315243031857106, Loss: 0.004459678646407461\n",
      "Iteration:250, Price of Hedge: 0.37219422807121416, Loss: 0.0031810699754575953\n",
      "Iteration:260, Price of Hedge: 0.3999697696630335, Loss: 0.0043164381646459745\n",
      "Iteration:270, Price of Hedge: 0.3411476269186693, Loss: 0.003928129954847259\n",
      "Iteration:280, Price of Hedge: 0.32690950852513084, Loss: 0.0039132394877745115\n",
      "Iteration:290, Price of Hedge: 0.29883733056711886, Loss: 0.004015956255123632\n",
      "Iteration:300, Price of Hedge: 0.33705836816432677, Loss: 0.004282390288243043\n",
      "Iteration:310, Price of Hedge: 0.3182088016529178, Loss: 0.003725691155928823\n",
      "Iteration:320, Price of Hedge: 0.3248282695042633, Loss: 0.0035269105624852414\n",
      "Iteration:330, Price of Hedge: 0.3445671470570602, Loss: 0.0036378688604997043\n",
      "Iteration:340, Price of Hedge: 0.3613464104505027, Loss: 0.00462231193352105\n",
      "Iteration:350, Price of Hedge: 0.38058519827688425, Loss: 0.004046594226581446\n",
      "Iteration:360, Price of Hedge: 0.34897505637796655, Loss: 0.004073623830663564\n",
      "Iteration:370, Price of Hedge: 0.33988965633807594, Loss: 0.003746673440657666\n",
      "Iteration:380, Price of Hedge: 0.30518325845136757, Loss: 0.0035197681398995593\n",
      "Iteration:390, Price of Hedge: 0.34959780478613994, Loss: 0.0035632883700238427\n",
      "Iteration:400, Price of Hedge: 0.3349526657565008, Loss: 0.003655804791417472\n",
      "Iteration:410, Price of Hedge: 0.34583149691434584, Loss: 0.00301325241357393\n",
      "Iteration:420, Price of Hedge: 0.3515279062114445, Loss: 0.003093487525880678\n",
      "Iteration:430, Price of Hedge: 0.3483736101973193, Loss: 0.0029967978311570497\n",
      "Iteration:440, Price of Hedge: 0.3478566894328452, Loss: 0.0035160418520213898\n",
      "Iteration:450, Price of Hedge: 0.33496229162936686, Loss: 0.003237229948497977\n",
      "Iteration:460, Price of Hedge: 0.3369675773871165, Loss: 0.0025312098638333945\n",
      "Iteration:470, Price of Hedge: 0.2972893022494219, Loss: 0.0031820925464564054\n",
      "Iteration:480, Price of Hedge: 0.29386499765351176, Loss: 0.002111559051951706\n",
      "Iteration:490, Price of Hedge: 0.3064904975528435, Loss: 0.0030611316974424874\n",
      "Iteration:500, Price of Hedge: 0.3385053248169299, Loss: 0.002296117765322414\n",
      "Iteration:510, Price of Hedge: 0.38231466575443274, Loss: 0.0024238650504994517\n",
      "Iteration:520, Price of Hedge: 0.365305150342877, Loss: 0.002837540185295406\n",
      "Iteration:530, Price of Hedge: 0.41602692171803707, Loss: 0.0026713962045808114\n",
      "Iteration:540, Price of Hedge: 0.40826741446816467, Loss: 0.002631501251187296\n",
      "Iteration:550, Price of Hedge: 0.405042661621286, Loss: 0.002700961321957629\n",
      "Iteration:560, Price of Hedge: 0.3428914762476893, Loss: 0.002285421040798963\n",
      "Iteration:570, Price of Hedge: 0.36731470793769744, Loss: 0.0025787002325353024\n",
      "Iteration:580, Price of Hedge: 0.4137645568053699, Loss: 0.0026413068971967713\n",
      "Iteration:590, Price of Hedge: 0.4098002350458898, Loss: 0.0030034116139052267\n",
      "Iteration:600, Price of Hedge: 0.36634841839229465, Loss: 0.0024894415318911455\n",
      "Iteration:610, Price of Hedge: 0.3344451430335823, Loss: 0.0024867073336743537\n",
      "Iteration:620, Price of Hedge: 0.30229273413690405, Loss: 0.0023755763822449483\n",
      "Iteration:630, Price of Hedge: 0.35161599149184325, Loss: 0.002839592892004505\n",
      "Iteration:640, Price of Hedge: 0.33419751887804805, Loss: 0.002550388632348932\n",
      "Iteration:650, Price of Hedge: 0.343236726119747, Loss: 0.0019582214602972712\n",
      "Iteration:660, Price of Hedge: 0.3645719322280541, Loss: 0.0025529090162206723\n",
      "Iteration:670, Price of Hedge: 0.3438792958519286, Loss: 0.002616257245098641\n",
      "Iteration:680, Price of Hedge: 0.36283993012717697, Loss: 0.002623322240637416\n",
      "Iteration:690, Price of Hedge: 0.34813319120697767, Loss: 0.0025157602755857098\n",
      "Iteration:700, Price of Hedge: 0.3864042662557409, Loss: 0.002454790258501971\n",
      "Iteration:710, Price of Hedge: 0.3541929060074864, Loss: 0.002743596258347303\n",
      "Iteration:720, Price of Hedge: 0.31598721854481937, Loss: 0.0020846262316782213\n",
      "Iteration:730, Price of Hedge: 0.3201543101705909, Loss: 0.0020989520152881803\n",
      "Iteration:740, Price of Hedge: 0.3027038842155065, Loss: 0.0022633016019415475\n",
      "Iteration:750, Price of Hedge: 0.3610760601217521, Loss: 0.002419423007420418\n",
      "Iteration:760, Price of Hedge: 0.35856777978837895, Loss: 0.002664046419903987\n",
      "Iteration:770, Price of Hedge: 0.3274309859158137, Loss: 0.0027609405843290746\n",
      "Iteration:780, Price of Hedge: 0.3796875998715791, Loss: 0.0027903136915292223\n",
      "Iteration:790, Price of Hedge: 0.37606001278892903, Loss: 0.00257827749865851\n",
      "Iteration:800, Price of Hedge: 0.3836145857750608, Loss: 0.002901573910528321\n",
      "Iteration:810, Price of Hedge: 0.3600448101739602, Loss: 0.0029227128292830915\n",
      "Iteration:820, Price of Hedge: 0.3641950707616729, Loss: 0.0034470485684476413\n",
      "Iteration:830, Price of Hedge: 0.34700687864490476, Loss: 0.0028397121474560637\n",
      "Iteration:840, Price of Hedge: 0.3883883352227059, Loss: 0.002556509818884889\n",
      "Iteration:850, Price of Hedge: 0.36800637531727887, Loss: 0.002573622531200481\n",
      "Iteration:860, Price of Hedge: 0.35191356766219145, Loss: 0.002539957785184832\n",
      "Iteration:870, Price of Hedge: 0.3887168110145325, Loss: 0.002606957767283746\n",
      "Iteration:880, Price of Hedge: 0.413107861531941, Loss: 0.0027653474737488804\n",
      "Iteration:890, Price of Hedge: 0.33811274299012833, Loss: 0.0024021280745547768\n",
      "Iteration:900, Price of Hedge: 0.3342395537548242, Loss: 0.0027059019685197637\n",
      "Iteration:910, Price of Hedge: 0.3450914723391236, Loss: 0.002076907778562531\n",
      "Iteration:920, Price of Hedge: 0.35499595441895904, Loss: 0.0026735864110456254\n",
      "Iteration:930, Price of Hedge: 0.3447719958840594, Loss: 0.0025419519766257223\n",
      "Iteration:940, Price of Hedge: 0.34227738542931263, Loss: 0.0023646616160376776\n",
      "Iteration:950, Price of Hedge: 0.32682307502173275, Loss: 0.0030417602512757378\n",
      "Iteration:960, Price of Hedge: 0.3279848723104067, Loss: 0.0023077967898806227\n",
      "Iteration:970, Price of Hedge: 0.3475288401771223, Loss: 0.0023991219917077534\n",
      "Iteration:980, Price of Hedge: 0.3417242679653924, Loss: 0.002457645714593948\n",
      "Iteration:990, Price of Hedge: 0.30880307079054886, Loss: 0.0027549188514999212\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 19 \n",
      "\n",
      "tf.Tensor(0.07963603, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_126 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.0640532414202255, Loss: 0.0013415920793874436\n",
      "Iteration:20, Price of Hedge: 0.08323916550754262, Loss: 0.0009188619925687425\n",
      "Iteration:30, Price of Hedge: 0.07399479071121817, Loss: 0.0008835189437561564\n",
      "Iteration:40, Price of Hedge: 0.07177194678362753, Loss: 0.0007732690430389821\n",
      "Iteration:50, Price of Hedge: 0.07493162917509011, Loss: 0.0010517841487089896\n",
      "Iteration:60, Price of Hedge: 0.07399920514963299, Loss: 0.0011118975623392036\n",
      "Iteration:70, Price of Hedge: 0.07107063862754615, Loss: 0.0010373682482606172\n",
      "Iteration:80, Price of Hedge: 0.06540392958580554, Loss: 0.0010002084357585428\n",
      "Iteration:90, Price of Hedge: 0.07810490845283624, Loss: 0.0007049766993422191\n",
      "Iteration:100, Price of Hedge: 0.0847525951430228, Loss: 0.0010203239631023653\n",
      "Iteration:110, Price of Hedge: 0.08297190739856575, Loss: 0.0009980327389691457\n",
      "Iteration:120, Price of Hedge: 0.07515346380468912, Loss: 0.0010255471790204806\n",
      "Iteration:130, Price of Hedge: 0.06685634741874225, Loss: 0.001068592096975518\n",
      "Iteration:140, Price of Hedge: 0.06443089168701732, Loss: 0.0008997349530082133\n",
      "Iteration:150, Price of Hedge: 0.07157386380853836, Loss: 0.0009451015620443037\n",
      "Iteration:160, Price of Hedge: 0.07902454152599603, Loss: 0.0010342061760149068\n",
      "Iteration:170, Price of Hedge: 0.07699705599666373, Loss: 0.0008649239668645503\n",
      "Iteration:180, Price of Hedge: 0.07063988511042396, Loss: 0.000826979668619443\n",
      "Iteration:190, Price of Hedge: 0.07119057720341715, Loss: 0.0007940722140581391\n",
      "Iteration:200, Price of Hedge: 0.08243036135642257, Loss: 0.0009182663976037286\n",
      "Iteration:210, Price of Hedge: 0.08131938915578729, Loss: 0.0008796914072684014\n",
      "Iteration:220, Price of Hedge: 0.07761695962056336, Loss: 0.0010696640216745212\n",
      "Iteration:230, Price of Hedge: 0.07249222298604252, Loss: 0.000686307547276277\n",
      "Iteration:240, Price of Hedge: 0.07715402593930776, Loss: 0.0010478074494391088\n",
      "Iteration:250, Price of Hedge: 0.0740714324335201, Loss: 0.0008715396124792107\n",
      "Iteration:260, Price of Hedge: 0.08402631343251699, Loss: 0.0009045009313785046\n",
      "Iteration:270, Price of Hedge: 0.07299206324429264, Loss: 0.001036548827879069\n",
      "Iteration:280, Price of Hedge: 0.07381913349924218, Loss: 0.0009217271203870725\n",
      "Iteration:290, Price of Hedge: 0.0652611544804671, Loss: 0.0009689607015000989\n",
      "Iteration:300, Price of Hedge: 0.059030504830914765, Loss: 0.000815741032922368\n",
      "Iteration:310, Price of Hedge: 0.06031310977316906, Loss: 0.0011414342305005043\n",
      "Iteration:320, Price of Hedge: 0.07085990508866047, Loss: 0.0009108608229418946\n",
      "Iteration:330, Price of Hedge: 0.0740226968254376, Loss: 0.0008654779652367273\n",
      "Iteration:340, Price of Hedge: 0.07061241056085521, Loss: 0.0012432757699437635\n",
      "Iteration:350, Price of Hedge: 0.05615930520992407, Loss: 0.0009961257951662805\n",
      "Iteration:360, Price of Hedge: 0.06290124457990487, Loss: 0.0008713191180398372\n",
      "Iteration:370, Price of Hedge: 0.06210963022077465, Loss: 0.0007979258296597624\n",
      "Iteration:380, Price of Hedge: 0.06897846519677842, Loss: 0.0008619619157351766\n",
      "Iteration:390, Price of Hedge: 0.06762222388605466, Loss: 0.0008597377166685849\n",
      "Iteration:400, Price of Hedge: 0.06576495681418493, Loss: 0.001390084526137203\n",
      "Iteration:410, Price of Hedge: 0.0687834863674297, Loss: 0.0007101505193063407\n",
      "Iteration:420, Price of Hedge: 0.0746419868995929, Loss: 0.0007798098635325434\n",
      "Iteration:430, Price of Hedge: 0.07802797555438445, Loss: 0.0009779054313402424\n",
      "Iteration:440, Price of Hedge: 0.07760431945591506, Loss: 0.0007674525882128691\n",
      "Iteration:450, Price of Hedge: 0.07247160147514364, Loss: 0.0005173237449335177\n",
      "Iteration:460, Price of Hedge: 0.07604128068390281, Loss: 0.0006825583293734727\n",
      "Iteration:470, Price of Hedge: 0.07255067659812653, Loss: 0.0007395879080995815\n",
      "Iteration:480, Price of Hedge: 0.07106159656817823, Loss: 0.0006004155389122134\n",
      "Iteration:490, Price of Hedge: 0.06271503743207063, Loss: 0.0005083758059812316\n",
      "Iteration:500, Price of Hedge: 0.06835118337722434, Loss: 0.0005182468724454492\n",
      "Iteration:510, Price of Hedge: 0.06394486149758905, Loss: 0.0005833485462389265\n",
      "Iteration:520, Price of Hedge: 0.07129880633840457, Loss: 0.0004868336861141298\n",
      "Iteration:530, Price of Hedge: 0.07658087168618266, Loss: 0.0005534789428482401\n",
      "Iteration:540, Price of Hedge: 0.07987648654346202, Loss: 0.0006419375097363456\n",
      "Iteration:550, Price of Hedge: 0.0778470511738405, Loss: 0.0006065467710800188\n",
      "Iteration:560, Price of Hedge: 0.07837549948881417, Loss: 0.0006816332926429247\n",
      "Iteration:570, Price of Hedge: 0.07488850390746649, Loss: 0.0007496412033874966\n",
      "Iteration:580, Price of Hedge: 0.07720681201561774, Loss: 0.0006448045467732921\n",
      "Iteration:590, Price of Hedge: 0.07537914091955145, Loss: 0.000623899496599023\n",
      "Iteration:600, Price of Hedge: 0.07925803880031168, Loss: 0.0006428525535354113\n",
      "Iteration:610, Price of Hedge: 0.07618498131343188, Loss: 0.0005996115547662884\n",
      "Iteration:620, Price of Hedge: 0.0790066809889467, Loss: 0.0006999806398177988\n",
      "Iteration:630, Price of Hedge: 0.07819858397990487, Loss: 0.0007031308505350831\n",
      "Iteration:640, Price of Hedge: 0.08178662288482741, Loss: 0.0006923639137013105\n",
      "Iteration:650, Price of Hedge: 0.08269698511735868, Loss: 0.0004557215469991327\n",
      "Iteration:660, Price of Hedge: 0.0771424464877768, Loss: 0.0005427891871925827\n",
      "Iteration:670, Price of Hedge: 0.08069585622916264, Loss: 0.0005743143674755147\n",
      "Iteration:680, Price of Hedge: 0.08075726319933807, Loss: 0.0007801276874996876\n",
      "Iteration:690, Price of Hedge: 0.07266169790440813, Loss: 0.0006525909902382887\n",
      "Iteration:700, Price of Hedge: 0.07614771076625004, Loss: 0.000553904779843073\n",
      "Iteration:710, Price of Hedge: 0.07557692231934254, Loss: 0.0006502281900244711\n",
      "Iteration:720, Price of Hedge: 0.07028491538587645, Loss: 0.0005739080288835741\n",
      "Iteration:730, Price of Hedge: 0.07346291067733546, Loss: 0.0004910446911920996\n",
      "Iteration:740, Price of Hedge: 0.08078993732301143, Loss: 0.000503268768047016\n",
      "Iteration:750, Price of Hedge: 0.07887074852312992, Loss: 0.0005142057878243511\n",
      "Iteration:760, Price of Hedge: 0.07439992072715285, Loss: 0.0005975426523543992\n",
      "Iteration:770, Price of Hedge: 0.07157848622991736, Loss: 0.000609557730703314\n",
      "Iteration:780, Price of Hedge: 0.07995133961227197, Loss: 0.0006380810912393065\n",
      "Iteration:790, Price of Hedge: 0.07695317159122084, Loss: 0.0006578247271696314\n",
      "Iteration:800, Price of Hedge: 0.07678856867379125, Loss: 0.000592644125466113\n",
      "Iteration:810, Price of Hedge: 0.0697105808294296, Loss: 0.000503025362984244\n",
      "Iteration:820, Price of Hedge: 0.07268202303958304, Loss: 0.0006556524832224131\n",
      "Iteration:830, Price of Hedge: 0.07750645827169222, Loss: 0.0006209236341009339\n",
      "Iteration:840, Price of Hedge: 0.08456348143326409, Loss: 0.00071472801311534\n",
      "Iteration:850, Price of Hedge: 0.0721854273155742, Loss: 0.0005288608280598628\n",
      "Iteration:860, Price of Hedge: 0.06995986401072685, Loss: 0.000587719966302358\n",
      "Iteration:870, Price of Hedge: 0.0653048257033717, Loss: 0.0006909539354421623\n",
      "Iteration:880, Price of Hedge: 0.06969752469885293, Loss: 0.0005992547339933596\n",
      "Iteration:890, Price of Hedge: 0.07238328670897687, Loss: 0.0007071667762037492\n",
      "Iteration:900, Price of Hedge: 0.06764636030904825, Loss: 0.000603197961004942\n",
      "Iteration:910, Price of Hedge: 0.0761943717442648, Loss: 0.0006175372489786168\n",
      "Iteration:920, Price of Hedge: 0.0812652407910619, Loss: 0.0005736969992939378\n",
      "Iteration:930, Price of Hedge: 0.07586067867695334, Loss: 0.0005964082515227953\n",
      "Iteration:940, Price of Hedge: 0.07830113517997006, Loss: 0.0006530240172691881\n",
      "Iteration:950, Price of Hedge: 0.07025221526433256, Loss: 0.0006246005860480186\n",
      "Iteration:960, Price of Hedge: 0.0627394858295105, Loss: 0.0006169658645305276\n",
      "Iteration:970, Price of Hedge: 0.0635269041323383, Loss: 0.0005511141521724605\n",
      "Iteration:980, Price of Hedge: 0.07214250483134066, Loss: 0.0006100873966935483\n",
      "Iteration:990, Price of Hedge: 0.07454775501809507, Loss: 0.000639422906331677\n",
      "tf.Tensor(0.04422377, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_127 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.03450472732922094, Loss: 0.0005307920636229979\n",
      "Iteration:20, Price of Hedge: 0.026640644473641117, Loss: 0.0002804751826207541\n",
      "Iteration:30, Price of Hedge: 0.03465250702463507, Loss: 0.0002557251286394724\n",
      "Iteration:40, Price of Hedge: 0.044330081737697924, Loss: 0.0002937626130017357\n",
      "Iteration:50, Price of Hedge: 0.04327316170966711, Loss: 0.00031439864614860036\n",
      "Iteration:60, Price of Hedge: 0.04254580888689574, Loss: 0.0002624482998217492\n",
      "Iteration:70, Price of Hedge: 0.038214181489060195, Loss: 0.0002842955290724425\n",
      "Iteration:80, Price of Hedge: 0.040212832780195384, Loss: 0.00025680615259315864\n",
      "Iteration:90, Price of Hedge: 0.042891219194451935, Loss: 0.00023678880783223333\n",
      "Iteration:100, Price of Hedge: 0.04421994435901411, Loss: 0.0003293042205504415\n",
      "Iteration:110, Price of Hedge: 0.04401534631757187, Loss: 0.0003128621923115249\n",
      "Iteration:120, Price of Hedge: 0.04266700835948711, Loss: 0.0002648471517700812\n",
      "Iteration:130, Price of Hedge: 0.03588732008150686, Loss: 0.00023271926772941431\n",
      "Iteration:140, Price of Hedge: 0.03456778516417458, Loss: 0.00028219057492603894\n",
      "Iteration:150, Price of Hedge: 0.0395630836009353, Loss: 0.00022622737604061083\n",
      "Iteration:160, Price of Hedge: 0.035200812513114244, Loss: 0.0002807123725676042\n",
      "Iteration:170, Price of Hedge: 0.03521162502746478, Loss: 0.0002531179687535745\n",
      "Iteration:180, Price of Hedge: 0.035041492362974935, Loss: 0.0003396171695702055\n",
      "Iteration:190, Price of Hedge: 0.03770558514801792, Loss: 0.0003112034469288094\n",
      "Iteration:200, Price of Hedge: 0.03964120200228294, Loss: 0.00024274016723335734\n",
      "Iteration:210, Price of Hedge: 0.04001764596788249, Loss: 0.0002735870671365104\n",
      "Iteration:220, Price of Hedge: 0.04482007920216802, Loss: 0.0003312094988647263\n",
      "Iteration:230, Price of Hedge: 0.04249557320168407, Loss: 0.0002693490283353639\n",
      "Iteration:240, Price of Hedge: 0.04070239348044069, Loss: 0.00030934920974626245\n",
      "Iteration:250, Price of Hedge: 0.044924081083408396, Loss: 0.0002764677327446452\n",
      "Iteration:260, Price of Hedge: 0.043105816016897336, Loss: 0.000248460247141008\n",
      "Iteration:270, Price of Hedge: 0.043548013796623763, Loss: 0.00030279157188020656\n",
      "Iteration:280, Price of Hedge: 0.04392113523437047, Loss: 0.00027423394696329817\n",
      "Iteration:290, Price of Hedge: 0.03607747110629944, Loss: 0.00024680424372119925\n",
      "Iteration:300, Price of Hedge: 0.04282985902044345, Loss: 0.00028912928470362087\n",
      "Iteration:310, Price of Hedge: 0.039530438074919516, Loss: 0.0002934167397695975\n",
      "Iteration:320, Price of Hedge: 0.037131307786886225, Loss: 0.0002957960933150372\n",
      "Iteration:330, Price of Hedge: 0.041431202183961346, Loss: 0.00024582081333615613\n",
      "Iteration:340, Price of Hedge: 0.04017848439366034, Loss: 0.0002540255178540285\n",
      "Iteration:350, Price of Hedge: 0.03711821265950377, Loss: 0.00030470288251288613\n",
      "Iteration:360, Price of Hedge: 0.04903985596165228, Loss: 0.00032512238183346476\n",
      "Iteration:370, Price of Hedge: 0.04624243829720598, Loss: 0.00023387923990397796\n",
      "Iteration:380, Price of Hedge: 0.03922339282489418, Loss: 0.00028220211148108354\n",
      "Iteration:390, Price of Hedge: 0.0361983716033798, Loss: 0.000343271576488946\n",
      "Iteration:400, Price of Hedge: 0.046033602602868484, Loss: 0.00022819888799222032\n",
      "Iteration:410, Price of Hedge: 0.04644651118166365, Loss: 0.00026281783517823065\n",
      "Iteration:420, Price of Hedge: 0.037786378730242376, Loss: 0.0002692404466042575\n",
      "Iteration:430, Price of Hedge: 0.032884568635882516, Loss: 0.00023108633741969475\n",
      "Iteration:440, Price of Hedge: 0.03446822631900659, Loss: 0.0002802272888631496\n",
      "Iteration:450, Price of Hedge: 0.037630011938194485, Loss: 0.0002754174187755143\n",
      "Iteration:460, Price of Hedge: 0.044256611755599806, Loss: 0.0003014572311756114\n",
      "Iteration:470, Price of Hedge: 0.03982597146787725, Loss: 0.00028970012075912877\n",
      "Iteration:480, Price of Hedge: 0.04426966268660237, Loss: 0.00023305695569450502\n",
      "Iteration:490, Price of Hedge: 0.03073595382820926, Loss: 0.0002091377570956343\n",
      "Iteration:500, Price of Hedge: 0.03692052745183361, Loss: 0.0002324999310077125\n",
      "Iteration:510, Price of Hedge: 0.03554541688668422, Loss: 0.0002683488821320079\n",
      "Iteration:520, Price of Hedge: 0.045636453933184384, Loss: 0.0002471003757151258\n",
      "Iteration:530, Price of Hedge: 0.04476569165703381, Loss: 0.00024981506116864005\n",
      "Iteration:540, Price of Hedge: 0.036629424096013, Loss: 0.00020811197861680952\n",
      "Iteration:550, Price of Hedge: 0.04238572959893716, Loss: 0.0003582988331113368\n",
      "Iteration:560, Price of Hedge: 0.03631604056515414, Loss: 0.00024877140915383067\n",
      "Iteration:570, Price of Hedge: 0.0403932034060972, Loss: 0.0003360595234758179\n",
      "Iteration:580, Price of Hedge: 0.04056740733711095, Loss: 0.00028046163529291124\n",
      "Iteration:590, Price of Hedge: 0.0455944985697343, Loss: 0.00016946208191703782\n",
      "Iteration:600, Price of Hedge: 0.04012934581858474, Loss: 0.00019033950935387622\n",
      "Iteration:610, Price of Hedge: 0.04028720488840065, Loss: 0.00019107821447178486\n",
      "Iteration:620, Price of Hedge: 0.036556874438531395, Loss: 0.00016681371134419365\n",
      "Iteration:630, Price of Hedge: 0.041862514655299776, Loss: 0.00017024070798378477\n",
      "Iteration:640, Price of Hedge: 0.04700080137993723, Loss: 0.0001895519769853915\n",
      "Iteration:650, Price of Hedge: 0.04078506930849102, Loss: 0.0001718796401456446\n",
      "Iteration:660, Price of Hedge: 0.039532127936503514, Loss: 0.00015945231275141247\n",
      "Iteration:670, Price of Hedge: 0.039514189405842615, Loss: 0.00017657767876835817\n",
      "Iteration:680, Price of Hedge: 0.03821939666188712, Loss: 0.00019836363022579517\n",
      "Iteration:690, Price of Hedge: 0.04239287121396984, Loss: 0.00019833574344749194\n",
      "Iteration:700, Price of Hedge: 0.03901478071224318, Loss: 0.00015539889945265228\n",
      "Iteration:710, Price of Hedge: 0.03377276248421879, Loss: 0.00016066397600447702\n",
      "Iteration:720, Price of Hedge: 0.04088756331324106, Loss: 0.00019043194397008745\n",
      "Iteration:730, Price of Hedge: 0.04115746540565013, Loss: 0.00022211012578321476\n",
      "Iteration:740, Price of Hedge: 0.043743928549311306, Loss: 0.0002098476005150951\n",
      "Iteration:750, Price of Hedge: 0.03626731015664575, Loss: 0.00017300790710467195\n",
      "Iteration:760, Price of Hedge: 0.03311164703596603, Loss: 0.00019281990931013793\n",
      "Iteration:770, Price of Hedge: 0.048581752684739854, Loss: 0.00015577691458330822\n",
      "Iteration:780, Price of Hedge: 0.03865586711073732, Loss: 0.00017880555409632848\n",
      "Iteration:790, Price of Hedge: 0.0400790971344378, Loss: 0.00014209690620201054\n",
      "Iteration:800, Price of Hedge: 0.04149369846491169, Loss: 0.00018395634157203355\n",
      "Iteration:810, Price of Hedge: 0.04255788749754075, Loss: 0.0001841331474024266\n",
      "Iteration:820, Price of Hedge: 0.0422602560764318, Loss: 0.00017427633914532392\n",
      "Iteration:830, Price of Hedge: 0.0406942223497353, Loss: 0.00018615608639166448\n",
      "Iteration:840, Price of Hedge: 0.04031611712020933, Loss: 0.00019068857138732076\n",
      "Iteration:850, Price of Hedge: 0.04030011803068945, Loss: 0.00015266269466802929\n",
      "Iteration:860, Price of Hedge: 0.0440369349492542, Loss: 0.00016348166786452067\n",
      "Iteration:870, Price of Hedge: 0.03869446354931583, Loss: 0.0001960776049733659\n",
      "Iteration:880, Price of Hedge: 0.04188466744077246, Loss: 0.0001736109967682975\n",
      "Iteration:890, Price of Hedge: 0.044238777216421, Loss: 0.00017140940366255908\n",
      "Iteration:900, Price of Hedge: 0.03553954396773307, Loss: 0.00018445369302164116\n",
      "Iteration:910, Price of Hedge: 0.03672366377687197, Loss: 0.0001505840735209485\n",
      "Iteration:920, Price of Hedge: 0.03683073600662112, Loss: 0.00015519902051217005\n",
      "Iteration:930, Price of Hedge: 0.04418077076770999, Loss: 0.00014681336675329004\n",
      "Iteration:940, Price of Hedge: 0.04194625639604155, Loss: 0.00016705136844027968\n",
      "Iteration:950, Price of Hedge: 0.038426386507417476, Loss: 0.00017407270270011765\n",
      "Iteration:960, Price of Hedge: 0.0414617834790576, Loss: 0.0001858066993848384\n",
      "Iteration:970, Price of Hedge: 0.04397330776093611, Loss: 0.00017289227751335345\n",
      "Iteration:980, Price of Hedge: 0.034329028520652116, Loss: 0.00015839650470104993\n",
      "Iteration:990, Price of Hedge: 0.04183754110087534, Loss: 0.00015522302792073117\n",
      "tf.Tensor(0.0799854, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_128 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.05627869783051409, Loss: 0.0009671262267613168\n",
      "Iteration:20, Price of Hedge: 0.08081978807794599, Loss: 0.0010129152199500613\n",
      "Iteration:30, Price of Hedge: 0.07361331355788536, Loss: 0.0009210152661948134\n",
      "Iteration:40, Price of Hedge: 0.06604657094726463, Loss: 0.0010353218096337269\n",
      "Iteration:50, Price of Hedge: 0.07041321487690766, Loss: 0.0009737119748248757\n",
      "Iteration:60, Price of Hedge: 0.07538293660864781, Loss: 0.0007826883152595165\n",
      "Iteration:70, Price of Hedge: 0.08169785055613943, Loss: 0.0010305385264308686\n",
      "Iteration:80, Price of Hedge: 0.07398025270202169, Loss: 0.0009477448955297341\n",
      "Iteration:90, Price of Hedge: 0.07068476263452084, Loss: 0.001016168203499257\n",
      "Iteration:100, Price of Hedge: 0.06816595894889588, Loss: 0.000976711966596544\n",
      "Iteration:110, Price of Hedge: 0.08029357038026319, Loss: 0.0009640993434423262\n",
      "Iteration:120, Price of Hedge: 0.07990796996466543, Loss: 0.0009288589049749607\n",
      "Iteration:130, Price of Hedge: 0.0764085162037631, Loss: 0.0008546416465859963\n",
      "Iteration:140, Price of Hedge: 0.07521054992878362, Loss: 0.0011229460073647335\n",
      "Iteration:150, Price of Hedge: 0.07380735126432114, Loss: 0.0009583827366876907\n",
      "Iteration:160, Price of Hedge: 0.06961227768140787, Loss: 0.0010273630490331698\n",
      "Iteration:170, Price of Hedge: 0.0701794836217573, Loss: 0.0010143676072355001\n",
      "Iteration:180, Price of Hedge: 0.09150605676921941, Loss: 0.0009547939743920208\n",
      "Iteration:190, Price of Hedge: 0.07864483222785879, Loss: 0.001046897686457493\n",
      "Iteration:200, Price of Hedge: 0.0804050544486401, Loss: 0.0009264605201758647\n",
      "Iteration:210, Price of Hedge: 0.07053864940260723, Loss: 0.0008354578179270433\n",
      "Iteration:220, Price of Hedge: 0.07382732282845694, Loss: 0.0010442261615312143\n",
      "Iteration:230, Price of Hedge: 0.06738458775075173, Loss: 0.0008957533791376093\n",
      "Iteration:240, Price of Hedge: 0.0679052419041426, Loss: 0.0008754450613351894\n",
      "Iteration:250, Price of Hedge: 0.06496671819764543, Loss: 0.0007748965097337246\n",
      "Iteration:260, Price of Hedge: 0.06998281493082459, Loss: 0.0009576359478569163\n",
      "Iteration:270, Price of Hedge: 0.08674159862440689, Loss: 0.0010063802489773677\n",
      "Iteration:280, Price of Hedge: 0.08304005821635485, Loss: 0.0008445582100169435\n",
      "Iteration:290, Price of Hedge: 0.06672494378197058, Loss: 0.0008838068701721991\n",
      "Iteration:300, Price of Hedge: 0.07223054402007989, Loss: 0.0011105155317908677\n",
      "Iteration:310, Price of Hedge: 0.07916288659419735, Loss: 0.0011013071672949515\n",
      "Iteration:320, Price of Hedge: 0.0719786194551375, Loss: 0.000777148331537747\n",
      "Iteration:330, Price of Hedge: 0.07456487201604745, Loss: 0.0008846110168048149\n",
      "Iteration:340, Price of Hedge: 0.06993068400085178, Loss: 0.0009907084888960416\n",
      "Iteration:350, Price of Hedge: 0.0736008345800343, Loss: 0.0010277171075323555\n",
      "Iteration:360, Price of Hedge: 0.06728539027598401, Loss: 0.0008235416127294615\n",
      "Iteration:370, Price of Hedge: 0.06929874336289998, Loss: 0.000952161933731599\n",
      "Iteration:380, Price of Hedge: 0.06773364555954231, Loss: 0.0010861841247683524\n",
      "Iteration:390, Price of Hedge: 0.07187316689272194, Loss: 0.0009224839021493292\n",
      "Iteration:400, Price of Hedge: 0.07338356517649913, Loss: 0.0009695127500319867\n",
      "Iteration:410, Price of Hedge: 0.08039397935579728, Loss: 0.0006797919528414575\n",
      "Iteration:420, Price of Hedge: 0.07553352147429138, Loss: 0.0009408297869439863\n",
      "Iteration:430, Price of Hedge: 0.0811725063869062, Loss: 0.0009183288737363293\n",
      "Iteration:440, Price of Hedge: 0.07785893740024363, Loss: 0.000698578135946426\n",
      "Iteration:450, Price of Hedge: 0.07520914604377538, Loss: 0.0008766544497745832\n",
      "Iteration:460, Price of Hedge: 0.06533834735762412, Loss: 0.0009098287074821299\n",
      "Iteration:470, Price of Hedge: 0.07040729776157661, Loss: 0.0007013883432632761\n",
      "Iteration:480, Price of Hedge: 0.06170714678805922, Loss: 0.0010659047295968893\n",
      "Iteration:490, Price of Hedge: 0.06688894874837814, Loss: 0.0010007800639366682\n",
      "Iteration:500, Price of Hedge: 0.07992618927232797, Loss: 0.0009735996965215543\n",
      "Iteration:510, Price of Hedge: 0.08517722876142386, Loss: 0.0013229832098837768\n",
      "Iteration:520, Price of Hedge: 0.0815476452594055, Loss: 0.0008838652028941851\n",
      "Iteration:530, Price of Hedge: 0.07803554613428076, Loss: 0.001038815760945333\n",
      "Iteration:540, Price of Hedge: 0.0669655072774944, Loss: 0.0009068139294216016\n",
      "Iteration:550, Price of Hedge: 0.08038243110171095, Loss: 0.0009217657109761301\n",
      "Iteration:560, Price of Hedge: 0.07642360016824057, Loss: 0.0009320633862469618\n",
      "Iteration:570, Price of Hedge: 0.0845922662755072, Loss: 0.0009085220707583108\n",
      "Iteration:580, Price of Hedge: 0.07908477859199792, Loss: 0.0011645250516389982\n",
      "Iteration:590, Price of Hedge: 0.07406182362057478, Loss: 0.0011385759271231866\n",
      "Iteration:600, Price of Hedge: 0.0771221473504724, Loss: 0.0009185094776931191\n",
      "Iteration:610, Price of Hedge: 0.0733292608245506, Loss: 0.0008158745969821801\n",
      "Iteration:620, Price of Hedge: 0.0804914765698328, Loss: 0.0007643070896096171\n",
      "Iteration:630, Price of Hedge: 0.08792799064742951, Loss: 0.0008000687041376242\n",
      "Iteration:640, Price of Hedge: 0.08221935224010934, Loss: 0.0009377312469943666\n",
      "Iteration:650, Price of Hedge: 0.07900703975955992, Loss: 0.000668693827510225\n",
      "Iteration:660, Price of Hedge: 0.07952191718612056, Loss: 0.000744027044491391\n",
      "Iteration:670, Price of Hedge: 0.08390132607019041, Loss: 0.0006021433817601785\n",
      "Iteration:680, Price of Hedge: 0.08771554644866342, Loss: 0.0007227468125481362\n",
      "Iteration:690, Price of Hedge: 0.08054951941556254, Loss: 0.0006574361402486573\n",
      "Iteration:700, Price of Hedge: 0.08441206463576378, Loss: 0.0007389134258461993\n",
      "Iteration:710, Price of Hedge: 0.08074685365198064, Loss: 0.0005654707449787022\n",
      "Iteration:720, Price of Hedge: 0.07872329380109733, Loss: 0.0004896618075886372\n",
      "Iteration:730, Price of Hedge: 0.07795744853122955, Loss: 0.0005444245751135002\n",
      "Iteration:740, Price of Hedge: 0.0775196339924733, Loss: 0.0006869731740050122\n",
      "Iteration:750, Price of Hedge: 0.08085705862512782, Loss: 0.0006498183985903516\n",
      "Iteration:760, Price of Hedge: 0.08423820647642799, Loss: 0.0006419968986218216\n",
      "Iteration:770, Price of Hedge: 0.0752541847546695, Loss: 0.0005531703806224697\n",
      "Iteration:780, Price of Hedge: 0.07534098124519772, Loss: 0.0006059151040696542\n",
      "Iteration:790, Price of Hedge: 0.07453993485864174, Loss: 0.0006141290093963914\n",
      "Iteration:800, Price of Hedge: 0.0706240212098308, Loss: 0.0005415777270478817\n",
      "Iteration:810, Price of Hedge: 0.07370421771195623, Loss: 0.0006397145293199347\n",
      "Iteration:820, Price of Hedge: 0.07177661080159936, Loss: 0.0007030650434253216\n",
      "Iteration:830, Price of Hedge: 0.07482659257860291, Loss: 0.0005258120902809638\n",
      "Iteration:840, Price of Hedge: 0.07469711278424995, Loss: 0.000643879266312708\n",
      "Iteration:850, Price of Hedge: 0.07065767285343583, Loss: 0.0006190682798223879\n",
      "Iteration:860, Price of Hedge: 0.08339547510427536, Loss: 0.000584915283532994\n",
      "Iteration:870, Price of Hedge: 0.07421512266390096, Loss: 0.0006082533687931657\n",
      "Iteration:880, Price of Hedge: 0.06843446495565786, Loss: 0.0005730158550862341\n",
      "Iteration:890, Price of Hedge: 0.0837148173470581, Loss: 0.0005713922474503974\n",
      "Iteration:900, Price of Hedge: 0.08094522780321967, Loss: 0.0007516479952618393\n",
      "Iteration:910, Price of Hedge: 0.07575260552918905, Loss: 0.0005466355315147942\n",
      "Iteration:920, Price of Hedge: 0.06848580035079266, Loss: 0.0005728684796577066\n",
      "Iteration:930, Price of Hedge: 0.06500666652549114, Loss: 0.0006337450932744626\n",
      "Iteration:940, Price of Hedge: 0.06967107966495689, Loss: 0.0005214460322783276\n",
      "Iteration:950, Price of Hedge: 0.06277230554125879, Loss: 0.0005378593816163235\n",
      "Iteration:960, Price of Hedge: 0.06835231168480504, Loss: 0.0006709502801849343\n",
      "Iteration:970, Price of Hedge: 0.0660756469656576, Loss: 0.0005118266983197839\n",
      "Iteration:980, Price of Hedge: 0.06703746418352807, Loss: 0.0005055269674536511\n",
      "Iteration:990, Price of Hedge: 0.07568246327451789, Loss: 0.0005258241142960807\n",
      "tf.Tensor(0.027648736, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_129 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.014681451147202651, Loss: 0.00017213332249160773\n",
      "Iteration:20, Price of Hedge: 0.03822626789906636, Loss: 0.0001507918025996785\n",
      "Iteration:30, Price of Hedge: 0.031956920419240475, Loss: 0.00013859375408153962\n",
      "Iteration:40, Price of Hedge: 0.025627278678097554, Loss: 0.000126466783335194\n",
      "Iteration:50, Price of Hedge: 0.029446410054312366, Loss: 0.00015262545474958866\n",
      "Iteration:60, Price of Hedge: 0.029453772651244492, Loss: 0.00016146401984815095\n",
      "Iteration:70, Price of Hedge: 0.028777729225737403, Loss: 0.0001377157775588056\n",
      "Iteration:80, Price of Hedge: 0.027829729876049925, Loss: 0.00014549298974868285\n",
      "Iteration:90, Price of Hedge: 0.028476143528521902, Loss: 0.0001212990058448854\n",
      "Iteration:100, Price of Hedge: 0.027084118748810226, Loss: 0.00012375367197149656\n",
      "Iteration:110, Price of Hedge: 0.028688091167961005, Loss: 0.0001339533068352855\n",
      "Iteration:120, Price of Hedge: 0.032234699866418026, Loss: 0.00015362387453185522\n",
      "Iteration:130, Price of Hedge: 0.030205038315322952, Loss: 0.00011870837897977327\n",
      "Iteration:140, Price of Hedge: 0.03437813329849604, Loss: 0.00015312899084886367\n",
      "Iteration:150, Price of Hedge: 0.031048284445311936, Loss: 0.00013303246429244298\n",
      "Iteration:160, Price of Hedge: 0.030000851040234977, Loss: 0.00012692181715727446\n",
      "Iteration:170, Price of Hedge: 0.02925397901627491, Loss: 0.0001288573078406241\n",
      "Iteration:180, Price of Hedge: 0.031432504373984926, Loss: 0.00013372644494871744\n",
      "Iteration:190, Price of Hedge: 0.03370424769624236, Loss: 0.00017910656069097808\n",
      "Iteration:200, Price of Hedge: 0.02854136438630306, Loss: 0.00015826887140545087\n",
      "Iteration:210, Price of Hedge: 0.02386515341319395, Loss: 0.0001227509970690155\n",
      "Iteration:220, Price of Hedge: 0.029216817660149275, Loss: 0.00012663719125213801\n",
      "Iteration:230, Price of Hedge: 0.030165115985347768, Loss: 0.0001417892071867849\n",
      "Iteration:240, Price of Hedge: 0.028709503014123783, Loss: 0.00012509532457717631\n",
      "Iteration:250, Price of Hedge: 0.02719250387102079, Loss: 0.0001527687781662651\n",
      "Iteration:260, Price of Hedge: 0.030206678780952956, Loss: 0.00013185102356386147\n",
      "Iteration:270, Price of Hedge: 0.029579308568639107, Loss: 0.0001458403558272925\n",
      "Iteration:280, Price of Hedge: 0.028460929574691818, Loss: 0.00012685987926183695\n",
      "Iteration:290, Price of Hedge: 0.027170767051476474, Loss: 0.000135158277667774\n",
      "Iteration:300, Price of Hedge: 0.022209541423823254, Loss: 0.00015338944685874822\n",
      "Iteration:310, Price of Hedge: 0.03196122046702499, Loss: 0.00016368630969612608\n",
      "Iteration:320, Price of Hedge: 0.03091314491454611, Loss: 0.00014885801802658194\n",
      "Iteration:330, Price of Hedge: 0.03163642907058062, Loss: 0.00011736599518398505\n",
      "Iteration:340, Price of Hedge: 0.029308829323504426, Loss: 0.00012100687508571906\n",
      "Iteration:350, Price of Hedge: 0.029423732111855117, Loss: 0.00012044929185092701\n",
      "Iteration:360, Price of Hedge: 0.02520358878239648, Loss: 0.00012743256360345234\n",
      "Iteration:370, Price of Hedge: 0.03321287754420865, Loss: 0.0001381041004389072\n",
      "Iteration:380, Price of Hedge: 0.034764141880661015, Loss: 0.00014465703634634897\n",
      "Iteration:390, Price of Hedge: 0.022952854339308715, Loss: 0.00013209095547361827\n",
      "Iteration:400, Price of Hedge: 0.026377904794561147, Loss: 0.00012551375827216105\n",
      "Iteration:410, Price of Hedge: 0.026265796777291683, Loss: 0.000165877077126092\n",
      "Iteration:420, Price of Hedge: 0.03229023651742935, Loss: 0.00012162501507907708\n",
      "Iteration:430, Price of Hedge: 0.02572983507773685, Loss: 0.00012089743014406795\n",
      "Iteration:440, Price of Hedge: 0.028579134092598935, Loss: 0.00011409628566105834\n",
      "Iteration:450, Price of Hedge: 0.03212677230672867, Loss: 0.00015882308304140946\n",
      "Iteration:460, Price of Hedge: 0.025805842451998018, Loss: 0.0001414480054470063\n",
      "Iteration:470, Price of Hedge: 0.02923180803229286, Loss: 0.00011935682274095971\n",
      "Iteration:480, Price of Hedge: 0.02788830567812539, Loss: 0.0001234951048693922\n",
      "Iteration:490, Price of Hedge: 0.027812943051053196, Loss: 0.00012186857247312166\n",
      "Iteration:500, Price of Hedge: 0.023765758354610256, Loss: 0.00016164019604261726\n",
      "Iteration:510, Price of Hedge: 0.030905532738056962, Loss: 0.0001396185170185471\n",
      "Iteration:520, Price of Hedge: 0.02818592929987318, Loss: 0.00011700671679985841\n",
      "Iteration:530, Price of Hedge: 0.03323653560638462, Loss: 0.00010850225480377174\n",
      "Iteration:540, Price of Hedge: 0.025956240132973818, Loss: 0.0001516992704567871\n",
      "Iteration:550, Price of Hedge: 0.03157141099618954, Loss: 0.00015006093746459948\n",
      "Iteration:560, Price of Hedge: 0.0327994230101325, Loss: 0.0001315279898671945\n",
      "Iteration:570, Price of Hedge: 0.028728991017867855, Loss: 0.0001514720835968375\n",
      "Iteration:580, Price of Hedge: 0.024494585256640278, Loss: 0.00015398825093590474\n",
      "Iteration:590, Price of Hedge: 0.026492760786744896, Loss: 0.00014521327906594217\n",
      "Iteration:600, Price of Hedge: 0.028773161399886504, Loss: 0.0001238005900034561\n",
      "Iteration:610, Price of Hedge: 0.02707344922274757, Loss: 0.00013804661061662948\n",
      "Iteration:620, Price of Hedge: 0.030760690802011936, Loss: 0.00015546800707331998\n",
      "Iteration:630, Price of Hedge: 0.025616107393133802, Loss: 0.00013749146468219897\n",
      "Iteration:640, Price of Hedge: 0.028185313150341784, Loss: 0.00012157845248675359\n",
      "Iteration:650, Price of Hedge: 0.0340527569499649, Loss: 0.00013347553503191556\n",
      "Iteration:660, Price of Hedge: 0.026772128703811404, Loss: 0.00010980381381850424\n",
      "Iteration:670, Price of Hedge: 0.02580014891835347, Loss: 0.000150077104890331\n",
      "Iteration:680, Price of Hedge: 0.02928802842729894, Loss: 0.00014092861673996315\n",
      "Iteration:690, Price of Hedge: 0.029673813427777418, Loss: 0.0001312157818463\n",
      "Iteration:700, Price of Hedge: 0.026096324458713127, Loss: 0.0001205783469050703\n",
      "Iteration:710, Price of Hedge: 0.029903244635143267, Loss: 0.0001323904082892874\n",
      "Iteration:720, Price of Hedge: 0.02304370649763854, Loss: 0.0001406977129969622\n",
      "Iteration:730, Price of Hedge: 0.02954531895271728, Loss: 0.00010460111184509846\n",
      "Iteration:740, Price of Hedge: 0.03170992505054926, Loss: 0.00013365312282950792\n",
      "Iteration:750, Price of Hedge: 0.030795041788334032, Loss: 0.00013208609102831337\n",
      "Iteration:760, Price of Hedge: 0.02611218055994513, Loss: 0.00014975625460857123\n",
      "Iteration:770, Price of Hedge: 0.023577744354774666, Loss: 0.00015361013425106707\n",
      "Iteration:780, Price of Hedge: 0.03155261193601433, Loss: 0.0001409320289604693\n",
      "Iteration:790, Price of Hedge: 0.03003302080522019, Loss: 0.0001246705539012516\n",
      "Iteration:800, Price of Hedge: 0.02832255070925882, Loss: 0.00025366632071324724\n",
      "Iteration:810, Price of Hedge: 0.027968306325298897, Loss: 0.00016030703336653018\n",
      "Iteration:820, Price of Hedge: 0.02306495455721702, Loss: 0.0001367387857088842\n",
      "Iteration:830, Price of Hedge: 0.02934860346561763, Loss: 0.00012056123502544869\n",
      "Iteration:840, Price of Hedge: 0.029121353479588663, Loss: 9.743821105592798e-05\n",
      "Iteration:850, Price of Hedge: 0.02310881036500234, Loss: 0.00011497783689098928\n",
      "Iteration:860, Price of Hedge: 0.030344654679392846, Loss: 0.00010453145583184942\n",
      "Iteration:870, Price of Hedge: 0.02899657670001332, Loss: 0.0001123700372137465\n",
      "Iteration:880, Price of Hedge: 0.020738081450621948, Loss: 0.00010381398569334066\n",
      "Iteration:890, Price of Hedge: 0.034898722457210596, Loss: 9.332418006609278e-05\n",
      "Iteration:900, Price of Hedge: 0.021723092668679556, Loss: 7.712909097547238e-05\n",
      "Iteration:910, Price of Hedge: 0.031248247066439916, Loss: 8.463104055576876e-05\n",
      "Iteration:920, Price of Hedge: 0.028932520546831597, Loss: 7.715606376614004e-05\n",
      "Iteration:930, Price of Hedge: 0.027319383878321446, Loss: 7.67144452514662e-05\n",
      "Iteration:940, Price of Hedge: 0.03146435696494976, Loss: 0.0001017623474923457\n",
      "Iteration:950, Price of Hedge: 0.03029351426828697, Loss: 9.518448003328905e-05\n",
      "Iteration:960, Price of Hedge: 0.02982326738605323, Loss: 9.690644289413186e-05\n",
      "Iteration:970, Price of Hedge: 0.02228548120362106, Loss: 8.786644507610686e-05\n",
      "Iteration:980, Price of Hedge: 0.031722219443519606, Loss: 7.510969622717689e-05\n",
      "Iteration:990, Price of Hedge: 0.02721312798170672, Loss: 0.00011386057840526154\n",
      "tf.Tensor(0.06961206, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_130 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.05574428560404243, Loss: 0.0017660306325162356\n",
      "Iteration:20, Price of Hedge: 0.09369975708395373, Loss: 0.0010995174576394762\n",
      "Iteration:30, Price of Hedge: 0.06093485404630172, Loss: 0.000887463064444538\n",
      "Iteration:40, Price of Hedge: 0.08299303326815277, Loss: 0.0008819319362474154\n",
      "Iteration:50, Price of Hedge: 0.06769562627368941, Loss: 0.0011982472957111634\n",
      "Iteration:60, Price of Hedge: 0.07992031375358977, Loss: 0.0008707798247131748\n",
      "Iteration:70, Price of Hedge: 0.07709862447722315, Loss: 0.000906722530658044\n",
      "Iteration:80, Price of Hedge: 0.06712661608112569, Loss: 0.0011038665764045996\n",
      "Iteration:90, Price of Hedge: 0.08177951506702641, Loss: 0.0009390767180372794\n",
      "Iteration:100, Price of Hedge: 0.07166944757930338, Loss: 0.0008505861412710924\n",
      "Iteration:110, Price of Hedge: 0.07135075528328372, Loss: 0.0009310757921404678\n",
      "Iteration:120, Price of Hedge: 0.0794367741601576, Loss: 0.0009977958333740045\n",
      "Iteration:130, Price of Hedge: 0.06567553973830798, Loss: 0.0009700560242825729\n",
      "Iteration:140, Price of Hedge: 0.0782638282357695, Loss: 0.0009114348071770362\n",
      "Iteration:150, Price of Hedge: 0.07775545027683961, Loss: 0.0009332808177775487\n",
      "Iteration:160, Price of Hedge: 0.07073229714098517, Loss: 0.0010981644309654426\n",
      "Iteration:170, Price of Hedge: 0.07017751298317165, Loss: 0.0006912776901735196\n",
      "Iteration:180, Price of Hedge: 0.07598318064285792, Loss: 0.0007662355628990092\n",
      "Iteration:190, Price of Hedge: 0.07182454047569564, Loss: 0.0008876840463439839\n",
      "Iteration:200, Price of Hedge: 0.07603476041797563, Loss: 0.0009273703644008258\n",
      "Iteration:210, Price of Hedge: 0.07528715005449271, Loss: 0.0010052968689666653\n",
      "Iteration:220, Price of Hedge: 0.0732679890433019, Loss: 0.000916726998695383\n",
      "Iteration:230, Price of Hedge: 0.07561701623526318, Loss: 0.0011604312807084183\n",
      "Iteration:240, Price of Hedge: 0.07932219114561434, Loss: 0.000846101589849213\n",
      "Iteration:250, Price of Hedge: 0.06951718267060869, Loss: 0.0009756960185625108\n",
      "Iteration:260, Price of Hedge: 0.072836206010507, Loss: 0.0008511402208866148\n",
      "Iteration:270, Price of Hedge: 0.07599800462863016, Loss: 0.0007947204547109621\n",
      "Iteration:280, Price of Hedge: 0.0757764663747551, Loss: 0.001009974617063869\n",
      "Iteration:290, Price of Hedge: 0.07069549975504685, Loss: 0.0011077559390781921\n",
      "Iteration:300, Price of Hedge: 0.07379367118485192, Loss: 0.0008048672610894148\n",
      "Iteration:310, Price of Hedge: 0.07673845517857103, Loss: 0.0010846432634797898\n",
      "Iteration:320, Price of Hedge: 0.07324794468512863, Loss: 0.0009399677950494567\n",
      "Iteration:330, Price of Hedge: 0.07581045599067693, Loss: 0.0008760673853608347\n",
      "Iteration:340, Price of Hedge: 0.08135477225756915, Loss: 0.0008404734570977013\n",
      "Iteration:350, Price of Hedge: 0.08401365246957226, Loss: 0.0009282596540594046\n",
      "Iteration:360, Price of Hedge: 0.07570036540816005, Loss: 0.0010516955122191751\n",
      "Iteration:370, Price of Hedge: 0.06855329082267048, Loss: 0.000901448050188991\n",
      "Iteration:380, Price of Hedge: 0.06766783974967439, Loss: 0.000995489497285229\n",
      "Iteration:390, Price of Hedge: 0.07909878624463573, Loss: 0.0010221486886397013\n",
      "Iteration:400, Price of Hedge: 0.08052184208260371, Loss: 0.0008923691063422723\n",
      "Iteration:410, Price of Hedge: 0.0775819144910983, Loss: 0.0008700830817831573\n",
      "Iteration:420, Price of Hedge: 0.07429567966550366, Loss: 0.001011761726932292\n",
      "Iteration:430, Price of Hedge: 0.073461148021714, Loss: 0.0009396480212420233\n",
      "Iteration:440, Price of Hedge: 0.07580021802926495, Loss: 0.0009434626400378621\n",
      "Iteration:450, Price of Hedge: 0.07533495493881048, Loss: 0.0008182274042645155\n",
      "Iteration:460, Price of Hedge: 0.07652187211881767, Loss: 0.0009016642387310592\n",
      "Iteration:470, Price of Hedge: 0.07653089337988916, Loss: 0.0007228082325172469\n",
      "Iteration:480, Price of Hedge: 0.07374580390564489, Loss: 0.0005883499678241422\n",
      "Iteration:490, Price of Hedge: 0.07509647647250262, Loss: 0.001072297930931887\n",
      "Iteration:500, Price of Hedge: 0.06876272446803, Loss: 0.0010318992712227137\n",
      "Iteration:510, Price of Hedge: 0.08007193333448015, Loss: 0.0007975530851911383\n",
      "Iteration:520, Price of Hedge: 0.074943354214696, Loss: 0.0005748894891174916\n",
      "Iteration:530, Price of Hedge: 0.06947328266644348, Loss: 0.0005136326972660088\n",
      "Iteration:540, Price of Hedge: 0.067910431079099, Loss: 0.000808017471806699\n",
      "Iteration:550, Price of Hedge: 0.07512389382675622, Loss: 0.0006007133363947204\n",
      "Iteration:560, Price of Hedge: 0.07718630489534917, Loss: 0.0008471113633889971\n",
      "Iteration:570, Price of Hedge: 0.07377941395265708, Loss: 0.0005901477205708106\n",
      "Iteration:580, Price of Hedge: 0.06679665630802134, Loss: 0.0006060259199927587\n",
      "Iteration:590, Price of Hedge: 0.07602692465979999, Loss: 0.0006342174014628554\n",
      "Iteration:600, Price of Hedge: 0.08327258836988705, Loss: 0.000634733702922774\n",
      "Iteration:610, Price of Hedge: 0.08208910810836301, Loss: 0.0005751595826192224\n",
      "Iteration:620, Price of Hedge: 0.07492905538590833, Loss: 0.0006275454542098435\n",
      "Iteration:630, Price of Hedge: 0.0657276966661513, Loss: 0.0005599931561461879\n",
      "Iteration:640, Price of Hedge: 0.07514187395400995, Loss: 0.0005975871737076699\n",
      "Iteration:650, Price of Hedge: 0.07942839244670097, Loss: 0.0006184764626729344\n",
      "Iteration:660, Price of Hedge: 0.07164886246542324, Loss: 0.0006071847344496506\n",
      "Iteration:670, Price of Hedge: 0.0726106744837196, Loss: 0.000542027002747858\n",
      "Iteration:680, Price of Hedge: 0.07696154290552926, Loss: 0.000589284794377809\n",
      "Iteration:690, Price of Hedge: 0.0700865100371928, Loss: 0.0006253939273156983\n",
      "Iteration:700, Price of Hedge: 0.07070262317157017, Loss: 0.0006222232838970498\n",
      "Iteration:710, Price of Hedge: 0.06989870142053434, Loss: 0.0007508882887391488\n",
      "Iteration:720, Price of Hedge: 0.08535617730380807, Loss: 0.0007765940894355339\n",
      "Iteration:730, Price of Hedge: 0.08006156538371556, Loss: 0.000617439025774047\n",
      "Iteration:740, Price of Hedge: 0.07946851236049213, Loss: 0.0005984427879995868\n",
      "Iteration:750, Price of Hedge: 0.07684302901296292, Loss: 0.0005372940091757927\n",
      "Iteration:760, Price of Hedge: 0.07855257098494661, Loss: 0.000703198444998443\n",
      "Iteration:770, Price of Hedge: 0.07656575132468646, Loss: 0.0005423302841561783\n",
      "Iteration:780, Price of Hedge: 0.07095712152569433, Loss: 0.0005760556154754681\n",
      "Iteration:790, Price of Hedge: 0.07616012214963774, Loss: 0.0005143911038951732\n",
      "Iteration:800, Price of Hedge: 0.07767329180641269, Loss: 0.0006117361491447815\n",
      "Iteration:810, Price of Hedge: 0.0758386376823239, Loss: 0.0005838760186588354\n",
      "Iteration:820, Price of Hedge: 0.07393409088312097, Loss: 0.0004581557601135433\n",
      "Iteration:830, Price of Hedge: 0.07246338094848426, Loss: 0.0006370483258327786\n",
      "Iteration:840, Price of Hedge: 0.06727594264983594, Loss: 0.00043014354208503747\n",
      "Iteration:850, Price of Hedge: 0.07115047808792241, Loss: 0.0005070093741552095\n",
      "Iteration:860, Price of Hedge: 0.07072767991918028, Loss: 0.0005260162954295877\n",
      "Iteration:870, Price of Hedge: 0.07676356912149629, Loss: 0.0006669185385485554\n",
      "Iteration:880, Price of Hedge: 0.07960998237273031, Loss: 0.0005604253707436335\n",
      "Iteration:890, Price of Hedge: 0.08126552156806355, Loss: 0.0006846980353608645\n",
      "Iteration:900, Price of Hedge: 0.08281883193692607, Loss: 0.0005445752815191884\n",
      "Iteration:910, Price of Hedge: 0.0789517370893833, Loss: 0.0006651661602102843\n",
      "Iteration:920, Price of Hedge: 0.07384737238620431, Loss: 0.0006454705797187543\n",
      "Iteration:930, Price of Hedge: 0.07889247754331308, Loss: 0.00065020946343336\n",
      "Iteration:940, Price of Hedge: 0.08059326343250461, Loss: 0.0005912319536366395\n",
      "Iteration:950, Price of Hedge: 0.07943501670411024, Loss: 0.0005437481836415015\n",
      "Iteration:960, Price of Hedge: 0.07881762967407724, Loss: 0.0005947431285374671\n",
      "Iteration:970, Price of Hedge: 0.07496775581596893, Loss: 0.0006935611156388966\n",
      "Iteration:980, Price of Hedge: 0.07278164167985324, Loss: 0.0007340685601875396\n",
      "Iteration:990, Price of Hedge: 0.07320621810293915, Loss: 0.0006423400298910531\n",
      "tf.Tensor(0.062000595, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_131 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.06363187833393624, Loss: 0.0010389417693740244\n",
      "Iteration:20, Price of Hedge: 0.07626933920370504, Loss: 0.00109487513164086\n",
      "Iteration:30, Price of Hedge: 0.08383115781764872, Loss: 0.0011028569653515063\n",
      "Iteration:40, Price of Hedge: 0.06923409705805739, Loss: 0.0008072911562989615\n",
      "Iteration:50, Price of Hedge: 0.0689943602948162, Loss: 0.0009327554983062925\n",
      "Iteration:60, Price of Hedge: 0.07080562673458246, Loss: 0.0009345886731515485\n",
      "Iteration:70, Price of Hedge: 0.0760210699393582, Loss: 0.0009227618356338896\n",
      "Iteration:80, Price of Hedge: 0.08034602368383048, Loss: 0.0010510380098249783\n",
      "Iteration:90, Price of Hedge: 0.07533828786581154, Loss: 0.0011372951257831998\n",
      "Iteration:100, Price of Hedge: 0.07987324200922075, Loss: 0.0009167157871137199\n",
      "Iteration:110, Price of Hedge: 0.07637688199491066, Loss: 0.0010781691437727892\n",
      "Iteration:120, Price of Hedge: 0.07901036228741276, Loss: 0.0008344560874784523\n",
      "Iteration:130, Price of Hedge: 0.06968933017006407, Loss: 0.0009342043108845344\n",
      "Iteration:140, Price of Hedge: 0.07453991925991943, Loss: 0.0008581789818440377\n",
      "Iteration:150, Price of Hedge: 0.08502604594475827, Loss: 0.0009071621383999195\n",
      "Iteration:160, Price of Hedge: 0.08048997389291657, Loss: 0.0010776192075678814\n",
      "Iteration:170, Price of Hedge: 0.08096328072451087, Loss: 0.0010865312775831804\n",
      "Iteration:180, Price of Hedge: 0.07202557160930212, Loss: 0.0009866631389993108\n",
      "Iteration:190, Price of Hedge: 0.07485175331769511, Loss: 0.0009641398026283277\n",
      "Iteration:200, Price of Hedge: 0.06994831575664051, Loss: 0.0008651175697566016\n",
      "Iteration:210, Price of Hedge: 0.07548163492430149, Loss: 0.0010818524733224866\n",
      "Iteration:220, Price of Hedge: 0.08388886269106166, Loss: 0.0009255930849771943\n",
      "Iteration:230, Price of Hedge: 0.08811172279798996, Loss: 0.001023028229096834\n",
      "Iteration:240, Price of Hedge: 0.07653034742460818, Loss: 0.0010938928995951613\n",
      "Iteration:250, Price of Hedge: 0.07308531240628469, Loss: 0.000743320471116582\n",
      "Iteration:260, Price of Hedge: 0.06946546770656425, Loss: 0.0009559947510368039\n",
      "Iteration:270, Price of Hedge: 0.07512174640265101, Loss: 0.0010599347248479996\n",
      "Iteration:280, Price of Hedge: 0.067157995510847, Loss: 0.0010396565483267173\n",
      "Iteration:290, Price of Hedge: 0.06802364660565274, Loss: 0.0009921423526987327\n",
      "Iteration:300, Price of Hedge: 0.0802348047937329, Loss: 0.0009983633993848606\n",
      "Iteration:310, Price of Hedge: 0.07732495153884855, Loss: 0.0009241668580489693\n",
      "Iteration:320, Price of Hedge: 0.08027989030079397, Loss: 0.0010356649002812857\n",
      "Iteration:330, Price of Hedge: 0.06547732157429209, Loss: 0.000930690454953309\n",
      "Iteration:340, Price of Hedge: 0.07157860582012177, Loss: 0.0008976530922827353\n",
      "Iteration:350, Price of Hedge: 0.06951930409684337, Loss: 0.0007720202515770769\n",
      "Iteration:360, Price of Hedge: 0.07011024089340623, Loss: 0.0008899384679350586\n",
      "Iteration:370, Price of Hedge: 0.0672709354599732, Loss: 0.0008305105044098537\n",
      "Iteration:380, Price of Hedge: 0.06522678529563564, Loss: 0.0007357707707600358\n",
      "Iteration:390, Price of Hedge: 0.07174967700773749, Loss: 0.001165033391251069\n",
      "Iteration:400, Price of Hedge: 0.07109253923367476, Loss: 0.000991834115446344\n",
      "Iteration:410, Price of Hedge: 0.07532321430048228, Loss: 0.0009168721805535851\n",
      "Iteration:420, Price of Hedge: 0.06906853741899255, Loss: 0.0006771811573158537\n",
      "Iteration:430, Price of Hedge: 0.07296421952496246, Loss: 0.0012986174369261638\n",
      "Iteration:440, Price of Hedge: 0.07965098101454515, Loss: 0.0005745489170136397\n",
      "Iteration:450, Price of Hedge: 0.07469251636074148, Loss: 0.0010103969199731777\n",
      "Iteration:460, Price of Hedge: 0.07332672343238755, Loss: 0.0005798322530073396\n",
      "Iteration:470, Price of Hedge: 0.07282542209381404, Loss: 0.0005843027087087949\n",
      "Iteration:480, Price of Hedge: 0.08136447466284835, Loss: 0.0006046610724119716\n",
      "Iteration:490, Price of Hedge: 0.0829200676447428, Loss: 0.0007489333301191614\n",
      "Iteration:500, Price of Hedge: 0.07384776755383626, Loss: 0.0005193140037870747\n",
      "Iteration:510, Price of Hedge: 0.06746291933463766, Loss: 0.0005741476967524584\n",
      "Iteration:520, Price of Hedge: 0.06487283988718673, Loss: 0.0006371247351991127\n",
      "Iteration:530, Price of Hedge: 0.07284980809636465, Loss: 0.0007185108657631334\n",
      "Iteration:540, Price of Hedge: 0.07534650319289682, Loss: 0.0005019990158020016\n",
      "Iteration:550, Price of Hedge: 0.07536316782790209, Loss: 0.0006631716360810946\n",
      "Iteration:560, Price of Hedge: 0.07604159265834909, Loss: 0.0004951224978053115\n",
      "Iteration:570, Price of Hedge: 0.07837240054264782, Loss: 0.0006251999588285928\n",
      "Iteration:580, Price of Hedge: 0.0856697584184829, Loss: 0.0005917259131765773\n",
      "Iteration:590, Price of Hedge: 0.08200007060139569, Loss: 0.0006699457062192549\n",
      "Iteration:600, Price of Hedge: 0.0821211478839956, Loss: 0.0006481761049850765\n",
      "Iteration:610, Price of Hedge: 0.0709275203503168, Loss: 0.0006206388761753612\n",
      "Iteration:620, Price of Hedge: 0.07570422349214567, Loss: 0.0006831146025593204\n",
      "Iteration:630, Price of Hedge: 0.07893911772303142, Loss: 0.0006115502643705417\n",
      "Iteration:640, Price of Hedge: 0.07011880459195652, Loss: 0.0005420650246334979\n",
      "Iteration:650, Price of Hedge: 0.07247556875018546, Loss: 0.00062760545242041\n",
      "Iteration:660, Price of Hedge: 0.06919064421726517, Loss: 0.0006690095391503892\n",
      "Iteration:670, Price of Hedge: 0.06761082122004325, Loss: 0.0006384386432023437\n",
      "Iteration:680, Price of Hedge: 0.06580767131545429, Loss: 0.0006015903989298188\n",
      "Iteration:690, Price of Hedge: 0.06500580339618978, Loss: 0.0005599967308533849\n",
      "Iteration:700, Price of Hedge: 0.06707556666256664, Loss: 0.0006703192224996601\n",
      "Iteration:710, Price of Hedge: 0.06886143838240599, Loss: 0.0005704203333095625\n",
      "Iteration:720, Price of Hedge: 0.07235621252661417, Loss: 0.0006605602312304004\n",
      "Iteration:730, Price of Hedge: 0.07282364383947026, Loss: 0.0008123882825450401\n",
      "Iteration:740, Price of Hedge: 0.07315056706129752, Loss: 0.000614889365865845\n",
      "Iteration:750, Price of Hedge: 0.06653175880568796, Loss: 0.0004934116348165318\n",
      "Iteration:760, Price of Hedge: 0.06037053906915446, Loss: 0.0004800474294741619\n",
      "Iteration:770, Price of Hedge: 0.07280197721417636, Loss: 0.0006157089081124112\n",
      "Iteration:780, Price of Hedge: 0.07557929852470835, Loss: 0.0005937239307696185\n",
      "Iteration:790, Price of Hedge: 0.0756692823541627, Loss: 0.0005020626699631103\n",
      "Iteration:800, Price of Hedge: 0.07016180506980163, Loss: 0.0005833864868812211\n",
      "Iteration:810, Price of Hedge: 0.05599256006796338, Loss: 0.0007188109786809838\n",
      "Iteration:820, Price of Hedge: 0.06555884569667825, Loss: 0.0006921328576270369\n",
      "Iteration:830, Price of Hedge: 0.06872951998779797, Loss: 0.0005201686025371743\n",
      "Iteration:840, Price of Hedge: 0.07047163729154704, Loss: 0.0006303251952721745\n",
      "Iteration:850, Price of Hedge: 0.06985514978783414, Loss: 0.0006005854999907578\n",
      "Iteration:860, Price of Hedge: 0.0679571388532807, Loss: 0.000557445202348239\n",
      "Iteration:870, Price of Hedge: 0.07304316465859273, Loss: 0.0005286862361106315\n",
      "Iteration:880, Price of Hedge: 0.06664197417798334, Loss: 0.0005827618474202323\n",
      "Iteration:890, Price of Hedge: 0.06443113086742613, Loss: 0.0005236282285353555\n",
      "Iteration:900, Price of Hedge: 0.07045318920262389, Loss: 0.0006387130019797072\n",
      "Iteration:910, Price of Hedge: 0.07410507887755102, Loss: 0.0005636025948732581\n",
      "Iteration:920, Price of Hedge: 0.07539235303735126, Loss: 0.0007336880163577586\n",
      "Iteration:930, Price of Hedge: 0.0691513042395897, Loss: 0.0005731453163571043\n",
      "Iteration:940, Price of Hedge: 0.06910791899326085, Loss: 0.000560130822994942\n",
      "Iteration:950, Price of Hedge: 0.08156929628597709, Loss: 0.0006889764724155034\n",
      "Iteration:960, Price of Hedge: 0.08297318649379548, Loss: 0.0006488984801905628\n",
      "Iteration:970, Price of Hedge: 0.07774695417275268, Loss: 0.000581226104462429\n",
      "Iteration:980, Price of Hedge: 0.07160689150325084, Loss: 0.0005970659570253556\n",
      "Iteration:990, Price of Hedge: 0.06298588324717969, Loss: 0.0007513616937127043\n",
      "tf.Tensor(0.06956502, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_132 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.07193645090914913, Loss: 0.0009742708477977757\n",
      "Iteration:20, Price of Hedge: 0.058712166105934216, Loss: 0.0014188635188594478\n",
      "Iteration:30, Price of Hedge: 0.08588339851929305, Loss: 0.0009611216935906386\n",
      "Iteration:40, Price of Hedge: 0.0699982836637858, Loss: 0.0012108810421351812\n",
      "Iteration:50, Price of Hedge: 0.07056741344655393, Loss: 0.0007825703499220182\n",
      "Iteration:60, Price of Hedge: 0.07776860519932427, Loss: 0.0009723393685046045\n",
      "Iteration:70, Price of Hedge: 0.08213018474378941, Loss: 0.0009892125551774766\n",
      "Iteration:80, Price of Hedge: 0.0675462217113676, Loss: 0.0008358469735514351\n",
      "Iteration:90, Price of Hedge: 0.06626591498086754, Loss: 0.0009635273090474739\n",
      "Iteration:100, Price of Hedge: 0.06753816237150545, Loss: 0.0010271326429056593\n",
      "Iteration:110, Price of Hedge: 0.06949827181959023, Loss: 0.0013104476866643289\n",
      "Iteration:120, Price of Hedge: 0.062455620280843505, Loss: 0.0010791396767767525\n",
      "Iteration:130, Price of Hedge: 0.06564224686531617, Loss: 0.0008635597286088537\n",
      "Iteration:140, Price of Hedge: 0.07760186005736358, Loss: 0.0011532279207332463\n",
      "Iteration:150, Price of Hedge: 0.06726907921201786, Loss: 0.0009643104136536351\n",
      "Iteration:160, Price of Hedge: 0.07083497833040298, Loss: 0.0010971723684749524\n",
      "Iteration:170, Price of Hedge: 0.07499817852405499, Loss: 0.0009799870483356843\n",
      "Iteration:180, Price of Hedge: 0.07488861829809679, Loss: 0.0009284299401113305\n",
      "Iteration:190, Price of Hedge: 0.07254130176601592, Loss: 0.0009673411966532042\n",
      "Iteration:200, Price of Hedge: 0.07253905555000273, Loss: 0.001146183147768265\n",
      "Iteration:210, Price of Hedge: 0.0751093142209669, Loss: 0.0009698864694207554\n",
      "Iteration:220, Price of Hedge: 0.07167946715860296, Loss: 0.0009446184891126475\n",
      "Iteration:230, Price of Hedge: 0.07694694250144352, Loss: 0.0009206013313500794\n",
      "Iteration:240, Price of Hedge: 0.08263500619403175, Loss: 0.0008247996659327406\n",
      "Iteration:250, Price of Hedge: 0.07331823772744883, Loss: 0.000797736207691635\n",
      "Iteration:260, Price of Hedge: 0.06893303131825235, Loss: 0.00093345646589027\n",
      "Iteration:270, Price of Hedge: 0.07059403526596952, Loss: 0.0008334934350789913\n",
      "Iteration:280, Price of Hedge: 0.07613882469410527, Loss: 0.0008502943151744713\n",
      "Iteration:290, Price of Hedge: 0.07399342322322866, Loss: 0.0008984078429613573\n",
      "Iteration:300, Price of Hedge: 0.07272165419340837, Loss: 0.0008746142668852874\n",
      "Iteration:310, Price of Hedge: 0.07563284893841171, Loss: 0.0008230966429267905\n",
      "Iteration:320, Price of Hedge: 0.07419529148826598, Loss: 0.0009481372196445959\n",
      "Iteration:330, Price of Hedge: 0.06976047074296332, Loss: 0.0008597135873950057\n",
      "Iteration:340, Price of Hedge: 0.07946210128562115, Loss: 0.0010701454697392698\n",
      "Iteration:350, Price of Hedge: 0.0782809816307406, Loss: 0.0010547189020743142\n",
      "Iteration:360, Price of Hedge: 0.0746174033132263, Loss: 0.000913108420091957\n",
      "Iteration:370, Price of Hedge: 0.07446455663284723, Loss: 0.0010190775276974762\n",
      "Iteration:380, Price of Hedge: 0.0747860670980316, Loss: 0.0009381338890140922\n",
      "Iteration:390, Price of Hedge: 0.08026330885897437, Loss: 0.0010007525224425828\n",
      "Iteration:400, Price of Hedge: 0.07225540838344813, Loss: 0.0010214442275918723\n",
      "Iteration:410, Price of Hedge: 0.07083946036328115, Loss: 0.0010440757800989076\n",
      "Iteration:420, Price of Hedge: 0.0715318252519026, Loss: 0.0008996261681687434\n",
      "Iteration:430, Price of Hedge: 0.07717965983964348, Loss: 0.0008576150717837239\n",
      "Iteration:440, Price of Hedge: 0.06750240490038806, Loss: 0.0008180030101445634\n",
      "Iteration:450, Price of Hedge: 0.06812229812513948, Loss: 0.0008445014209185198\n",
      "Iteration:460, Price of Hedge: 0.06732572337231346, Loss: 0.0008194503603425884\n",
      "Iteration:470, Price of Hedge: 0.07925832997646154, Loss: 0.0010588938351069332\n",
      "Iteration:480, Price of Hedge: 0.07558876694915284, Loss: 0.0009002164823163072\n",
      "Iteration:490, Price of Hedge: 0.07481341685782184, Loss: 0.0009910315124372904\n",
      "Iteration:500, Price of Hedge: 0.07563208460101833, Loss: 0.0007789672887975607\n",
      "Iteration:510, Price of Hedge: 0.0775171433964772, Loss: 0.0009604215384401149\n",
      "Iteration:520, Price of Hedge: 0.07311176783932893, Loss: 0.0007925487388454888\n",
      "Iteration:530, Price of Hedge: 0.06034597628108429, Loss: 0.0007328342300411128\n",
      "Iteration:540, Price of Hedge: 0.06577321893743715, Loss: 0.000972003752244821\n",
      "Iteration:550, Price of Hedge: 0.0680731361519804, Loss: 0.0010050516765502948\n",
      "Iteration:560, Price of Hedge: 0.07842181209536392, Loss: 0.0009040090029222014\n",
      "Iteration:570, Price of Hedge: 0.07523588745339538, Loss: 0.0008477336874146424\n",
      "Iteration:580, Price of Hedge: 0.06477699613771648, Loss: 0.0009020303212453618\n",
      "Iteration:590, Price of Hedge: 0.06892358369210427, Loss: 0.0008216759405460516\n",
      "Iteration:600, Price of Hedge: 0.07949315314217387, Loss: 0.0010892652786420598\n",
      "Iteration:610, Price of Hedge: 0.08379462041041563, Loss: 0.0009188108092611502\n",
      "Iteration:620, Price of Hedge: 0.0791593300855098, Loss: 0.0008913831371026859\n",
      "Iteration:630, Price of Hedge: 0.08066825169024128, Loss: 0.0010531392064666578\n",
      "Iteration:640, Price of Hedge: 0.08505757616212861, Loss: 0.0008751422673869413\n",
      "Iteration:650, Price of Hedge: 0.07452428414058687, Loss: 0.0005974812730069612\n",
      "Iteration:660, Price of Hedge: 0.07425186285452412, Loss: 0.0013147652830114431\n",
      "Iteration:670, Price of Hedge: 0.07940993395862961, Loss: 0.0007073282879743736\n",
      "Iteration:680, Price of Hedge: 0.07450636640822239, Loss: 0.0008618874968308043\n",
      "Iteration:690, Price of Hedge: 0.07232185374093092, Loss: 0.0006283597968823051\n",
      "Iteration:700, Price of Hedge: 0.0737426477641634, Loss: 0.0007161662640586819\n",
      "Iteration:710, Price of Hedge: 0.0686522595161776, Loss: 0.0006467214835076396\n",
      "Iteration:720, Price of Hedge: 0.06638839614847569, Loss: 0.0005143377270172556\n",
      "Iteration:730, Price of Hedge: 0.07511042692982528, Loss: 0.0007791374936061413\n",
      "Iteration:740, Price of Hedge: 0.0774430286671901, Loss: 0.0010470270258633452\n",
      "Iteration:750, Price of Hedge: 0.07580802258999597, Loss: 0.0005465919444599954\n",
      "Iteration:760, Price of Hedge: 0.07090174606148025, Loss: 0.0006737951784102636\n",
      "Iteration:770, Price of Hedge: 0.07723695394670216, Loss: 0.0005978448369775569\n",
      "Iteration:780, Price of Hedge: 0.07334143302752949, Loss: 0.0006521569882872447\n",
      "Iteration:790, Price of Hedge: 0.0758544235893055, Loss: 0.0005496232961629821\n",
      "Iteration:800, Price of Hedge: 0.07190225331026312, Loss: 0.0005877119638328376\n",
      "Iteration:810, Price of Hedge: 0.07844994179126985, Loss: 0.0006930568381940949\n",
      "Iteration:820, Price of Hedge: 0.07044646095373253, Loss: 0.0005030114703721833\n",
      "Iteration:830, Price of Hedge: 0.07257240561830969, Loss: 0.0009159803723512994\n",
      "Iteration:840, Price of Hedge: 0.07022605620701228, Loss: 0.0004909817275994266\n",
      "Iteration:850, Price of Hedge: 0.0725012182492435, Loss: 0.0006580604141145918\n",
      "Iteration:860, Price of Hedge: 0.06947349584898177, Loss: 0.0005145875909259856\n",
      "Iteration:870, Price of Hedge: 0.06135663829809346, Loss: 0.0006363468301670561\n",
      "Iteration:880, Price of Hedge: 0.06029468248254233, Loss: 0.0007811883193736824\n",
      "Iteration:890, Price of Hedge: 0.05908219899666278, Loss: 0.0005638381193315278\n",
      "Iteration:900, Price of Hedge: 0.06602142580689474, Loss: 0.0006408155797582582\n",
      "Iteration:910, Price of Hedge: 0.06995013040800302, Loss: 0.0006559404096384558\n",
      "Iteration:920, Price of Hedge: 0.06826367454504378, Loss: 0.0005870337850072405\n",
      "Iteration:930, Price of Hedge: 0.07463847198749818, Loss: 0.0005498241703344453\n",
      "Iteration:940, Price of Hedge: 0.0802212547036163, Loss: 0.0005700711494110999\n",
      "Iteration:950, Price of Hedge: 0.0776500653088874, Loss: 0.0005661200011733425\n",
      "Iteration:960, Price of Hedge: 0.07648348366320334, Loss: 0.0005405264381586061\n",
      "Iteration:970, Price of Hedge: 0.0748417025409509, Loss: 0.0007099221442624648\n",
      "Iteration:980, Price of Hedge: 0.07318976665047217, Loss: 0.0006575928992835767\n",
      "Iteration:990, Price of Hedge: 0.07172106895101393, Loss: 0.0006746064338356006\n",
      "\n",
      "\n",
      " ############\n",
      " \n",
      " ##### Calculations for Stock: 20 \n",
      "\n",
      "tf.Tensor(0.07821209, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_133 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.06513045736260707, Loss: 0.0014315241925659805\n",
      "Iteration:20, Price of Hedge: 0.10590461475562875, Loss: 0.0017144148331821095\n",
      "Iteration:30, Price of Hedge: 0.07999428911373342, Loss: 0.001639401930724782\n",
      "Iteration:40, Price of Hedge: 0.08838241718923286, Loss: 0.0014634270378486303\n",
      "Iteration:50, Price of Hedge: 0.0918294458475259, Loss: 0.0016152999430646853\n",
      "Iteration:60, Price of Hedge: 0.08774634575731141, Loss: 0.0015654468820415434\n",
      "Iteration:70, Price of Hedge: 0.08847318305575413, Loss: 0.00130494476643912\n",
      "Iteration:80, Price of Hedge: 0.0961480749790411, Loss: 0.0013896488407686425\n",
      "Iteration:90, Price of Hedge: 0.08643134412836274, Loss: 0.0016577207969620921\n",
      "Iteration:100, Price of Hedge: 0.08548968259757429, Loss: 0.001546504521407166\n",
      "Iteration:110, Price of Hedge: 0.09911718815231581, Loss: 0.0017694356608445093\n",
      "Iteration:120, Price of Hedge: 0.09681477740463151, Loss: 0.0018869944712617936\n",
      "Iteration:130, Price of Hedge: 0.07927986428195836, Loss: 0.001475385758059744\n",
      "Iteration:140, Price of Hedge: 0.08747271266915532, Loss: 0.0017013633328551768\n",
      "Iteration:150, Price of Hedge: 0.08430357929665319, Loss: 0.001494934889885191\n",
      "Iteration:160, Price of Hedge: 0.09110675708811442, Loss: 0.0017080752581792203\n",
      "Iteration:170, Price of Hedge: 0.09328356560727542, Loss: 0.0012539027298674287\n",
      "Iteration:180, Price of Hedge: 0.10062518209016957, Loss: 0.0014195502290786032\n",
      "Iteration:190, Price of Hedge: 0.08629641242279433, Loss: 0.0017175303812587916\n",
      "Iteration:200, Price of Hedge: 0.08666714784462215, Loss: 0.0013075383432985088\n",
      "Iteration:210, Price of Hedge: 0.09441415615189043, Loss: 0.0015650573645354714\n",
      "Iteration:220, Price of Hedge: 0.09534610934362177, Loss: 0.001430935624510643\n",
      "Iteration:230, Price of Hedge: 0.09107491373600708, Loss: 0.0015868497738521948\n",
      "Iteration:240, Price of Hedge: 0.09645457434673688, Loss: 0.0015479924427620473\n",
      "Iteration:250, Price of Hedge: 0.08704742111760168, Loss: 0.0014894168238778205\n",
      "Iteration:260, Price of Hedge: 0.08195567669287981, Loss: 0.0016649006760681262\n",
      "Iteration:270, Price of Hedge: 0.08298229802985588, Loss: 0.0014887900736353377\n",
      "Iteration:280, Price of Hedge: 0.08924586265764702, Loss: 0.001118863803389758\n",
      "Iteration:290, Price of Hedge: 0.08300497292127318, Loss: 0.0014481236764379622\n",
      "Iteration:300, Price of Hedge: 0.09522443780847283, Loss: 0.001677829490220084\n",
      "Iteration:310, Price of Hedge: 0.09140762088338192, Loss: 0.0014928663920955375\n",
      "Iteration:320, Price of Hedge: 0.07848967651933662, Loss: 0.0019199098844686624\n",
      "Iteration:330, Price of Hedge: 0.08296021037455716, Loss: 0.0012784819948668425\n",
      "Iteration:340, Price of Hedge: 0.0994883592654574, Loss: 0.0016690807376027017\n",
      "Iteration:350, Price of Hedge: 0.09486266247322846, Loss: 0.0015439260398310672\n",
      "Iteration:360, Price of Hedge: 0.08745742558697174, Loss: 0.0016796151734375098\n",
      "Iteration:370, Price of Hedge: 0.09042412351492003, Loss: 0.0015527998465109992\n",
      "Iteration:380, Price of Hedge: 0.10015383038950887, Loss: 0.0019021943855840329\n",
      "Iteration:390, Price of Hedge: 0.09362835845283257, Loss: 0.0019401763382363322\n",
      "Iteration:400, Price of Hedge: 0.08068348647128544, Loss: 0.0013119944117285342\n",
      "Iteration:410, Price of Hedge: 0.08283429558487398, Loss: 0.0017638193275027801\n",
      "Iteration:420, Price of Hedge: 0.08789196137161781, Loss: 0.0016842997430185135\n",
      "Iteration:430, Price of Hedge: 0.08934862897839792, Loss: 0.0015751411617661803\n",
      "Iteration:440, Price of Hedge: 0.0884263651826231, Loss: 0.001612427103464431\n",
      "Iteration:450, Price of Hedge: 0.08406346602500747, Loss: 0.0015959432021046994\n",
      "Iteration:460, Price of Hedge: 0.08514891516089448, Loss: 0.0014219971449013213\n",
      "Iteration:470, Price of Hedge: 0.07373591489550647, Loss: 0.001405658128662579\n",
      "Iteration:480, Price of Hedge: 0.0774284508733409, Loss: 0.0016032146888612874\n",
      "Iteration:490, Price of Hedge: 0.09515896098125154, Loss: 0.0016622980716373581\n",
      "Iteration:500, Price of Hedge: 0.0985578552209219, Loss: 0.0016463389533614148\n",
      "Iteration:510, Price of Hedge: 0.0996614044894315, Loss: 0.001407884534954884\n",
      "Iteration:520, Price of Hedge: 0.09148636735257298, Loss: 0.0014799433496695436\n",
      "Iteration:530, Price of Hedge: 0.08963301227614408, Loss: 0.0019022615743939707\n",
      "Iteration:540, Price of Hedge: 0.09000175867240898, Loss: 0.0013751714281426963\n",
      "Iteration:550, Price of Hedge: 0.08523780566045644, Loss: 0.0013570931984801858\n",
      "Iteration:560, Price of Hedge: 0.09159569745768152, Loss: 0.001536033870543907\n",
      "Iteration:570, Price of Hedge: 0.08821688290464635, Loss: 0.0012224562949148421\n",
      "Iteration:580, Price of Hedge: 0.09501770228008297, Loss: 0.001100595180766928\n",
      "Iteration:590, Price of Hedge: 0.10605996712364316, Loss: 0.0011594499143990466\n",
      "Iteration:600, Price of Hedge: 0.09434183139380252, Loss: 0.0010612194302908496\n",
      "Iteration:610, Price of Hedge: 0.08732916185281425, Loss: 0.0011043092124281672\n",
      "Iteration:620, Price of Hedge: 0.09061434065958736, Loss: 0.0011207877860408555\n",
      "Iteration:630, Price of Hedge: 0.08923915680003489, Loss: 0.0008382134804054364\n",
      "Iteration:640, Price of Hedge: 0.09289345139353457, Loss: 0.0010593239362871375\n",
      "Iteration:650, Price of Hedge: 0.09389718946498675, Loss: 0.0011142065385123523\n",
      "Iteration:660, Price of Hedge: 0.08909514187772913, Loss: 0.001243522354717963\n",
      "Iteration:670, Price of Hedge: 0.0950797504060958, Loss: 0.0011143835381085764\n",
      "Iteration:680, Price of Hedge: 0.08795148059370063, Loss: 0.0008572632099420385\n",
      "Iteration:690, Price of Hedge: 0.09224969853432015, Loss: 0.0013431564041861855\n",
      "Iteration:700, Price of Hedge: 0.10189620731107708, Loss: 0.000916493993719647\n",
      "Iteration:710, Price of Hedge: 0.0959977804188867, Loss: 0.0009963341309843666\n",
      "Iteration:720, Price of Hedge: 0.08819828077985789, Loss: 0.0009561446411438745\n",
      "Iteration:730, Price of Hedge: 0.08078052250410507, Loss: 0.0009605510579313136\n",
      "Iteration:740, Price of Hedge: 0.08955569601104826, Loss: 0.0008605062539653319\n",
      "Iteration:750, Price of Hedge: 0.09046427341664014, Loss: 0.0011016243239041711\n",
      "Iteration:760, Price of Hedge: 0.10656524591747711, Loss: 0.0011751722439174994\n",
      "Iteration:770, Price of Hedge: 0.10134889377701341, Loss: 0.0009447796687421683\n",
      "Iteration:780, Price of Hedge: 0.09142097576930439, Loss: 0.0011646460956892034\n",
      "Iteration:790, Price of Hedge: 0.08129512130343386, Loss: 0.0008968134441337927\n",
      "Iteration:800, Price of Hedge: 0.08588731722225304, Loss: 0.0009301824558042293\n",
      "Iteration:810, Price of Hedge: 0.09005491301269046, Loss: 0.0010248101249707208\n",
      "Iteration:820, Price of Hedge: 0.0838219320208168, Loss: 0.0008610762489025036\n",
      "Iteration:830, Price of Hedge: 0.0916439928926593, Loss: 0.001113995722521699\n",
      "Iteration:840, Price of Hedge: 0.08810403885437665, Loss: 0.0010117793436600685\n",
      "Iteration:850, Price of Hedge: 0.09461184634974415, Loss: 0.0011107956704571875\n",
      "Iteration:860, Price of Hedge: 0.09295685395124025, Loss: 0.0011446540208942756\n",
      "Iteration:870, Price of Hedge: 0.09321501999775705, Loss: 0.0008796521049381778\n",
      "Iteration:880, Price of Hedge: 0.09063448664707464, Loss: 0.0010738723115438441\n",
      "Iteration:890, Price of Hedge: 0.09005602118407552, Loss: 0.0012028005341520375\n",
      "Iteration:900, Price of Hedge: 0.08502256467989752, Loss: 0.0008568202669725578\n",
      "Iteration:910, Price of Hedge: 0.08490056164048809, Loss: 0.000892107489568128\n",
      "Iteration:920, Price of Hedge: 0.09364406228322934, Loss: 0.0010025345185957434\n",
      "Iteration:930, Price of Hedge: 0.08966373798531606, Loss: 0.0007208748095361316\n",
      "Iteration:940, Price of Hedge: 0.09195379783140964, Loss: 0.001146940734323254\n",
      "Iteration:950, Price of Hedge: 0.09173969343688668, Loss: 0.0009355176764929251\n",
      "Iteration:960, Price of Hedge: 0.09110817782065936, Loss: 0.0012836254906584577\n",
      "Iteration:970, Price of Hedge: 0.07764142341760305, Loss: 0.0008021633540318263\n",
      "Iteration:980, Price of Hedge: 0.07945075946401445, Loss: 0.0008560624689521012\n",
      "Iteration:990, Price of Hedge: 0.09037038193851998, Loss: 0.001056265809484147\n",
      "tf.Tensor(0.08264104, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_134 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.09289431330461184, Loss: 0.0014170774144855347\n",
      "Iteration:20, Price of Hedge: 0.07787875205346069, Loss: 0.0015078625200933614\n",
      "Iteration:30, Price of Hedge: 0.09448078850824827, Loss: 0.0014840387592233162\n",
      "Iteration:40, Price of Hedge: 0.07797468938644556, Loss: 0.00106842417221642\n",
      "Iteration:50, Price of Hedge: 0.08119330213771292, Loss: 0.0013216990509613113\n",
      "Iteration:60, Price of Hedge: 0.08552306981238046, Loss: 0.0014353074849387858\n",
      "Iteration:70, Price of Hedge: 0.08734943097045544, Loss: 0.0012025222333654994\n",
      "Iteration:80, Price of Hedge: 0.08898502563394572, Loss: 0.0011967014477309746\n",
      "Iteration:90, Price of Hedge: 0.07897074603060474, Loss: 0.001262866812261154\n",
      "Iteration:100, Price of Hedge: 0.085640270775788, Loss: 0.0013566575071664033\n",
      "Iteration:110, Price of Hedge: 0.07811881796735491, Loss: 0.0014071265149449674\n",
      "Iteration:120, Price of Hedge: 0.07171219504383827, Loss: 0.0009856363109068899\n",
      "Iteration:130, Price of Hedge: 0.09292938645537134, Loss: 0.0011304477313956562\n",
      "Iteration:140, Price of Hedge: 0.09458870735236218, Loss: 0.0012876223368919247\n",
      "Iteration:150, Price of Hedge: 0.08029041713385111, Loss: 0.0013193816289903458\n",
      "Iteration:160, Price of Hedge: 0.07856642449141446, Loss: 0.001094424169760777\n",
      "Iteration:170, Price of Hedge: 0.08012620886630657, Loss: 0.001112754801439475\n",
      "Iteration:180, Price of Hedge: 0.08190543011854032, Loss: 0.0013731529519780627\n",
      "Iteration:190, Price of Hedge: 0.08682462183990367, Loss: 0.0013560078180130386\n",
      "Iteration:200, Price of Hedge: 0.08722636711741245, Loss: 0.0012839205886474802\n",
      "Iteration:210, Price of Hedge: 0.0756701617472693, Loss: 0.0013006368389754995\n",
      "Iteration:220, Price of Hedge: 0.07984811467795935, Loss: 0.0011200293220520185\n",
      "Iteration:230, Price of Hedge: 0.07359216517660912, Loss: 0.0012614010898522876\n",
      "Iteration:240, Price of Hedge: 0.08367528400752774, Loss: 0.0013514533342556811\n",
      "Iteration:250, Price of Hedge: 0.08623804872984805, Loss: 0.001365072683621671\n",
      "Iteration:260, Price of Hedge: 0.0793016204329966, Loss: 0.0011650510044645124\n",
      "Iteration:270, Price of Hedge: 0.08768730958429387, Loss: 0.0014210840282552484\n",
      "Iteration:280, Price of Hedge: 0.08708649126258762, Loss: 0.0012049084720691106\n",
      "Iteration:290, Price of Hedge: 0.08060460740039019, Loss: 0.0013875735353022112\n",
      "Iteration:300, Price of Hedge: 0.07634017447968944, Loss: 0.0016130135996181405\n",
      "Iteration:310, Price of Hedge: 0.07895666657108436, Loss: 0.0013749674938253076\n",
      "Iteration:320, Price of Hedge: 0.07998620040977755, Loss: 0.0013648680093394149\n",
      "Iteration:330, Price of Hedge: 0.08598588764622121, Loss: 0.0013217330893452006\n",
      "Iteration:340, Price of Hedge: 0.08824352637563919, Loss: 0.0012468369533439104\n",
      "Iteration:350, Price of Hedge: 0.07774826250498279, Loss: 0.0014568571857790813\n",
      "Iteration:360, Price of Hedge: 0.0705264942838049, Loss: 0.0011749000848393586\n",
      "Iteration:370, Price of Hedge: 0.07825917687124502, Loss: 0.0011980646850057396\n",
      "Iteration:380, Price of Hedge: 0.07316277244377574, Loss: 0.00139204958278365\n",
      "Iteration:390, Price of Hedge: 0.08742955081443994, Loss: 0.0010752732870268344\n",
      "Iteration:400, Price of Hedge: 0.07946227213340364, Loss: 0.0010923707672544135\n",
      "Iteration:410, Price of Hedge: 0.08483153298190445, Loss: 0.0016519335317360495\n",
      "Iteration:420, Price of Hedge: 0.08150847744548315, Loss: 0.0012535546503939176\n",
      "Iteration:430, Price of Hedge: 0.08910765379567494, Loss: 0.0012162617530259157\n",
      "Iteration:440, Price of Hedge: 0.09598850777114336, Loss: 0.0012697005358023317\n",
      "Iteration:450, Price of Hedge: 0.09911759542897869, Loss: 0.0011367933001139696\n",
      "Iteration:460, Price of Hedge: 0.0912500332294968, Loss: 0.0010970181905990862\n",
      "Iteration:470, Price of Hedge: 0.08716938627080992, Loss: 0.001361885210959901\n",
      "Iteration:480, Price of Hedge: 0.082224412989531, Loss: 0.0011162090314358552\n",
      "Iteration:490, Price of Hedge: 0.07681267223793639, Loss: 0.0012512131055682828\n",
      "Iteration:500, Price of Hedge: 0.0772415819217045, Loss: 0.0014469554199056933\n",
      "Iteration:510, Price of Hedge: 0.08434474265425536, Loss: 0.0013730043670327375\n",
      "Iteration:520, Price of Hedge: 0.0894443863519271, Loss: 0.0014321929728129178\n",
      "Iteration:530, Price of Hedge: 0.09808056485822333, Loss: 0.0011373086856439451\n",
      "Iteration:540, Price of Hedge: 0.10524222188542466, Loss: 0.0013113644056406359\n",
      "Iteration:550, Price of Hedge: 0.09196130877079724, Loss: 0.0013461482301370786\n",
      "Iteration:560, Price of Hedge: 0.08226661821766612, Loss: 0.0012342189984326456\n",
      "Iteration:570, Price of Hedge: 0.08245134186315965, Loss: 0.00100595818804311\n",
      "Iteration:580, Price of Hedge: 0.08847556988642964, Loss: 0.0008067503222468519\n",
      "Iteration:590, Price of Hedge: 0.09042396249856495, Loss: 0.0020444572190773335\n",
      "Iteration:600, Price of Hedge: 0.09674002792966689, Loss: 0.001410671538630548\n",
      "Iteration:610, Price of Hedge: 0.09844364726740906, Loss: 0.0012616859763261434\n",
      "Iteration:620, Price of Hedge: 0.09084459404737118, Loss: 0.0016221881280200855\n",
      "Iteration:630, Price of Hedge: 0.08854093305504733, Loss: 0.0014738528468409395\n",
      "Iteration:640, Price of Hedge: 0.07883949402232772, Loss: 0.0012783692242210876\n",
      "Iteration:650, Price of Hedge: 0.08104168156051657, Loss: 0.0010819629394083763\n",
      "Iteration:660, Price of Hedge: 0.0790371321266548, Loss: 0.0012023675067117767\n",
      "Iteration:670, Price of Hedge: 0.07699681811886165, Loss: 0.0015510258547384748\n",
      "Iteration:680, Price of Hedge: 0.07892098724110568, Loss: 0.0015408787165151372\n",
      "Iteration:690, Price of Hedge: 0.07294951101722943, Loss: 0.0010239543556018525\n",
      "Iteration:700, Price of Hedge: 0.07923435821854383, Loss: 0.0014114265987809958\n",
      "Iteration:710, Price of Hedge: 0.0886620931264801, Loss: 0.001404281054044798\n",
      "Iteration:720, Price of Hedge: 0.08894376756084056, Loss: 0.001374049345418138\n",
      "Iteration:730, Price of Hedge: 0.09285114197834617, Loss: 0.001281797629443604\n",
      "Iteration:740, Price of Hedge: 0.08051523385176296, Loss: 0.0011838156255377984\n",
      "Iteration:750, Price of Hedge: 0.08519565726162312, Loss: 0.0012718723326874404\n",
      "Iteration:760, Price of Hedge: 0.08553545860017238, Loss: 0.0010984014809217511\n",
      "Iteration:770, Price of Hedge: 0.0732776954993362, Loss: 0.0010084956755655682\n",
      "Iteration:780, Price of Hedge: 0.07942112771890208, Loss: 0.0010905519336109391\n",
      "Iteration:790, Price of Hedge: 0.07758056397115283, Loss: 0.0012210513976180558\n",
      "Iteration:800, Price of Hedge: 0.08104165314586566, Loss: 0.0009337363590682157\n",
      "Iteration:810, Price of Hedge: 0.08214350700687163, Loss: 0.0008249424325024179\n",
      "Iteration:820, Price of Hedge: 0.08456291981540716, Loss: 0.0016612319302567568\n",
      "Iteration:830, Price of Hedge: 0.09473558268285842, Loss: 0.0012015685666447063\n",
      "Iteration:840, Price of Hedge: 0.08685755442029545, Loss: 0.0008829664815746651\n",
      "Iteration:850, Price of Hedge: 0.08463598335441844, Loss: 0.0014547370384417001\n",
      "Iteration:860, Price of Hedge: 0.08338161859048795, Loss: 0.001006769263534002\n",
      "Iteration:870, Price of Hedge: 0.08449898685088471, Loss: 0.0007929951153312519\n",
      "Iteration:880, Price of Hedge: 0.08589260234732023, Loss: 0.0009517743346419527\n",
      "Iteration:890, Price of Hedge: 0.07933209041031049, Loss: 0.0008411580226013182\n",
      "Iteration:900, Price of Hedge: 0.09249261538485455, Loss: 0.0009940192988904361\n",
      "Iteration:910, Price of Hedge: 0.085888264377283, Loss: 0.0009519113021388636\n",
      "Iteration:920, Price of Hedge: 0.07894697717512784, Loss: 0.0007891969496646167\n",
      "Iteration:930, Price of Hedge: 0.08163155077007644, Loss: 0.0009087056415033489\n",
      "Iteration:940, Price of Hedge: 0.07794014190672768, Loss: 0.000635553456514426\n",
      "Iteration:950, Price of Hedge: 0.07969985650111937, Loss: 0.0008004253985483323\n",
      "Iteration:960, Price of Hedge: 0.08593936339114946, Loss: 0.0011124975156551642\n",
      "Iteration:970, Price of Hedge: 0.08816371909281458, Loss: 0.0007679359091189997\n",
      "Iteration:980, Price of Hedge: 0.08938650570804611, Loss: 0.0008934791624423788\n",
      "Iteration:990, Price of Hedge: 0.08516536724376493, Loss: 0.0008120814731287784\n",
      "tf.Tensor(0.07617336, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_135 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.10798264447671499, Loss: 0.002062482023276435\n",
      "Iteration:20, Price of Hedge: 0.07853619603863322, Loss: 0.001569310090620002\n",
      "Iteration:30, Price of Hedge: 0.08741237889374673, Loss: 0.0014643021203005313\n",
      "Iteration:40, Price of Hedge: 0.08861901651571742, Loss: 0.0015556158568094558\n",
      "Iteration:50, Price of Hedge: 0.07859076163990934, Loss: 0.001207388316328417\n",
      "Iteration:60, Price of Hedge: 0.09023828222649115, Loss: 0.0015419527015233302\n",
      "Iteration:70, Price of Hedge: 0.07729051668632748, Loss: 0.0014747083942203475\n",
      "Iteration:80, Price of Hedge: 0.09451234771384662, Loss: 0.001170594303273853\n",
      "Iteration:90, Price of Hedge: 0.08223847824172593, Loss: 0.0011691970276151986\n",
      "Iteration:100, Price of Hedge: 0.0904652300432204, Loss: 0.0011314787984415542\n",
      "Iteration:110, Price of Hedge: 0.09050002851902121, Loss: 0.001427403476213751\n",
      "Iteration:120, Price of Hedge: 0.0855399102288132, Loss: 0.0014250610434302757\n",
      "Iteration:130, Price of Hedge: 0.09132189388162004, Loss: 0.0017004755230075608\n",
      "Iteration:140, Price of Hedge: 0.08267881061515538, Loss: 0.0015500458452684107\n",
      "Iteration:150, Price of Hedge: 0.09118792827418218, Loss: 0.0015429472143047905\n",
      "Iteration:160, Price of Hedge: 0.08682698972747857, Loss: 0.0013006363949965793\n",
      "Iteration:170, Price of Hedge: 0.08583284633647992, Loss: 0.0014644470054215209\n",
      "Iteration:180, Price of Hedge: 0.0915108134238963, Loss: 0.0013414238504462217\n",
      "Iteration:190, Price of Hedge: 0.09123633736776356, Loss: 0.0014853601884830868\n",
      "Iteration:200, Price of Hedge: 0.08159877920603975, Loss: 0.0011750483737987371\n",
      "Iteration:210, Price of Hedge: 0.10126362140966591, Loss: 0.001495800352793819\n",
      "Iteration:220, Price of Hedge: 0.08621236188543548, Loss: 0.0015226973357501449\n",
      "Iteration:230, Price of Hedge: 0.09210770105222821, Loss: 0.0014583877291103108\n",
      "Iteration:240, Price of Hedge: 0.08432676565178666, Loss: 0.0013182815972188288\n",
      "Iteration:250, Price of Hedge: 0.0883435648899038, Loss: 0.0012207837523256048\n",
      "Iteration:260, Price of Hedge: 0.08645848011997116, Loss: 0.0012431297293594489\n",
      "Iteration:270, Price of Hedge: 0.0848023700785319, Loss: 0.0016924267771545097\n",
      "Iteration:280, Price of Hedge: 0.0894596734341107, Loss: 0.0017519087050080317\n",
      "Iteration:290, Price of Hedge: 0.08646171939017364, Loss: 0.001222033183003801\n",
      "Iteration:300, Price of Hedge: 0.07749029062524712, Loss: 0.001224785260337735\n",
      "Iteration:310, Price of Hedge: 0.09155499820604404, Loss: 0.0013931570142038385\n",
      "Iteration:320, Price of Hedge: 0.08980978929093623, Loss: 0.0014144703702655636\n",
      "Iteration:330, Price of Hedge: 0.07868885848636253, Loss: 0.0014096283361608286\n",
      "Iteration:340, Price of Hedge: 0.09526058124441618, Loss: 0.0015080281242306314\n",
      "Iteration:350, Price of Hedge: 0.09060745484251953, Loss: 0.0015318740840466916\n",
      "Iteration:360, Price of Hedge: 0.08368524807844295, Loss: 0.0012169274994168976\n",
      "Iteration:370, Price of Hedge: 0.09141371109022457, Loss: 0.001328886329716017\n",
      "Iteration:380, Price of Hedge: 0.08890057729147428, Loss: 0.001304941658586678\n",
      "Iteration:390, Price of Hedge: 0.08105885348120978, Loss: 0.0017123642425422414\n",
      "Iteration:400, Price of Hedge: 0.09474180549140528, Loss: 0.0015520421224870294\n",
      "Iteration:410, Price of Hedge: 0.08562604450723796, Loss: 0.0014945270212504136\n",
      "Iteration:420, Price of Hedge: 0.07950268723853213, Loss: 0.0015036977018350495\n",
      "Iteration:430, Price of Hedge: 0.08581657421306517, Loss: 0.0012670261547794491\n",
      "Iteration:440, Price of Hedge: 0.08979867916243478, Loss: 0.0011317846999176373\n",
      "Iteration:450, Price of Hedge: 0.08959106277986706, Loss: 0.0012657807939080222\n",
      "Iteration:460, Price of Hedge: 0.08224001263287448, Loss: 0.0015999561795722705\n",
      "Iteration:470, Price of Hedge: 0.0843862280445677, Loss: 0.0012618529124001742\n",
      "Iteration:480, Price of Hedge: 0.08438298877436523, Loss: 0.0008882800212927532\n",
      "Iteration:490, Price of Hedge: 0.08719363343957695, Loss: 0.0006906020328593443\n",
      "Iteration:500, Price of Hedge: 0.09034392789853314, Loss: 0.0009495184777479349\n",
      "Iteration:510, Price of Hedge: 0.08780298562810315, Loss: 0.0008183961853121313\n",
      "Iteration:520, Price of Hedge: 0.08610231194250417, Loss: 0.001023763666655586\n",
      "Iteration:530, Price of Hedge: 0.08527629804087411, Loss: 0.0008525537775414981\n",
      "Iteration:540, Price of Hedge: 0.08725907238059705, Loss: 0.0008167866137330892\n",
      "Iteration:550, Price of Hedge: 0.08317941046314133, Loss: 0.0018319814872269856\n",
      "Iteration:560, Price of Hedge: 0.08463185375848781, Loss: 0.0009985375243693028\n",
      "Iteration:570, Price of Hedge: 0.08527103185890751, Loss: 0.0009365997271181702\n",
      "Iteration:580, Price of Hedge: 0.0921203550434285, Loss: 0.0010439159438442535\n",
      "Iteration:590, Price of Hedge: 0.08567112908666416, Loss: 0.0009941097965936896\n",
      "Iteration:600, Price of Hedge: 0.08320053202030948, Loss: 0.0008147702094700837\n",
      "Iteration:610, Price of Hedge: 0.0824878073318132, Loss: 0.0010696285390342064\n",
      "Iteration:620, Price of Hedge: 0.0826381018919676, Loss: 0.000816855652455195\n",
      "Iteration:630, Price of Hedge: 0.09657039246380066, Loss: 0.0008251246118527123\n",
      "Iteration:640, Price of Hedge: 0.09456204493826874, Loss: 0.0009685304690763119\n",
      "Iteration:650, Price of Hedge: 0.0935546129621997, Loss: 0.0008522130977166587\n",
      "Iteration:660, Price of Hedge: 0.08715036739780828, Loss: 0.0009450983716104532\n",
      "Iteration:670, Price of Hedge: 0.08474677207827312, Loss: 0.0008807339335739628\n",
      "Iteration:680, Price of Hedge: 0.08615361933047723, Loss: 0.0008192901368681448\n",
      "Iteration:690, Price of Hedge: 0.0818482219547306, Loss: 0.0009200993245419009\n",
      "Iteration:700, Price of Hedge: 0.0849104878252021, Loss: 0.0009141627344056658\n",
      "Iteration:710, Price of Hedge: 0.08221478042287629, Loss: 0.0008524365671065404\n",
      "Iteration:720, Price of Hedge: 0.08356557504040722, Loss: 0.0010622214907139548\n",
      "Iteration:730, Price of Hedge: 0.09006258496843315, Loss: 0.0008951455633232186\n",
      "Iteration:740, Price of Hedge: 0.08818225491675093, Loss: 0.0008082659922842517\n",
      "Iteration:750, Price of Hedge: 0.0866183693605791, Loss: 0.0007500772270325751\n",
      "Iteration:760, Price of Hedge: 0.09061908590628746, Loss: 0.0009460855587397287\n",
      "Iteration:770, Price of Hedge: 0.08769998251859476, Loss: 0.000781697257742997\n",
      "Iteration:780, Price of Hedge: 0.07960194908567217, Loss: 0.000978685302934268\n",
      "Iteration:790, Price of Hedge: 0.09159331062700601, Loss: 0.0008846463498160872\n",
      "Iteration:800, Price of Hedge: 0.09384443292981785, Loss: 0.000995488055155258\n",
      "Iteration:810, Price of Hedge: 0.09789647580659988, Loss: 0.0008005480107268204\n",
      "Iteration:820, Price of Hedge: 0.09465677938436556, Loss: 0.0009976489745568194\n",
      "Iteration:830, Price of Hedge: 0.08249367969299896, Loss: 0.0007290290743792394\n",
      "Iteration:840, Price of Hedge: 0.08932882396672141, Loss: 0.0007953562692258664\n",
      "Iteration:850, Price of Hedge: 0.09895303671407304, Loss: 0.0007731232848272373\n",
      "Iteration:860, Price of Hedge: 0.0976952811351353, Loss: 0.0010723558275450905\n",
      "Iteration:870, Price of Hedge: 0.08765277631190145, Loss: 0.0009556967404097837\n",
      "Iteration:880, Price of Hedge: 0.08217873170243592, Loss: 0.0008071152729193342\n",
      "Iteration:890, Price of Hedge: 0.08771483390946457, Loss: 0.0008604429129727031\n",
      "Iteration:900, Price of Hedge: 0.08317848225121195, Loss: 0.000794291755767973\n",
      "Iteration:910, Price of Hedge: 0.08085741254943742, Loss: 0.0007395767555851696\n",
      "Iteration:920, Price of Hedge: 0.08622840669164304, Loss: 0.0008659712644917272\n",
      "Iteration:930, Price of Hedge: 0.0836490193985469, Loss: 0.0010836725542374582\n",
      "Iteration:940, Price of Hedge: 0.09040134443644944, Loss: 0.000962407629783013\n",
      "Iteration:950, Price of Hedge: 0.08002420026957964, Loss: 0.0007176743874891866\n",
      "Iteration:960, Price of Hedge: 0.08145985997779519, Loss: 0.000721019472667661\n",
      "Iteration:970, Price of Hedge: 0.09295626671512167, Loss: 0.0008480873496033325\n",
      "Iteration:980, Price of Hedge: 0.08037329319897281, Loss: 0.0013032617903452558\n",
      "Iteration:990, Price of Hedge: 0.08299381543502023, Loss: 0.0008867950597973406\n",
      "tf.Tensor(0.08932924, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_136 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.06908727327267669, Loss: 0.001835680719590882\n",
      "Iteration:20, Price of Hedge: 0.11091272539120496, Loss: 0.001564057671999941\n",
      "Iteration:30, Price of Hedge: 0.09195283173327908, Loss: 0.0022566218696975283\n",
      "Iteration:40, Price of Hedge: 0.08999945708568617, Loss: 0.0014413861483295153\n",
      "Iteration:50, Price of Hedge: 0.09755433499512663, Loss: 0.0017103928281431591\n",
      "Iteration:60, Price of Hedge: 0.09068038577982662, Loss: 0.0017934207340555952\n",
      "Iteration:70, Price of Hedge: 0.09538874079152038, Loss: 0.0016923666920072966\n",
      "Iteration:80, Price of Hedge: 0.08754715905451035, Loss: 0.0017860571956695326\n",
      "Iteration:90, Price of Hedge: 0.0977755525239246, Loss: 0.0016220136443044098\n",
      "Iteration:100, Price of Hedge: 0.0828815775639697, Loss: 0.0016468143067920771\n",
      "Iteration:110, Price of Hedge: 0.09934503576632352, Loss: 0.0014643049321670266\n",
      "Iteration:120, Price of Hedge: 0.0802833229426767, Loss: 0.0018430532855483238\n",
      "Iteration:130, Price of Hedge: 0.10163380748157635, Loss: 0.0016893091571761997\n",
      "Iteration:140, Price of Hedge: 0.08579384249234608, Loss: 0.0018152168431966541\n",
      "Iteration:150, Price of Hedge: 0.08976998983657722, Loss: 0.0014893000574217829\n",
      "Iteration:160, Price of Hedge: 0.09855861294494588, Loss: 0.001962261477654503\n",
      "Iteration:170, Price of Hedge: 0.08303857798173624, Loss: 0.0016120440976491901\n",
      "Iteration:180, Price of Hedge: 0.09046653711716175, Loss: 0.001684658921965032\n",
      "Iteration:190, Price of Hedge: 0.09177905719993192, Loss: 0.0017626639463591998\n",
      "Iteration:200, Price of Hedge: 0.09268657379189023, Loss: 0.001589603035129916\n",
      "Iteration:210, Price of Hedge: 0.08857713332029249, Loss: 0.002047711880549041\n",
      "Iteration:220, Price of Hedge: 0.09511317550710316, Loss: 0.0015252040407341295\n",
      "Iteration:230, Price of Hedge: 0.09261992249243178, Loss: 0.001970497138632998\n",
      "Iteration:240, Price of Hedge: 0.08363563609797353, Loss: 0.0012835531220944496\n",
      "Iteration:250, Price of Hedge: 0.10089467611084472, Loss: 0.0017505061755988204\n",
      "Iteration:260, Price of Hedge: 0.08917194667910877, Loss: 0.001229124784301183\n",
      "Iteration:270, Price of Hedge: 0.0847295906860296, Loss: 0.0014492398394435834\n",
      "Iteration:280, Price of Hedge: 0.09820880017772993, Loss: 0.0016678535798670068\n",
      "Iteration:290, Price of Hedge: 0.09381611299442198, Loss: 0.001744403537346395\n",
      "Iteration:300, Price of Hedge: 0.09672931560627802, Loss: 0.0015379444598309089\n",
      "Iteration:310, Price of Hedge: 0.09231536479254743, Loss: 0.0020816966909819267\n",
      "Iteration:320, Price of Hedge: 0.09810341970909632, Loss: 0.0017181966456251807\n",
      "Iteration:330, Price of Hedge: 0.09860282614174451, Loss: 0.00179914599022577\n",
      "Iteration:340, Price of Hedge: 0.09518681681068272, Loss: 0.0014510910835482393\n",
      "Iteration:350, Price of Hedge: 0.09302740752942214, Loss: 0.0013662544075145223\n",
      "Iteration:360, Price of Hedge: 0.08464714084067139, Loss: 0.0013930263364082985\n",
      "Iteration:370, Price of Hedge: 0.09475964989216976, Loss: 0.0015777906799695261\n",
      "Iteration:380, Price of Hedge: 0.093010491340587, Loss: 0.0015401758978843105\n",
      "Iteration:390, Price of Hedge: 0.09309482602445485, Loss: 0.001701511473821582\n",
      "Iteration:400, Price of Hedge: 0.0909841289263852, Loss: 0.0011762132264926172\n",
      "Iteration:410, Price of Hedge: 0.0903623784785168, Loss: 0.0011186297525022759\n",
      "Iteration:420, Price of Hedge: 0.09187145217310473, Loss: 0.001338198639576227\n",
      "Iteration:430, Price of Hedge: 0.09408842953708642, Loss: 0.0015695082532114267\n",
      "Iteration:440, Price of Hedge: 0.10715899846265983, Loss: 0.0014711954850100018\n",
      "Iteration:450, Price of Hedge: 0.09327267332443086, Loss: 0.001407613263834584\n",
      "Iteration:460, Price of Hedge: 0.08892986332500072, Loss: 0.0013442876624750965\n",
      "Iteration:470, Price of Hedge: 0.09848625030065676, Loss: 0.0013223369006768015\n",
      "Iteration:480, Price of Hedge: 0.09408734030880196, Loss: 0.0013788801320568922\n",
      "Iteration:490, Price of Hedge: 0.08730161858454295, Loss: 0.0009620528906256975\n",
      "Iteration:500, Price of Hedge: 0.09704304176685241, Loss: 0.0011855007475297774\n",
      "Iteration:510, Price of Hedge: 0.09050670596198244, Loss: 0.0010423767429240782\n",
      "Iteration:520, Price of Hedge: 0.087892093973322, Loss: 0.0012114505014596544\n",
      "Iteration:530, Price of Hedge: 0.08722690699577952, Loss: 0.0011312647266054853\n",
      "Iteration:540, Price of Hedge: 0.09114955902391841, Loss: 0.00111821936798695\n",
      "Iteration:550, Price of Hedge: 0.09515826008652936, Loss: 0.0010312355358982005\n",
      "Iteration:560, Price of Hedge: 0.10110756814692934, Loss: 0.0012267279640999717\n",
      "Iteration:570, Price of Hedge: 0.09216816742934099, Loss: 0.0009393171000998345\n",
      "Iteration:580, Price of Hedge: 0.09741371088782813, Loss: 0.00125355820222528\n",
      "Iteration:590, Price of Hedge: 0.09791408341860687, Loss: 0.0014441235743590797\n",
      "Iteration:600, Price of Hedge: 0.08948377852962323, Loss: 0.001040845829610415\n",
      "Iteration:610, Price of Hedge: 0.08986439277841356, Loss: 0.001014072272793931\n",
      "Iteration:620, Price of Hedge: 0.09216227612505463, Loss: 0.0010525185534003723\n",
      "Iteration:630, Price of Hedge: 0.09099087267019854, Loss: 0.0013492519387758861\n",
      "Iteration:640, Price of Hedge: 0.093128686816776, Loss: 0.0016287855067826928\n",
      "Iteration:650, Price of Hedge: 0.09810510564504966, Loss: 0.0012973324518647188\n",
      "Iteration:660, Price of Hedge: 0.0920302237707773, Loss: 0.0011050202446690194\n",
      "Iteration:670, Price of Hedge: 0.08741731357145284, Loss: 0.0012077772418625954\n",
      "Iteration:680, Price of Hedge: 0.1038621128197164, Loss: 0.0010573436423096493\n",
      "Iteration:690, Price of Hedge: 0.09202410514928373, Loss: 0.0010473493808278666\n",
      "Iteration:700, Price of Hedge: 0.08929574931307513, Loss: 0.0016827839989846272\n",
      "Iteration:710, Price of Hedge: 0.08625995642569108, Loss: 0.0011662821580104897\n",
      "Iteration:720, Price of Hedge: 0.08453256349669687, Loss: 0.0007397115771839658\n",
      "Iteration:730, Price of Hedge: 0.09991859496626744, Loss: 0.0009638293242822837\n",
      "Iteration:740, Price of Hedge: 0.1034910648367287, Loss: 0.0010785910675017107\n",
      "Iteration:750, Price of Hedge: 0.09584561049177295, Loss: 0.0008388895123080719\n",
      "Iteration:760, Price of Hedge: 0.08675986485050514, Loss: 0.001033840434220057\n",
      "Iteration:770, Price of Hedge: 0.0946560879611937, Loss: 0.0010129032762967948\n",
      "Iteration:780, Price of Hedge: 0.08815453168902394, Loss: 0.0010096178322866133\n",
      "Iteration:790, Price of Hedge: 0.08841894895873849, Loss: 0.001081154823776953\n",
      "Iteration:800, Price of Hedge: 0.09603943629710443, Loss: 0.0010708045651975806\n",
      "Iteration:810, Price of Hedge: 0.10266385751976088, Loss: 0.0010626758291423899\n",
      "Iteration:820, Price of Hedge: 0.09531174655913474, Loss: 0.0010375674152664715\n",
      "Iteration:830, Price of Hedge: 0.08264500665213603, Loss: 0.0010540147623617658\n",
      "Iteration:840, Price of Hedge: 0.08978616724448897, Loss: 0.0012406690501902018\n",
      "Iteration:850, Price of Hedge: 0.09021672497800921, Loss: 0.0009862336845441466\n",
      "Iteration:860, Price of Hedge: 0.09583850682904824, Loss: 0.0010898447491873963\n",
      "Iteration:870, Price of Hedge: 0.10420957664245804, Loss: 0.0011699504598429388\n",
      "Iteration:880, Price of Hedge: 0.08923782131144264, Loss: 0.0008989464668598624\n",
      "Iteration:890, Price of Hedge: 0.09050691433608904, Loss: 0.0008256131366580099\n",
      "Iteration:900, Price of Hedge: 0.1016704150234844, Loss: 0.0012279467602326676\n",
      "Iteration:910, Price of Hedge: 0.10169215223142203, Loss: 0.0009801485834590729\n",
      "Iteration:920, Price of Hedge: 0.09887287898388734, Loss: 0.0009151388960584205\n",
      "Iteration:930, Price of Hedge: 0.09275225899321811, Loss: 0.0011005850432482477\n",
      "Iteration:940, Price of Hedge: 0.09042585680862487, Loss: 0.0011779489620815098\n",
      "Iteration:950, Price of Hedge: 0.08483880713253455, Loss: 0.000951200417890985\n",
      "Iteration:960, Price of Hedge: 0.0866383353886107, Loss: 0.0010971307392553808\n",
      "Iteration:970, Price of Hedge: 0.09525979510574131, Loss: 0.0008953139793269838\n",
      "Iteration:980, Price of Hedge: 0.09619736492680032, Loss: 0.0008196251189635073\n",
      "Iteration:990, Price of Hedge: 0.10470353693368395, Loss: 0.000858658635688525\n",
      "tf.Tensor(0.08493878, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_137 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.07561052886658289, Loss: 0.0037464438983366042\n",
      "Iteration:20, Price of Hedge: 0.09099765430021307, Loss: 0.0016207210736744581\n",
      "Iteration:30, Price of Hedge: 0.09900065019742925, Loss: 0.00151570200388198\n",
      "Iteration:40, Price of Hedge: 0.07469273564254948, Loss: 0.0015774381607068122\n",
      "Iteration:50, Price of Hedge: 0.09092876771488391, Loss: 0.0014639886711828032\n",
      "Iteration:60, Price of Hedge: 0.09161104136916691, Loss: 0.0015962488075948356\n",
      "Iteration:70, Price of Hedge: 0.083094744275013, Loss: 0.0014459552833912426\n",
      "Iteration:80, Price of Hedge: 0.0967073510811332, Loss: 0.0013937184995450379\n",
      "Iteration:90, Price of Hedge: 0.10661421383252616, Loss: 0.0013780334642558899\n",
      "Iteration:100, Price of Hedge: 0.09299564942126749, Loss: 0.001506573057315852\n",
      "Iteration:110, Price of Hedge: 0.07472142496840703, Loss: 0.001414800394596316\n",
      "Iteration:120, Price of Hedge: 0.09484025278521954, Loss: 0.0016675318431427666\n",
      "Iteration:130, Price of Hedge: 0.09929048910814799, Loss: 0.0013649889195987085\n",
      "Iteration:140, Price of Hedge: 0.09284539274731429, Loss: 0.0013310909810412275\n",
      "Iteration:150, Price of Hedge: 0.09758555322491418, Loss: 0.0015770333999244768\n",
      "Iteration:160, Price of Hedge: 0.08603868206759131, Loss: 0.0014614523676041325\n",
      "Iteration:170, Price of Hedge: 0.0959348987964475, Loss: 0.0014244971902015013\n",
      "Iteration:180, Price of Hedge: 0.09884450221918968, Loss: 0.0016141814121714891\n",
      "Iteration:190, Price of Hedge: 0.08853621622299812, Loss: 0.0013579925517797297\n",
      "Iteration:200, Price of Hedge: 0.08742025922359602, Loss: 0.0018770478635174559\n",
      "Iteration:210, Price of Hedge: 0.09143255000377053, Loss: 0.0016033395949308638\n",
      "Iteration:220, Price of Hedge: 0.09255391525839371, Loss: 0.0015227466174102978\n",
      "Iteration:230, Price of Hedge: 0.0877567360479901, Loss: 0.0013802863612904393\n",
      "Iteration:240, Price of Hedge: 0.08749018767945813, Loss: 0.0018447025192442456\n",
      "Iteration:250, Price of Hedge: 0.09454961826427563, Loss: 0.0014017972879716955\n",
      "Iteration:260, Price of Hedge: 0.09651782535963775, Loss: 0.001539689888959561\n",
      "Iteration:270, Price of Hedge: 0.09729789277076435, Loss: 0.001561478450458975\n",
      "Iteration:280, Price of Hedge: 0.08802630584106765, Loss: 0.0016537834439039445\n",
      "Iteration:290, Price of Hedge: 0.06687553367601069, Loss: 0.0016984975969176475\n",
      "Iteration:300, Price of Hedge: 0.08375602897383203, Loss: 0.0013983642949670027\n",
      "Iteration:310, Price of Hedge: 0.09294237195083212, Loss: 0.0013758743947664964\n",
      "Iteration:320, Price of Hedge: 0.09391528959760932, Loss: 0.0013718417342334587\n",
      "Iteration:330, Price of Hedge: 0.0791584200640166, Loss: 0.0017091667063582783\n",
      "Iteration:340, Price of Hedge: 0.0912626966922474, Loss: 0.0012841338465221952\n",
      "Iteration:350, Price of Hedge: 0.0913478364578907, Loss: 0.0016798148159586689\n",
      "Iteration:360, Price of Hedge: 0.08693079791876243, Loss: 0.0012625912493446246\n",
      "Iteration:370, Price of Hedge: 0.09348371840820703, Loss: 0.0013705445758213307\n",
      "Iteration:380, Price of Hedge: 0.0874157791803043, Loss: 0.0012863114151332677\n",
      "Iteration:390, Price of Hedge: 0.08956788589628388, Loss: 0.0013371157749896279\n",
      "Iteration:400, Price of Hedge: 0.10079138885482734, Loss: 0.0011170848538526233\n",
      "Iteration:410, Price of Hedge: 0.09711246823054864, Loss: 0.001290454330431512\n",
      "Iteration:420, Price of Hedge: 0.0898057070527571, Loss: 0.001622865195873535\n",
      "Iteration:430, Price of Hedge: 0.09068688326333216, Loss: 0.0010060137594046336\n",
      "Iteration:440, Price of Hedge: 0.08517410001314119, Loss: 0.0008887300679249587\n",
      "Iteration:450, Price of Hedge: 0.0978506429747, Loss: 0.0010070079022036604\n",
      "Iteration:460, Price of Hedge: 0.10475474960615401, Loss: 0.0012059977743500538\n",
      "Iteration:470, Price of Hedge: 0.08867604472007144, Loss: 0.001051790871950009\n",
      "Iteration:480, Price of Hedge: 0.08011833800800758, Loss: 0.0010369518384934827\n",
      "Iteration:490, Price of Hedge: 0.08948391113132743, Loss: 0.0012727662102469672\n",
      "Iteration:500, Price of Hedge: 0.09465647629475597, Loss: 0.0014510869397449833\n",
      "Iteration:510, Price of Hedge: 0.09551716554203295, Loss: 0.0008383607334140009\n",
      "Iteration:520, Price of Hedge: 0.09906662901681641, Loss: 0.0008582601646075605\n",
      "Iteration:530, Price of Hedge: 0.08701370239853502, Loss: 0.0011023684325745851\n",
      "Iteration:540, Price of Hedge: 0.09175131502910432, Loss: 0.001078224636899494\n",
      "Iteration:550, Price of Hedge: 0.08631681414213972, Loss: 0.0011136150845940328\n",
      "Iteration:560, Price of Hedge: 0.08109911704153347, Loss: 0.0013429822164564564\n",
      "Iteration:570, Price of Hedge: 0.07690481147925111, Loss: 0.0012676783598133622\n",
      "Iteration:580, Price of Hedge: 0.07692486275123542, Loss: 0.0010351663772655173\n",
      "Iteration:590, Price of Hedge: 0.09048639895814005, Loss: 0.001249108497493112\n",
      "Iteration:600, Price of Hedge: 0.08710305700406167, Loss: 0.0008379319237734828\n",
      "Iteration:610, Price of Hedge: 0.09521464422546301, Loss: 0.0008532632558561293\n",
      "Iteration:620, Price of Hedge: 0.08242735042625071, Loss: 0.0010764853494792392\n",
      "Iteration:630, Price of Hedge: 0.09181583522974535, Loss: 0.0011228685672473038\n",
      "Iteration:640, Price of Hedge: 0.09237142689877088, Loss: 0.0010013470229769284\n",
      "Iteration:650, Price of Hedge: 0.09320623039907901, Loss: 0.0009855257601557364\n",
      "Iteration:660, Price of Hedge: 0.09904621782592073, Loss: 0.0011143756944809846\n",
      "Iteration:670, Price of Hedge: 0.08800557261746178, Loss: 0.0008082634764037033\n",
      "Iteration:680, Price of Hedge: 0.09287576800912518, Loss: 0.0011624467721110365\n",
      "Iteration:690, Price of Hedge: 0.08664295750515691, Loss: 0.0009717581218303684\n",
      "Iteration:700, Price of Hedge: 0.08571562642997178, Loss: 0.0008225150517521928\n",
      "Iteration:710, Price of Hedge: 0.08578762915534952, Loss: 0.0008793553050299607\n",
      "Iteration:720, Price of Hedge: 0.09017952072843229, Loss: 0.000931269316201111\n",
      "Iteration:730, Price of Hedge: 0.09009716559857707, Loss: 0.0009384005796153727\n",
      "Iteration:740, Price of Hedge: 0.09053917443640955, Loss: 0.001071279844631756\n",
      "Iteration:750, Price of Hedge: 0.08933854177732882, Loss: 0.0009040262516764152\n",
      "Iteration:760, Price of Hedge: 0.08946969433432769, Loss: 0.0009975451574859573\n",
      "Iteration:770, Price of Hedge: 0.09143140394618428, Loss: 0.0010504428779515072\n",
      "Iteration:780, Price of Hedge: 0.0905152398288024, Loss: 0.0011012259268196932\n",
      "Iteration:790, Price of Hedge: 0.08681310443473933, Loss: 0.0009689286441713295\n",
      "Iteration:800, Price of Hedge: 0.09041777757621929, Loss: 0.001112161941587908\n",
      "Iteration:810, Price of Hedge: 0.09004768621981185, Loss: 0.00097906512690058\n",
      "Iteration:820, Price of Hedge: 0.09209257498639971, Loss: 0.0009905882297943978\n",
      "Iteration:830, Price of Hedge: 0.09167271063316774, Loss: 0.0009992298354990158\n",
      "Iteration:840, Price of Hedge: 0.09962768577036485, Loss: 0.0008287536955472019\n",
      "Iteration:850, Price of Hedge: 0.10110493505594605, Loss: 0.0010172098718236543\n",
      "Iteration:860, Price of Hedge: 0.10411237012173302, Loss: 0.0009964412039006442\n",
      "Iteration:870, Price of Hedge: 0.091739229330922, Loss: 0.0010740114989353565\n",
      "Iteration:880, Price of Hedge: 0.08549385955125643, Loss: 0.0011545837574396423\n",
      "Iteration:890, Price of Hedge: 0.08846424191227129, Loss: 0.0008058205563912679\n",
      "Iteration:900, Price of Hedge: 0.0900314140963971, Loss: 0.0010072357373862584\n",
      "Iteration:910, Price of Hedge: 0.08553553437257477, Loss: 0.0010864099062705356\n",
      "Iteration:920, Price of Hedge: 0.09073557650342252, Loss: 0.0009546760328720261\n",
      "Iteration:930, Price of Hedge: 0.09020491395478558, Loss: 0.0008924147969774588\n",
      "Iteration:940, Price of Hedge: 0.09613102618850178, Loss: 0.0010459669044665554\n",
      "Iteration:950, Price of Hedge: 0.09292311628907299, Loss: 0.0009093277299671687\n",
      "Iteration:960, Price of Hedge: 0.09430542275445077, Loss: 0.0007647180978976764\n",
      "Iteration:970, Price of Hedge: 0.0908837967940613, Loss: 0.0008919456592516806\n",
      "Iteration:980, Price of Hedge: 0.09106298905417987, Loss: 0.0010464549852929328\n",
      "Iteration:990, Price of Hedge: 0.08909760448080703, Loss: 0.0008444632236734529\n",
      "tf.Tensor(0.0754191, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_138 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.08641909741382534, Loss: 0.0017750303872121175\n",
      "Iteration:20, Price of Hedge: 0.09928183211117414, Loss: 0.0014580804956974669\n",
      "Iteration:30, Price of Hedge: 0.10195439104456767, Loss: 0.0015800634080625152\n",
      "Iteration:40, Price of Hedge: 0.08624255718779068, Loss: 0.0017552469825097283\n",
      "Iteration:50, Price of Hedge: 0.0809878073824123, Loss: 0.001871938110123783\n",
      "Iteration:60, Price of Hedge: 0.08594086936764711, Loss: 0.001468071501333834\n",
      "Iteration:70, Price of Hedge: 0.10060564228190146, Loss: 0.0017220734695571947\n",
      "Iteration:80, Price of Hedge: 0.09200112716825685, Loss: 0.0015912864552027005\n",
      "Iteration:90, Price of Hedge: 0.0859962305791484, Loss: 0.0014984282640230439\n",
      "Iteration:100, Price of Hedge: 0.07888027378214275, Loss: 0.001321010735641881\n",
      "Iteration:110, Price of Hedge: 0.0837342065219417, Loss: 0.0015343041286704385\n",
      "Iteration:120, Price of Hedge: 0.09697490343399692, Loss: 0.0015882676945306428\n",
      "Iteration:130, Price of Hedge: 0.10211231967426357, Loss: 0.0015075326437555825\n",
      "Iteration:140, Price of Hedge: 0.09798154927139109, Loss: 0.0014961522800846395\n",
      "Iteration:150, Price of Hedge: 0.08599191155221177, Loss: 0.001200917175572147\n",
      "Iteration:160, Price of Hedge: 0.08770241670702177, Loss: 0.0015236803050796776\n",
      "Iteration:170, Price of Hedge: 0.10320646369332565, Loss: 0.0014741292977153097\n",
      "Iteration:180, Price of Hedge: 0.09158684155815137, Loss: 0.0014681457938064968\n",
      "Iteration:190, Price of Hedge: 0.0868863763478572, Loss: 0.001558610790612791\n",
      "Iteration:200, Price of Hedge: 0.08191029849539433, Loss: 0.0012759937890045368\n",
      "Iteration:210, Price of Hedge: 0.08694984520641498, Loss: 0.0016244615960779418\n",
      "Iteration:220, Price of Hedge: 0.08235595388009216, Loss: 0.001495718068700591\n",
      "Iteration:230, Price of Hedge: 0.08444146612591509, Loss: 0.0012959155671370848\n",
      "Iteration:240, Price of Hedge: 0.08534438901597809, Loss: 0.0017323968674118895\n",
      "Iteration:250, Price of Hedge: 0.08236141896461503, Loss: 0.0015565052945797798\n",
      "Iteration:260, Price of Hedge: 0.09616515218423131, Loss: 0.0015927440379980284\n",
      "Iteration:270, Price of Hedge: 0.09407189221026328, Loss: 0.001664697629708578\n",
      "Iteration:280, Price of Hedge: 0.08509173541173566, Loss: 0.0017816882951008583\n",
      "Iteration:290, Price of Hedge: 0.08731128903739886, Loss: 0.001378464863773443\n",
      "Iteration:300, Price of Hedge: 0.09695970159576603, Loss: 0.0013322951998660404\n",
      "Iteration:310, Price of Hedge: 0.09289685168009214, Loss: 0.0014654640131349427\n",
      "Iteration:320, Price of Hedge: 0.08230827409588386, Loss: 0.001324812083157445\n",
      "Iteration:330, Price of Hedge: 0.09421542408350377, Loss: 0.001999221686818231\n",
      "Iteration:340, Price of Hedge: 0.0900663357023518, Loss: 0.0011895522771669276\n",
      "Iteration:350, Price of Hedge: 0.0791976654326831, Loss: 0.0014361266260467297\n",
      "Iteration:360, Price of Hedge: 0.08135106975105373, Loss: 0.0013796048536477868\n",
      "Iteration:370, Price of Hedge: 0.09185888342585713, Loss: 0.0015060081681362635\n",
      "Iteration:380, Price of Hedge: 0.08522522744165854, Loss: 0.001267111842711066\n",
      "Iteration:390, Price of Hedge: 0.0824324461203119, Loss: 0.0016594529067231357\n",
      "Iteration:400, Price of Hedge: 0.08427955944509335, Loss: 0.0014543071188538813\n",
      "Iteration:410, Price of Hedge: 0.09355417727088593, Loss: 0.0015699075382537453\n",
      "Iteration:420, Price of Hedge: 0.10691479348128467, Loss: 0.001615941788590458\n",
      "Iteration:430, Price of Hedge: 0.10810757422516701, Loss: 0.0013849109937172032\n",
      "Iteration:440, Price of Hedge: 0.1038418437020752, Loss: 0.0015840498947878423\n",
      "Iteration:450, Price of Hedge: 0.08582736230885643, Loss: 0.001969447424472448\n",
      "Iteration:460, Price of Hedge: 0.08429630514602308, Loss: 0.0013204508782233891\n",
      "Iteration:470, Price of Hedge: 0.08840988468510176, Loss: 0.0012900972233866215\n",
      "Iteration:480, Price of Hedge: 0.08611519325091166, Loss: 0.0015726943939364357\n",
      "Iteration:490, Price of Hedge: 0.09120179462382083, Loss: 0.0015800468328494909\n",
      "Iteration:500, Price of Hedge: 0.08899977283776224, Loss: 0.0015096347359502048\n",
      "Iteration:510, Price of Hedge: 0.08013895757300986, Loss: 0.0014845234362113047\n",
      "Iteration:520, Price of Hedge: 0.08081861707941015, Loss: 0.0014221631930175116\n",
      "Iteration:530, Price of Hedge: 0.10285612999084322, Loss: 0.0014231445344243365\n",
      "Iteration:540, Price of Hedge: 0.10212876228558372, Loss: 0.0015236191839816504\n",
      "Iteration:550, Price of Hedge: 0.09360520051235, Loss: 0.0015151357827656309\n",
      "Iteration:560, Price of Hedge: 0.08991217674967515, Loss: 0.0015083498609548718\n",
      "Iteration:570, Price of Hedge: 0.09591783106280757, Loss: 0.0013636694142475925\n",
      "Iteration:580, Price of Hedge: 0.09483411522062539, Loss: 0.0014685609140969724\n",
      "Iteration:590, Price of Hedge: 0.09131300009588869, Loss: 0.001391659769291631\n",
      "Iteration:600, Price of Hedge: 0.08315039910457357, Loss: 0.0013333074718043126\n",
      "Iteration:610, Price of Hedge: 0.08395798136932058, Loss: 0.0016097858728675973\n",
      "Iteration:620, Price of Hedge: 0.0839997793207928, Loss: 0.001709978595810524\n",
      "Iteration:630, Price of Hedge: 0.0856302025178195, Loss: 0.001450970617267866\n",
      "Iteration:640, Price of Hedge: 0.07820906289860971, Loss: 0.001725084830580581\n",
      "Iteration:650, Price of Hedge: 0.08680663536588469, Loss: 0.0011935201167776021\n",
      "Iteration:660, Price of Hedge: 0.09090119603196171, Loss: 0.001428139297277653\n",
      "Iteration:670, Price of Hedge: 0.08682684765422408, Loss: 0.0014031577873764522\n",
      "Iteration:680, Price of Hedge: 0.08018080288223359, Loss: 0.001705296394117095\n",
      "Iteration:690, Price of Hedge: 0.09328209751697898, Loss: 0.0013868837400530464\n",
      "Iteration:700, Price of Hedge: 0.09726081165134133, Loss: 0.0012170524794829606\n",
      "Iteration:710, Price of Hedge: 0.09352914396344403, Loss: 0.001758157708311181\n",
      "Iteration:720, Price of Hedge: 0.08999961810204127, Loss: 0.001294754266274567\n",
      "Iteration:730, Price of Hedge: 0.08946889872410253, Loss: 0.0016402000568304985\n",
      "Iteration:740, Price of Hedge: 0.0845566970068603, Loss: 0.0013946067533715744\n",
      "Iteration:750, Price of Hedge: 0.09781367551388058, Loss: 0.0014241813731961982\n",
      "Iteration:760, Price of Hedge: 0.0837568719418087, Loss: 0.0012518494753540387\n",
      "Iteration:770, Price of Hedge: 0.08637625759182015, Loss: 0.0013134981683315726\n",
      "Iteration:780, Price of Hedge: 0.0823522410323747, Loss: 0.0013023414220434848\n",
      "Iteration:790, Price of Hedge: 0.08860899561550041, Loss: 0.0014033152519001835\n",
      "Iteration:800, Price of Hedge: 0.09504875949351543, Loss: 0.0009771648231252316\n",
      "Iteration:810, Price of Hedge: 0.09897269018094476, Loss: 0.0008862993573328315\n",
      "Iteration:820, Price of Hedge: 0.09974142014636271, Loss: 0.0009017015040532649\n",
      "Iteration:830, Price of Hedge: 0.09882715033904077, Loss: 0.0012478302821815833\n",
      "Iteration:840, Price of Hedge: 0.08938248977071907, Loss: 0.0009933526645416134\n",
      "Iteration:850, Price of Hedge: 0.08527464051957168, Loss: 0.0011235651701732464\n",
      "Iteration:860, Price of Hedge: 0.08220971314346599, Loss: 0.0010581046221790347\n",
      "Iteration:870, Price of Hedge: 0.09071383929548489, Loss: 0.001021183927139213\n",
      "Iteration:880, Price of Hedge: 0.08398391447404094, Loss: 0.0010217164798541067\n",
      "Iteration:890, Price of Hedge: 0.08970713662878893, Loss: 0.0012580304018894094\n",
      "Iteration:900, Price of Hedge: 0.0837366312388184, Loss: 0.0013931101004312607\n",
      "Iteration:910, Price of Hedge: 0.0885792644191099, Loss: 0.0011580911909099712\n",
      "Iteration:920, Price of Hedge: 0.0840805337586474, Loss: 0.0014221051797719264\n",
      "Iteration:930, Price of Hedge: 0.08067357922967204, Loss: 0.001224807163297803\n",
      "Iteration:940, Price of Hedge: 0.09103534159885526, Loss: 0.0009238891286055372\n",
      "Iteration:950, Price of Hedge: 0.09593808123734816, Loss: 0.0012728986639581885\n",
      "Iteration:960, Price of Hedge: 0.09683392887933735, Loss: 0.0010947446485447432\n",
      "Iteration:970, Price of Hedge: 0.09559939754173427, Loss: 0.0009603060555637977\n",
      "Iteration:980, Price of Hedge: 0.09333569702012454, Loss: 0.0010142637757015514\n",
      "Iteration:990, Price of Hedge: 0.08895358008695098, Loss: 0.0009902319367108613\n",
      "tf.Tensor(0.080270864, shape=(), dtype=float32)\n",
      "WARNING:tensorflow:Layer concatenate_139 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:10, Price of Hedge: 0.07660856980052984, Loss: 0.0016347072976215847\n",
      "Iteration:20, Price of Hedge: 0.0891183661190638, Loss: 0.0014024870832208601\n",
      "Iteration:30, Price of Hedge: 0.08279797218947493, Loss: 0.001249675902553249\n",
      "Iteration:40, Price of Hedge: 0.08381391908926332, Loss: 0.0012650668758041883\n",
      "Iteration:50, Price of Hedge: 0.08113948478891046, Loss: 0.00134481007767131\n",
      "Iteration:60, Price of Hedge: 0.08294552000004245, Loss: 0.0014700451356275178\n",
      "Iteration:70, Price of Hedge: 0.09253985000619877, Loss: 0.0014565714113473848\n",
      "Iteration:80, Price of Hedge: 0.07322808351886678, Loss: 0.001196309192354894\n",
      "Iteration:90, Price of Hedge: 0.07135760861527131, Loss: 0.0013144596786799577\n",
      "Iteration:100, Price of Hedge: 0.08495567659168159, Loss: 0.0013160841975493164\n",
      "Iteration:110, Price of Hedge: 0.0930784591855371, Loss: 0.0013856673858044122\n",
      "Iteration:120, Price of Hedge: 0.08325346851493406, Loss: 0.0012587555674592242\n",
      "Iteration:130, Price of Hedge: 0.06450458679035832, Loss: 0.0013161735853052692\n",
      "Iteration:140, Price of Hedge: 0.08614074749362004, Loss: 0.0014160094971892522\n",
      "Iteration:150, Price of Hedge: 0.0880925593354135, Loss: 0.0013368163852043758\n",
      "Iteration:160, Price of Hedge: 0.09257084091877914, Loss: 0.0012551726575724452\n",
      "Iteration:170, Price of Hedge: 0.08260632484071237, Loss: 0.0011200581806818377\n",
      "Iteration:180, Price of Hedge: 0.07725082615479692, Loss: 0.0011689689704431404\n",
      "Iteration:190, Price of Hedge: 0.0732428307226833, Loss: 0.0011123705376839598\n",
      "Iteration:200, Price of Hedge: 0.08454183614444019, Loss: 0.0011997837713851212\n",
      "Iteration:210, Price of Hedge: 0.0919297779798498, Loss: 0.0014265131504855866\n",
      "Iteration:220, Price of Hedge: 0.08665786572532852, Loss: 0.0013963147402779486\n",
      "Iteration:230, Price of Hedge: 0.07617524163854696, Loss: 0.0013815089312439576\n",
      "Iteration:240, Price of Hedge: 0.07319978726234666, Loss: 0.0011325934075209541\n",
      "Iteration:250, Price of Hedge: 0.08243486136563831, Loss: 0.0013529304521235018\n",
      "Iteration:260, Price of Hedge: 0.08326340417119837, Loss: 0.0012151008961423181\n",
      "Iteration:270, Price of Hedge: 0.08618885349759182, Loss: 0.0012421766546105494\n",
      "Iteration:280, Price of Hedge: 0.08517790757636164, Loss: 0.0012023085315118643\n",
      "Iteration:290, Price of Hedge: 0.07680235771966011, Loss: 0.0011874333137733338\n",
      "Iteration:300, Price of Hedge: 0.07519977140896401, Loss: 0.0012157162509258467\n",
      "Iteration:310, Price of Hedge: 0.07401099713085842, Loss: 0.001324787072344935\n",
      "Iteration:320, Price of Hedge: 0.07077645796776223, Loss: 0.0013592423524403595\n",
      "Iteration:330, Price of Hedge: 0.08034928281896327, Loss: 0.0012671445491581944\n",
      "Iteration:340, Price of Hedge: 0.08678637571979379, Loss: 0.0010116306847182566\n",
      "Iteration:350, Price of Hedge: 0.0789079543878934, Loss: 0.0010868174789193663\n",
      "Iteration:360, Price of Hedge: 0.08495167012590485, Loss: 0.001278723223413536\n",
      "Iteration:370, Price of Hedge: 0.09125632233889576, Loss: 0.0011256470613269954\n",
      "Iteration:380, Price of Hedge: 0.08337535789573991, Loss: 0.000984209510650036\n",
      "Iteration:390, Price of Hedge: 0.07061337207892819, Loss: 0.0008885352351754361\n",
      "Iteration:400, Price of Hedge: 0.07343800622393246, Loss: 0.0007796070049862491\n",
      "Iteration:410, Price of Hedge: 0.0752489429623445, Loss: 0.0008088740214155953\n",
      "Iteration:420, Price of Hedge: 0.07616886728519531, Loss: 0.000932187094625847\n",
      "Iteration:430, Price of Hedge: 0.08101268914504942, Loss: 0.0012091071807183384\n",
      "Iteration:440, Price of Hedge: 0.08332179627879555, Loss: 0.0011021679020955853\n",
      "Iteration:450, Price of Hedge: 0.08175940722757104, Loss: 0.0010963602138392091\n",
      "Iteration:460, Price of Hedge: 0.08685582112659063, Loss: 0.0011336048654978725\n",
      "Iteration:470, Price of Hedge: 0.08405101093636347, Loss: 0.0007657689220055275\n",
      "Iteration:480, Price of Hedge: 0.08640864082229456, Loss: 0.0009183230388782881\n",
      "Iteration:490, Price of Hedge: 0.08447114049300382, Loss: 0.0007410202790480213\n",
      "Iteration:500, Price of Hedge: 0.08607564952841074, Loss: 0.0007437686565576196\n",
      "Iteration:510, Price of Hedge: 0.08954333563790726, Loss: 0.0009457596042157456\n",
      "Iteration:520, Price of Hedge: 0.08356179589183767, Loss: 0.000923986581978542\n",
      "Iteration:530, Price of Hedge: 0.0803383431783672, Loss: 0.0008425067565646871\n",
      "Iteration:540, Price of Hedge: 0.08115648622169828, Loss: 0.0007304386334546886\n",
      "Iteration:550, Price of Hedge: 0.08196639848781899, Loss: 0.000782411989808185\n",
      "Iteration:560, Price of Hedge: 0.08008177782385104, Loss: 0.0007662427215099687\n",
      "Iteration:570, Price of Hedge: 0.0824827779386041, Loss: 0.0008150764809286004\n",
      "Iteration:580, Price of Hedge: 0.08447719281364527, Loss: 0.0010788441354862787\n",
      "Iteration:590, Price of Hedge: 0.07224635259453578, Loss: 0.0008284207113569808\n",
      "Iteration:600, Price of Hedge: 0.08032141751798179, Loss: 0.0007432793917874547\n",
      "Iteration:610, Price of Hedge: 0.08198654447530629, Loss: 0.0007933388290120468\n",
      "Iteration:620, Price of Hedge: 0.07503890659867522, Loss: 0.0008796011213588306\n",
      "Iteration:630, Price of Hedge: 0.08053735939326287, Loss: 0.0007155227176484646\n",
      "Iteration:640, Price of Hedge: 0.08096623119082977, Loss: 0.0008401914064953498\n",
      "Iteration:650, Price of Hedge: 0.08441706741234327, Loss: 0.0009726978032151722\n",
      "Iteration:660, Price of Hedge: 0.08226914712159612, Loss: 0.0008771554634763867\n",
      "Iteration:670, Price of Hedge: 0.08452818764045844, Loss: 0.0008456441336049502\n",
      "Iteration:680, Price of Hedge: 0.07376432954640534, Loss: 0.0008871664481641672\n",
      "Iteration:690, Price of Hedge: 0.07474343685130336, Loss: 0.0009089778745779764\n",
      "Iteration:700, Price of Hedge: 0.0772125184696101, Loss: 0.0008893466066522748\n",
      "Iteration:710, Price of Hedge: 0.0831272790502922, Loss: 0.0007373081712954366\n",
      "Iteration:720, Price of Hedge: 0.08492419315848565, Loss: 0.0006673369454640032\n",
      "Iteration:730, Price of Hedge: 0.08010561771595519, Loss: 0.0008479850864586913\n",
      "Iteration:740, Price of Hedge: 0.08100512137636003, Loss: 0.0008625178484567009\n",
      "Iteration:750, Price of Hedge: 0.0852014917366077, Loss: 0.0008207456477618446\n",
      "Iteration:760, Price of Hedge: 0.08300475507561629, Loss: 0.0008353049744985852\n",
      "Iteration:770, Price of Hedge: 0.08544966529755839, Loss: 0.0008036257465987906\n",
      "Iteration:780, Price of Hedge: 0.08356477943018205, Loss: 0.0006615095741421606\n",
      "Iteration:790, Price of Hedge: 0.08018321812755999, Loss: 0.0007121475158998969\n",
      "Iteration:800, Price of Hedge: 0.07563470973449782, Loss: 0.0006941556401373839\n",
      "Iteration:810, Price of Hedge: 0.07716530752714164, Loss: 0.0009440617548280516\n",
      "Iteration:820, Price of Hedge: 0.07699373986501427, Loss: 0.0007437891535844399\n",
      "Iteration:830, Price of Hedge: 0.07895161823477466, Loss: 0.0007176816391448848\n",
      "Iteration:840, Price of Hedge: 0.07748886042115188, Loss: 0.0008469986392942829\n",
      "Iteration:850, Price of Hedge: 0.0795960767244864, Loss: 0.0009434169494428102\n",
      "Iteration:860, Price of Hedge: 0.08421280395858162, Loss: 0.0007418794522552785\n",
      "Iteration:870, Price of Hedge: 0.07993526241226619, Loss: 0.00070519436202916\n",
      "Iteration:880, Price of Hedge: 0.08207534973091554, Loss: 0.0006805044722821063\n",
      "Iteration:890, Price of Hedge: 0.07574877087898102, Loss: 0.0007806183889666807\n",
      "Iteration:900, Price of Hedge: 0.08002716486482342, Loss: 0.000775299003526142\n",
      "Iteration:910, Price of Hedge: 0.08340037226008121, Loss: 0.0006949513243590388\n",
      "Iteration:920, Price of Hedge: 0.0807698101807162, Loss: 0.0006820237681473551\n",
      "Iteration:930, Price of Hedge: 0.07576871796391202, Loss: 0.0008932664965395576\n",
      "Iteration:940, Price of Hedge: 0.08183001763505472, Loss: 0.0009481535385539752\n",
      "Iteration:950, Price of Hedge: 0.07663873195245897, Loss: 0.0007199406038913447\n",
      "Iteration:960, Price of Hedge: 0.07828549830952766, Loss: 0.0007515741759588357\n",
      "Iteration:970, Price of Hedge: 0.07766049911990648, Loss: 0.0008282258046109714\n",
      "Iteration:980, Price of Hedge: 0.08684605595823171, Loss: 0.0007710043954301304\n",
      "Iteration:990, Price of Hedge: 0.08619597610341713, Loss: 0.001055428983215878\n"
     ]
    }
   ],
   "source": [
    "# Create Lists to collect the hedging errors\n",
    "derivative_payoff = []\n",
    "error_fix = []\n",
    "error_robust = []\n",
    "error_robust_a_0_fix = []\n",
    "error_robust_a_1_fix = []\n",
    "error_robust_b_0_fix = []\n",
    "error_robust_b_1_fix = []\n",
    "error_robust_gamma_fix = []\n",
    "epochs = 1000 # Number of epochs for training\n",
    "\n",
    "for j in range(len(stocks)):\n",
    "    print(\"\\n\\n ############\\n \\n ##### Calculations for Stock: {} \\n\".format(str(j+1)))\n",
    "    # Load Parameters from the List\n",
    "    list_a0 = list_parameters[j]['a0']\n",
    "    list_a1 = list_parameters[j]['a1']\n",
    "    list_b0 = list_parameters[j]['b0']\n",
    "    list_b1 = list_parameters[j]['b1']\n",
    "    list_gamma = list_parameters[j]['gamma']\n",
    "    \n",
    "    x_0 = stocks[j].iloc[start_index][\"CLOSE\"].astype('float32')\n",
    "    T = (30/250)\n",
    "    n = 30\n",
    "    def derivative(path):\n",
    "        return tf.nn.relu(10-tf.math.reduce_mean(path))\n",
    "    \n",
    "    #######################################################\n",
    "    #ROBUST\n",
    "    # Assign the intervals\n",
    "    a_0=[np.min(list_a0).astype('float32'),np.max(list_a0).astype('float32')]\n",
    "    a_1=[np.min(list_a1).astype('float32'),np.max(list_a1).astype('float32')]\n",
    "    b_0=[np.min(list_b0).astype('float32'),np.max(list_b0).astype('float32')]\n",
    "    b_1=[np.min(list_b1).astype('float32'),np.max(list_b1).astype('float32')]\n",
    "    gamma=[np.min(list_gamma).astype('float32'),np.max(list_gamma).astype('float32')]\n",
    "    # Assign the closing data of the beginning of the test period\n",
    "    price_robust, hedge_robust = optimal_hedge(derivative,a_0,a_1,b_0,b_1,gamma,x_0,T,n,\n",
    "                                 depth = 4,nr_neurons = 256,EPOCHS = epochs,l_r = 0.005,BATCH_SIZE =256,scaling_factor=x_0/10.)\n",
    "    #######################################################\n",
    "    # NON ROBUST\n",
    "    a_0_fix=[list_a0[len(list_a0)-1],list_a0[len(list_a0)-1]]\n",
    "    a_1_fix=[list_a1[len(list_a1)-1],list_a1[len(list_a1)-1]]\n",
    "    b_0_fix=[list_b0[len(list_b0)-1],list_b0[len(list_b0)-1]]\n",
    "    b_1_fix=[list_b1[len(list_b1)-1],list_b1[len(list_b1)-1]]  \n",
    "    gamma_fix=[list_gamma[len(list_gamma)-1],list_gamma[len(list_gamma)-1]]\n",
    "    price_fix, hedge_fix = optimal_hedge(derivative,a_0_fix,a_1_fix,b_0_fix,b_1_fix,gamma_fix,x_0,T,n,\n",
    "                             depth = 4,nr_neurons = 256,EPOCHS = epochs,l_r = 0.005,BATCH_SIZE =256,scaling_factor=x_0/10.)\n",
    "    \n",
    "    #######################################################\n",
    "    # a_0 fix, rest robust:\n",
    "    a_0_a_0_fix=[list_a0[len(list_a0)-1],list_a0[len(list_a0)-1]]\n",
    "    a_1_a_0_fix=[np.min(list_a1).astype('float32'),np.max(list_a1).astype('float32')]\n",
    "    b_0_a_0_fix=[np.min(list_b0).astype('float32'),np.max(list_b0).astype('float32')]\n",
    "    b_1_a_0_fix=[np.min(list_b1).astype('float32'),np.max(list_b1).astype('float32')]\n",
    "    gamma_a_0_fix=[np.min(list_gamma).astype('float32'),np.max(list_gamma).astype('float32')]\n",
    "    # Assign the closing data of the beginning of the test period\n",
    "    price_robust_a_0_fix, hedge_robust_a_0_fix = optimal_hedge(derivative,a_0_a_0_fix,a_1_a_0_fix\n",
    "                                                               ,b_0_a_0_fix,b_1_a_0_fix,gamma_a_0_fix,x_0,T,n,\n",
    "                                 depth = 4,nr_neurons = 256,EPOCHS = epochs,l_r = 0.005,BATCH_SIZE =256,scaling_factor=x_0/10.)\n",
    "       \n",
    "    #######################################################\n",
    "    # a_1 fix, rest robust:\n",
    "    a_0_a_1_fix=[np.min(list_a0).astype('float32'),np.max(list_a0).astype('float32')]\n",
    "    a_1_a_1_fix=[list_a1[len(list_a1)-1],list_a1[len(list_a1)-1]]\n",
    "    b_0_a_1_fix=[np.min(list_b0).astype('float32'),np.max(list_b0).astype('float32')]\n",
    "    b_1_a_1_fix=[np.min(list_b1).astype('float32'),np.max(list_b1).astype('float32')]\n",
    "    gamma_a_1_fix=[np.min(list_gamma).astype('float32'),np.max(list_gamma).astype('float32')]\n",
    "    # Assign the closing data of the beginning of the test period\n",
    "    price_robust_a_1_fix, hedge_robust_a_1_fix = optimal_hedge(derivative,a_0_a_1_fix,a_1_a_1_fix\n",
    "                                                               ,b_0_a_1_fix,b_1_a_1_fix,gamma_a_1_fix,x_0,T,n,\n",
    "                                 depth = 4,nr_neurons = 256,EPOCHS = epochs,l_r = 0.005,BATCH_SIZE =256,scaling_factor=x_0/10.)\n",
    "    \n",
    "    #######################################################\n",
    "    # b_0 fix, rest robust:\n",
    "    a_0_b_0_fix=[np.min(list_a0).astype('float32'),np.max(list_a0).astype('float32')]\n",
    "    a_1_b_0_fix=[np.min(list_a1).astype('float32'),np.max(list_a1).astype('float32')]\n",
    "    b_0_b_0_fix=[list_b0[len(list_b0)-1],list_b0[len(list_b0)-1]]\n",
    "    b_1_b_0_fix=[np.min(list_b1).astype('float32'),np.max(list_b1).astype('float32')]\n",
    "    gamma_b_0_fix=[np.min(list_gamma).astype('float32'),np.max(list_gamma).astype('float32')]\n",
    "    # Assign the closing data of the beginning of the test period\n",
    "    price_robust_b_0_fix, hedge_robust_b_0_fix = optimal_hedge(derivative,a_0_b_0_fix,a_1_b_0_fix\n",
    "                                                               ,b_0_b_0_fix,b_1_b_0_fix,gamma_b_0_fix,x_0,T,n,\n",
    "                                 depth = 4,nr_neurons = 256,EPOCHS = epochs,l_r = 0.005,BATCH_SIZE =256,scaling_factor=x_0/10.)\n",
    "    #######################################################\n",
    "    # b_1 fix, rest robust:\n",
    "    a_0_b_1_fix=[np.min(list_a0).astype('float32'),np.max(list_a0).astype('float32')]\n",
    "    a_1_b_1_fix=[np.min(list_a1).astype('float32'),np.max(list_a1).astype('float32')]\n",
    "    b_0_b_1_fix=[np.min(list_b0).astype('float32'),np.max(list_b0).astype('float32')]\n",
    "    b_1_b_1_fix=[list_b1[len(list_b1)-1],list_b1[len(list_b1)-1]]  \n",
    "    gamma_b_1_fix=[np.min(list_gamma).astype('float32'),np.max(list_gamma).astype('float32')]\n",
    "    # Assign the closing data of the beginning of the test period\n",
    "    price_robust_b_1_fix, hedge_robust_b_1_fix = optimal_hedge(derivative,a_0_b_1_fix,a_1_b_1_fix\n",
    "                                                               ,b_0_b_1_fix,b_1_b_1_fix,gamma_b_1_fix,x_0,T,n,\n",
    "                                 depth = 4,nr_neurons = 256,EPOCHS = epochs,l_r = 0.005,BATCH_SIZE =256,scaling_factor=x_0/10.)\n",
    "    #######################################################\n",
    "    # gamma fix, rest robust:\n",
    "    a_0_gamma_fix=[np.min(list_a0).astype('float32'),np.max(list_a0).astype('float32')]\n",
    "    a_1_gamma_fix=[np.min(list_a1).astype('float32'),np.max(list_a1).astype('float32')]\n",
    "    b_0_gamma_fix=[np.min(list_b0).astype('float32'),np.max(list_b0).astype('float32')]\n",
    "    b_1_gamma_fix=[np.min(list_b1).astype('float32'),np.max(list_b1).astype('float32')]\n",
    "    gamma_gamma_fix=[list_gamma[len(list_gamma)-1],list_gamma[len(list_gamma)-1]]\n",
    "    # Assign the closing data of the beginning of the test period\n",
    "    price_robust_gamma_fix, hedge_robust_gamma_fix = optimal_hedge(derivative,a_0_gamma_fix,a_1_gamma_fix\n",
    "                                                               ,b_0_gamma_fix,b_1_gamma_fix,gamma_gamma_fix,x_0,T,n,\n",
    "                                 depth = 4,nr_neurons = 256,EPOCHS = epochs,l_r = 0.005,BATCH_SIZE =256,scaling_factor=x_0/10.)\n",
    "    \n",
    "    ####################################################\n",
    "    #Evaluate\n",
    "    t_k = np.linspace(0,T,n+1)\n",
    "    test_period= np.array(stocks[j].iloc[start_index:end_index][\"CLOSE\"])/(x_0/10) #Normalize the values of the test period\n",
    "    \n",
    "    # Fix Parameters\n",
    "    hedge_evaluated_fix = [hedge_fix([tf.reshape(test_period[i],(1,1)),tf.reshape(t_k[i],(1,1))]) for i in range(n-1)]\n",
    "    delta_S_fix = tf.reduce_sum([hedge_evaluated_fix[i]*np.reshape(np.diff(test_period)[i],(1,1)) for i in range(n-1)],0)\n",
    "    \n",
    "    # Robust Parameters\n",
    "    hedge_evaluated_robust = [hedge_robust([tf.reshape(test_period[i],(1,1)),tf.reshape(t_k[i],(1,1))]) for i in range(n-1)]\n",
    "    delta_S_robust = tf.reduce_sum([hedge_evaluated_robust[i]*np.reshape(np.diff(test_period)[i],(1,1)) for i in range(n-1)],0)\n",
    "    \n",
    "    # a_0 fix, rest robust:\n",
    "    hedge_evaluated_a_0_fix = [hedge_robust_a_0_fix([tf.reshape(test_period[i],(1,1)),tf.reshape(t_k[i],(1,1))]) for i in range(n-1)]\n",
    "    delta_S_robust_a_0_fix = tf.reduce_sum([hedge_evaluated_a_0_fix[i]*np.reshape(np.diff(test_period)[i],(1,1)) for i in range(n-1)],0)\n",
    "\n",
    "    # a_1 fix, rest robust:\n",
    "    hedge_evaluated_a_1_fix = [hedge_robust_a_1_fix([tf.reshape(test_period[i],(1,1)),tf.reshape(t_k[i],(1,1))]) for i in range(n-1)]\n",
    "    delta_S_robust_a_1_fix = tf.reduce_sum([hedge_evaluated_a_1_fix[i]*np.reshape(np.diff(test_period)[i],(1,1)) for i in range(n-1)],0)\n",
    "        \n",
    "    # b_0 fix, rest robust:\n",
    "    hedge_evaluated_b_0_fix = [hedge_robust_b_0_fix([tf.reshape(test_period[i],(1,1)),tf.reshape(t_k[i],(1,1))]) for i in range(n-1)]\n",
    "    delta_S_robust_b_0_fix = tf.reduce_sum([hedge_evaluated_b_0_fix[i]*np.reshape(np.diff(test_period)[i],(1,1)) for i in range(n-1)],0)\n",
    "        \n",
    "    # b_1 fix, rest robust:\n",
    "    hedge_evaluated_b_1_fix = [hedge_robust_b_1_fix([tf.reshape(test_period[i],(1,1)),tf.reshape(t_k[i],(1,1))]) for i in range(n-1)]\n",
    "    delta_S_robust_b_1_fix = tf.reduce_sum([hedge_evaluated_b_1_fix[i]*np.reshape(np.diff(test_period)[i],(1,1)) for i in range(n-1)],0)\n",
    "        \n",
    "    # gamma fix, rest robust:\n",
    "    hedge_evaluated_gamma_fix = [hedge_robust_gamma_fix([tf.reshape(test_period[i],(1,1)),tf.reshape(t_k[i],(1,1))]) for i in range(n-1)]\n",
    "    delta_S_robust_gamma_fix = tf.reduce_sum([hedge_evaluated_gamma_fix[i]*np.reshape(np.diff(test_period)[i],(1,1)) for i in range(n-1)],0) \n",
    "  \n",
    "    #########################################################\n",
    "    # Derivative\n",
    "    derivative_on_batch = derivative(test_period)\n",
    "    derivative_payoff+= [derivative(test_period)]\n",
    "    # Compute Hedging Error (Relative), Percentage Values:\n",
    "    error_fix += [10*(delta_S_fix.numpy()+price_fix - derivative_on_batch.numpy())]\n",
    "    error_robust += [10*(delta_S_robust.numpy()+price_robust - derivative_on_batch.numpy())]\n",
    "    error_robust_a_0_fix += [10*(delta_S_robust_a_0_fix.numpy()+price_robust_a_0_fix - derivative_on_batch.numpy())]\n",
    "    error_robust_a_1_fix += [10*(delta_S_robust_a_1_fix.numpy()+price_robust_a_1_fix - derivative_on_batch.numpy())]\n",
    "    error_robust_b_0_fix += [10*(delta_S_robust_b_0_fix.numpy()+price_robust_b_0_fix - derivative_on_batch.numpy())]\n",
    "    error_robust_b_1_fix += [10*(delta_S_robust_b_1_fix.numpy()+price_robust_b_1_fix - derivative_on_batch.numpy())]\n",
    "    error_robust_gamma_fix += [10*(delta_S_robust_gamma_fix.numpy()+price_robust_gamma_fix - derivative_on_batch.numpy())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the errors to lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_fix = [e[0][0] for e in error_fix]\n",
    "error_robust = [e[0][0] for e in error_robust]\n",
    "error_robust_a_0_fix = [e[0][0] for e in error_robust_a_0_fix]\n",
    "error_robust_a_1_fix = [e[0][0] for e in error_robust_a_1_fix]\n",
    "error_robust_b_0_fix = [e[0][0] for e in error_robust_b_0_fix]\n",
    "error_robust_b_1_fix = [e[0][0] for e in error_robust_b_1_fix]\n",
    "error_robust_gamma_fix = [e[0][0] for e in error_robust_gamma_fix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all Computed Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_computations= pd.DataFrame({'error_fix': error_fix,\n",
    "                   'error_robust': error_robust,\n",
    "                   'error_robust_a_0_fix': error_robust_a_0_fix,\n",
    "                   'error_robust_a_1_fix': error_robust_a_1_fix,\n",
    "                    'error_robust_b_0_fix': error_robust_b_0_fix,\n",
    "                    'error_robust_b_1_fix': error_robust_b_1_fix,\n",
    "                    'error_robust_gamma_fix':error_robust_gamma_fix})\n",
    "list_computations.to_csv('csv/sp500_results_asian_atm.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the computed absolute Hedging Errors (in %)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error_fix</th>\n",
       "      <th>error_robust</th>\n",
       "      <th>error_robust_a_0_fix</th>\n",
       "      <th>error_robust_a_1_fix</th>\n",
       "      <th>error_robust_b_0_fix</th>\n",
       "      <th>error_robust_b_1_fix</th>\n",
       "      <th>error_robust_gamma_fix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.132842</td>\n",
       "      <td>1.665683</td>\n",
       "      <td>1.742616</td>\n",
       "      <td>1.709083</td>\n",
       "      <td>1.663152</td>\n",
       "      <td>1.581958</td>\n",
       "      <td>1.574225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.372283</td>\n",
       "      <td>1.551203</td>\n",
       "      <td>2.283776</td>\n",
       "      <td>1.638364</td>\n",
       "      <td>1.346073</td>\n",
       "      <td>1.230587</td>\n",
       "      <td>2.363789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.097453</td>\n",
       "      <td>0.149301</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.353197</td>\n",
       "      <td>0.116044</td>\n",
       "      <td>0.026064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.597618</td>\n",
       "      <td>0.737359</td>\n",
       "      <td>0.572661</td>\n",
       "      <td>0.861445</td>\n",
       "      <td>0.814505</td>\n",
       "      <td>0.834941</td>\n",
       "      <td>0.288040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.440880</td>\n",
       "      <td>1.237834</td>\n",
       "      <td>0.879888</td>\n",
       "      <td>1.225167</td>\n",
       "      <td>1.325731</td>\n",
       "      <td>1.209334</td>\n",
       "      <td>0.646026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.577708</td>\n",
       "      <td>1.995292</td>\n",
       "      <td>1.938697</td>\n",
       "      <td>1.774768</td>\n",
       "      <td>1.933137</td>\n",
       "      <td>1.815018</td>\n",
       "      <td>1.574852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.653414</td>\n",
       "      <td>6.422673</td>\n",
       "      <td>9.922445</td>\n",
       "      <td>6.579260</td>\n",
       "      <td>5.829702</td>\n",
       "      <td>4.986020</td>\n",
       "      <td>9.305378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       error_fix  error_robust  error_robust_a_0_fix  error_robust_a_1_fix  \\\n",
       "count  20.000000     20.000000             20.000000             20.000000   \n",
       "mean    2.132842      1.665683              1.742616              1.709083   \n",
       "std     2.372283      1.551203              2.283776              1.638364   \n",
       "min     0.097453      0.149301              0.008348              0.119420   \n",
       "25%     0.597618      0.737359              0.572661              0.861445   \n",
       "50%     1.440880      1.237834              0.879888              1.225167   \n",
       "75%     2.577708      1.995292              1.938697              1.774768   \n",
       "max     8.653414      6.422673              9.922445              6.579260   \n",
       "\n",
       "       error_robust_b_0_fix  error_robust_b_1_fix  error_robust_gamma_fix  \n",
       "count             20.000000             20.000000               20.000000  \n",
       "mean               1.663152              1.581958                1.574225  \n",
       "std                1.346073              1.230587                2.363789  \n",
       "min                0.353197              0.116044                0.026064  \n",
       "25%                0.814505              0.834941                0.288040  \n",
       "50%                1.325731              1.209334                0.646026  \n",
       "75%                1.933137              1.815018                1.574852  \n",
       "max                5.829702              4.986020                9.305378  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(list_computations).describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
